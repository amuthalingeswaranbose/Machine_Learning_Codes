{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c05ed729",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d9c94adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Multivariate_Logistic_Regression import Multivariate_Logistic_Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a506b1",
   "metadata": {},
   "source": [
    "# random value generating method (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31019cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_value_gen(starting_value, ending_value, Number_of_values):\n",
    "    generated_random_values = []\n",
    "    for i in range(Number_of_values):\n",
    "        random_value_i = random.uniform(starting_value, ending_value) # for radom float value \n",
    "        random_value_j = random.uniform(starting_value, ending_value) \n",
    "        generated_random_values.append([random_value_i, random_value_j])\n",
    "    return generated_random_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4704e435",
   "metadata": {},
   "source": [
    "# initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1ef69174",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_min, pos_max = 2,5\n",
    "neg_min, neg_max = -10,-2\n",
    "\n",
    "training_sample_count = 50\n",
    "testing_sample_count = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e3efc4",
   "metadata": {},
   "source": [
    "# prepare x_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8458d6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train1 = np.array(random_value_gen(pos_min, pos_max, training_sample_count))\n",
    "x_train1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beb2087",
   "metadata": {},
   "source": [
    "# prepare x_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5eef3604",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test1 = np.array(random_value_gen(pos_min, pos_max, testing_sample_count))\n",
    "x_test1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b681ff5",
   "metadata": {},
   "source": [
    "# prepare x_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3c28b5cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train2 = np.array(random_value_gen(neg_min, neg_max, training_sample_count))\n",
    "x_train2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1027152f",
   "metadata": {},
   "source": [
    "# prepare x_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dd5b16d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test2 = np.array(random_value_gen(neg_min, neg_max, testing_sample_count))\n",
    "x_test2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461176d8",
   "metadata": {},
   "source": [
    "# concatenate x_train1 and x_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "03ce4ad8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = np.concatenate((x_train1, x_train2))\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68218d60",
   "metadata": {},
   "source": [
    "# concatenate x_test1 and x_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1415c071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 2)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = np.concatenate((x_test1, x_test2))\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d8fa26",
   "metadata": {},
   "source": [
    "# plot x_train1 and x_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "01db59a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x11,x12 = list(zip(*x_train1))\n",
    "x21,x22 = list(zip(*x_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3336e839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x20bb1a6f2b0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x11,x12)\n",
    "plt.scatter(x21,x22)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78e0987",
   "metadata": {},
   "source": [
    "# prepare y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e821022d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = np.array([1]*len(x_train1) + [0]*len(x_train2))\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0a0b952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5e8176",
   "metadata": {},
   "source": [
    "# prepare y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f186fbc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test= np.array([1]*len(x_test1) + [0]*len(x_test2))\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9c4829ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c14e632",
   "metadata": {},
   "source": [
    "# create an Multivariate_Logistic_Regression object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3d45d94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x_train row and column\n",
    "train_row, train_col = x_train.shape\n",
    "train_row, train_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3955d0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Multivariate_Logistic_Regression.Multivariate_Logistic_Regression at 0x20bb2efbb20>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr = Multivariate_Logistic_Regression(slope_count=train_col, intercept=1, learning_rate=0.0001, epochs=10000)\n",
    "mlr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4735da5f",
   "metadata": {},
   "source": [
    "# fit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "66f0730c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 0 -> loss: 0.00043369465519651487, self.slope: [1.00001359 1.00001364], self.intercept: 1.0000011381172198\n",
      "iteration - 1 -> loss: 0.00043365746633545007, self.slope: [1.00002718 1.00002727], self.intercept: 1.0000022761576823\n",
      "iteration - 2 -> loss: 0.00043362028407917654, self.slope: [1.00004077 1.0000409 ], self.intercept: 1.000003414121397\n",
      "iteration - 3 -> loss: 0.00043358310842592056, self.slope: [1.00005435 1.00005454], self.intercept: 1.0000045520083751\n",
      "iteration - 4 -> loss: 0.0004335459393738896, self.slope: [1.00006794 1.00006817], self.intercept: 1.0000056898186285\n",
      "iteration - 5 -> loss: 0.0004335087769213163, self.slope: [1.00008152 1.0000818 ], self.intercept: 1.0000068275521685\n",
      "iteration - 6 -> loss: 0.00043347162106638907, self.slope: [1.0000951  1.00009543], self.intercept: 1.000007965209008\n",
      "iteration - 7 -> loss: 0.00043343447180734635, self.slope: [1.00010869 1.00010905], self.intercept: 1.0000091027891558\n",
      "iteration - 8 -> loss: 0.00043339732914240205, self.slope: [1.00012227 1.00012268], self.intercept: 1.0000102402926245\n",
      "iteration - 9 -> loss: 0.0004333601930697767, self.slope: [1.00013585 1.0001363 ], self.intercept: 1.000011377719425\n",
      "iteration - 10 -> loss: 0.0004333230635876902, self.slope: [1.00014942 1.00014993], self.intercept: 1.0000125150695687\n",
      "iteration - 11 -> loss: 0.00043328594069435883, self.slope: [1.000163   1.00016355], self.intercept: 1.000013652343068\n",
      "iteration - 12 -> loss: 0.0004332488243880002, self.slope: [1.00017657 1.00017717], self.intercept: 1.0000147895399323\n",
      "iteration - 13 -> loss: 0.0004332117146668469, self.slope: [1.00019015 1.00019079], self.intercept: 1.0000159266601736\n",
      "iteration - 14 -> loss: 0.00043317461152911926, self.slope: [1.00020372 1.00020441], self.intercept: 1.0000170637038037\n",
      "iteration - 15 -> loss: 0.00043313751497303557, self.slope: [1.00021729 1.00021803], self.intercept: 1.000018200670835\n",
      "iteration - 16 -> loss: 0.00043310042499682626, self.slope: [1.00023086 1.00023165], self.intercept: 1.0000193375612767\n",
      "iteration - 17 -> loss: 0.00043306334159872443, self.slope: [1.00024443 1.00024526], self.intercept: 1.0000204743751402\n",
      "iteration - 18 -> loss: 0.0004330262647769315, self.slope: [1.000258   1.00025888], self.intercept: 1.0000216111124391\n",
      "iteration - 19 -> loss: 0.00043298919452968516, self.slope: [1.00027157 1.00027249], self.intercept: 1.0000227477731831\n",
      "iteration - 20 -> loss: 0.00043295213085521497, self.slope: [1.00028513 1.0002861 ], self.intercept: 1.0000238843573834\n",
      "iteration - 21 -> loss: 0.00043291507375174226, self.slope: [1.0002987  1.00029971], self.intercept: 1.0000250208650514\n",
      "iteration - 22 -> loss: 0.0004328780232174923, self.slope: [1.00031226 1.00031332], self.intercept: 1.0000261572961977\n",
      "iteration - 23 -> loss: 0.0004328409792507045, self.slope: [1.00032582 1.00032693], self.intercept: 1.0000272936508343\n",
      "iteration - 24 -> loss: 0.0004328039418496047, self.slope: [1.00033938 1.00034054], self.intercept: 1.000028429928974\n",
      "iteration - 25 -> loss: 0.00043276691101242144, self.slope: [1.00035294 1.00035414], self.intercept: 1.0000295661306255\n",
      "iteration - 26 -> loss: 0.000432729886737376, self.slope: [1.0003665  1.00036775], self.intercept: 1.000030702255801\n",
      "iteration - 27 -> loss: 0.00043269286902271076, self.slope: [1.00038006 1.00038135], self.intercept: 1.000031838304512\n",
      "iteration - 28 -> loss: 0.0004326558578666539, self.slope: [1.00039362 1.00039495], self.intercept: 1.000032974276771\n",
      "iteration - 29 -> loss: 0.00043261885326744526, self.slope: [1.00040717 1.00040855], self.intercept: 1.000034110172588\n",
      "iteration - 30 -> loss: 0.0004325818552233034, self.slope: [1.00042072 1.00042215], self.intercept: 1.0000352459919746\n",
      "iteration - 31 -> loss: 0.0004325448637324571, self.slope: [1.00043428 1.00043575], self.intercept: 1.000036381734943\n",
      "iteration - 32 -> loss: 0.0004325078787931679, self.slope: [1.00044783 1.00044935], self.intercept: 1.0000375174015022\n",
      "iteration - 33 -> loss: 0.0004324709004036524, self.slope: [1.00046138 1.00046295], self.intercept: 1.0000386529916638\n",
      "iteration - 34 -> loss: 0.00043243392856214544, self.slope: [1.00047493 1.00047654], self.intercept: 1.0000397885054393\n",
      "iteration - 35 -> loss: 0.00043239696326687635, self.slope: [1.00048847 1.00049014], self.intercept: 1.0000409239428418\n",
      "iteration - 36 -> loss: 0.0004323600045160928, self.slope: [1.00050202 1.00050373], self.intercept: 1.000042059303881\n",
      "iteration - 37 -> loss: 0.0004323230523080422, self.slope: [1.00051557 1.00051732], self.intercept: 1.0000431945885693\n",
      "iteration - 38 -> loss: 0.0004322861066409497, self.slope: [1.00052911 1.00053091], self.intercept: 1.0000443297969166\n",
      "iteration - 39 -> loss: 0.00043224916751304223, self.slope: [1.00054265 1.0005445 ], self.intercept: 1.000045464928935\n",
      "iteration - 40 -> loss: 0.0004322122349225889, self.slope: [1.00055619 1.00055809], self.intercept: 1.0000465999846346\n",
      "iteration - 41 -> loss: 0.00043217530886781314, self.slope: [1.00056973 1.00057168], self.intercept: 1.0000477349640278\n",
      "iteration - 42 -> loss: 0.0004321383893469273, self.slope: [1.00058327 1.00058526], self.intercept: 1.0000488698671266\n",
      "iteration - 43 -> loss: 0.00043210147635823015, self.slope: [1.00059681 1.00059885], self.intercept: 1.0000500046939413\n",
      "iteration - 44 -> loss: 0.00043206456989991455, self.slope: [1.00061035 1.00061243], self.intercept: 1.000051139444483\n",
      "iteration - 45 -> loss: 0.0004320276699702552, self.slope: [1.00062388 1.00062601], self.intercept: 1.000052274118762\n",
      "iteration - 46 -> loss: 0.000431990776567464, self.slope: [1.00063742 1.00063959], self.intercept: 1.0000534087167914\n",
      "iteration - 47 -> loss: 0.0004319538896898301, self.slope: [1.00065095 1.00065317], self.intercept: 1.0000545432385823\n",
      "iteration - 48 -> loss: 0.00043191700933553905, self.slope: [1.00066448 1.00066675], self.intercept: 1.0000556776841447\n",
      "iteration - 49 -> loss: 0.00043188013550290267, self.slope: [1.00067801 1.00068033], self.intercept: 1.0000568120534903\n",
      "iteration - 50 -> loss: 0.0004318432681901162, self.slope: [1.00069154 1.0006939 ], self.intercept: 1.0000579463466297\n",
      "iteration - 51 -> loss: 0.0004318064073954302, self.slope: [1.00070507 1.00070748], self.intercept: 1.0000590805635747\n",
      "iteration - 52 -> loss: 0.0004317695531171002, self.slope: [1.0007186  1.00072105], self.intercept: 1.0000602147043383\n",
      "iteration - 53 -> loss: 0.0004317327053533805, self.slope: [1.00073212 1.00073462], self.intercept: 1.0000613487689294\n",
      "iteration - 54 -> loss: 0.000431695864102527, self.slope: [1.00074565 1.00074819], self.intercept: 1.0000624827573599\n",
      "iteration - 55 -> loss: 0.00043165902936276925, self.slope: [1.00075917 1.00076177], self.intercept: 1.0000636166696397\n",
      "iteration - 56 -> loss: 0.0004316222011323494, self.slope: [1.00077269 1.00077533], self.intercept: 1.0000647505057816\n",
      "iteration - 57 -> loss: 0.0004315853794095561, self.slope: [1.00078621 1.0007889 ], self.intercept: 1.0000658842657963\n",
      "iteration - 58 -> loss: 0.0004315485641925804, self.slope: [1.00079973 1.00080247], self.intercept: 1.0000670179496967\n",
      "iteration - 59 -> loss: 0.000431511755479745, self.slope: [1.00081325 1.00081603], self.intercept: 1.0000681515574903\n",
      "iteration - 60 -> loss: 0.00043147495326926013, self.slope: [1.00082677 1.0008296 ], self.intercept: 1.0000692850891917\n",
      "iteration - 61 -> loss: 0.00043143815755935784, self.slope: [1.00084028 1.00084316], self.intercept: 1.0000704185448122\n",
      "iteration - 62 -> loss: 0.0004314013683483519, self.slope: [1.0008538  1.00085672], self.intercept: 1.0000715519243597\n",
      "iteration - 63 -> loss: 0.00043136458563443314, self.slope: [1.00086731 1.00087028], self.intercept: 1.000072685227848\n",
      "iteration - 64 -> loss: 0.0004313278094159069, self.slope: [1.00088082 1.00088384], self.intercept: 1.000073818455288\n",
      "iteration - 65 -> loss: 0.0004312910396909886, self.slope: [1.00089434 1.0008974 ], self.intercept: 1.0000749516066902\n",
      "iteration - 66 -> loss: 0.0004312542764579425, self.slope: [1.00090785 1.00091096], self.intercept: 1.000076084682067\n",
      "iteration - 67 -> loss: 0.0004312175197150593, self.slope: [1.00092135 1.00092451], self.intercept: 1.0000772176814279\n",
      "iteration - 68 -> loss: 0.00043118076946056365, self.slope: [1.00093486 1.00093807], self.intercept: 1.0000783506047861\n",
      "iteration - 69 -> loss: 0.0004311440256927067, self.slope: [1.00094837 1.00095162], self.intercept: 1.00007948345215\n",
      "iteration - 70 -> loss: 0.0004311072884097708, self.slope: [1.00096187 1.00096517], self.intercept: 1.000080616223534\n",
      "iteration - 71 -> loss: 0.00043107055760999207, self.slope: [1.00097538 1.00097873], self.intercept: 1.0000817489189475\n",
      "iteration - 72 -> loss: 0.00043103383329165176, self.slope: [1.00098888 1.00099228], self.intercept: 1.0000828815384017\n",
      "iteration - 73 -> loss: 0.00043099711545300194, self.slope: [1.00100238 1.00100582], self.intercept: 1.0000840140819078\n",
      "iteration - 74 -> loss: 0.0004309604040923077, self.slope: [1.00101588 1.00101937], self.intercept: 1.0000851465494769\n",
      "iteration - 75 -> loss: 0.00043092369920781556, self.slope: [1.00102938 1.00103292], self.intercept: 1.0000862789411207\n",
      "iteration - 76 -> loss: 0.0004308870007977932, self.slope: [1.00104288 1.00104646], self.intercept: 1.00008741125685\n",
      "iteration - 77 -> loss: 0.0004308503088605078, self.slope: [1.00105638 1.00106001], self.intercept: 1.000088543496676\n",
      "iteration - 78 -> loss: 0.00043081362339421667, self.slope: [1.00106987 1.00107355], self.intercept: 1.0000896756606081\n",
      "iteration - 79 -> loss: 0.00043077694439719647, self.slope: [1.00108337 1.00108709], self.intercept: 1.0000908077486612\n",
      "iteration - 80 -> loss: 0.00043074027186771106, self.slope: [1.00109686 1.00110063], self.intercept: 1.000091939760844\n",
      "iteration - 81 -> loss: 0.00043070360580400494, self.slope: [1.00111035 1.00111417], self.intercept: 1.0000930716971683\n",
      "iteration - 82 -> loss: 0.00043066694620436086, self.slope: [1.00112384 1.00112771], self.intercept: 1.0000942035576441\n",
      "iteration - 83 -> loss: 0.0004306302930670407, self.slope: [1.00113733 1.00114125], self.intercept: 1.0000953353422841\n",
      "iteration - 84 -> loss: 0.00043059364639030326, self.slope: [1.00115082 1.00115478], self.intercept: 1.0000964670510981\n",
      "iteration - 85 -> loss: 0.0004305570061724391, self.slope: [1.00116431 1.00116832], self.intercept: 1.0000975986840985\n",
      "iteration - 86 -> loss: 0.00043052037241170937, self.slope: [1.00117779 1.00118185], self.intercept: 1.0000987302412971\n",
      "iteration - 87 -> loss: 0.00043048374510634685, self.slope: [1.00119128 1.00119538], self.intercept: 1.0000998617227033\n",
      "iteration - 88 -> loss: 0.0004304471242546759, self.slope: [1.00120476 1.00120891], self.intercept: 1.000100993128328\n",
      "iteration - 89 -> loss: 0.000430410509854926, self.slope: [1.00121825 1.00122244], self.intercept: 1.0001021244581845\n",
      "iteration - 90 -> loss: 0.00043037390190539586, self.slope: [1.00123173 1.00123597], self.intercept: 1.000103255712281\n",
      "iteration - 91 -> loss: 0.0004303373004043353, self.slope: [1.00124521 1.0012495 ], self.intercept: 1.0001043868906305\n",
      "iteration - 92 -> loss: 0.00043030070535003256, self.slope: [1.00125869 1.00126302], self.intercept: 1.0001055179932443\n",
      "iteration - 93 -> loss: 0.00043026411674072903, self.slope: [1.00127216 1.00127655], self.intercept: 1.0001066490201334\n",
      "iteration - 94 -> loss: 0.00043022753457474985, self.slope: [1.00128564 1.00129007], self.intercept: 1.000107779971308\n",
      "iteration - 95 -> loss: 0.00043019095885033756, self.slope: [1.00129911 1.0013036 ], self.intercept: 1.0001089108467787\n",
      "iteration - 96 -> loss: 0.00043015438956574016, self.slope: [1.00131259 1.00131712], self.intercept: 1.0001100416465583\n",
      "iteration - 97 -> loss: 0.0004301178267192796, self.slope: [1.00132606 1.00133064], self.intercept: 1.0001111723706582\n",
      "iteration - 98 -> loss: 0.0004300812703092311, self.slope: [1.00133953 1.00134416], self.intercept: 1.000112303019088\n",
      "iteration - 99 -> loss: 0.0004300447203338464, self.slope: [1.001353   1.00135768], self.intercept: 1.0001134335918591\n",
      "iteration - 100 -> loss: 0.00043000817679140704, self.slope: [1.00136647 1.00137119], self.intercept: 1.000114564088983\n",
      "iteration - 101 -> loss: 0.00042997163968020184, self.slope: [1.00137994 1.00138471], self.intercept: 1.000115694510471\n",
      "iteration - 102 -> loss: 0.00042993510899847897, self.slope: [1.00139341 1.00139822], self.intercept: 1.000116824856334\n",
      "iteration - 103 -> loss: 0.0004298985847445633, self.slope: [1.00140687 1.00141174], self.intercept: 1.000117955126583\n",
      "iteration - 104 -> loss: 0.00042986206691669374, self.slope: [1.00142034 1.00142525], self.intercept: 1.0001190853212294\n",
      "iteration - 105 -> loss: 0.00042982555551316466, self.slope: [1.0014338  1.00143876], self.intercept: 1.0001202154402833\n",
      "iteration - 106 -> loss: 0.0004297890505322754, self.slope: [1.00144726 1.00145227], self.intercept: 1.0001213454837563\n",
      "iteration - 107 -> loss: 0.00042975255197229257, self.slope: [1.00146072 1.00146578], self.intercept: 1.000122475451659\n",
      "iteration - 108 -> loss: 0.00042971605983148505, self.slope: [1.00147418 1.00147928], self.intercept: 1.000123605344003\n",
      "iteration - 109 -> loss: 0.00042967957410814994, self.slope: [1.00148764 1.00149279], self.intercept: 1.0001247351608005\n",
      "iteration - 110 -> loss: 0.00042964309480056763, self.slope: [1.0015011 1.0015063], self.intercept: 1.00012586490206\n",
      "iteration - 111 -> loss: 0.00042960662190702053, self.slope: [1.00151456 1.0015198 ], self.intercept: 1.0001269945677946\n",
      "iteration - 112 -> loss: 0.0004295701554258053, self.slope: [1.00152801 1.0015333 ], self.intercept: 1.0001281241580158\n",
      "iteration - 113 -> loss: 0.0004295336953551776, self.slope: [1.00154146 1.0015468 ], self.intercept: 1.0001292536727324\n",
      "iteration - 114 -> loss: 0.00042949724169344785, self.slope: [1.00155492 1.0015603 ], self.intercept: 1.0001303831119566\n",
      "iteration - 115 -> loss: 0.00042946079443891407, self.slope: [1.00156837 1.0015738 ], self.intercept: 1.0001315124757013\n",
      "iteration - 116 -> loss: 0.0004294243535898155, self.slope: [1.00158182 1.0015873 ], self.intercept: 1.000132641763976\n",
      "iteration - 117 -> loss: 0.0004293879191444804, self.slope: [1.00159527 1.0016008 ], self.intercept: 1.0001337709767912\n",
      "iteration - 118 -> loss: 0.0004293514911011869, self.slope: [1.00160871 1.00161429], self.intercept: 1.0001349001141584\n",
      "iteration - 119 -> loss: 0.000429315069458224, self.slope: [1.00162216 1.00162779], self.intercept: 1.0001360291760881\n",
      "iteration - 120 -> loss: 0.00042927865421387573, self.slope: [1.00163561 1.00164128], self.intercept: 1.0001371581625929\n",
      "iteration - 121 -> loss: 0.00042924224536643944, self.slope: [1.00164905 1.00165477], self.intercept: 1.0001382870736824\n",
      "iteration - 122 -> loss: 0.0004292058429141978, self.slope: [1.00166249 1.00166826], self.intercept: 1.00013941590937\n",
      "iteration - 123 -> loss: 0.0004291694468554531, self.slope: [1.00167594 1.00168175], self.intercept: 1.0001405446696647\n",
      "iteration - 124 -> loss: 0.0004291330571884816, self.slope: [1.00168938 1.00169524], self.intercept: 1.0001416733545765\n",
      "iteration - 125 -> loss: 0.00042909667391160253, self.slope: [1.00170282 1.00170873], self.intercept: 1.0001428019641174\n",
      "iteration - 126 -> loss: 0.00042906029702305805, self.slope: [1.00171625 1.00172222], self.intercept: 1.0001439304983\n",
      "iteration - 127 -> loss: 0.00042902392652121153, self.slope: [1.00172969 1.0017357 ], self.intercept: 1.0001450589571328\n",
      "iteration - 128 -> loss: 0.0004289875624042911, self.slope: [1.00174313 1.00174918], self.intercept: 1.0001461873406294\n",
      "iteration - 129 -> loss: 0.00042895120467062524, self.slope: [1.00175656 1.00176267], self.intercept: 1.0001473156487979\n",
      "iteration - 130 -> loss: 0.00042891485331851705, self.slope: [1.00176999 1.00177615], self.intercept: 1.0001484438816513\n",
      "iteration - 131 -> loss: 0.00042887850834623847, self.slope: [1.00178343 1.00178963], self.intercept: 1.0001495720392006\n",
      "iteration - 132 -> loss: 0.0004288421697521112, self.slope: [1.00179686 1.00180311], self.intercept: 1.0001507001214565\n",
      "iteration - 133 -> loss: 0.00042880583753440927, self.slope: [1.00181029 1.00181659], self.intercept: 1.0001518281284292\n",
      "iteration - 134 -> loss: 0.00042876951169143517, self.slope: [1.00182372 1.00183006], self.intercept: 1.0001529560601312\n",
      "iteration - 135 -> loss: 0.0004287331922215084, self.slope: [1.00183714 1.00184354], self.intercept: 1.0001540839165728\n",
      "iteration - 136 -> loss: 0.00042869687912289796, self.slope: [1.00185057 1.00185701], self.intercept: 1.0001552116977654\n",
      "iteration - 137 -> loss: 0.00042866057239394206, self.slope: [1.001864   1.00187049], self.intercept: 1.000156339403718\n",
      "iteration - 138 -> loss: 0.0004286242720328915, self.slope: [1.00187742 1.00188396], self.intercept: 1.0001574670344453\n",
      "iteration - 139 -> loss: 0.0004285879780380762, self.slope: [1.00189084 1.00189743], self.intercept: 1.0001585945899543\n",
      "iteration - 140 -> loss: 0.00042855169040780433, self.slope: [1.00190426 1.0019109 ], self.intercept: 1.0001597220702596\n",
      "iteration - 141 -> loss: 0.00042851540914035785, self.slope: [1.00191768 1.00192437], self.intercept: 1.0001608494753698\n",
      "iteration - 142 -> loss: 0.0004284791342340609, self.slope: [1.0019311  1.00193783], self.intercept: 1.0001619768052978\n",
      "iteration - 143 -> loss: 0.0004284428656871935, self.slope: [1.00194452 1.0019513 ], self.intercept: 1.0001631040600525\n",
      "iteration - 144 -> loss: 0.0004284066034980811, self.slope: [1.00195794 1.00196477], self.intercept: 1.0001642312396453\n",
      "iteration - 145 -> loss: 0.00042837034766500797, self.slope: [1.00197135 1.00197823], self.intercept: 1.0001653583440882\n",
      "iteration - 146 -> loss: 0.0004283340981862995, self.slope: [1.00198477 1.00199169], self.intercept: 1.0001664853733925\n",
      "iteration - 147 -> loss: 0.00042829785506026343, self.slope: [1.00199818 1.00200515], self.intercept: 1.0001676123275685\n",
      "iteration - 148 -> loss: 0.0004282616182851804, self.slope: [1.00201159 1.00201861], self.intercept: 1.0001687392066263\n",
      "iteration - 149 -> loss: 0.00042822538785937956, self.slope: [1.002025   1.00203207], self.intercept: 1.0001698660105782\n",
      "iteration - 150 -> loss: 0.00042818916378114814, self.slope: [1.00203841 1.00204553], self.intercept: 1.000170992739434\n",
      "iteration - 151 -> loss: 0.0004281529460488279, self.slope: [1.00205182 1.00205899], self.intercept: 1.0001721193932056\n",
      "iteration - 152 -> loss: 0.0004281167346606876, self.slope: [1.00206523 1.00207244], self.intercept: 1.0001732459719024\n",
      "iteration - 153 -> loss: 0.00042808052961505896, self.slope: [1.00207864 1.0020859 ], self.intercept: 1.0001743724755388\n",
      "iteration - 154 -> loss: 0.0004280443309102653, self.slope: [1.00209204 1.00209935], self.intercept: 1.0001754989041227\n",
      "iteration - 155 -> loss: 0.0004280081385445948, self.slope: [1.00210544 1.0021128 ], self.intercept: 1.0001766252576663\n",
      "iteration - 156 -> loss: 0.00042797195251634436, self.slope: [1.00211885 1.00212626], self.intercept: 1.0001777515361796\n",
      "iteration - 157 -> loss: 0.0004279357728238764, self.slope: [1.00213225 1.00213971], self.intercept: 1.000178877739675\n",
      "iteration - 158 -> loss: 0.00042789959946546704, self.slope: [1.00214565 1.00215315], self.intercept: 1.000180003868162\n",
      "iteration - 159 -> loss: 0.00042786343243942976, self.slope: [1.00215905 1.0021666 ], self.intercept: 1.0001811299216512\n",
      "iteration - 160 -> loss: 0.00042782727174408837, self.slope: [1.00217245 1.00218005], self.intercept: 1.0001822559001559\n",
      "iteration - 161 -> loss: 0.0004277911173777445, self.slope: [1.00218584 1.00219349], self.intercept: 1.0001833818036856\n",
      "iteration - 162 -> loss: 0.0004277549693387243, self.slope: [1.00219924 1.00220694], self.intercept: 1.0001845076322522\n",
      "iteration - 163 -> loss: 0.0004277188276253507, self.slope: [1.00221263 1.00222038], self.intercept: 1.0001856333858645\n",
      "iteration - 164 -> loss: 0.0004276826922359358, self.slope: [1.00222602 1.00223382], self.intercept: 1.0001867590645341\n",
      "iteration - 165 -> loss: 0.0004276465631687679, self.slope: [1.00223942 1.00224726], self.intercept: 1.0001878846682726\n",
      "iteration - 166 -> loss: 0.0004276104404222211, self.slope: [1.00225281 1.0022607 ], self.intercept: 1.0001890101970914\n",
      "iteration - 167 -> loss: 0.0004275743239945422, self.slope: [1.0022662  1.00227414], self.intercept: 1.0001901356510015\n",
      "iteration - 168 -> loss: 0.00042753821388410887, self.slope: [1.00227959 1.00228758], self.intercept: 1.0001912610300132\n",
      "iteration - 169 -> loss: 0.00042750211008922773, self.slope: [1.00229297 1.00230101], self.intercept: 1.0001923863341373\n",
      "iteration - 170 -> loss: 0.00042746601260818423, self.slope: [1.00230636 1.00231445], self.intercept: 1.0001935115633853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 171 -> loss: 0.0004274299214393368, self.slope: [1.00231974 1.00232788], self.intercept: 1.0001946367177668\n",
      "iteration - 172 -> loss: 0.0004273938365809825, self.slope: [1.00233313 1.00234131], self.intercept: 1.0001957617972945\n",
      "iteration - 173 -> loss: 0.0004273577580314681, self.slope: [1.00234651 1.00235474], self.intercept: 1.0001968868019782\n",
      "iteration - 174 -> loss: 0.00042732168578909276, self.slope: [1.00235989 1.00236817], self.intercept: 1.000198011731828\n",
      "iteration - 175 -> loss: 0.0004272856198521748, self.slope: [1.00237327 1.0023816 ], self.intercept: 1.000199136586858\n",
      "iteration - 176 -> loss: 0.000427249560219072, self.slope: [1.00238665 1.00239503], self.intercept: 1.0002002613670766\n",
      "iteration - 177 -> loss: 0.00042721350688807396, self.slope: [1.00240003 1.00240846], self.intercept: 1.0002013860724952\n",
      "iteration - 178 -> loss: 0.00042717745985751594, self.slope: [1.0024134  1.00242188], self.intercept: 1.0002025107031238\n",
      "iteration - 179 -> loss: 0.0004271414191257387, self.slope: [1.00242678 1.00243531], self.intercept: 1.0002036352589745\n",
      "iteration - 180 -> loss: 0.00042710538469104497, self.slope: [1.00244015 1.00244873], self.intercept: 1.0002047597400574\n",
      "iteration - 181 -> loss: 0.000427069356551771, self.slope: [1.00245353 1.00246215], self.intercept: 1.0002058841463841\n",
      "iteration - 182 -> loss: 0.0004270333347062377, self.slope: [1.0024669  1.00247557], self.intercept: 1.0002070084779668\n",
      "iteration - 183 -> loss: 0.00042699731915277867, self.slope: [1.00248027 1.00248899], self.intercept: 1.0002081327348138\n",
      "iteration - 184 -> loss: 0.0004269613098897265, self.slope: [1.00249364 1.00250241], self.intercept: 1.0002092569169385\n",
      "iteration - 185 -> loss: 0.00042692530691540394, self.slope: [1.00250701 1.00251583], self.intercept: 1.0002103810243497\n",
      "iteration - 186 -> loss: 0.0004268893102281318, self.slope: [1.00252037 1.00252924], self.intercept: 1.0002115050570575\n",
      "iteration - 187 -> loss: 0.0004268533198262662, self.slope: [1.00253374 1.00254266], self.intercept: 1.0002126290150755\n",
      "iteration - 188 -> loss: 0.0004268173357081093, self.slope: [1.0025471  1.00255607], self.intercept: 1.0002137528984112\n",
      "iteration - 189 -> loss: 0.00042678135787199966, self.slope: [1.00256047 1.00256949], self.intercept: 1.0002148767070786\n",
      "iteration - 190 -> loss: 0.00042674538631628275, self.slope: [1.00257383 1.0025829 ], self.intercept: 1.0002160004410867\n",
      "iteration - 191 -> loss: 0.00042670942103927516, self.slope: [1.00258719 1.00259631], self.intercept: 1.0002171241004483\n",
      "iteration - 192 -> loss: 0.0004266734620393066, self.slope: [1.00260055 1.00260972], self.intercept: 1.0002182476851729\n",
      "iteration - 193 -> loss: 0.00042663750931472635, self.slope: [1.00261391 1.00262312], self.intercept: 1.000219371195272\n",
      "iteration - 194 -> loss: 0.00042660156286385695, self.slope: [1.00262727 1.00263653], self.intercept: 1.0002204946307554\n",
      "iteration - 195 -> loss: 0.00042656562268504513, self.slope: [1.00264062 1.00264994], self.intercept: 1.000221617991636\n",
      "iteration - 196 -> loss: 0.0004265296887766185, self.slope: [1.00265398 1.00266334], self.intercept: 1.000222741277923\n",
      "iteration - 197 -> loss: 0.00042649376113690276, self.slope: [1.00266733 1.00267674], self.intercept: 1.000223864489627\n",
      "iteration - 198 -> loss: 0.0004264578397642548, self.slope: [1.00268069 1.00269015], self.intercept: 1.00022498762676\n",
      "iteration - 199 -> loss: 0.00042642192465699574, self.slope: [1.00269404 1.00270355], self.intercept: 1.0002261106893326\n",
      "iteration - 200 -> loss: 0.00042638601581347467, self.slope: [1.00270739 1.00271695], self.intercept: 1.0002272336773543\n",
      "iteration - 201 -> loss: 0.00042635011323201505, self.slope: [1.00272074 1.00273035], self.intercept: 1.000228356590838\n",
      "iteration - 202 -> loss: 0.00042631421691096766, self.slope: [1.00273409 1.00274374], self.intercept: 1.000229479429793\n",
      "iteration - 203 -> loss: 0.0004262783268486753, self.slope: [1.00274743 1.00275714], self.intercept: 1.0002306021942315\n",
      "iteration - 204 -> loss: 0.00042624244304345367, self.slope: [1.00276078 1.00277054], self.intercept: 1.0002317248841628\n",
      "iteration - 205 -> loss: 0.00042620656549368307, self.slope: [1.00277413 1.00278393], self.intercept: 1.000232847499598\n",
      "iteration - 206 -> loss: 0.0004261706941976641, self.slope: [1.00278747 1.00279732], self.intercept: 1.0002339700405487\n",
      "iteration - 207 -> loss: 0.00042613482915376913, self.slope: [1.00280081 1.00281071], self.intercept: 1.0002350925070258\n",
      "iteration - 208 -> loss: 0.00042609897036031415, self.slope: [1.00281415 1.0028241 ], self.intercept: 1.0002362148990394\n",
      "iteration - 209 -> loss: 0.0004260631178156766, self.slope: [1.00282749 1.00283749], self.intercept: 1.000237337216601\n",
      "iteration - 210 -> loss: 0.00042602727151817306, self.slope: [1.00284083 1.00285088], self.intercept: 1.0002384594597216\n",
      "iteration - 211 -> loss: 0.00042599143146613704, self.slope: [1.00285417 1.00286427], self.intercept: 1.000239581628412\n",
      "iteration - 212 -> loss: 0.0004259555976579498, self.slope: [1.00286751 1.00287766], self.intercept: 1.0002407037226817\n",
      "iteration - 213 -> loss: 0.0004259197700919312, self.slope: [1.00288084 1.00289104], self.intercept: 1.0002418257425414\n",
      "iteration - 214 -> loss: 0.0004258839487664256, self.slope: [1.00289418 1.00290442], self.intercept: 1.0002429476880035\n",
      "iteration - 215 -> loss: 0.0004258481336798046, self.slope: [1.00290751 1.00291781], self.intercept: 1.0002440695590784\n",
      "iteration - 216 -> loss: 0.0004258123248303963, self.slope: [1.00292084 1.00293119], self.intercept: 1.0002451913557773\n",
      "iteration - 217 -> loss: 0.0004257765222165193, self.slope: [1.00293417 1.00294457], self.intercept: 1.000246313078111\n",
      "iteration - 218 -> loss: 0.0004257407258365925, self.slope: [1.0029475  1.00295795], self.intercept: 1.00024743472609\n",
      "iteration - 219 -> loss: 0.0004257049356889055, self.slope: [1.00296083 1.00297132], self.intercept: 1.0002485562997234\n",
      "iteration - 220 -> loss: 0.0004256691517718172, self.slope: [1.00297416 1.0029847 ], self.intercept: 1.0002496777990237\n",
      "iteration - 221 -> loss: 0.00042563337408370474, self.slope: [1.00298748 1.00299808], self.intercept: 1.0002507992240017\n",
      "iteration - 222 -> loss: 0.00042559760262288584, self.slope: [1.00300081 1.00301145], self.intercept: 1.0002519205746683\n",
      "iteration - 223 -> loss: 0.0004255618373877458, self.slope: [1.00301413 1.00302482], self.intercept: 1.0002530418510351\n",
      "iteration - 224 -> loss: 0.0004255260783765939, self.slope: [1.00302745 1.0030382 ], self.intercept: 1.0002541630531103\n",
      "iteration - 225 -> loss: 0.00042549032558781565, self.slope: [1.00304077 1.00305157], self.intercept: 1.0002552841809076\n",
      "iteration - 226 -> loss: 0.00042545457901976955, self.slope: [1.00305409 1.00306494], self.intercept: 1.0002564052344363\n",
      "iteration - 227 -> loss: 0.00042541883867077627, self.slope: [1.00306741 1.00307831], self.intercept: 1.0002575262137066\n",
      "iteration - 228 -> loss: 0.00042538310453922487, self.slope: [1.00308073 1.00309167], self.intercept: 1.0002586471187296\n",
      "iteration - 229 -> loss: 0.00042534737662344805, self.slope: [1.00309405 1.00310504], self.intercept: 1.0002597679495169\n",
      "iteration - 230 -> loss: 0.0004253116549217962, self.slope: [1.00310736 1.0031184 ], self.intercept: 1.0002608887060784\n",
      "iteration - 231 -> loss: 0.00042527593943263777, self.slope: [1.00312068 1.00313177], self.intercept: 1.0002620093884262\n",
      "iteration - 232 -> loss: 0.0004252402301543285, self.slope: [1.00313399 1.00314513], self.intercept: 1.0002631299965692\n",
      "iteration - 233 -> loss: 0.0004252045270852289, self.slope: [1.0031473  1.00315849], self.intercept: 1.0002642505305188\n",
      "iteration - 234 -> loss: 0.00042516883022369585, self.slope: [1.00316061 1.00317185], self.intercept: 1.0002653709902871\n",
      "iteration - 235 -> loss: 0.0004251331395680636, self.slope: [1.00317392 1.00318521], self.intercept: 1.0002664913758839\n",
      "iteration - 236 -> loss: 0.0004250974551167249, self.slope: [1.00318723 1.00319857], self.intercept: 1.0002676116873206\n",
      "iteration - 237 -> loss: 0.00042506177686803357, self.slope: [1.00320054 1.00321193], self.intercept: 1.0002687319246057\n",
      "iteration - 238 -> loss: 0.0004250261048203178, self.slope: [1.00321385 1.00322528], self.intercept: 1.0002698520877515\n",
      "iteration - 239 -> loss: 0.0004249904389719652, self.slope: [1.00322715 1.00323864], self.intercept: 1.0002709721767697\n",
      "iteration - 240 -> loss: 0.00042495477932132444, self.slope: [1.00324045 1.00325199], self.intercept: 1.0002720921916701\n",
      "iteration - 241 -> loss: 0.0004249191258667865, self.slope: [1.00325376 1.00326534], self.intercept: 1.000273212132464\n",
      "iteration - 242 -> loss: 0.0004248834786066678, self.slope: [1.00326706 1.0032787 ], self.intercept: 1.000274331999161\n",
      "iteration - 243 -> loss: 0.00042484783753939294, self.slope: [1.00328036 1.00329205], self.intercept: 1.0002754517917722\n",
      "iteration - 244 -> loss: 0.00042481220266325987, self.slope: [1.00329366 1.0033054 ], self.intercept: 1.00027657151031\n",
      "iteration - 245 -> loss: 0.00042477657397667416, self.slope: [1.00330696 1.00331874], self.intercept: 1.0002776911547817\n",
      "iteration - 246 -> loss: 0.00042474095147796825, self.slope: [1.00332025 1.00333209], self.intercept: 1.0002788107252012\n",
      "iteration - 247 -> loss: 0.00042470533516554895, self.slope: [1.00333355 1.00334544], self.intercept: 1.000279930221578\n",
      "iteration - 248 -> loss: 0.0004246697250377516, self.slope: [1.00334684 1.00335878], self.intercept: 1.000281049643922\n",
      "iteration - 249 -> loss: 0.0004246341210929393, self.slope: [1.00336014 1.00337212], self.intercept: 1.000282168992246\n",
      "iteration - 250 -> loss: 0.0004245985233294933, self.slope: [1.00337343 1.00338547], self.intercept: 1.0002832882665602\n",
      "iteration - 251 -> loss: 0.00042456293174579767, self.slope: [1.00338672 1.00339881], self.intercept: 1.0002844074668746\n",
      "iteration - 252 -> loss: 0.00042452734634017714, self.slope: [1.00340001 1.00341215], self.intercept: 1.0002855265931998\n",
      "iteration - 253 -> loss: 0.00042449176711102134, self.slope: [1.0034133  1.00342548], self.intercept: 1.0002866456455464\n",
      "iteration - 254 -> loss: 0.0004244561940567153, self.slope: [1.00342658 1.00343882], self.intercept: 1.0002877646239252\n",
      "iteration - 255 -> loss: 0.00042442062717562313, self.slope: [1.00343987 1.00345216], self.intercept: 1.0002888835283492\n",
      "iteration - 256 -> loss: 0.0004243850664660941, self.slope: [1.00345316 1.00346549], self.intercept: 1.000290002358826\n",
      "iteration - 257 -> loss: 0.0004243495119265121, self.slope: [1.00346644 1.00347883], self.intercept: 1.0002911211153673\n",
      "iteration - 258 -> loss: 0.0004243139635552531, self.slope: [1.00347972 1.00349216], self.intercept: 1.0002922397979863\n",
      "iteration - 259 -> loss: 0.00042427842135068334, self.slope: [1.003493   1.00350549], self.intercept: 1.0002933584066895\n",
      "iteration - 260 -> loss: 0.0004242428853111805, self.slope: [1.00350629 1.00351882], self.intercept: 1.0002944769414903\n",
      "iteration - 261 -> loss: 0.0004242073554351171, self.slope: [1.00351956 1.00353215], self.intercept: 1.0002955954023987\n",
      "iteration - 262 -> loss: 0.00042417183172086, self.slope: [1.00353284 1.00354548], self.intercept: 1.0002967137894252\n",
      "iteration - 263 -> loss: 0.0004241363141667933, self.slope: [1.00354612 1.00355881], self.intercept: 1.0002978321025817\n",
      "iteration - 264 -> loss: 0.0004241008027712901, self.slope: [1.0035594  1.00357213], self.intercept: 1.0002989503418769\n",
      "iteration - 265 -> loss: 0.0004240652975327179, self.slope: [1.00357267 1.00358546], self.intercept: 1.0003000685073224\n",
      "iteration - 266 -> loss: 0.00042402979844944906, self.slope: [1.00358594 1.00359878], self.intercept: 1.0003011865989293\n",
      "iteration - 267 -> loss: 0.00042399430551988036, self.slope: [1.00359922 1.00361211], self.intercept: 1.0003023046167072\n",
      "iteration - 268 -> loss: 0.0004239588187423803, self.slope: [1.00361249 1.00362543], self.intercept: 1.0003034225606677\n",
      "iteration - 269 -> loss: 0.0004239233381153214, self.slope: [1.00362576 1.00363875], self.intercept: 1.0003045404308213\n",
      "iteration - 270 -> loss: 0.00042388786363708244, self.slope: [1.00363903 1.00365207], self.intercept: 1.000305658227179\n",
      "iteration - 271 -> loss: 0.00042385239530605987, self.slope: [1.00365229 1.00366538], self.intercept: 1.0003067759497521\n",
      "iteration - 272 -> loss: 0.00042381693312059493, self.slope: [1.00366556 1.0036787 ], self.intercept: 1.0003078935985485\n",
      "iteration - 273 -> loss: 0.0004237814770791049, self.slope: [1.00367883 1.00369202], self.intercept: 1.0003090111735824\n",
      "iteration - 274 -> loss: 0.0004237460271799647, self.slope: [1.00369209 1.00370533], self.intercept: 1.0003101286748628\n",
      "iteration - 275 -> loss: 0.00042371058342153064, self.slope: [1.00370535 1.00371865], self.intercept: 1.0003112461024002\n",
      "iteration - 276 -> loss: 0.00042367514580221415, self.slope: [1.00371861 1.00373196], self.intercept: 1.000312363456205\n",
      "iteration - 277 -> loss: 0.0004236397143203949, self.slope: [1.00373188 1.00374527], self.intercept: 1.000313480736288\n",
      "iteration - 278 -> loss: 0.0004236042889744288, self.slope: [1.00374514 1.00375858], self.intercept: 1.0003145979426618\n",
      "iteration - 279 -> loss: 0.0004235688697627152, self.slope: [1.00375839 1.00377189], self.intercept: 1.0003157150753346\n",
      "iteration - 280 -> loss: 0.00042353345668365386, self.slope: [1.00377165 1.0037852 ], self.intercept: 1.0003168321343172\n",
      "iteration - 281 -> loss: 0.00042349804973561023, self.slope: [1.00378491 1.0037985 ], self.intercept: 1.0003179491196215\n",
      "iteration - 282 -> loss: 0.00042346264891698204, self.slope: [1.00379816 1.00381181], self.intercept: 1.0003190660312586\n",
      "iteration - 283 -> loss: 0.0004234272542261394, self.slope: [1.00381142 1.00382511], self.intercept: 1.0003201828692379\n",
      "iteration - 284 -> loss: 0.00042339186566147443, self.slope: [1.00382467 1.00383841], self.intercept: 1.00032129963357\n",
      "iteration - 285 -> loss: 0.00042335648322141184, self.slope: [1.00383792 1.00385172], self.intercept: 1.0003224163242648\n",
      "iteration - 286 -> loss: 0.0004233211069042695, self.slope: [1.00385117 1.00386502], self.intercept: 1.0003235329413342\n",
      "iteration - 287 -> loss: 0.0004232857367084867, self.slope: [1.00386442 1.00387832], self.intercept: 1.000324649484789\n",
      "iteration - 288 -> loss: 0.00042325037263244233, self.slope: [1.00387767 1.00389162], self.intercept: 1.0003257659546387\n",
      "iteration - 289 -> loss: 0.0004232150146745075, self.slope: [1.00389091 1.00390491], self.intercept: 1.000326882350896\n",
      "iteration - 290 -> loss: 0.0004231796628330843, self.slope: [1.00390416 1.00391821], self.intercept: 1.00032799867357\n",
      "iteration - 291 -> loss: 0.00042314431710658104, self.slope: [1.0039174 1.0039315], self.intercept: 1.000329114922673\n",
      "iteration - 292 -> loss: 0.00042310897749335595, self.slope: [1.00393065 1.0039448 ], self.intercept: 1.000330231098212\n",
      "iteration - 293 -> loss: 0.00042307364399182026, self.slope: [1.00394389 1.00395809], self.intercept: 1.0003313472001998\n",
      "iteration - 294 -> loss: 0.00042303831660036565, self.slope: [1.00395713 1.00397138], self.intercept: 1.0003324632286474\n",
      "iteration - 295 -> loss: 0.0004230029953173866, self.slope: [1.00397037 1.00398467], self.intercept: 1.0003335791835652\n",
      "iteration - 296 -> loss: 0.0004229676801412586, self.slope: [1.00398361 1.00399796], self.intercept: 1.000334695064964\n",
      "iteration - 297 -> loss: 0.0004229323710703948, self.slope: [1.00399685 1.00401125], self.intercept: 1.0003358108728535\n",
      "iteration - 298 -> loss: 0.0004228970681031811, self.slope: [1.00401008 1.00402454], self.intercept: 1.0003369266072457\n",
      "iteration - 299 -> loss: 0.00042286177123801894, self.slope: [1.00402332 1.00403783], self.intercept: 1.0003380422681496\n",
      "iteration - 300 -> loss: 0.0004228264804733094, self.slope: [1.00403655 1.00405111], self.intercept: 1.0003391578555774\n",
      "iteration - 301 -> loss: 0.00042279119580742935, self.slope: [1.00404979 1.00406439], self.intercept: 1.0003402733695395\n",
      "iteration - 302 -> loss: 0.0004227559172387766, self.slope: [1.00406302 1.00407768], self.intercept: 1.0003413888100454\n",
      "iteration - 303 -> loss: 0.00042272064476577, self.slope: [1.00407625 1.00409096], self.intercept: 1.000342504177105\n",
      "iteration - 304 -> loss: 0.0004226853783867796, self.slope: [1.00408948 1.00410424], self.intercept: 1.0003436194707316\n",
      "iteration - 305 -> loss: 0.0004226501181002383, self.slope: [1.00410271 1.00411752], self.intercept: 1.000344734690933\n",
      "iteration - 306 -> loss: 0.00042261486390450325, self.slope: [1.00411593 1.0041308 ], self.intercept: 1.000345849837723\n",
      "iteration - 307 -> loss: 0.00042257961579801834, self.slope: [1.00412916 1.00414407], self.intercept: 1.0003469649111099\n",
      "iteration - 308 -> loss: 0.0004225443737791469, self.slope: [1.00414239 1.00415735], self.intercept: 1.0003480799111044\n",
      "iteration - 309 -> loss: 0.00042250913784631515, self.slope: [1.00415561 1.00417062], self.intercept: 1.0003491948377177\n",
      "iteration - 310 -> loss: 0.0004224739079979111, self.slope: [1.00416883 1.0041839 ], self.intercept: 1.000350309690961\n",
      "iteration - 311 -> loss: 0.0004224386842323336, self.slope: [1.00418205 1.00419717], self.intercept: 1.0003514244708431\n",
      "iteration - 312 -> loss: 0.00042240346654798873, self.slope: [1.00419527 1.00421044], self.intercept: 1.000352539177375\n",
      "iteration - 313 -> loss: 0.0004223682549432875, self.slope: [1.00420849 1.00422371], self.intercept: 1.0003536538105673\n",
      "iteration - 314 -> loss: 0.00042233304941663143, self.slope: [1.00422171 1.00423698], self.intercept: 1.0003547683704324\n",
      "iteration - 315 -> loss: 0.0004222978499663982, self.slope: [1.00423493 1.00425025], self.intercept: 1.0003558828569796\n",
      "iteration - 316 -> loss: 0.00042226265659102923, self.slope: [1.00424814 1.00426351], self.intercept: 1.00035699727022\n",
      "iteration - 317 -> loss: 0.00042222746928892647, self.slope: [1.00426136 1.00427678], self.intercept: 1.0003581116101636\n",
      "iteration - 318 -> loss: 0.0004221922880584738, self.slope: [1.00427457 1.00429004], self.intercept: 1.000359225876821\n",
      "iteration - 319 -> loss: 0.0004221571128980851, self.slope: [1.00428778 1.00430331], self.intercept: 1.000360340070202\n",
      "iteration - 320 -> loss: 0.00042212194380616237, self.slope: [1.00430099 1.00431657], self.intercept: 1.0003614541903183\n",
      "iteration - 321 -> loss: 0.0004220867807811294, self.slope: [1.0043142  1.00432983], self.intercept: 1.0003625682371797\n",
      "iteration - 322 -> loss: 0.0004220516238213958, self.slope: [1.00432741 1.00434309], self.intercept: 1.0003636822107973\n",
      "iteration - 323 -> loss: 0.0004220164729253459, self.slope: [1.00434062 1.00435635], self.intercept: 1.000364796111182\n",
      "iteration - 324 -> loss: 0.0004219813280914064, self.slope: [1.00435383 1.00436961], self.intercept: 1.000365909938343\n",
      "iteration - 325 -> loss: 0.00042194618931797886, self.slope: [1.00436703 1.00438286], self.intercept: 1.0003670236922924\n",
      "iteration - 326 -> loss: 0.0004219110566034898, self.slope: [1.00438024 1.00439612], self.intercept: 1.00036813737304\n",
      "iteration - 327 -> loss: 0.00042187592994633104, self.slope: [1.00439344 1.00440937], self.intercept: 1.0003692509805964\n",
      "iteration - 328 -> loss: 0.00042184080934492174, self.slope: [1.00440664 1.00442263], self.intercept: 1.0003703645149729\n",
      "iteration - 329 -> loss: 0.0004218056947976692, self.slope: [1.00441984 1.00443588], self.intercept: 1.0003714779761783\n",
      "iteration - 330 -> loss: 0.0004217705863030042, self.slope: [1.00443304 1.00444913], self.intercept: 1.0003725913642254\n",
      "iteration - 331 -> loss: 0.00042173548385930707, self.slope: [1.00444624 1.00446238], self.intercept: 1.0003737046791226\n",
      "iteration - 332 -> loss: 0.00042170038746500366, self.slope: [1.00445944 1.00447563], self.intercept: 1.0003748179208802\n",
      "iteration - 333 -> loss: 0.0004216652971185285, self.slope: [1.00447263 1.00448887], self.intercept: 1.00037593108951\n",
      "iteration - 334 -> loss: 0.00042163021281829775, self.slope: [1.00448583 1.00450212], self.intercept: 1.0003770441850224\n",
      "iteration - 335 -> loss: 0.0004215951345626834, self.slope: [1.00449902 1.00451537], self.intercept: 1.0003781572074288\n",
      "iteration - 336 -> loss: 0.00042156006235014444, self.slope: [1.00451222 1.00452861], self.intercept: 1.0003792701567384\n",
      "iteration - 337 -> loss: 0.0004215249961790756, self.slope: [1.00452541 1.00454185], self.intercept: 1.0003803830329632\n",
      "iteration - 338 -> loss: 0.00042148993604789847, self.slope: [1.0045386  1.00455509], self.intercept: 1.0003814958361121\n",
      "iteration - 339 -> loss: 0.0004214548819550476, self.slope: [1.00455179 1.00456834], self.intercept: 1.0003826085661953\n",
      "iteration - 340 -> loss: 0.000421419833898909, self.slope: [1.00456498 1.00458157], self.intercept: 1.0003837212232254\n",
      "iteration - 341 -> loss: 0.00042138479187792984, self.slope: [1.00457816 1.00459481], self.intercept: 1.0003848338072112\n",
      "iteration - 342 -> loss: 0.00042134975589052547, self.slope: [1.00459135 1.00460805], self.intercept: 1.000385946318163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 343 -> loss: 0.0004213147259350946, self.slope: [1.00460453 1.00462129], self.intercept: 1.000387058756093\n",
      "iteration - 344 -> loss: 0.0004212797020100526, self.slope: [1.00461772 1.00463452], self.intercept: 1.0003881711210107\n",
      "iteration - 345 -> loss: 0.00042124468411385924, self.slope: [1.0046309  1.00464776], self.intercept: 1.0003892834129264\n",
      "iteration - 346 -> loss: 0.00042120967224492544, self.slope: [1.00464408 1.00466099], self.intercept: 1.000390395631851\n",
      "iteration - 347 -> loss: 0.00042117466640162417, self.slope: [1.00465726 1.00467422], self.intercept: 1.000391507777795\n",
      "iteration - 348 -> loss: 0.00042113966658245016, self.slope: [1.00467044 1.00468745], self.intercept: 1.0003926198507693\n",
      "iteration - 349 -> loss: 0.00042110467278577257, self.slope: [1.00468362 1.00470068], self.intercept: 1.0003937318507832\n",
      "iteration - 350 -> loss: 0.00042106968501006114, self.slope: [1.00469679 1.00471391], self.intercept: 1.0003948437778478\n",
      "iteration - 351 -> loss: 0.000421034703253705, self.slope: [1.00470997 1.00472713], self.intercept: 1.0003959556319748\n",
      "iteration - 352 -> loss: 0.0004209997275151106, self.slope: [1.00472314 1.00474036], self.intercept: 1.000397067413172\n",
      "iteration - 353 -> loss: 0.0004209647577927629, self.slope: [1.00473632 1.00475359], self.intercept: 1.0003981791214518\n",
      "iteration - 354 -> loss: 0.0004209297940850345, self.slope: [1.00474949 1.00476681], self.intercept: 1.000399290756824\n",
      "iteration - 355 -> loss: 0.0004208948363903932, self.slope: [1.00476266 1.00478003], self.intercept: 1.0004004023192994\n",
      "iteration - 356 -> loss: 0.00042085988470723124, self.slope: [1.00477583 1.00479325], self.intercept: 1.000401513808888\n",
      "iteration - 357 -> loss: 0.0004208249390339912, self.slope: [1.004789   1.00480647], self.intercept: 1.0004026252256009\n",
      "iteration - 358 -> loss: 0.00042078999936910367, self.slope: [1.00480217 1.00481969], self.intercept: 1.000403736569449\n",
      "iteration - 359 -> loss: 0.00042075506571099435, self.slope: [1.00481533 1.00483291], self.intercept: 1.000404847840441\n",
      "iteration - 360 -> loss: 0.0004207201380580966, self.slope: [1.0048285  1.00484613], self.intercept: 1.0004059590385894\n",
      "iteration - 361 -> loss: 0.00042068521640881417, self.slope: [1.00484166 1.00485934], self.intercept: 1.0004070701639032\n",
      "iteration - 362 -> loss: 0.0004206503007616272, self.slope: [1.00485482 1.00487256], self.intercept: 1.0004081812163945\n",
      "iteration - 363 -> loss: 0.0004206153911149224, self.slope: [1.00486799 1.00488577], self.intercept: 1.000409292196073\n",
      "iteration - 364 -> loss: 0.000420580487467141, self.slope: [1.00488115 1.00489898], self.intercept: 1.0004104031029493\n",
      "iteration - 365 -> loss: 0.00042054558981672837, self.slope: [1.00489431 1.0049122 ], self.intercept: 1.0004115139370318\n",
      "iteration - 366 -> loss: 0.0004205106981621268, self.slope: [1.00490746 1.00492541], self.intercept: 1.0004126246983336\n",
      "iteration - 367 -> loss: 0.0004204758125017163, self.slope: [1.00492062 1.00493861], self.intercept: 1.000413735386863\n",
      "iteration - 368 -> loss: 0.0004204409328339915, self.slope: [1.00493378 1.00495182], self.intercept: 1.000414846002632\n",
      "iteration - 369 -> loss: 0.00042040605915735345, self.slope: [1.00494693 1.00496503], self.intercept: 1.0004159565456516\n",
      "iteration - 370 -> loss: 0.0004203711914702441, self.slope: [1.00496009 1.00497823], self.intercept: 1.0004170670159307\n",
      "iteration - 371 -> loss: 0.00042033632977110246, self.slope: [1.00497324 1.00499144], self.intercept: 1.00041817741348\n",
      "iteration - 372 -> loss: 0.0004203014740583602, self.slope: [1.00498639 1.00500464], self.intercept: 1.0004192877383105\n",
      "iteration - 373 -> loss: 0.00042026662433046214, self.slope: [1.00499954 1.00501785], self.intercept: 1.0004203979904336\n",
      "iteration - 374 -> loss: 0.0004202317805858034, self.slope: [1.00501269 1.00503105], self.intercept: 1.0004215081698564\n",
      "iteration - 375 -> loss: 0.00042019694282287697, self.slope: [1.00502584 1.00504425], self.intercept: 1.000422618276592\n",
      "iteration - 376 -> loss: 0.00042016211104012503, self.slope: [1.00503899 1.00505745], self.intercept: 1.0004237283106496\n",
      "iteration - 377 -> loss: 0.0004201272852359265, self.slope: [1.00505213 1.00507064], self.intercept: 1.0004248382720422\n",
      "iteration - 378 -> loss: 0.000420092465408759, self.slope: [1.00506528 1.00508384], self.intercept: 1.0004259481607782\n",
      "iteration - 379 -> loss: 0.00042005765155706665, self.slope: [1.00507842 1.00509704], self.intercept: 1.0004270579768693\n",
      "iteration - 380 -> loss: 0.0004200228436792659, self.slope: [1.00509156 1.00511023], self.intercept: 1.0004281677203233\n",
      "iteration - 381 -> loss: 0.0004199880417738348, self.slope: [1.0051047  1.00512342], self.intercept: 1.0004292773911523\n",
      "iteration - 382 -> loss: 0.00041995324583917165, self.slope: [1.00511784 1.00513662], self.intercept: 1.0004303869893667\n",
      "iteration - 383 -> loss: 0.00041991845587374004, self.slope: [1.00513098 1.00514981], self.intercept: 1.0004314965149772\n",
      "iteration - 384 -> loss: 0.00041988367187598596, self.slope: [1.00514412 1.005163  ], self.intercept: 1.000432605967993\n",
      "iteration - 385 -> loss: 0.0004198488938443444, self.slope: [1.00515726 1.00517618], self.intercept: 1.0004337153484255\n",
      "iteration - 386 -> loss: 0.00041981412177726033, self.slope: [1.00517039 1.00518937], self.intercept: 1.0004348246562844\n",
      "iteration - 387 -> loss: 0.0004197793556731817, self.slope: [1.00518353 1.00520256], self.intercept: 1.0004359338915811\n",
      "iteration - 388 -> loss: 0.0004197445955305467, self.slope: [1.00519666 1.00521574], self.intercept: 1.0004370430543272\n",
      "iteration - 389 -> loss: 0.0004197098413478072, self.slope: [1.00520979 1.00522893], self.intercept: 1.0004381521445305\n",
      "iteration - 390 -> loss: 0.00041967509312340097, self.slope: [1.00522292 1.00524211], self.intercept: 1.000439261162201\n",
      "iteration - 391 -> loss: 0.000419640350855778, self.slope: [1.00523605 1.00525529], self.intercept: 1.0004403701073523\n",
      "iteration - 392 -> loss: 0.00041960561454339103, self.slope: [1.00524918 1.00526848], self.intercept: 1.0004414789799916\n",
      "iteration - 393 -> loss: 0.0004195708841846749, self.slope: [1.00526231 1.00528166], self.intercept: 1.000442587780131\n",
      "iteration - 394 -> loss: 0.0004195361597780951, self.slope: [1.00527544 1.00529483], self.intercept: 1.0004436965077816\n",
      "iteration - 395 -> loss: 0.00041950144132207754, self.slope: [1.00528856 1.00530801], self.intercept: 1.0004448051629518\n",
      "iteration - 396 -> loss: 0.00041946672881508745, self.slope: [1.00530169 1.00532119], self.intercept: 1.0004459137456532\n",
      "iteration - 397 -> loss: 0.00041943202225556254, self.slope: [1.00531481 1.00533436], self.intercept: 1.0004470222558952\n",
      "iteration - 398 -> loss: 0.0004193973216419684, self.slope: [1.00532793 1.00534754], self.intercept: 1.0004481306936897\n",
      "iteration - 399 -> loss: 0.0004193626269727469, self.slope: [1.00534105 1.00536071], self.intercept: 1.0004492390590458\n",
      "iteration - 400 -> loss: 0.0004193279382463406, self.slope: [1.00535417 1.00537388], self.intercept: 1.0004503473519741\n",
      "iteration - 401 -> loss: 0.00041929325546122346, self.slope: [1.00536729 1.00538705], self.intercept: 1.000451455572485\n",
      "iteration - 402 -> loss: 0.0004192585786158266, self.slope: [1.00538041 1.00540022], self.intercept: 1.0004525637205899\n",
      "iteration - 403 -> loss: 0.0004192239077086031, self.slope: [1.00539352 1.00541339], self.intercept: 1.0004536717962986\n",
      "iteration - 404 -> loss: 0.0004191892427380265, self.slope: [1.00540664 1.00542656], self.intercept: 1.0004547797996204\n",
      "iteration - 405 -> loss: 0.00041915458370251463, self.slope: [1.00541975 1.00543973], self.intercept: 1.0004558877305658\n",
      "iteration - 406 -> loss: 0.00041911993060055893, self.slope: [1.00543287 1.00545289], self.intercept: 1.0004569955891471\n",
      "iteration - 407 -> loss: 0.00041908528343060915, self.slope: [1.00544598 1.00546606], self.intercept: 1.0004581033753737\n",
      "iteration - 408 -> loss: 0.00041905064219109297, self.slope: [1.00545909 1.00547922], self.intercept: 1.000459211089255\n",
      "iteration - 409 -> loss: 0.00041901600688049154, self.slope: [1.0054722  1.00549238], self.intercept: 1.000460318730802\n",
      "iteration - 410 -> loss: 0.0004189813774972517, self.slope: [1.00548531 1.00550554], self.intercept: 1.0004614263000247\n",
      "iteration - 411 -> loss: 0.00041894675403983915, self.slope: [1.00549841 1.0055187 ], self.intercept: 1.000462533796933\n",
      "iteration - 412 -> loss: 0.0004189121365067002, self.slope: [1.00551152 1.00553186], self.intercept: 1.0004636412215397\n",
      "iteration - 413 -> loss: 0.00041887752489629793, self.slope: [1.00552463 1.00554502], self.intercept: 1.0004647485738531\n",
      "iteration - 414 -> loss: 0.0004188429192070833, self.slope: [1.00553773 1.00555817], self.intercept: 1.0004658558538844\n",
      "iteration - 415 -> loss: 0.0004188083194375341, self.slope: [1.00555083 1.00557133], self.intercept: 1.0004669630616432\n",
      "iteration - 416 -> loss: 0.0004187737255860847, self.slope: [1.00556393 1.00558448], self.intercept: 1.000468070197139\n",
      "iteration - 417 -> loss: 0.0004187391376512231, self.slope: [1.00557703 1.00559764], self.intercept: 1.0004691772603844\n",
      "iteration - 418 -> loss: 0.0004187045556313905, self.slope: [1.00559013 1.00561079], self.intercept: 1.0004702842513882\n",
      "iteration - 419 -> loss: 0.0004186699795250644, self.slope: [1.00560323 1.00562394], self.intercept: 1.000471391170161\n",
      "iteration - 420 -> loss: 0.00041863540933068246, self.slope: [1.00561633 1.00563709], self.intercept: 1.0004724980167128\n",
      "iteration - 421 -> loss: 0.0004186008450467331, self.slope: [1.00562942 1.00565024], self.intercept: 1.0004736047910547\n",
      "iteration - 422 -> loss: 0.00041856628667165884, self.slope: [1.00564252 1.00566338], self.intercept: 1.0004747114931962\n",
      "iteration - 423 -> loss: 0.0004185317342039305, self.slope: [1.00565561 1.00567653], self.intercept: 1.0004758181231488\n",
      "iteration - 424 -> loss: 0.00041849718764201975, self.slope: [1.00566871 1.00568968], self.intercept: 1.000476924680923\n",
      "iteration - 425 -> loss: 0.0004184626469843709, self.slope: [1.0056818  1.00570282], self.intercept: 1.0004780311665284\n",
      "iteration - 426 -> loss: 0.00041842811222948416, self.slope: [1.00569489 1.00571596], self.intercept: 1.0004791375799749\n",
      "iteration - 427 -> loss: 0.0004183935833757874, self.slope: [1.00570798 1.0057291 ], self.intercept: 1.0004802439212734\n",
      "iteration - 428 -> loss: 0.0004183590604217689, self.slope: [1.00572106 1.00574224], self.intercept: 1.0004813501904348\n",
      "iteration - 429 -> loss: 0.0004183245433658904, self.slope: [1.00573415 1.00575538], self.intercept: 1.000482456387468\n",
      "iteration - 430 -> loss: 0.00041829003220660916, self.slope: [1.00574724 1.00576852], self.intercept: 1.000483562512384\n",
      "iteration - 431 -> loss: 0.0004182555269424122, self.slope: [1.00576032 1.00578166], self.intercept: 1.0004846685651918\n",
      "iteration - 432 -> loss: 0.0004182210275717635, self.slope: [1.00577341 1.0057948 ], self.intercept: 1.0004857745459046\n",
      "iteration - 433 -> loss: 0.00041818653409310695, self.slope: [1.00578649 1.00580793], self.intercept: 1.0004868804545295\n",
      "iteration - 434 -> loss: 0.0004181520465049363, self.slope: [1.00579957 1.00582107], self.intercept: 1.0004879862910792\n",
      "iteration - 435 -> loss: 0.00041811756480572505, self.slope: [1.00581265 1.0058342 ], self.intercept: 1.0004890920555622\n",
      "iteration - 436 -> loss: 0.00041808308899393345, self.slope: [1.00582573 1.00584733], self.intercept: 1.00049019774799\n",
      "iteration - 437 -> loss: 0.0004180486190680263, self.slope: [1.00583881 1.00586046], self.intercept: 1.0004913033683718\n",
      "iteration - 438 -> loss: 0.0004180141550264857, self.slope: [1.00585188 1.00587359], self.intercept: 1.0004924089167195\n",
      "iteration - 439 -> loss: 0.00041797969686777607, self.slope: [1.00586496 1.00588672], self.intercept: 1.0004935143930416\n",
      "iteration - 440 -> loss: 0.00041794524459038795, self.slope: [1.00587803 1.00589985], self.intercept: 1.00049461979735\n",
      "iteration - 441 -> loss: 0.0004179107981927662, self.slope: [1.00589111 1.00591297], self.intercept: 1.0004957251296542\n",
      "iteration - 442 -> loss: 0.0004178763576734101, self.slope: [1.00590418 1.0059261 ], self.intercept: 1.0004968303899637\n",
      "iteration - 443 -> loss: 0.00041784192303078295, self.slope: [1.00591725 1.00593922], self.intercept: 1.0004979355782904\n",
      "iteration - 444 -> loss: 0.00041780749426335027, self.slope: [1.00593032 1.00595235], self.intercept: 1.0004990406946443\n",
      "iteration - 445 -> loss: 0.00041777307136960865, self.slope: [1.00594339 1.00596547], self.intercept: 1.0005001457390355\n",
      "iteration - 446 -> loss: 0.0004177386543480026, self.slope: [1.00595646 1.00597859], self.intercept: 1.000501250711474\n",
      "iteration - 447 -> loss: 0.00041770424319704293, self.slope: [1.00596952 1.00599171], self.intercept: 1.0005023556119703\n",
      "iteration - 448 -> loss: 0.00041766983791518116, self.slope: [1.00598259 1.00600483], self.intercept: 1.0005034604405354\n",
      "iteration - 449 -> loss: 0.00041763543850090965, self.slope: [1.00599565 1.00601794], self.intercept: 1.000504565197178\n",
      "iteration - 450 -> loss: 0.00041760104495270256, self.slope: [1.00600872 1.00603106], self.intercept: 1.0005056698819095\n",
      "iteration - 451 -> loss: 0.0004175666572690176, self.slope: [1.00602178 1.00604417], self.intercept: 1.0005067744947387\n",
      "iteration - 452 -> loss: 0.0004175322754483727, self.slope: [1.00603484 1.00605729], self.intercept: 1.0005078790356767\n",
      "iteration - 453 -> loss: 0.00041749789948922916, self.slope: [1.0060479 1.0060704], self.intercept: 1.0005089835047338\n",
      "iteration - 454 -> loss: 0.00041746352939005666, self.slope: [1.00606096 1.00608351], self.intercept: 1.0005100879019193\n",
      "iteration - 455 -> loss: 0.00041742916514933884, self.slope: [1.00607402 1.00609662], self.intercept: 1.0005111922272458\n",
      "iteration - 456 -> loss: 0.00041739480676557754, self.slope: [1.00608707 1.00610973], self.intercept: 1.0005122964807214\n",
      "iteration - 457 -> loss: 0.00041736045423722767, self.slope: [1.00610013 1.00612284], self.intercept: 1.000513400662357\n",
      "iteration - 458 -> loss: 0.0004173261075627845, self.slope: [1.00611318 1.00613595], self.intercept: 1.000514504772164\n",
      "iteration - 459 -> loss: 0.00041729176674072617, self.slope: [1.00612623 1.00614906], self.intercept: 1.0005156088101514\n",
      "iteration - 460 -> loss: 0.0004172574317695537, self.slope: [1.00613929 1.00616216], self.intercept: 1.0005167127763295\n",
      "iteration - 461 -> loss: 0.00041722310264771583, self.slope: [1.00615234 1.00617527], self.intercept: 1.0005178166707092\n",
      "iteration - 462 -> loss: 0.00041718877937373735, self.slope: [1.00616539 1.00618837], self.intercept: 1.0005189204933005\n",
      "iteration - 463 -> loss: 0.00041715446194605556, self.slope: [1.00617844 1.00620147], self.intercept: 1.0005200242441128\n",
      "iteration - 464 -> loss: 0.00041712015036319557, self.slope: [1.00619148 1.00621457], self.intercept: 1.0005211279231565\n",
      "iteration - 465 -> loss: 0.00041708584462363143, self.slope: [1.00620453 1.00622767], self.intercept: 1.0005222315304423\n",
      "iteration - 466 -> loss: 0.0004170515447258523, self.slope: [1.00621757 1.00624077], self.intercept: 1.0005233350659806\n",
      "iteration - 467 -> loss: 0.00041701725066833136, self.slope: [1.00623062 1.00625387], self.intercept: 1.0005244385297802\n",
      "iteration - 468 -> loss: 0.0004169829624495714, self.slope: [1.00624366 1.00626696], self.intercept: 1.000525541921853\n",
      "iteration - 469 -> loss: 0.00041694868006805796, self.slope: [1.0062567  1.00628006], self.intercept: 1.0005266452422095\n",
      "iteration - 470 -> loss: 0.0004169144035222681, self.slope: [1.00626974 1.00629315], self.intercept: 1.0005277484908597\n",
      "iteration - 471 -> loss: 0.0004168801328106976, self.slope: [1.00628278 1.00630625], self.intercept: 1.0005288516678124\n",
      "iteration - 472 -> loss: 0.0004168458679318492, self.slope: [1.00629582 1.00631934], self.intercept: 1.0005299547730786\n",
      "iteration - 473 -> loss: 0.0004168116088841922, self.slope: [1.00630886 1.00633243], self.intercept: 1.000531057806669\n",
      "iteration - 474 -> loss: 0.00041677735566622803, self.slope: [1.0063219  1.00634552], self.intercept: 1.0005321607685935\n",
      "iteration - 475 -> loss: 0.0004167431082764455, self.slope: [1.00633493 1.00635861], self.intercept: 1.0005332636588622\n",
      "iteration - 476 -> loss: 0.0004167088667133318, self.slope: [1.00634797 1.00637169], self.intercept: 1.0005343664774848\n",
      "iteration - 477 -> loss: 0.0004166746309753848, self.slope: [1.006361   1.00638478], self.intercept: 1.0005354692244723\n",
      "iteration - 478 -> loss: 0.0004166404010611069, self.slope: [1.00637403 1.00639787], self.intercept: 1.0005365718998351\n",
      "iteration - 479 -> loss: 0.0004166061769689578, self.slope: [1.00638706 1.00641095], self.intercept: 1.0005376745035826\n",
      "iteration - 480 -> loss: 0.0004165719586974681, self.slope: [1.00640009 1.00642403], self.intercept: 1.0005387770357255\n",
      "iteration - 481 -> loss: 0.0004165377462451092, self.slope: [1.00641312 1.00643711], self.intercept: 1.0005398794962734\n",
      "iteration - 482 -> loss: 0.00041650353961038825, self.slope: [1.00642615 1.0064502 ], self.intercept: 1.0005409818852367\n",
      "iteration - 483 -> loss: 0.0004164693387917973, self.slope: [1.00643917 1.00646328], self.intercept: 1.0005420842026247\n",
      "iteration - 484 -> loss: 0.000416435143787819, self.slope: [1.0064522  1.00647635], self.intercept: 1.000543186448449\n",
      "iteration - 485 -> loss: 0.0004164009545969926, self.slope: [1.00646522 1.00648943], self.intercept: 1.0005442886227205\n",
      "iteration - 486 -> loss: 0.0004163667712177556, self.slope: [1.00647824 1.00650251], self.intercept: 1.0005453907254471\n",
      "iteration - 487 -> loss: 0.00041633259364865513, self.slope: [1.00649127 1.00651558], self.intercept: 1.000546492756642\n",
      "iteration - 488 -> loss: 0.00041629842188814687, self.slope: [1.00650429 1.00652866], self.intercept: 1.0005475947163114\n",
      "iteration - 489 -> loss: 0.00041626425593475463, self.slope: [1.00651731 1.00654173], self.intercept: 1.0005486966044699\n",
      "iteration - 490 -> loss: 0.0004162300957869773, self.slope: [1.00653033 1.0065548 ], self.intercept: 1.0005497984211253\n",
      "iteration - 491 -> loss: 0.00041619594144331405, self.slope: [1.00654334 1.00656787], self.intercept: 1.0005509001662878\n",
      "iteration - 492 -> loss: 0.0004161617929022604, self.slope: [1.00655636 1.00658094], self.intercept: 1.0005520018399667\n",
      "iteration - 493 -> loss: 0.0004161276501623107, self.slope: [1.00656937 1.00659401], self.intercept: 1.0005531034421744\n",
      "iteration - 494 -> loss: 0.0004160935132219757, self.slope: [1.00658239 1.00660708], self.intercept: 1.0005542049729184\n",
      "iteration - 495 -> loss: 0.0004160593820797502, self.slope: [1.0065954  1.00662015], self.intercept: 1.0005553064322101\n",
      "iteration - 496 -> loss: 0.0004160252567341538, self.slope: [1.00660841 1.00663321], self.intercept: 1.00055640782006\n",
      "iteration - 497 -> loss: 0.0004159911371836532, self.slope: [1.00662142 1.00664628], self.intercept: 1.0005575091364771\n",
      "iteration - 498 -> loss: 0.00041595702342678243, self.slope: [1.00663443 1.00665934], self.intercept: 1.0005586103814734\n",
      "iteration - 499 -> loss: 0.00041592291546203684, self.slope: [1.00664744 1.0066724 ], self.intercept: 1.0005597115550575\n",
      "iteration - 500 -> loss: 0.00041588881328791287, self.slope: [1.00666045 1.00668546], self.intercept: 1.0005608126572398\n",
      "iteration - 501 -> loss: 0.00041585471690293253, self.slope: [1.00667345 1.00669852], self.intercept: 1.0005619136880315\n",
      "iteration - 502 -> loss: 0.00041582062630558873, self.slope: [1.00668646 1.00671158], self.intercept: 1.0005630146474436\n",
      "iteration - 503 -> loss: 0.00041578654149438245, self.slope: [1.00669946 1.00672464], self.intercept: 1.0005641155354836\n",
      "iteration - 504 -> loss: 0.000415752462467827, self.slope: [1.00671247 1.0067377 ], self.intercept: 1.0005652163521637\n",
      "iteration - 505 -> loss: 0.0004157183892244426, self.slope: [1.00672547 1.00675075], self.intercept: 1.0005663170974928\n",
      "iteration - 506 -> loss: 0.000415684321762705, self.slope: [1.00673847 1.00676381], self.intercept: 1.0005674177714814\n",
      "iteration - 507 -> loss: 0.00041565026008114027, self.slope: [1.00675147 1.00677686], self.intercept: 1.00056851837414\n",
      "iteration - 508 -> loss: 0.00041561620417826636, self.slope: [1.00676447 1.00678991], self.intercept: 1.0005696189054782\n",
      "iteration - 509 -> loss: 0.0004155821540525781, self.slope: [1.00677746 1.00680296], self.intercept: 1.000570719365506\n",
      "iteration - 510 -> loss: 0.00041554810970256996, self.slope: [1.00679046 1.00681601], self.intercept: 1.0005718197542335\n",
      "iteration - 511 -> loss: 0.00041551407112678634, self.slope: [1.00680345 1.00682906], self.intercept: 1.000572920071671\n",
      "iteration - 512 -> loss: 0.00041548003832372096, self.slope: [1.00681645 1.00684211], self.intercept: 1.0005740203178293\n",
      "iteration - 513 -> loss: 0.0004154460112918872, self.slope: [1.00682944 1.00685516], self.intercept: 1.000575120492717\n",
      "iteration - 514 -> loss: 0.00041541199002978436, self.slope: [1.00684243 1.0068682 ], self.intercept: 1.000576220596346\n",
      "iteration - 515 -> loss: 0.00041537797453594747, self.slope: [1.00685542 1.00688125], self.intercept: 1.0005773206287254\n",
      "iteration - 516 -> loss: 0.00041534396480885497, self.slope: [1.00686841 1.00689429], self.intercept: 1.000578420589865\n",
      "iteration - 517 -> loss: 0.0004153099608470636, self.slope: [1.0068814  1.00690733], self.intercept: 1.0005795204797763\n",
      "iteration - 518 -> loss: 0.0004152759626490504, self.slope: [1.00689439 1.00692037], self.intercept: 1.0005806202984673\n",
      "iteration - 519 -> loss: 0.00041524197021333616, self.slope: [1.00690737 1.00693341], self.intercept: 1.00058172004595\n",
      "iteration - 520 -> loss: 0.0004152079835384536, self.slope: [1.00692036 1.00694645], self.intercept: 1.0005828197222348\n",
      "iteration - 521 -> loss: 0.0004151740026229051, self.slope: [1.00693334 1.00695949], self.intercept: 1.0005839193273307\n",
      "iteration - 522 -> loss: 0.00041514002746520837, self.slope: [1.00694633 1.00697253], self.intercept: 1.0005850188612484\n",
      "iteration - 523 -> loss: 0.0004151060580638626, self.slope: [1.00695931 1.00698556], self.intercept: 1.0005861183239968\n",
      "iteration - 524 -> loss: 0.00041507209441740906, self.slope: [1.00697229 1.0069986 ], self.intercept: 1.0005872177155863\n",
      "iteration - 525 -> loss: 0.0004150381365243532, self.slope: [1.00698527 1.00701163], self.intercept: 1.0005883170360277\n",
      "iteration - 526 -> loss: 0.00041500418438322176, self.slope: [1.00699825 1.00702466], self.intercept: 1.0005894162853306\n",
      "iteration - 527 -> loss: 0.0004149702379925046, self.slope: [1.00701122 1.0070377 ], self.intercept: 1.000590515463506\n",
      "iteration - 528 -> loss: 0.00041493629735076654, self.slope: [1.0070242  1.00705073], self.intercept: 1.000591614570563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 529 -> loss: 0.00041490236245648543, self.slope: [1.00703717 1.00706375], self.intercept: 1.0005927136065131\n",
      "iteration - 530 -> loss: 0.0004148684333082022, self.slope: [1.00705015 1.00707678], self.intercept: 1.0005938125713647\n",
      "iteration - 531 -> loss: 0.0004148345099044312, self.slope: [1.00706312 1.00708981], self.intercept: 1.0005949114651282\n",
      "iteration - 532 -> loss: 0.0004148005922436896, self.slope: [1.00707609 1.00710284], self.intercept: 1.0005960102878144\n",
      "iteration - 533 -> loss: 0.00041476668032450404, self.slope: [1.00708906 1.00711586], self.intercept: 1.0005971090394323\n",
      "iteration - 534 -> loss: 0.00041473277414540594, self.slope: [1.00710203 1.00712888], self.intercept: 1.000598207719993\n",
      "iteration - 535 -> loss: 0.0004146988737048985, self.slope: [1.007115   1.00714191], self.intercept: 1.000599306329506\n",
      "iteration - 536 -> loss: 0.00041466497900149676, self.slope: [1.00712797 1.00715493], self.intercept: 1.0006004048679826\n",
      "iteration - 537 -> loss: 0.00041463109003377253, self.slope: [1.00714093 1.00716795], self.intercept: 1.00060150333543\n",
      "iteration - 538 -> loss: 0.0004145972068001847, self.slope: [1.0071539  1.00718097], self.intercept: 1.0006026017318599\n",
      "iteration - 539 -> loss: 0.00041456332929929265, self.slope: [1.00716686 1.00719399], self.intercept: 1.0006037000572825\n",
      "iteration - 540 -> loss: 0.00041452945752963144, self.slope: [1.00717983 1.007207  ], self.intercept: 1.0006047983117097\n",
      "iteration - 541 -> loss: 0.0004144955914896933, self.slope: [1.00719279 1.00722002], self.intercept: 1.000605896495148\n",
      "iteration - 542 -> loss: 0.0004144617311780431, self.slope: [1.00720575 1.00723304], self.intercept: 1.0006069946076097\n",
      "iteration - 543 -> loss: 0.0004144278765931784, self.slope: [1.00721871 1.00724605], self.intercept: 1.000608092649105\n",
      "iteration - 544 -> loss: 0.00041439402773362795, self.slope: [1.00723167 1.00725906], self.intercept: 1.0006091906196433\n",
      "iteration - 545 -> loss: 0.0004143601845979277, self.slope: [1.00724462 1.00727207], self.intercept: 1.0006102885192347\n",
      "iteration - 546 -> loss: 0.000414326347184612, self.slope: [1.00725758 1.00728508], self.intercept: 1.000611386347888\n",
      "iteration - 547 -> loss: 0.0004142925154921969, self.slope: [1.00727054 1.00729809], self.intercept: 1.000612484105615\n",
      "iteration - 548 -> loss: 0.0004142586895192115, self.slope: [1.00728349 1.0073111 ], self.intercept: 1.0006135817924264\n",
      "iteration - 549 -> loss: 0.0004142248692641837, self.slope: [1.00729644 1.00732411], self.intercept: 1.0006146794083308\n",
      "iteration - 550 -> loss: 0.00041419105472564796, self.slope: [1.00730939 1.00733712], self.intercept: 1.000615776953337\n",
      "iteration - 551 -> loss: 0.00041415724590214415, self.slope: [1.00732234 1.00735012], self.intercept: 1.0006168744274575\n",
      "iteration - 552 -> loss: 0.00041412344279218916, self.slope: [1.00733529 1.00736313], self.intercept: 1.0006179718307013\n",
      "iteration - 553 -> loss: 0.0004140896453943176, self.slope: [1.00734824 1.00737613], self.intercept: 1.0006190691630776\n",
      "iteration - 554 -> loss: 0.000414055853707052, self.slope: [1.00736119 1.00738913], self.intercept: 1.0006201664245968\n",
      "iteration - 555 -> loss: 0.0004140220677289381, self.slope: [1.00737414 1.00740213], self.intercept: 1.0006212636152705\n",
      "iteration - 556 -> loss: 0.0004139882874585116, self.slope: [1.00738708 1.00741513], self.intercept: 1.0006223607351081\n",
      "iteration - 557 -> loss: 0.0004139545128942929, self.slope: [1.00740003 1.00742813], self.intercept: 1.0006234577841182\n",
      "iteration - 558 -> loss: 0.00041392074403482813, self.slope: [1.00741297 1.00744113], self.intercept: 1.0006245547623127\n",
      "iteration - 559 -> loss: 0.00041388698087864467, self.slope: [1.00742591 1.00745412], self.intercept: 1.000625651669701\n",
      "iteration - 560 -> loss: 0.00041385322342429317, self.slope: [1.00743885 1.00746712], self.intercept: 1.0006267485062923\n",
      "iteration - 561 -> loss: 0.00041381947167028324, self.slope: [1.00745179 1.00748011], self.intercept: 1.0006278452720982\n",
      "iteration - 562 -> loss: 0.00041378572561515966, self.slope: [1.00746473 1.00749311], self.intercept: 1.0006289419671275\n",
      "iteration - 563 -> loss: 0.0004137519852574546, self.slope: [1.00747767 1.0075061 ], self.intercept: 1.0006300385913884\n",
      "iteration - 564 -> loss: 0.00041371825059571506, self.slope: [1.0074906  1.00751909], self.intercept: 1.0006311351448947\n",
      "iteration - 565 -> loss: 0.00041368452162849386, self.slope: [1.00750354 1.00753208], self.intercept: 1.0006322316276546\n",
      "iteration - 566 -> loss: 0.00041365079835429077, self.slope: [1.00751647 1.00754507], self.intercept: 1.0006333280396775\n",
      "iteration - 567 -> loss: 0.0004136170807716663, self.slope: [1.0075294  1.00755806], self.intercept: 1.0006344243809744\n",
      "iteration - 568 -> loss: 0.00041358336887916265, self.slope: [1.00754234 1.00757104], self.intercept: 1.0006355206515547\n",
      "iteration - 569 -> loss: 0.0004135496626753117, self.slope: [1.00755527 1.00758403], self.intercept: 1.0006366168514287\n",
      "iteration - 570 -> loss: 0.000413515962158653, self.slope: [1.0075682  1.00759701], self.intercept: 1.000637712980606\n",
      "iteration - 571 -> loss: 0.00041348226732772187, self.slope: [1.00758113 1.00761   ], self.intercept: 1.0006388090390983\n",
      "iteration - 572 -> loss: 0.00041344857818107725, self.slope: [1.00759405 1.00762298], self.intercept: 1.0006399050269132\n",
      "iteration - 573 -> loss: 0.0004134148947172562, self.slope: [1.00760698 1.00763596], self.intercept: 1.0006410009440618\n",
      "iteration - 574 -> loss: 0.0004133812169347687, self.slope: [1.00761991 1.00764894], self.intercept: 1.0006420967905536\n",
      "iteration - 575 -> loss: 0.00041334754483220187, self.slope: [1.00763283 1.00766192], self.intercept: 1.000643192566399\n",
      "iteration - 576 -> loss: 0.000413313878408075, self.slope: [1.00764575 1.0076749 ], self.intercept: 1.0006442882716078\n",
      "iteration - 577 -> loss: 0.00041328021766092837, self.slope: [1.00765867 1.00768787], self.intercept: 1.0006453839061906\n",
      "iteration - 578 -> loss: 0.0004132465625893273, self.slope: [1.0076716  1.00770085], self.intercept: 1.0006464794701566\n",
      "iteration - 579 -> loss: 0.00041321291319178265, self.slope: [1.00768452 1.00771382], self.intercept: 1.0006475749635162\n",
      "iteration - 580 -> loss: 0.0004131792694668831, self.slope: [1.00769743 1.0077268 ], self.intercept: 1.0006486703862791\n",
      "iteration - 581 -> loss: 0.0004131456314131338, self.slope: [1.00771035 1.00773977], self.intercept: 1.0006497657384574\n",
      "iteration - 582 -> loss: 0.0004131119990290891, self.slope: [1.00772327 1.00775274], self.intercept: 1.000650861020057\n",
      "iteration - 583 -> loss: 0.0004130783723133209, self.slope: [1.00773618 1.00776571], self.intercept: 1.0006519562310894\n",
      "iteration - 584 -> loss: 0.0004130447512643625, self.slope: [1.0077491  1.00777868], self.intercept: 1.0006530513715652\n",
      "iteration - 585 -> loss: 0.00041301113588074656, self.slope: [1.00776201 1.00779165], self.intercept: 1.0006541464414946\n",
      "iteration - 586 -> loss: 0.00041297752616103767, self.slope: [1.00777492 1.00780462], self.intercept: 1.000655241440888\n",
      "iteration - 587 -> loss: 0.0004129439221037639, self.slope: [1.00778783 1.00781758], self.intercept: 1.0006563363697543\n",
      "iteration - 588 -> loss: 0.00041291032370750866, self.slope: [1.00780074 1.00783055], self.intercept: 1.0006574312281038\n",
      "iteration - 589 -> loss: 0.0004128767309707896, self.slope: [1.00781365 1.00784351], self.intercept: 1.0006585260159464\n",
      "iteration - 590 -> loss: 0.0004128431438921596, self.slope: [1.00782656 1.00785647], self.intercept: 1.000659620733291\n",
      "iteration - 591 -> loss: 0.00041280956247020527, self.slope: [1.00783947 1.00786944], self.intercept: 1.0006607153801492\n",
      "iteration - 592 -> loss: 0.00041277598670342154, self.slope: [1.00785237 1.0078824 ], self.intercept: 1.0006618099565303\n",
      "iteration - 593 -> loss: 0.0004127424165903953, self.slope: [1.00786528 1.00789536], self.intercept: 1.000662904462446\n",
      "iteration - 594 -> loss: 0.0004127088521296892, self.slope: [1.00787818 1.00790831], self.intercept: 1.000663998897903\n",
      "iteration - 595 -> loss: 0.00041267529331981553, self.slope: [1.00789108 1.00792127], self.intercept: 1.0006650932629126\n",
      "iteration - 596 -> loss: 0.0004126417401593773, self.slope: [1.00790398 1.00793423], self.intercept: 1.000666187557484\n",
      "iteration - 597 -> loss: 0.0004126081926468706, self.slope: [1.00791688 1.00794718], self.intercept: 1.000667281781628\n",
      "iteration - 598 -> loss: 0.0004125746507808936, self.slope: [1.00792978 1.00796014], self.intercept: 1.0006683759353556\n",
      "iteration - 599 -> loss: 0.00041254111455998557, self.slope: [1.00794268 1.00797309], self.intercept: 1.0006694700186756\n",
      "iteration - 600 -> loss: 0.00041250758398270323, self.slope: [1.00795558 1.00798604], self.intercept: 1.0006705640315987\n",
      "iteration - 601 -> loss: 0.0004124740590476115, self.slope: [1.00796847 1.00799899], self.intercept: 1.0006716579741342\n",
      "iteration - 602 -> loss: 0.00041244053975323275, self.slope: [1.00798137 1.00801194], self.intercept: 1.0006727518462912\n",
      "iteration - 603 -> loss: 0.00041240702609816676, self.slope: [1.00799426 1.00802489], self.intercept: 1.0006738456480808\n",
      "iteration - 604 -> loss: 0.0004123735180809433, self.slope: [1.00800715 1.00803784], self.intercept: 1.0006749393795127\n",
      "iteration - 605 -> loss: 0.00041234001570012303, self.slope: [1.00802004 1.00805079], self.intercept: 1.0006760330405964\n",
      "iteration - 606 -> loss: 0.0004123065189542681, self.slope: [1.00803293 1.00806373], self.intercept: 1.0006771266313417\n",
      "iteration - 607 -> loss: 0.0004122730278419447, self.slope: [1.00804582 1.00807668], self.intercept: 1.0006782201517592\n",
      "iteration - 608 -> loss: 0.00041223954236170054, self.slope: [1.00805871 1.00808962], self.intercept: 1.0006793136018584\n",
      "iteration - 609 -> loss: 0.00041220606251208685, self.slope: [1.0080716  1.00810256], self.intercept: 1.00068040698165\n",
      "iteration - 610 -> loss: 0.00041217258829168434, self.slope: [1.00808448 1.0081155 ], self.intercept: 1.000681500291142\n",
      "iteration - 611 -> loss: 0.0004121391196990568, self.slope: [1.00809737 1.00812844], self.intercept: 1.0006825935303458\n",
      "iteration - 612 -> loss: 0.00041210565673273597, self.slope: [1.00811025 1.00814138], self.intercept: 1.0006836866992714\n",
      "iteration - 613 -> loss: 0.0004120721993912908, self.slope: [1.00812314 1.00815432], self.intercept: 1.0006847797979286\n",
      "iteration - 614 -> loss: 0.00041203874767331366, self.slope: [1.00813602 1.00816726], self.intercept: 1.0006858728263257\n",
      "iteration - 615 -> loss: 0.0004120053015773268, self.slope: [1.0081489  1.00818019], self.intercept: 1.0006869657844748\n",
      "iteration - 616 -> loss: 0.0004119718611019175, self.slope: [1.00816178 1.00819313], self.intercept: 1.0006880586723845\n",
      "iteration - 617 -> loss: 0.0004119384262456509, self.slope: [1.00817465 1.00820606], self.intercept: 1.0006891514900647\n",
      "iteration - 618 -> loss: 0.00041190499700707417, self.slope: [1.00818753 1.00821899], self.intercept: 1.0006902442375276\n",
      "iteration - 619 -> loss: 0.0004118715733847584, self.slope: [1.00820041 1.00823192], self.intercept: 1.0006913369147785\n",
      "iteration - 620 -> loss: 0.000411838155377274, self.slope: [1.00821328 1.00824486], self.intercept: 1.0006924295218307\n",
      "iteration - 621 -> loss: 0.00041180474298317877, self.slope: [1.00822616 1.00825778], self.intercept: 1.0006935220586939\n",
      "iteration - 622 -> loss: 0.0004117713362010519, self.slope: [1.00823903 1.00827071], self.intercept: 1.0006946145253786\n",
      "iteration - 623 -> loss: 0.00041173793502944164, self.slope: [1.0082519  1.00828364], self.intercept: 1.0006957069218922\n",
      "iteration - 624 -> loss: 0.00041170453946692733, self.slope: [1.00826477 1.00829657], self.intercept: 1.0006967992482467\n",
      "iteration - 625 -> loss: 0.0004116711495120698, self.slope: [1.00827764 1.00830949], self.intercept: 1.0006978915044504\n",
      "iteration - 626 -> loss: 0.000411637765163456, self.slope: [1.00829051 1.00832241], self.intercept: 1.000698983690515\n",
      "iteration - 627 -> loss: 0.0004116043864196107, self.slope: [1.00830338 1.00833534], self.intercept: 1.0007000758064493\n",
      "iteration - 628 -> loss: 0.00041157101327913995, self.slope: [1.00831624 1.00834826], self.intercept: 1.0007011678522635\n",
      "iteration - 629 -> loss: 0.0004115376457406054, self.slope: [1.00832911 1.00836118], self.intercept: 1.0007022598279665\n",
      "iteration - 630 -> loss: 0.0004115042838025645, self.slope: [1.00834197 1.0083741 ], self.intercept: 1.0007033517335688\n",
      "iteration - 631 -> loss: 0.00041147092746361436, self.slope: [1.00835483 1.00838702], self.intercept: 1.0007044435690797\n",
      "iteration - 632 -> loss: 0.00041143757672228545, self.slope: [1.0083677  1.00839994], self.intercept: 1.0007055353345098\n",
      "iteration - 633 -> loss: 0.00041140423157718596, self.slope: [1.00838056 1.00841285], self.intercept: 1.0007066270298697\n",
      "iteration - 634 -> loss: 0.00041137089202687564, self.slope: [1.00839342 1.00842577], self.intercept: 1.0007077186551672\n",
      "iteration - 635 -> loss: 0.00041133755806992497, self.slope: [1.00840627 1.00843868], self.intercept: 1.0007088102104145\n",
      "iteration - 636 -> loss: 0.0004113042297048994, self.slope: [1.00841913 1.00845159], self.intercept: 1.00070990169562\n",
      "iteration - 637 -> loss: 0.0004112709069303834, self.slope: [1.00843199 1.00846451], self.intercept: 1.000710993110794\n",
      "iteration - 638 -> loss: 0.00041123758974494066, self.slope: [1.00844484 1.00847742], self.intercept: 1.0007120844559452\n",
      "iteration - 639 -> loss: 0.00041120427814714033, self.slope: [1.0084577  1.00849033], self.intercept: 1.000713175731084\n",
      "iteration - 640 -> loss: 0.00041117097213559125, self.slope: [1.00847055 1.00850324], self.intercept: 1.0007142669362217\n",
      "iteration - 641 -> loss: 0.00041113767170882984, self.slope: [1.0084834  1.00851614], self.intercept: 1.0007153580713672\n",
      "iteration - 642 -> loss: 0.000411104376865449, self.slope: [1.00849625 1.00852905], self.intercept: 1.0007164491365308\n",
      "iteration - 643 -> loss: 0.0004110710876040158, self.slope: [1.0085091  1.00854196], self.intercept: 1.0007175401317205\n",
      "iteration - 644 -> loss: 0.0004110378039231305, self.slope: [1.00852195 1.00855486], self.intercept: 1.0007186310569485\n",
      "iteration - 645 -> loss: 0.00041100452582134135, self.slope: [1.0085348  1.00856777], self.intercept: 1.0007197219122237\n",
      "iteration - 646 -> loss: 0.00041097125329725003, self.slope: [1.00854765 1.00858067], self.intercept: 1.0007208126975538\n",
      "iteration - 647 -> loss: 0.0004109379863494033, self.slope: [1.00856049 1.00859357], self.intercept: 1.0007219034129515\n",
      "iteration - 648 -> loss: 0.00041090472497640873, self.slope: [1.00857334 1.00860647], self.intercept: 1.000722994058426\n",
      "iteration - 649 -> loss: 0.000410871469176846, self.slope: [1.00858618 1.00861937], self.intercept: 1.0007240846339869\n",
      "iteration - 650 -> loss: 0.0004108382189492729, self.slope: [1.00859902 1.00863227], self.intercept: 1.0007251751396442\n",
      "iteration - 651 -> loss: 0.0004108049742922852, self.slope: [1.00861186 1.00864516], self.intercept: 1.000726265575406\n",
      "iteration - 652 -> loss: 0.0004107717352044356, self.slope: [1.0086247  1.00865806], self.intercept: 1.0007273559412846\n",
      "iteration - 653 -> loss: 0.0004107385016843484, self.slope: [1.00863754 1.00867095], self.intercept: 1.000728446237289\n",
      "iteration - 654 -> loss: 0.0004107052737305939, self.slope: [1.00865038 1.00868385], self.intercept: 1.0007295364634288\n",
      "iteration - 655 -> loss: 0.0004106720513417251, self.slope: [1.00866322 1.00869674], self.intercept: 1.0007306266197133\n",
      "iteration - 656 -> loss: 0.00041063883451635143, self.slope: [1.00867605 1.00870963], self.intercept: 1.000731716706153\n",
      "iteration - 657 -> loss: 0.0004106056232530535, self.slope: [1.00868889 1.00872252], self.intercept: 1.0007328067227577\n",
      "iteration - 658 -> loss: 0.00041057241755041525, self.slope: [1.00870172 1.00873541], self.intercept: 1.0007338966695365\n",
      "iteration - 659 -> loss: 0.00041053921740700654, self.slope: [1.00871455 1.0087483 ], self.intercept: 1.0007349865465005\n",
      "iteration - 660 -> loss: 0.00041050602282141147, self.slope: [1.00872738 1.00876119], self.intercept: 1.0007360763536581\n",
      "iteration - 661 -> loss: 0.0004104728337922454, self.slope: [1.00874021 1.00877408], self.intercept: 1.0007371660910205\n",
      "iteration - 662 -> loss: 0.00041043965031805767, self.slope: [1.00875304 1.00878696], self.intercept: 1.000738255758597\n",
      "iteration - 663 -> loss: 0.0004104064723974409, self.slope: [1.00876587 1.00879984], self.intercept: 1.0007393453563964\n",
      "iteration - 664 -> loss: 0.0004103733000290173, self.slope: [1.0087787  1.00881273], self.intercept: 1.0007404348844302\n",
      "iteration - 665 -> loss: 0.00041034013321132373, self.slope: [1.00879152 1.00882561], self.intercept: 1.000741524342706\n",
      "iteration - 666 -> loss: 0.00041030697194296815, self.slope: [1.00880435 1.00883849], self.intercept: 1.0007426137312343\n",
      "iteration - 667 -> loss: 0.00041027381622254903, self.slope: [1.00881717 1.00885137], self.intercept: 1.0007437030500266\n",
      "iteration - 668 -> loss: 0.0004102406660486271, self.slope: [1.00883    1.00886425], self.intercept: 1.000744792299092\n",
      "iteration - 669 -> loss: 0.00041020752141984377, self.slope: [1.00884282 1.00887713], self.intercept: 1.0007458814784393\n",
      "iteration - 670 -> loss: 0.00041017438233471897, self.slope: [1.00885564 1.00889   ], self.intercept: 1.0007469705880778\n",
      "iteration - 671 -> loss: 0.00041014124879190807, self.slope: [1.00886846 1.00890288], self.intercept: 1.00074805962802\n",
      "iteration - 672 -> loss: 0.00041010812078995, self.slope: [1.00888128 1.00891575], self.intercept: 1.0007491485982716\n",
      "iteration - 673 -> loss: 0.0004100749983274584, self.slope: [1.00889409 1.00892863], self.intercept: 1.0007502374988455\n",
      "iteration - 674 -> loss: 0.00041004188140302054, self.slope: [1.00890691 1.0089415 ], self.intercept: 1.0007513263297514\n",
      "iteration - 675 -> loss: 0.00041000877001522753, self.slope: [1.00891972 1.00895437], self.intercept: 1.000752415090998\n",
      "iteration - 676 -> loss: 0.00040997566416268153, self.slope: [1.00893254 1.00896724], self.intercept: 1.0007535037825952\n",
      "iteration - 677 -> loss: 0.00040994256384396484, self.slope: [1.00894535 1.00898011], self.intercept: 1.0007545924045531\n",
      "iteration - 678 -> loss: 0.00040990946905765624, self.slope: [1.00895816 1.00899298], self.intercept: 1.0007556809568818\n",
      "iteration - 679 -> loss: 0.0004098763798023884, self.slope: [1.00897097 1.00900585], self.intercept: 1.0007567694395898\n",
      "iteration - 680 -> loss: 0.000409843296076714, self.slope: [1.00898378 1.00901871], self.intercept: 1.0007578578526877\n",
      "iteration - 681 -> loss: 0.000409810217879258, self.slope: [1.00899659 1.00903158], self.intercept: 1.000758946196184\n",
      "iteration - 682 -> loss: 0.0004097771452085957, self.slope: [1.0090094  1.00904444], self.intercept: 1.0007600344700922\n",
      "iteration - 683 -> loss: 0.00040974407806332894, self.slope: [1.00902221 1.0090573 ], self.intercept: 1.0007611226744177\n",
      "iteration - 684 -> loss: 0.0004097110164420615, self.slope: [1.00903501 1.00907017], self.intercept: 1.0007622108091714\n",
      "iteration - 685 -> loss: 0.00040967796034338804, self.slope: [1.00904782 1.00908303], self.intercept: 1.0007632988743644\n",
      "iteration - 686 -> loss: 0.0004096449097658903, self.slope: [1.00906062 1.00909589], self.intercept: 1.000764386870006\n",
      "iteration - 687 -> loss: 0.00040961186470816867, self.slope: [1.00907342 1.00910875], self.intercept: 1.000765474796106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 688 -> loss: 0.0004095788251688428, self.slope: [1.00908622 1.0091216 ], self.intercept: 1.0007665626526723\n",
      "iteration - 689 -> loss: 0.00040954579114648934, self.slope: [1.00909902 1.00913446], self.intercept: 1.0007676504397178\n",
      "iteration - 690 -> loss: 0.00040951276263971397, self.slope: [1.00911182 1.00914731], self.intercept: 1.0007687381572494\n",
      "iteration - 691 -> loss: 0.00040947973964711946, self.slope: [1.00912462 1.00916017], self.intercept: 1.0007698258052793\n",
      "iteration - 692 -> loss: 0.00040944672216729536, self.slope: [1.00913742 1.00917302], self.intercept: 1.0007709133838143\n",
      "iteration - 693 -> loss: 0.000409413710198868, self.slope: [1.00915021 1.00918587], self.intercept: 1.0007720008928664\n",
      "iteration - 694 -> loss: 0.0004093807037404038, self.slope: [1.00916301 1.00919873], self.intercept: 1.0007730883324437\n",
      "iteration - 695 -> loss: 0.0004093477027905206, self.slope: [1.0091758  1.00921158], self.intercept: 1.0007741757025572\n",
      "iteration - 696 -> loss: 0.000409314707347813, self.slope: [1.00918859 1.00922442], self.intercept: 1.000775263003219\n",
      "iteration - 697 -> loss: 0.00040928171741090277, self.slope: [1.00920138 1.00923727], self.intercept: 1.0007763502344345\n",
      "iteration - 698 -> loss: 0.0004092487329783699, self.slope: [1.00921417 1.00925012], self.intercept: 1.000777437396216\n",
      "iteration - 699 -> loss: 0.00040921575404881714, self.slope: [1.00922696 1.00926297], self.intercept: 1.0007785244885714\n",
      "iteration - 700 -> loss: 0.00040918278062087476, self.slope: [1.00923975 1.00927581], self.intercept: 1.0007796115115124\n",
      "iteration - 701 -> loss: 0.0004091498126931123, self.slope: [1.00925254 1.00928865], self.intercept: 1.0007806984650462\n",
      "iteration - 702 -> loss: 0.00040911685026417813, self.slope: [1.00926532 1.0093015 ], self.intercept: 1.000781785349184\n",
      "iteration - 703 -> loss: 0.000409083893332616, self.slope: [1.00927811 1.00931434], self.intercept: 1.0007828721639367\n",
      "iteration - 704 -> loss: 0.00040905094189708766, self.slope: [1.00929089 1.00932718], self.intercept: 1.0007839589093117\n",
      "iteration - 705 -> loss: 0.00040901799595617546, self.slope: [1.00930368 1.00934002], self.intercept: 1.0007850455853202\n",
      "iteration - 706 -> loss: 0.00040898505550847396, self.slope: [1.00931646 1.00935286], self.intercept: 1.0007861321919707\n",
      "iteration - 707 -> loss: 0.00040895212055261517, self.slope: [1.00932924 1.00936569], self.intercept: 1.0007872187292735\n",
      "iteration - 708 -> loss: 0.0004089191910872025, self.slope: [1.00934202 1.00937853], self.intercept: 1.0007883051972393\n",
      "iteration - 709 -> loss: 0.00040888626711082924, self.slope: [1.0093548  1.00939137], self.intercept: 1.000789391595877\n",
      "iteration - 710 -> loss: 0.0004088533486221065, self.slope: [1.00936757 1.0094042 ], self.intercept: 1.0007904779251957\n",
      "iteration - 711 -> loss: 0.00040882043561964507, self.slope: [1.00938035 1.00941703], self.intercept: 1.000791564185207\n",
      "iteration - 712 -> loss: 0.0004087875281020653, self.slope: [1.00939313 1.00942986], self.intercept: 1.0007926503759175\n",
      "iteration - 713 -> loss: 0.0004087546260679594, self.slope: [1.0094059 1.0094427], self.intercept: 1.0007937364973403\n",
      "iteration - 714 -> loss: 0.0004087217295159516, self.slope: [1.00941867 1.00945553], self.intercept: 1.000794822549482\n",
      "iteration - 715 -> loss: 0.0004086888384446451, self.slope: [1.00943144 1.00946835], self.intercept: 1.0007959085323548\n",
      "iteration - 716 -> loss: 0.0004086559528526649, self.slope: [1.00944422 1.00948118], self.intercept: 1.000796994445967\n",
      "iteration - 717 -> loss: 0.00040862307273859476, self.slope: [1.00945699 1.00949401], self.intercept: 1.0007980802903282\n",
      "iteration - 718 -> loss: 0.0004085901981010785, self.slope: [1.00946975 1.00950683], self.intercept: 1.000799166065448\n",
      "iteration - 719 -> loss: 0.0004085573289386972, self.slope: [1.00948252 1.00951966], self.intercept: 1.000800251771336\n",
      "iteration - 720 -> loss: 0.00040852446525009686, self.slope: [1.00949529 1.00953248], self.intercept: 1.000801337408003\n",
      "iteration - 721 -> loss: 0.00040849160703386087, self.slope: [1.00950805 1.0095453 ], self.intercept: 1.0008024229754575\n",
      "iteration - 722 -> loss: 0.0004084587542886245, self.slope: [1.00952082 1.00955813], self.intercept: 1.0008035084737106\n",
      "iteration - 723 -> loss: 0.00040842590701298227, self.slope: [1.00953358 1.00957095], self.intercept: 1.0008045939027717\n",
      "iteration - 724 -> loss: 0.000408393065205575, self.slope: [1.00954634 1.00958377], self.intercept: 1.0008056792626494\n",
      "iteration - 725 -> loss: 0.0004083602288649954, self.slope: [1.00955911 1.00959658], self.intercept: 1.0008067645533543\n",
      "iteration - 726 -> loss: 0.0004083273979898697, self.slope: [1.00957187 1.0096094 ], self.intercept: 1.0008078497748951\n",
      "iteration - 727 -> loss: 0.0004082945725788189, self.slope: [1.00958462 1.00962222], self.intercept: 1.0008089349272833\n",
      "iteration - 728 -> loss: 0.0004082617526304572, self.slope: [1.00959738 1.00963503], self.intercept: 1.0008100200105259\n",
      "iteration - 729 -> loss: 0.00040822893814339593, self.slope: [1.00961014 1.00964785], self.intercept: 1.0008111050246342\n",
      "iteration - 730 -> loss: 0.000408196129116242, self.slope: [1.0096229  1.00966066], self.intercept: 1.0008121899696183\n",
      "iteration - 731 -> loss: 0.0004081633255476336, self.slope: [1.00963565 1.00967347], self.intercept: 1.0008132748454859\n",
      "iteration - 732 -> loss: 0.0004081305274361905, self.slope: [1.0096484  1.00968628], self.intercept: 1.000814359652247\n",
      "iteration - 733 -> loss: 0.0004080977347805222, self.slope: [1.00966116 1.00969909], self.intercept: 1.0008154443899122\n",
      "iteration - 734 -> loss: 0.0004080649475792442, self.slope: [1.00967391 1.0097119 ], self.intercept: 1.000816529058492\n",
      "iteration - 735 -> loss: 0.0004080321658309846, self.slope: [1.00968666 1.00972471], self.intercept: 1.0008176136579954\n",
      "iteration - 736 -> loss: 0.00040799938953436124, self.slope: [1.00969941 1.00973752], self.intercept: 1.0008186981884302\n",
      "iteration - 737 -> loss: 0.0004079666186880117, self.slope: [1.00971216 1.00975032], self.intercept: 1.000819782649808\n",
      "iteration - 738 -> loss: 0.00040793385329053044, self.slope: [1.0097249  1.00976313], self.intercept: 1.0008208670421392\n",
      "iteration - 739 -> loss: 0.00040790109334054537, self.slope: [1.00973765 1.00977593], self.intercept: 1.000821951365432\n",
      "iteration - 740 -> loss: 0.00040786833883669674, self.slope: [1.0097504  1.00978873], self.intercept: 1.0008230356196963\n",
      "iteration - 741 -> loss: 0.00040783558977759975, self.slope: [1.00976314 1.00980153], self.intercept: 1.0008241198049417\n",
      "iteration - 742 -> loss: 0.0004078028461618588, self.slope: [1.00977588 1.00981433], self.intercept: 1.0008252039211774\n",
      "iteration - 743 -> loss: 0.0004077701079881301, self.slope: [1.00978863 1.00982713], self.intercept: 1.0008262879684133\n",
      "iteration - 744 -> loss: 0.0004077373752549966, self.slope: [1.00980137 1.00983993], self.intercept: 1.0008273719466594\n",
      "iteration - 745 -> loss: 0.0004077046479611107, self.slope: [1.00981411 1.00985273], self.intercept: 1.0008284558559253\n",
      "iteration - 746 -> loss: 0.00040767192610510435, self.slope: [1.00982684 1.00986552], self.intercept: 1.0008295396962197\n",
      "iteration - 747 -> loss: 0.0004076392096855846, self.slope: [1.00983958 1.00987832], self.intercept: 1.0008306234675532\n",
      "iteration - 748 -> loss: 0.0004076064987012091, self.slope: [1.00985232 1.00989111], self.intercept: 1.0008317071699344\n",
      "iteration - 749 -> loss: 0.0004075737931505536, self.slope: [1.00986505 1.0099039 ], self.intercept: 1.0008327908033738\n",
      "iteration - 750 -> loss: 0.00040754109303228953, self.slope: [1.00987779 1.0099167 ], self.intercept: 1.0008338743678804\n",
      "iteration - 751 -> loss: 0.00040750839834502716, self.slope: [1.00989052 1.00992949], self.intercept: 1.0008349578634659\n",
      "iteration - 752 -> loss: 0.00040747570908737977, self.slope: [1.00990326 1.00994228], self.intercept: 1.0008360412901376\n",
      "iteration - 753 -> loss: 0.0004074430252580012, self.slope: [1.00991599 1.00995507], self.intercept: 1.0008371246479062\n",
      "iteration - 754 -> loss: 0.0004074103468555229, self.slope: [1.00992872 1.00996785], self.intercept: 1.0008382079367797\n",
      "iteration - 755 -> loss: 0.00040737767387854585, self.slope: [1.00994145 1.00998064], self.intercept: 1.0008392911567692\n",
      "iteration - 756 -> loss: 0.0004073450063257239, self.slope: [1.00995417 1.00999343], self.intercept: 1.0008403743078838\n",
      "iteration - 757 -> loss: 0.0004073123441956774, self.slope: [1.0099669  1.01000621], self.intercept: 1.0008414573901332\n",
      "iteration - 758 -> loss: 0.0004072796874870442, self.slope: [1.00997963 1.01001899], self.intercept: 1.0008425404035264\n",
      "iteration - 759 -> loss: 0.00040724703619844204, self.slope: [1.00999235 1.01003178], self.intercept: 1.0008436233480742\n",
      "iteration - 760 -> loss: 0.0004072143903285153, self.slope: [1.01000508 1.01004456], self.intercept: 1.000844706223785\n",
      "iteration - 761 -> loss: 0.00040718174987590465, self.slope: [1.0100178  1.01005734], self.intercept: 1.000845789030671\n",
      "iteration - 762 -> loss: 0.0004071491148392249, self.slope: [1.01003052 1.01007012], self.intercept: 1.0008468717687387\n",
      "iteration - 763 -> loss: 0.00040711648521711585, self.slope: [1.01004324 1.01008289], self.intercept: 1.0008479544379982\n",
      "iteration - 764 -> loss: 0.00040708386100820866, self.slope: [1.01005596 1.01009567], self.intercept: 1.0008490370384604\n",
      "iteration - 765 -> loss: 0.00040705124221114406, self.slope: [1.01006868 1.01010845], self.intercept: 1.0008501195701338\n",
      "iteration - 766 -> loss: 0.0004070186288245365, self.slope: [1.0100814  1.01012122], self.intercept: 1.0008512020330285\n",
      "iteration - 767 -> loss: 0.00040698602084705387, self.slope: [1.01009411 1.010134  ], self.intercept: 1.0008522844271537\n",
      "iteration - 768 -> loss: 0.00040695341827730466, self.slope: [1.01010683 1.01014677], self.intercept: 1.0008533667525197\n",
      "iteration - 769 -> loss: 0.00040692082111393093, self.slope: [1.01011954 1.01015954], self.intercept: 1.0008544490091358\n",
      "iteration - 770 -> loss: 0.00040688822935559235, self.slope: [1.01013226 1.01017231], self.intercept: 1.0008555311970102\n",
      "iteration - 771 -> loss: 0.00040685564300088373, self.slope: [1.01014497 1.01018508], self.intercept: 1.0008566133161536\n",
      "iteration - 772 -> loss: 0.0004068230620484704, self.slope: [1.01015768 1.01019785], self.intercept: 1.000857695366576\n",
      "iteration - 773 -> loss: 0.0004067904864970065, self.slope: [1.01017039 1.01021062], self.intercept: 1.0008587773482867\n",
      "iteration - 774 -> loss: 0.00040675791634508645, self.slope: [1.0101831  1.01022338], self.intercept: 1.0008598592612947\n",
      "iteration - 775 -> loss: 0.0004067253515913649, self.slope: [1.01019581 1.01023615], self.intercept: 1.0008609411056102\n",
      "iteration - 776 -> loss: 0.0004066927922344988, self.slope: [1.01020851 1.01024891], self.intercept: 1.0008620228812417\n",
      "iteration - 777 -> loss: 0.0004066602382731236, self.slope: [1.01022122 1.01026168], self.intercept: 1.0008631045882006\n",
      "iteration - 778 -> loss: 0.0004066276897058527, self.slope: [1.01023392 1.01027444], self.intercept: 1.000864186226495\n",
      "iteration - 779 -> loss: 0.0004065951465313685, self.slope: [1.01024663 1.0102872 ], self.intercept: 1.0008652677961345\n",
      "iteration - 780 -> loss: 0.000406562608748267, self.slope: [1.01025933 1.01029996], self.intercept: 1.0008663492971293\n",
      "iteration - 781 -> loss: 0.00040653007635522894, self.slope: [1.01027203 1.01031272], self.intercept: 1.0008674307294894\n",
      "iteration - 782 -> loss: 0.00040649754935088013, self.slope: [1.01028473 1.01032548], self.intercept: 1.0008685120932221\n",
      "iteration - 783 -> loss: 0.0004064650277338529, self.slope: [1.01029743 1.01033824], self.intercept: 1.0008695933883396\n",
      "iteration - 784 -> loss: 0.00040643251150280965, self.slope: [1.01031013 1.01035099], self.intercept: 1.0008706746148512\n",
      "iteration - 785 -> loss: 0.0004064000006563661, self.slope: [1.01032283 1.01036375], self.intercept: 1.0008717557727642\n",
      "iteration - 786 -> loss: 0.0004063674951931863, self.slope: [1.01033552 1.0103765 ], self.intercept: 1.00087283686209\n",
      "iteration - 787 -> loss: 0.0004063349951119368, self.slope: [1.01034822 1.01038925], self.intercept: 1.0008739178828363\n",
      "iteration - 788 -> loss: 0.0004063025004112152, self.slope: [1.01036091 1.01040201], self.intercept: 1.0008749988350147\n",
      "iteration - 789 -> loss: 0.0004062700110896887, self.slope: [1.0103736  1.01041476], self.intercept: 1.0008760797186342\n",
      "iteration - 790 -> loss: 0.00040623752714601954, self.slope: [1.0103863  1.01042751], self.intercept: 1.0008771605337032\n",
      "iteration - 791 -> loss: 0.0004062050485788315, self.slope: [1.01039899 1.01044026], self.intercept: 1.0008782412802326\n",
      "iteration - 792 -> loss: 0.0004061725753867609, self.slope: [1.01041168 1.010453  ], self.intercept: 1.0008793219582313\n",
      "iteration - 793 -> loss: 0.00040614010756847966, self.slope: [1.01042437 1.01046575], self.intercept: 1.0008804025677083\n",
      "iteration - 794 -> loss: 0.000406107645122619, self.slope: [1.01043705 1.0104785 ], self.intercept: 1.0008814831086754\n",
      "iteration - 795 -> loss: 0.0004060751880478528, self.slope: [1.01044974 1.01049124], self.intercept: 1.0008825635811396\n",
      "iteration - 796 -> loss: 0.0004060427363428164, self.slope: [1.01046243 1.01050398], self.intercept: 1.000883643985111\n",
      "iteration - 797 -> loss: 0.00040601029000612875, self.slope: [1.01047511 1.01051673], self.intercept: 1.0008847243206003\n",
      "iteration - 798 -> loss: 0.00040597784903647385, self.slope: [1.01048779 1.01052947], self.intercept: 1.000885804587616\n",
      "iteration - 799 -> loss: 0.00040594541343250004, self.slope: [1.01050048 1.01054221], self.intercept: 1.0008868847861665\n",
      "iteration - 800 -> loss: 0.00040591298319282677, self.slope: [1.01051316 1.01055495], self.intercept: 1.0008879649162645\n",
      "iteration - 801 -> loss: 0.00040588055831614745, self.slope: [1.01052584 1.01056769], self.intercept: 1.0008890449779155\n",
      "iteration - 802 -> loss: 0.0004058481388010892, self.slope: [1.01053852 1.01058042], self.intercept: 1.0008901249711317\n",
      "iteration - 803 -> loss: 0.0004058157246463013, self.slope: [1.0105512  1.01059316], self.intercept: 1.000891204895921\n",
      "iteration - 804 -> loss: 0.0004057833158504303, self.slope: [1.01056387 1.01060589], self.intercept: 1.0008922847522945\n",
      "iteration - 805 -> loss: 0.00040575091241216494, self.slope: [1.01057655 1.01061863], self.intercept: 1.000893364540262\n",
      "iteration - 806 -> loss: 0.00040571851433011285, self.slope: [1.01058922 1.01063136], self.intercept: 1.0008944442598313\n",
      "iteration - 807 -> loss: 0.0004056861216029616, self.slope: [1.0106019  1.01064409], self.intercept: 1.000895523911013\n",
      "iteration - 808 -> loss: 0.00040565373422934184, self.slope: [1.01061457 1.01065683], self.intercept: 1.0008966034938156\n",
      "iteration - 809 -> loss: 0.00040562135220791615, self.slope: [1.01062724 1.01066956], self.intercept: 1.0008976830082499\n",
      "iteration - 810 -> loss: 0.0004055889755373511, self.slope: [1.01063991 1.01068228], self.intercept: 1.0008987624543255\n",
      "iteration - 811 -> loss: 0.0004055566042162751, self.slope: [1.01065258 1.01069501], self.intercept: 1.0008998418320487\n",
      "iteration - 812 -> loss: 0.0004055242382433705, self.slope: [1.01066525 1.01070774], self.intercept: 1.0009009211414335\n",
      "iteration - 813 -> loss: 0.000405491877617288, self.slope: [1.01067792 1.01072046], self.intercept: 1.0009020003824856\n",
      "iteration - 814 -> loss: 0.0004054595223366515, self.slope: [1.01069059 1.01073319], self.intercept: 1.0009030795552167\n",
      "iteration - 815 -> loss: 0.0004054271724001765, self.slope: [1.01070325 1.01074591], self.intercept: 1.0009041586596361\n",
      "iteration - 816 -> loss: 0.00040539482780647056, self.slope: [1.01071592 1.01075864], self.intercept: 1.000905237695753\n",
      "iteration - 817 -> loss: 0.00040536248855422836, self.slope: [1.01072858 1.01077136], self.intercept: 1.0009063166635765\n",
      "iteration - 818 -> loss: 0.0004053301546420587, self.slope: [1.01074124 1.01078408], self.intercept: 1.0009073955631163\n",
      "iteration - 819 -> loss: 0.0004052978260686783, self.slope: [1.0107539 1.0107968], self.intercept: 1.0009084743943815\n",
      "iteration - 820 -> loss: 0.00040526550283270546, self.slope: [1.01076656 1.01080952], self.intercept: 1.000909553157382\n",
      "iteration - 821 -> loss: 0.0004052331849328304, self.slope: [1.01077922 1.01082223], self.intercept: 1.0009106318521268\n",
      "iteration - 822 -> loss: 0.00040520087236768106, self.slope: [1.01079188 1.01083495], self.intercept: 1.0009117104786267\n",
      "iteration - 823 -> loss: 0.00040516856513594956, self.slope: [1.01080454 1.01084766], self.intercept: 1.0009127890368905\n",
      "iteration - 824 -> loss: 0.00040513626323627263, self.slope: [1.01081719 1.01086038], self.intercept: 1.000913867526927\n",
      "iteration - 825 -> loss: 0.0004051039666673211, self.slope: [1.01082985 1.01087309], self.intercept: 1.0009149459487463\n",
      "iteration - 826 -> loss: 0.0004050716754277512, self.slope: [1.0108425 1.0108858], self.intercept: 1.0009160243023567\n",
      "iteration - 827 -> loss: 0.00040503938951623713, self.slope: [1.01085516 1.01089852], self.intercept: 1.0009171025877697\n",
      "iteration - 828 -> loss: 0.0004050071089314499, self.slope: [1.01086781 1.01091123], self.intercept: 1.000918180804993\n",
      "iteration - 829 -> loss: 0.00040497483367202643, self.slope: [1.01088046 1.01092394], self.intercept: 1.0009192589540366\n",
      "iteration - 830 -> loss: 0.00040494256373663315, self.slope: [1.01089311 1.01093664], self.intercept: 1.00092033703491\n",
      "iteration - 831 -> loss: 0.0004049102991239522, self.slope: [1.01090576 1.01094935], self.intercept: 1.0009214150476229\n",
      "iteration - 832 -> loss: 0.00040487803983263617, self.slope: [1.0109184  1.01096206], self.intercept: 1.000922492992184\n",
      "iteration - 833 -> loss: 0.0004048457858613729, self.slope: [1.01093105 1.01097476], self.intercept: 1.000923570868604\n",
      "iteration - 834 -> loss: 0.00040481353720878875, self.slope: [1.0109437  1.01098747], self.intercept: 1.0009246486768903\n",
      "iteration - 835 -> loss: 0.0004047812938735881, self.slope: [1.01095634 1.01100017], self.intercept: 1.000925726417055\n",
      "iteration - 836 -> loss: 0.00040474905585440176, self.slope: [1.01096898 1.01101287], self.intercept: 1.0009268040891046\n",
      "iteration - 837 -> loss: 0.0004047168231499184, self.slope: [1.01098163 1.01102557], self.intercept: 1.0009278816930498\n",
      "iteration - 838 -> loss: 0.0004046845957588137, self.slope: [1.01099427 1.01103827], self.intercept: 1.0009289592289012\n",
      "iteration - 839 -> loss: 0.00040465237367972494, self.slope: [1.01100691 1.01105097], self.intercept: 1.0009300366966671\n",
      "iteration - 840 -> loss: 0.00040462015691135724, self.slope: [1.01101955 1.01106367], self.intercept: 1.0009311140963577\n",
      "iteration - 841 -> loss: 0.0004045879454523522, self.slope: [1.01103218 1.01107636], self.intercept: 1.0009321914279814\n",
      "iteration - 842 -> loss: 0.00040455573930138386, self.slope: [1.01104482 1.01108906], self.intercept: 1.000933268691549\n",
      "iteration - 843 -> loss: 0.00040452353845714584, self.slope: [1.01105746 1.01110175], self.intercept: 1.0009343458870683\n",
      "iteration - 844 -> loss: 0.0004044913429182654, self.slope: [1.01107009 1.01111445], self.intercept: 1.0009354230145502\n",
      "iteration - 845 -> loss: 0.0004044591526834504, self.slope: [1.01108273 1.01112714], self.intercept: 1.0009365000740036\n",
      "iteration - 846 -> loss: 0.00040442696775134417, self.slope: [1.01109536 1.01113983], self.intercept: 1.0009375770654363\n",
      "iteration - 847 -> loss: 0.00040439478812063725, self.slope: [1.01110799 1.01115252], self.intercept: 1.0009386539888592\n",
      "iteration - 848 -> loss: 0.00040436261379000403, self.slope: [1.01112062 1.01116521], self.intercept: 1.0009397308442816\n",
      "iteration - 849 -> loss: 0.00040433044475810155, self.slope: [1.01113325 1.0111779 ], self.intercept: 1.0009408076317128\n",
      "iteration - 850 -> loss: 0.00040429828102361246, self.slope: [1.01114588 1.01119059], self.intercept: 1.0009418843511646\n",
      "iteration - 851 -> loss: 0.0004042661225851955, self.slope: [1.01115851 1.01120327], self.intercept: 1.0009429610026426\n",
      "iteration - 852 -> loss: 0.0004042339694415279, self.slope: [1.01117113 1.01121596], self.intercept: 1.000944037586158\n",
      "iteration - 853 -> loss: 0.0004042018215913152, self.slope: [1.01118376 1.01122864], self.intercept: 1.0009451141017194\n",
      "iteration - 854 -> loss: 0.0004041696790332034, self.slope: [1.01119638 1.01124133], self.intercept: 1.0009461905493382\n",
      "iteration - 855 -> loss: 0.0004041375417658744, self.slope: [1.01120901 1.01125401], self.intercept: 1.0009472669290214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 856 -> loss: 0.00040410540978799383, self.slope: [1.01122163 1.01126669], self.intercept: 1.0009483432407797\n",
      "iteration - 857 -> loss: 0.000404073283098256, self.slope: [1.01123425 1.01127937], self.intercept: 1.000949419484622\n",
      "iteration - 858 -> loss: 0.0004040411616953241, self.slope: [1.01124687 1.01129205], self.intercept: 1.000950495660557\n",
      "iteration - 859 -> loss: 0.00040400904557787116, self.slope: [1.01125949 1.01130473], self.intercept: 1.000951571768596\n",
      "iteration - 860 -> loss: 0.0004039769347445889, self.slope: [1.01127211 1.0113174 ], self.intercept: 1.0009526478087472\n",
      "iteration - 861 -> loss: 0.00040394482919414504, self.slope: [1.01128473 1.01133008], self.intercept: 1.0009537237810189\n",
      "iteration - 862 -> loss: 0.0004039127289252096, self.slope: [1.01129734 1.01134275], self.intercept: 1.0009547996854222\n",
      "iteration - 863 -> loss: 0.00040388063393647364, self.slope: [1.01130996 1.01135543], self.intercept: 1.000955875521965\n",
      "iteration - 864 -> loss: 0.00040384854422662557, self.slope: [1.01132257 1.0113681 ], self.intercept: 1.0009569512906575\n",
      "iteration - 865 -> loss: 0.00040381645979433426, self.slope: [1.01133518 1.01138077], self.intercept: 1.0009580269915104\n",
      "iteration - 866 -> loss: 0.00040378438063826903, self.slope: [1.0113478  1.01139344], self.intercept: 1.0009591026245326\n",
      "iteration - 867 -> loss: 0.0004037523067571143, self.slope: [1.01136041 1.01140611], self.intercept: 1.0009601781897308\n",
      "iteration - 868 -> loss: 0.00040372023814957205, self.slope: [1.01137302 1.01141878], self.intercept: 1.0009612536871166\n",
      "iteration - 869 -> loss: 0.00040368817481431084, self.slope: [1.01138563 1.01143145], self.intercept: 1.0009623291166991\n",
      "iteration - 870 -> loss: 0.0004036561167499899, self.slope: [1.01139823 1.01144412], self.intercept: 1.0009634044784883\n",
      "iteration - 871 -> loss: 0.00040362406395531766, self.slope: [1.01141084 1.01145678], self.intercept: 1.000964479772494\n",
      "iteration - 872 -> loss: 0.0004035920164289773, self.slope: [1.01142345 1.01146945], self.intercept: 1.000965554998723\n",
      "iteration - 873 -> loss: 0.0004035599741696451, self.slope: [1.01143605 1.01148211], self.intercept: 1.000966630157186\n",
      "iteration - 874 -> loss: 0.00040352793717598416, self.slope: [1.01144865 1.01149477], self.intercept: 1.0009677052478934\n",
      "iteration - 875 -> loss: 0.00040349590544671833, self.slope: [1.01146126 1.01150743], self.intercept: 1.000968780270853\n",
      "iteration - 876 -> loss: 0.00040346387898049235, self.slope: [1.01147386 1.01152009], self.intercept: 1.000969855226074\n",
      "iteration - 877 -> loss: 0.0004034318577760343, self.slope: [1.01148646 1.01153275], self.intercept: 1.0009709301135665\n",
      "iteration - 878 -> loss: 0.0004033998418319887, self.slope: [1.01149906 1.01154541], self.intercept: 1.0009720049333415\n",
      "iteration - 879 -> loss: 0.00040336783114706487, self.slope: [1.01151166 1.01155807], self.intercept: 1.000973079685406\n",
      "iteration - 880 -> loss: 0.0004033358257199287, self.slope: [1.01152425 1.01157072], self.intercept: 1.0009741543697699\n",
      "iteration - 881 -> loss: 0.0004033038255492973, self.slope: [1.01153685 1.01158338], self.intercept: 1.0009752289864424\n",
      "iteration - 882 -> loss: 0.000403271830633835, self.slope: [1.01154944 1.01159603], self.intercept: 1.0009763035354333\n",
      "iteration - 883 -> loss: 0.0004032398409722311, self.slope: [1.01156204 1.01160869], self.intercept: 1.0009773780167526\n",
      "iteration - 884 -> loss: 0.0004032078565631826, self.slope: [1.01157463 1.01162134], self.intercept: 1.000978452430408\n",
      "iteration - 885 -> loss: 0.0004031758774053688, self.slope: [1.01158722 1.01163399], self.intercept: 1.0009795267764101\n",
      "iteration - 886 -> loss: 0.0004031439034974701, self.slope: [1.01159981 1.01164664], self.intercept: 1.0009806010547675\n",
      "iteration - 887 -> loss: 0.00040311193483820055, self.slope: [1.0116124  1.01165929], self.intercept: 1.0009816752654899\n",
      "iteration - 888 -> loss: 0.0004030799714262536, self.slope: [1.01162499 1.01167194], self.intercept: 1.0009827494085868\n",
      "iteration - 889 -> loss: 0.00040304801326027, self.slope: [1.01163758 1.01168458], self.intercept: 1.0009838234840664\n",
      "iteration - 890 -> loss: 0.0004030160603389848, self.slope: [1.01165017 1.01169723], self.intercept: 1.0009848974919393\n",
      "iteration - 891 -> loss: 0.00040298411266107595, self.slope: [1.01166275 1.01170988], self.intercept: 1.0009859714322142\n",
      "iteration - 892 -> loss: 0.00040295217022523385, self.slope: [1.01167534 1.01172252], self.intercept: 1.0009870453048995\n",
      "iteration - 893 -> loss: 0.0004029202330301499, self.slope: [1.01168792 1.01173516], self.intercept: 1.0009881191100056\n",
      "iteration - 894 -> loss: 0.000402888301074531, self.slope: [1.0117005 1.0117478], self.intercept: 1.0009891928475432\n",
      "iteration - 895 -> loss: 0.00040285637435704546, self.slope: [1.01171309 1.01176045], self.intercept: 1.0009902665175203\n",
      "iteration - 896 -> loss: 0.0004028244528764108, self.slope: [1.01172567 1.01177308], self.intercept: 1.0009913401199468\n",
      "iteration - 897 -> loss: 0.000402792536631299, self.slope: [1.01173825 1.01178572], self.intercept: 1.000992413654831\n",
      "iteration - 898 -> loss: 0.00040276062562041815, self.slope: [1.01175082 1.01179836], self.intercept: 1.0009934871221824\n",
      "iteration - 899 -> loss: 0.0004027287198424416, self.slope: [1.0117634 1.011811 ], self.intercept: 1.000994560522011\n",
      "iteration - 900 -> loss: 0.00040269681929609524, self.slope: [1.01177598 1.01182363], self.intercept: 1.0009956338543258\n",
      "iteration - 901 -> loss: 0.00040266492398005534, self.slope: [1.01178855 1.01183627], self.intercept: 1.000996707119135\n",
      "iteration - 902 -> loss: 0.0004026330338930207, self.slope: [1.01180113 1.0118489 ], self.intercept: 1.000997780316449\n",
      "iteration - 903 -> loss: 0.00040260114903369043, self.slope: [1.0118137  1.01186153], self.intercept: 1.0009988534462773\n",
      "iteration - 904 -> loss: 0.00040256926940074875, self.slope: [1.01182627 1.01187417], self.intercept: 1.0009999265086291\n",
      "iteration - 905 -> loss: 0.0004025373949929177, self.slope: [1.01183884 1.0118868 ], self.intercept: 1.0010009995035125\n",
      "iteration - 906 -> loss: 0.00040250552580887457, self.slope: [1.01185142 1.01189943], self.intercept: 1.0010020724309376\n",
      "iteration - 907 -> loss: 0.00040247366184733056, self.slope: [1.01186398 1.01191205], self.intercept: 1.0010031452909154\n",
      "iteration - 908 -> loss: 0.0004024418031069675, self.slope: [1.01187655 1.01192468], self.intercept: 1.0010042180834529\n",
      "iteration - 909 -> loss: 0.0004024099495864941, self.slope: [1.01188912 1.01193731], self.intercept: 1.0010052908085612\n",
      "iteration - 910 -> loss: 0.00040237810128462316, self.slope: [1.01190169 1.01194993], self.intercept: 1.0010063634662483\n",
      "iteration - 911 -> loss: 0.0004023462582000162, self.slope: [1.01191425 1.01196256], self.intercept: 1.0010074360565238\n",
      "iteration - 912 -> loss: 0.00040231442033141016, self.slope: [1.01192681 1.01197518], self.intercept: 1.0010085085793954\n",
      "iteration - 913 -> loss: 0.00040228258767748963, self.slope: [1.01193938 1.0119878 ], self.intercept: 1.0010095810348747\n",
      "iteration - 914 -> loss: 0.000402250760236962, self.slope: [1.01195194 1.01200043], self.intercept: 1.0010106534229704\n",
      "iteration - 915 -> loss: 0.00040221893800852196, self.slope: [1.0119645  1.01201305], self.intercept: 1.0010117257436908\n",
      "iteration - 916 -> loss: 0.00040218712099086867, self.slope: [1.01197706 1.01202567], self.intercept: 1.001012797997047\n",
      "iteration - 917 -> loss: 0.0004021553091827166, self.slope: [1.01198962 1.01203828], self.intercept: 1.0010138701830458\n",
      "iteration - 918 -> loss: 0.00040212350258276886, self.slope: [1.01200218 1.0120509 ], self.intercept: 1.0010149423016987\n",
      "iteration - 919 -> loss: 0.00040209170118972443, self.slope: [1.01201473 1.01206352], self.intercept: 1.0010160143530131\n",
      "iteration - 920 -> loss: 0.00040205990500226613, self.slope: [1.01202729 1.01207613], self.intercept: 1.001017086336998\n",
      "iteration - 921 -> loss: 0.00040202811401912516, self.slope: [1.01203984 1.01208875], self.intercept: 1.0010181582536652\n",
      "iteration - 922 -> loss: 0.00040199632823900255, self.slope: [1.0120524  1.01210136], self.intercept: 1.0010192301030225\n",
      "iteration - 923 -> loss: 0.0004019645476605872, self.slope: [1.01206495 1.01211397], self.intercept: 1.0010203018850803\n",
      "iteration - 924 -> loss: 0.0004019327722826138, self.slope: [1.0120775  1.01212658], self.intercept: 1.0010213735998452\n",
      "iteration - 925 -> loss: 0.000401901002103759, self.slope: [1.01209005 1.01213919], self.intercept: 1.0010224452473286\n",
      "iteration - 926 -> loss: 0.0004018692371227267, self.slope: [1.0121026 1.0121518], self.intercept: 1.0010235168275414\n",
      "iteration - 927 -> loss: 0.00040183747733825296, self.slope: [1.01211515 1.01216441], self.intercept: 1.0010245883404898\n",
      "iteration - 928 -> loss: 0.00040180572274901226, self.slope: [1.0121277  1.01217702], self.intercept: 1.0010256597861842\n",
      "iteration - 929 -> loss: 0.0004017739733537442, self.slope: [1.01214024 1.01218962], self.intercept: 1.0010267311646337\n",
      "iteration - 930 -> loss: 0.00040174222915114133, self.slope: [1.01215279 1.01220223], self.intercept: 1.0010278024758477\n",
      "iteration - 931 -> loss: 0.0004017104901398992, self.slope: [1.01216533 1.01221483], self.intercept: 1.0010288737198345\n",
      "iteration - 932 -> loss: 0.00040167875631874313, self.slope: [1.01217787 1.01222743], self.intercept: 1.001029944896604\n",
      "iteration - 933 -> loss: 0.0004016470276863818, self.slope: [1.01219042 1.01224004], self.intercept: 1.001031016006165\n",
      "iteration - 934 -> loss: 0.000401615304241514, self.slope: [1.01220296 1.01225264], self.intercept: 1.0010320870485276\n",
      "iteration - 935 -> loss: 0.00040158358598285307, self.slope: [1.0122155  1.01226524], self.intercept: 1.0010331580237013\n",
      "iteration - 936 -> loss: 0.0004015518729091296, self.slope: [1.01222804 1.01227784], self.intercept: 1.0010342289316925\n",
      "iteration - 937 -> loss: 0.000401520165019018, self.slope: [1.01224057 1.01229043], self.intercept: 1.0010352997725147\n",
      "iteration - 938 -> loss: 0.00040148846231126254, self.slope: [1.01225311 1.01230303], self.intercept: 1.0010363705461756\n",
      "iteration - 939 -> loss: 0.00040145676478456967, self.slope: [1.01226565 1.01231563], self.intercept: 1.0010374412526828\n",
      "iteration - 940 -> loss: 0.0004014250724376268, self.slope: [1.01227818 1.01232822], self.intercept: 1.001038511892047\n",
      "iteration - 941 -> loss: 0.00040139338526916347, self.slope: [1.01229072 1.01234081], self.intercept: 1.0010395824642777\n",
      "iteration - 942 -> loss: 0.0004013617032779041, self.slope: [1.01230325 1.01235341], self.intercept: 1.0010406529693838\n",
      "iteration - 943 -> loss: 0.00040133002646254275, self.slope: [1.01231578 1.012366  ], self.intercept: 1.0010417234073743\n",
      "iteration - 944 -> loss: 0.00040129835482181263, self.slope: [1.01232831 1.01237859], self.intercept: 1.001042793778257\n",
      "iteration - 945 -> loss: 0.00040126668835441, self.slope: [1.01234084 1.01239118], self.intercept: 1.0010438640820425\n",
      "iteration - 946 -> loss: 0.000401235027059053, self.slope: [1.01235337 1.01240377], self.intercept: 1.0010449343187402\n",
      "iteration - 947 -> loss: 0.00040120337093447, self.slope: [1.0123659  1.01241636], self.intercept: 1.0010460044883596\n",
      "iteration - 948 -> loss: 0.0004011717199793599, self.slope: [1.01237842 1.01242894], self.intercept: 1.00104707459091\n",
      "iteration - 949 -> loss: 0.00040114007419244464, self.slope: [1.01239095 1.01244153], self.intercept: 1.0010481446263995\n",
      "iteration - 950 -> loss: 0.0004011084335724666, self.slope: [1.01240347 1.01245411], self.intercept: 1.0010492145948382\n",
      "iteration - 951 -> loss: 0.00040107679811809944, self.slope: [1.012416  1.0124667], self.intercept: 1.0010502844962341\n",
      "iteration - 952 -> loss: 0.000401045167828077, self.slope: [1.01242852 1.01247928], self.intercept: 1.001051354330598\n",
      "iteration - 953 -> loss: 0.0004010135427011209, self.slope: [1.01244104 1.01249186], self.intercept: 1.001052424097938\n",
      "iteration - 954 -> loss: 0.00040098192273594566, self.slope: [1.01245356 1.01250444], self.intercept: 1.0010534937982631\n",
      "iteration - 955 -> loss: 0.0004009503079312892, self.slope: [1.01246608 1.01251702], self.intercept: 1.0010545634315828\n",
      "iteration - 956 -> loss: 0.00040091869828584055, self.slope: [1.0124786 1.0125296], self.intercept: 1.0010556329979063\n",
      "iteration - 957 -> loss: 0.0004008870937983468, self.slope: [1.01249112 1.01254217], self.intercept: 1.0010567024972439\n",
      "iteration - 958 -> loss: 0.00040085549446749357, self.slope: [1.01250363 1.01255475], self.intercept: 1.0010577719296039\n",
      "iteration - 959 -> loss: 0.00040082390029203474, self.slope: [1.01251615 1.01256733], self.intercept: 1.0010588412949972\n",
      "iteration - 960 -> loss: 0.0004007923112706669, self.slope: [1.01252866 1.0125799 ], self.intercept: 1.00105991059343\n",
      "iteration - 961 -> loss: 0.0004007607274021311, self.slope: [1.01254118 1.01259247], self.intercept: 1.001060979824913\n",
      "iteration - 962 -> loss: 0.0004007291486851455, self.slope: [1.01255369 1.01260505], self.intercept: 1.0010620489894546\n",
      "iteration - 963 -> loss: 0.0004006975751184067, self.slope: [1.0125662  1.01261762], self.intercept: 1.0010631180870642\n",
      "iteration - 964 -> loss: 0.0004006660067006898, self.slope: [1.01257871 1.01263019], self.intercept: 1.0010641871177512\n",
      "iteration - 965 -> loss: 0.000400634443430661, self.slope: [1.01259122 1.01264276], self.intercept: 1.001065256081525\n",
      "iteration - 966 -> loss: 0.0004006028853070728, self.slope: [1.01260373 1.01265533], self.intercept: 1.0010663249783947\n",
      "iteration - 967 -> loss: 0.0004005713323286468, self.slope: [1.01261623 1.01266789], self.intercept: 1.0010673938083694\n",
      "iteration - 968 -> loss: 0.0004005397844941041, self.slope: [1.01262874 1.01268046], self.intercept: 1.0010684625714583\n",
      "iteration - 969 -> loss: 0.0004005082418021735, self.slope: [1.01264125 1.01269302], self.intercept: 1.00106953126767\n",
      "iteration - 970 -> loss: 0.0004004767042515674, self.slope: [1.01265375 1.01270559], self.intercept: 1.0010705998970164\n",
      "iteration - 971 -> loss: 0.0004004451718410265, self.slope: [1.01266625 1.01271815], self.intercept: 1.0010716684595033\n",
      "iteration - 972 -> loss: 0.00040041364456927053, self.slope: [1.01267875 1.01273071], self.intercept: 1.00107273695514\n",
      "iteration - 973 -> loss: 0.0004003821224350142, self.slope: [1.01269126 1.01274327], self.intercept: 1.001073805383939\n",
      "iteration - 974 -> loss: 0.0004003506054370115, self.slope: [1.01270375 1.01275583], self.intercept: 1.0010748737459056\n",
      "iteration - 975 -> loss: 0.0004003190935739714, self.slope: [1.01271625 1.01276839], self.intercept: 1.0010759420410507\n",
      "iteration - 976 -> loss: 0.00040028758684462176, self.slope: [1.01272875 1.01278095], self.intercept: 1.0010770102693827\n",
      "iteration - 977 -> loss: 0.0004002560852476986, self.slope: [1.01274125 1.01279351], self.intercept: 1.0010780784309126\n",
      "iteration - 978 -> loss: 0.0004002245887819202, self.slope: [1.01275374 1.01280606], self.intercept: 1.001079146525648\n",
      "iteration - 979 -> loss: 0.00040019309744602024, self.slope: [1.01276624 1.01281862], self.intercept: 1.001080214553597\n",
      "iteration - 980 -> loss: 0.00040016161123871167, self.slope: [1.01277873 1.01283117], self.intercept: 1.0010812825147721\n",
      "iteration - 981 -> loss: 0.00040013013015876013, self.slope: [1.01279122 1.01284373], self.intercept: 1.0010823504091781\n",
      "iteration - 982 -> loss: 0.00040009865420486643, self.slope: [1.01280372 1.01285628], self.intercept: 1.0010834182368278\n",
      "iteration - 983 -> loss: 0.0004000671833757874, self.slope: [1.01281621 1.01286883], self.intercept: 1.0010844859977286\n",
      "iteration - 984 -> loss: 0.00040003571767021587, self.slope: [1.0128287  1.01288138], self.intercept: 1.0010855536918912\n",
      "iteration - 985 -> loss: 0.00040000425708691987, self.slope: [1.01284119 1.01289393], self.intercept: 1.0010866213193232\n",
      "iteration - 986 -> loss: 0.0003999728016246124, self.slope: [1.01285367 1.01290648], self.intercept: 1.001087688880034\n",
      "iteration - 987 -> loss: 0.00039994135128202594, self.slope: [1.01286616 1.01291902], self.intercept: 1.0010887563740325\n",
      "iteration - 988 -> loss: 0.000399909906057898, self.slope: [1.01287864 1.01293157], self.intercept: 1.0010898238013297\n",
      "iteration - 989 -> loss: 0.0003998784659509619, self.slope: [1.01289113 1.01294411], self.intercept: 1.0010908911619336\n",
      "iteration - 990 -> loss: 0.0003998470309599328, self.slope: [1.01290361 1.01295666], self.intercept: 1.0010919584558515\n",
      "iteration - 991 -> loss: 0.0003998156010835916, self.slope: [1.01291609 1.0129692 ], self.intercept: 1.0010930256830937\n",
      "iteration - 992 -> loss: 0.00039978417632061786, self.slope: [1.01292858 1.01298174], self.intercept: 1.0010940928436691\n",
      "iteration - 993 -> loss: 0.00039975275666977866, self.slope: [1.01294106 1.01299428], self.intercept: 1.0010951599375886\n",
      "iteration - 994 -> loss: 0.000399721342129813, self.slope: [1.01295354 1.01300682], self.intercept: 1.0010962269648604\n",
      "iteration - 995 -> loss: 0.00039968993269943006, self.slope: [1.01296601 1.01301936], self.intercept: 1.0010972939254932\n",
      "iteration - 996 -> loss: 0.00039965852837737994, self.slope: [1.01297849 1.0130319 ], self.intercept: 1.0010983608194957\n",
      "iteration - 997 -> loss: 0.0003996271291624071, self.slope: [1.01299097 1.01304444], self.intercept: 1.001099427646877\n",
      "iteration - 998 -> loss: 0.0003995957350532369, self.slope: [1.01300344 1.01305697], self.intercept: 1.0011004944076471\n",
      "iteration - 999 -> loss: 0.0003995643460486154, self.slope: [1.01301592 1.01306951], self.intercept: 1.0011015611018153\n",
      "iteration - 1000 -> loss: 0.00039953296214728136, self.slope: [1.01302839 1.01308204], self.intercept: 1.001102627729391\n",
      "iteration - 1001 -> loss: 0.0003995015833479577, self.slope: [1.01304086 1.01309457], self.intercept: 1.001103694290383\n",
      "iteration - 1002 -> loss: 0.0003994702096493961, self.slope: [1.01305333 1.01310711], self.intercept: 1.0011047607847996\n",
      "iteration - 1003 -> loss: 0.0003994388410503237, self.slope: [1.0130658  1.01311964], self.intercept: 1.0011058272126494\n",
      "iteration - 1004 -> loss: 0.00039940747754949594, self.slope: [1.01307827 1.01313217], self.intercept: 1.0011068935739427\n",
      "iteration - 1005 -> loss: 0.00039937611914564236, self.slope: [1.01309074 1.01314469], self.intercept: 1.0011079598686876\n",
      "iteration - 1006 -> loss: 0.0003993447658375099, self.slope: [1.01310321 1.01315722], self.intercept: 1.0011090260968936\n",
      "iteration - 1007 -> loss: 0.0003993134176238438, self.slope: [1.01311567 1.01316975], self.intercept: 1.0011100922585705\n",
      "iteration - 1008 -> loss: 0.00039928207450335524, self.slope: [1.01312814 1.01318228], self.intercept: 1.001111158353726\n",
      "iteration - 1009 -> loss: 0.0003992507364748109, self.slope: [1.0131406 1.0131948], self.intercept: 1.0011122243823711\n",
      "iteration - 1010 -> loss: 0.0003992194035369665, self.slope: [1.01315307 1.01320732], self.intercept: 1.001113290344513\n",
      "iteration - 1011 -> loss: 0.0003991880756885293, self.slope: [1.01316553 1.01321985], self.intercept: 1.0011143562401632\n",
      "iteration - 1012 -> loss: 0.00039915675292826066, self.slope: [1.01317799 1.01323237], self.intercept: 1.0011154220693275\n",
      "iteration - 1013 -> loss: 0.0003991254352549047, self.slope: [1.01319045 1.01324489], self.intercept: 1.0011164878320167\n",
      "iteration - 1014 -> loss: 0.0003990941226672186, self.slope: [1.01320291 1.01325741], self.intercept: 1.0011175535282417\n",
      "iteration - 1015 -> loss: 0.00039906281516391586, self.slope: [1.01321537 1.01326993], self.intercept: 1.0011186191580077\n",
      "iteration - 1016 -> loss: 0.0003990315127437619, self.slope: [1.01322782 1.01328244], self.intercept: 1.0011196847213266\n",
      "iteration - 1017 -> loss: 0.0003990002154054858, self.slope: [1.01324028 1.01329496], self.intercept: 1.0011207502182076\n",
      "iteration - 1018 -> loss: 0.00039896892314785366, self.slope: [1.01325273 1.01330748], self.intercept: 1.0011218156486579\n",
      "iteration - 1019 -> loss: 0.0003989376359695982, self.slope: [1.01326519 1.01331999], self.intercept: 1.001122881012687\n",
      "iteration - 1020 -> loss: 0.00039890635386946485, self.slope: [1.01327764 1.0133325 ], self.intercept: 1.0011239463103054\n",
      "iteration - 1021 -> loss: 0.0003988750768461912, self.slope: [1.01329009 1.01334502], self.intercept: 1.0011250115415236\n",
      "iteration - 1022 -> loss: 0.000398843804898555, self.slope: [1.01330254 1.01335753], self.intercept: 1.001126076706345\n",
      "iteration - 1023 -> loss: 0.00039881253802526504, self.slope: [1.01331499 1.01337004], self.intercept: 1.0011271418047833\n",
      "iteration - 1024 -> loss: 0.00039878127622509365, self.slope: [1.01332744 1.01338255], self.intercept: 1.0011282068368472\n",
      "iteration - 1025 -> loss: 0.00039875001949679205, self.slope: [1.01333989 1.01339506], self.intercept: 1.0011292718025429\n",
      "iteration - 1026 -> loss: 0.00039871876783908767, self.slope: [1.01335233 1.01340756], self.intercept: 1.0011303367018825\n",
      "iteration - 1027 -> loss: 0.00039868752125074965, self.slope: [1.01336478 1.01342007], self.intercept: 1.0011314015348742\n",
      "iteration - 1028 -> loss: 0.000398656279730523, self.slope: [1.01337722 1.01343258], self.intercept: 1.0011324663015264\n",
      "iteration - 1029 -> loss: 0.0003986250432771451, self.slope: [1.01338967 1.01344508], self.intercept: 1.0011335310018494\n",
      "iteration - 1030 -> loss: 0.0003985938118893845, self.slope: [1.01340211 1.01345758], self.intercept: 1.0011345956358506\n",
      "iteration - 1031 -> loss: 0.0003985625855659699, self.slope: [1.01341455 1.01347009], self.intercept: 1.0011356602035406\n",
      "iteration - 1032 -> loss: 0.0003985313643056698, self.slope: [1.01342699 1.01348259], self.intercept: 1.0011367247049283\n",
      "iteration - 1033 -> loss: 0.0003985001481072188, self.slope: [1.01343943 1.01349509], self.intercept: 1.0011377891400206\n",
      "iteration - 1034 -> loss: 0.00039846893696940036, self.slope: [1.01345187 1.01350759], self.intercept: 1.001138853508829\n",
      "iteration - 1035 -> loss: 0.00039843773089095233, self.slope: [1.01346431 1.01352009], self.intercept: 1.0011399178113627\n",
      "iteration - 1036 -> loss: 0.00039840652987060694, self.slope: [1.01347674 1.01353258], self.intercept: 1.0011409820476298\n",
      "iteration - 1037 -> loss: 0.00039837533390712663, self.slope: [1.01348918 1.01354508], self.intercept: 1.0011420462176375\n",
      "iteration - 1038 -> loss: 0.00039834414299928886, self.slope: [1.01350161 1.01355758], self.intercept: 1.0011431103213986\n",
      "iteration - 1039 -> loss: 0.00039831295714582403, self.slope: [1.01351405 1.01357007], self.intercept: 1.0011441743589193\n",
      "iteration - 1040 -> loss: 0.00039828177634548926, self.slope: [1.01352648 1.01358256], self.intercept: 1.0011452383302095\n",
      "iteration - 1041 -> loss: 0.0003982506005970417, self.slope: [1.01353891 1.01359506], self.intercept: 1.0011463022352791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 1042 -> loss: 0.00039821942989924484, self.slope: [1.01355134 1.01360755], self.intercept: 1.0011473660741346\n",
      "iteration - 1043 -> loss: 0.00039818826425084164, self.slope: [1.01356377 1.01362004], self.intercept: 1.0011484298467856\n",
      "iteration - 1044 -> loss: 0.000398157103650592, self.slope: [1.0135762  1.01363253], self.intercept: 1.0011494935532435\n",
      "iteration - 1045 -> loss: 0.0003981259480972501, self.slope: [1.01358863 1.01364502], self.intercept: 1.0011505571935158\n",
      "iteration - 1046 -> loss: 0.0003980947975895726, self.slope: [1.01360105 1.0136575 ], self.intercept: 1.001151620767613\n",
      "iteration - 1047 -> loss: 0.0003980636521263342, self.slope: [1.01361348 1.01366999], self.intercept: 1.0011526842755425\n",
      "iteration - 1048 -> loss: 0.0003980325117062691, self.slope: [1.0136259  1.01368248], self.intercept: 1.0011537477173138\n",
      "iteration - 1049 -> loss: 0.000398001376328142, self.slope: [1.01363832 1.01369496], self.intercept: 1.0011548110929356\n",
      "iteration - 1050 -> loss: 0.000397970245990723, self.slope: [1.01365075 1.01370744], self.intercept: 1.0011558744024174\n",
      "iteration - 1051 -> loss: 0.00039793912069276143, self.slope: [1.01366317 1.01371993], self.intercept: 1.001156937645767\n",
      "iteration - 1052 -> loss: 0.00039790800043300686, self.slope: [1.01367559 1.01373241], self.intercept: 1.0011580008229939\n",
      "iteration - 1053 -> loss: 0.00039787688521024947, self.slope: [1.01368801 1.01374489], self.intercept: 1.0011590639341084\n",
      "iteration - 1054 -> loss: 0.0003978457750232025, self.slope: [1.01370043 1.01375737], self.intercept: 1.0011601269791184\n",
      "iteration - 1055 -> loss: 0.00039781466987066547, self.slope: [1.01371284 1.01376985], self.intercept: 1.0011611899580324\n",
      "iteration - 1056 -> loss: 0.00039778356975140043, self.slope: [1.01372526 1.01378232], self.intercept: 1.0011622528708617\n",
      "iteration - 1057 -> loss: 0.0003977524746641344, self.slope: [1.01373767 1.0137948 ], self.intercept: 1.0011633157176123\n",
      "iteration - 1058 -> loss: 0.0003977213846076609, self.slope: [1.01375009 1.01380728], self.intercept: 1.0011643784982953\n",
      "iteration - 1059 -> loss: 0.00039769029958074164, self.slope: [1.0137625  1.01381975], self.intercept: 1.001165441212919\n",
      "iteration - 1060 -> loss: 0.00039765921958210377, self.slope: [1.01377491 1.01383222], self.intercept: 1.0011665038614914\n",
      "iteration - 1061 -> loss: 0.0003976281446105491, self.slope: [1.01378732 1.0138447 ], self.intercept: 1.0011675664440236\n",
      "iteration - 1062 -> loss: 0.00039759707466483163, self.slope: [1.01379973 1.01385717], self.intercept: 1.0011686289605235\n",
      "iteration - 1063 -> loss: 0.00039756600974371085, self.slope: [1.01381214 1.01386964], self.intercept: 1.0011696914109995\n",
      "iteration - 1064 -> loss: 0.000397534949845938, self.slope: [1.01382455 1.01388211], self.intercept: 1.0011707537954617\n",
      "iteration - 1065 -> loss: 0.00039750389497030637, self.slope: [1.01383696 1.01389457], self.intercept: 1.0011718161139183\n",
      "iteration - 1066 -> loss: 0.0003974728451155511, self.slope: [1.01384936 1.01390704], self.intercept: 1.00117287836638\n",
      "iteration - 1067 -> loss: 0.0003974418002804577, self.slope: [1.01386177 1.01391951], self.intercept: 1.0011739405528535\n",
      "iteration - 1068 -> loss: 0.0003974107604637898, self.slope: [1.01387417 1.01393197], self.intercept: 1.001175002673349\n",
      "iteration - 1069 -> loss: 0.0003973797256643096, self.slope: [1.01388658 1.01394444], self.intercept: 1.0011760647278747\n",
      "iteration - 1070 -> loss: 0.0003973486958807935, self.slope: [1.01389898 1.0139569 ], self.intercept: 1.0011771267164398\n",
      "iteration - 1071 -> loss: 0.0003973176711119786, self.slope: [1.01391138 1.01396936], self.intercept: 1.0011781886390532\n",
      "iteration - 1072 -> loss: 0.00039728665135666934, self.slope: [1.01392378 1.01398183], self.intercept: 1.0011792504957253\n",
      "iteration - 1073 -> loss: 0.00039725563661360445, self.slope: [1.01393618 1.01399429], self.intercept: 1.0011803122864644\n",
      "iteration - 1074 -> loss: 0.00039722462688156955, self.slope: [1.01394858 1.01400675], self.intercept: 1.0011813740112783\n",
      "iteration - 1075 -> loss: 0.0003971936221593216, self.slope: [1.01396097 1.0140192 ], self.intercept: 1.0011824356701748\n",
      "iteration - 1076 -> loss: 0.0003971626224456469, self.slope: [1.01397337 1.01403166], self.intercept: 1.0011834972631675\n",
      "iteration - 1077 -> loss: 0.00039713162773931485, self.slope: [1.01398576 1.01404412], self.intercept: 1.0011845587902615\n",
      "iteration - 1078 -> loss: 0.00039710063803907926, self.slope: [1.01399816 1.01405657], self.intercept: 1.0011856202514657\n",
      "iteration - 1079 -> loss: 0.0003970696533437091, self.slope: [1.01401055 1.01406903], self.intercept: 1.0011866816467911\n",
      "iteration - 1080 -> loss: 0.0003970386736519855, self.slope: [1.01402294 1.01408148], self.intercept: 1.001187742976246\n",
      "iteration - 1081 -> loss: 0.0003970076989626818, self.slope: [1.01403533 1.01409393], self.intercept: 1.001188804239838\n",
      "iteration - 1082 -> loss: 0.00039697672927456354, self.slope: [1.01404772 1.01410638], self.intercept: 1.0011898654375784\n",
      "iteration - 1083 -> loss: 0.00039694576458638845, self.slope: [1.01406011 1.01411884], self.intercept: 1.0011909265694743\n",
      "iteration - 1084 -> loss: 0.0003969148048969726, self.slope: [1.0140725  1.01413128], self.intercept: 1.0011919876355349\n",
      "iteration - 1085 -> loss: 0.0003968838502050333, self.slope: [1.01408489 1.01414373], self.intercept: 1.00119304863577\n",
      "iteration - 1086 -> loss: 0.00039685290050937795, self.slope: [1.01409727 1.01415618], self.intercept: 1.0011941095701877\n",
      "iteration - 1087 -> loss: 0.000396821955808779, self.slope: [1.01410966 1.01416863], self.intercept: 1.0011951704387974\n",
      "iteration - 1088 -> loss: 0.00039679101610199085, self.slope: [1.01412204 1.01418107], self.intercept: 1.0011962312416078\n",
      "iteration - 1089 -> loss: 0.000396760081387824, self.slope: [1.01413442 1.01419352], self.intercept: 1.001197291978629\n",
      "iteration - 1090 -> loss: 0.0003967291516650087, self.slope: [1.0141468  1.01420596], self.intercept: 1.0011983526498685\n",
      "iteration - 1091 -> loss: 0.0003966982269323606, self.slope: [1.01415919 1.0142184 ], self.intercept: 1.0011994132553355\n",
      "iteration - 1092 -> loss: 0.0003966673071886255, self.slope: [1.01417156 1.01423084], self.intercept: 1.0012004737950384\n",
      "iteration - 1093 -> loss: 0.0003966363924325889, self.slope: [1.01418394 1.01424328], self.intercept: 1.0012015342689877\n",
      "iteration - 1094 -> loss: 0.0003966054826630407, self.slope: [1.01419632 1.01425572], self.intercept: 1.0012025946771912\n",
      "iteration - 1095 -> loss: 0.00039657457787873896, self.slope: [1.0142087  1.01426816], self.intercept: 1.0012036550196586\n",
      "iteration - 1096 -> loss: 0.0003965436780784682, self.slope: [1.01422107 1.0142806 ], self.intercept: 1.0012047152963988\n",
      "iteration - 1097 -> loss: 0.0003965127832609873, self.slope: [1.01423345 1.01429304], self.intercept: 1.0012057755074195\n",
      "iteration - 1098 -> loss: 0.00039648189342510675, self.slope: [1.01424582 1.01430547], self.intercept: 1.0012068356527297\n",
      "iteration - 1099 -> loss: 0.0003964510085696113, self.slope: [1.01425819 1.01431791], self.intercept: 1.0012078957323391\n",
      "iteration - 1100 -> loss: 0.0003964201286932376, self.slope: [1.01427057 1.01433034], self.intercept: 1.001208955746256\n",
      "iteration - 1101 -> loss: 0.00039638925379479174, self.slope: [1.01428294 1.01434277], self.intercept: 1.0012100156944905\n",
      "iteration - 1102 -> loss: 0.0003963583838730374, self.slope: [1.01429531 1.0143552 ], self.intercept: 1.0012110755770505\n",
      "iteration - 1103 -> loss: 0.00039632751892677896, self.slope: [1.01430768 1.01436763], self.intercept: 1.0012121353939467\n",
      "iteration - 1104 -> loss: 0.0003962966589547745, self.slope: [1.01432004 1.01438006], self.intercept: 1.0012131951451835\n",
      "iteration - 1105 -> loss: 0.0003962658039558161, self.slope: [1.01433241 1.01439249], self.intercept: 1.001214254830775\n",
      "iteration - 1106 -> loss: 0.0003962349539286731, self.slope: [1.01434478 1.01440492], self.intercept: 1.0012153144507272\n",
      "iteration - 1107 -> loss: 0.00039620410887215526, self.slope: [1.01435714 1.01441735], self.intercept: 1.0012163740050501\n",
      "iteration - 1108 -> loss: 0.00039617326878501854, self.slope: [1.0143695  1.01442977], self.intercept: 1.001217433493752\n",
      "iteration - 1109 -> loss: 0.00039614243366604913, self.slope: [1.01438187 1.0144422 ], self.intercept: 1.001218492916843\n",
      "iteration - 1110 -> loss: 0.0003961116035140358, self.slope: [1.01439423 1.01445462], self.intercept: 1.0012195522743301\n",
      "iteration - 1111 -> loss: 0.0003960807783277511, self.slope: [1.01440659 1.01446704], self.intercept: 1.0012206115662234\n",
      "iteration - 1112 -> loss: 0.00039604995810599666, self.slope: [1.01441895 1.01447946], self.intercept: 1.0012216707925319\n",
      "iteration - 1113 -> loss: 0.00039601914284753724, self.slope: [1.01443131 1.01449188], self.intercept: 1.0012227299532652\n",
      "iteration - 1114 -> loss: 0.0003959883325511784, self.slope: [1.01444366 1.0145043 ], self.intercept: 1.00122378904843\n",
      "iteration - 1115 -> loss: 0.00039595752721569065, self.slope: [1.01445602 1.01451672], self.intercept: 1.0012248480780368\n",
      "iteration - 1116 -> loss: 0.00039592672683985523, self.slope: [1.01446838 1.01452914], self.intercept: 1.001225907042095\n",
      "iteration - 1117 -> loss: 0.0003958959314224771, self.slope: [1.01448073 1.01454156], self.intercept: 1.0012269659406123\n",
      "iteration - 1118 -> loss: 0.00039586514096231763, self.slope: [1.01449308 1.01455397], self.intercept: 1.0012280247735956\n",
      "iteration - 1119 -> loss: 0.00039583435545818683, self.slope: [1.01450544 1.01456639], self.intercept: 1.0012290835410562\n",
      "iteration - 1120 -> loss: 0.000395803574908852, self.slope: [1.01451779 1.0145788 ], self.intercept: 1.0012301422430037\n",
      "iteration - 1121 -> loss: 0.00039577279931309793, self.slope: [1.01453014 1.01459121], self.intercept: 1.0012312008794453\n",
      "iteration - 1122 -> loss: 0.00039574202866972467, self.slope: [1.01454249 1.01460363], self.intercept: 1.0012322594503904\n",
      "iteration - 1123 -> loss: 0.00039571126297753036, self.slope: [1.01455484 1.01461604], self.intercept: 1.0012333179558488\n",
      "iteration - 1124 -> loss: 0.0003956805022352813, self.slope: [1.01456718 1.01462845], self.intercept: 1.0012343763958278\n",
      "iteration - 1125 -> loss: 0.0003956497464417913, self.slope: [1.01457953 1.01464085], self.intercept: 1.0012354347703376\n",
      "iteration - 1126 -> loss: 0.0003956189955958148, self.slope: [1.01459188 1.01465326], self.intercept: 1.0012364930793878\n",
      "iteration - 1127 -> loss: 0.0003955882496961713, self.slope: [1.01460422 1.01466567], self.intercept: 1.0012375513229852\n",
      "iteration - 1128 -> loss: 0.00039555750874163085, self.slope: [1.01461656 1.01467807], self.intercept: 1.0012386095011385\n",
      "iteration - 1129 -> loss: 0.00039552677273100716, self.slope: [1.01462891 1.01469048], self.intercept: 1.0012396676138584\n",
      "iteration - 1130 -> loss: 0.0003954960416630851, self.slope: [1.01464125 1.01470288], self.intercept: 1.001240725661153\n",
      "iteration - 1131 -> loss: 0.00039546531553662543, self.slope: [1.01465359 1.01471529], self.intercept: 1.0012417836430325\n",
      "iteration - 1132 -> loss: 0.00039543459435046073, self.slope: [1.01466593 1.01472769], self.intercept: 1.001242841559504\n",
      "iteration - 1133 -> loss: 0.0003954038781033607, self.slope: [1.01467827 1.01474009], self.intercept: 1.0012438994105763\n",
      "iteration - 1134 -> loss: 0.00039537316679411397, self.slope: [1.0146906  1.01475249], self.intercept: 1.001244957196258\n",
      "iteration - 1135 -> loss: 0.00039534246042152244, self.slope: [1.01470294 1.01476489], self.intercept: 1.0012460149165587\n",
      "iteration - 1136 -> loss: 0.0003953117589843755, self.slope: [1.01471528 1.01477728], self.intercept: 1.0012470725714882\n",
      "iteration - 1137 -> loss: 0.000395281062481465, self.slope: [1.01472761 1.01478968], self.intercept: 1.001248130161054\n",
      "iteration - 1138 -> loss: 0.0003952503709115984, self.slope: [1.01473994 1.01480208], self.intercept: 1.0012491876852658\n",
      "iteration - 1139 -> loss: 0.00039521968427356726, self.slope: [1.01475228 1.01481447], self.intercept: 1.0012502451441319\n",
      "iteration - 1140 -> loss: 0.0003951890025661551, self.slope: [1.01476461 1.01482687], self.intercept: 1.0012513025376615\n",
      "iteration - 1141 -> loss: 0.00039515832578817384, self.slope: [1.01477694 1.01483926], self.intercept: 1.0012523598658627\n",
      "iteration - 1142 -> loss: 0.000395127653938384, self.slope: [1.01478927 1.01485165], self.intercept: 1.0012534171287448\n",
      "iteration - 1143 -> loss: 0.0003950969870156082, self.slope: [1.0148016  1.01486404], self.intercept: 1.0012544743263159\n",
      "iteration - 1144 -> loss: 0.000395066325018638, self.slope: [1.01481392 1.01487643], self.intercept: 1.0012555314585858\n",
      "iteration - 1145 -> loss: 0.00039503566794628575, self.slope: [1.01482625 1.01488882], self.intercept: 1.0012565885255635\n",
      "iteration - 1146 -> loss: 0.0003950050157973296, self.slope: [1.01483858 1.01490121], self.intercept: 1.001257645527257\n",
      "iteration - 1147 -> loss: 0.0003949743685705659, self.slope: [1.0148509  1.01491359], self.intercept: 1.0012587024636759\n",
      "iteration - 1148 -> loss: 0.0003949437262648007, self.slope: [1.01486322 1.01492598], self.intercept: 1.0012597593348271\n",
      "iteration - 1149 -> loss: 0.0003949130888788141, self.slope: [1.01487555 1.01493837], self.intercept: 1.001260816140723\n",
      "iteration - 1150 -> loss: 0.00039488245641144617, self.slope: [1.01488787 1.01495075], self.intercept: 1.0012618728813698\n",
      "iteration - 1151 -> loss: 0.00039485182886146367, self.slope: [1.01490019 1.01496313], self.intercept: 1.0012629295567776\n",
      "iteration - 1152 -> loss: 0.0003948212062276649, self.slope: [1.01491251 1.01497551], self.intercept: 1.0012639861669537\n",
      "iteration - 1153 -> loss: 0.0003947905885088641, self.slope: [1.01492483 1.0149879 ], self.intercept: 1.0012650427119087\n",
      "iteration - 1154 -> loss: 0.00039475997570385864, self.slope: [1.01493714 1.01500028], self.intercept: 1.0012660991916493\n",
      "iteration - 1155 -> loss: 0.0003947293678114437, self.slope: [1.01494946 1.01501265], self.intercept: 1.0012671556061878\n",
      "iteration - 1156 -> loss: 0.0003946987648304196, self.slope: [1.01496178 1.01502503], self.intercept: 1.0012682119555287\n",
      "iteration - 1157 -> loss: 0.0003946681667595877, self.slope: [1.01497409 1.01503741], self.intercept: 1.001269268239684\n",
      "iteration - 1158 -> loss: 0.00039463757359775695, self.slope: [1.0149864  1.01504979], self.intercept: 1.0012703244586607\n",
      "iteration - 1159 -> loss: 0.00039460698534372207, self.slope: [1.01499872 1.01506216], self.intercept: 1.0012713806124685\n",
      "iteration - 1160 -> loss: 0.0003945764019962935, self.slope: [1.01501103 1.01507454], self.intercept: 1.0012724367011168\n",
      "iteration - 1161 -> loss: 0.00039454582355428407, self.slope: [1.01502334 1.01508691], self.intercept: 1.0012734927246136\n",
      "iteration - 1162 -> loss: 0.0003945152500164513, self.slope: [1.01503565 1.01509928], self.intercept: 1.0012745486829662\n",
      "iteration - 1163 -> loss: 0.0003944846813816562, self.slope: [1.01504796 1.01511165], self.intercept: 1.0012756045761855\n",
      "iteration - 1164 -> loss: 0.00039445411764866645, self.slope: [1.01506027 1.01512402], self.intercept: 1.001276660404282\n",
      "iteration - 1165 -> loss: 0.0003944235588162982, self.slope: [1.01507257 1.01513639], self.intercept: 1.0012777161672606\n",
      "iteration - 1166 -> loss: 0.0003943930048833552, self.slope: [1.01508488 1.01514876], self.intercept: 1.0012787718651313\n",
      "iteration - 1167 -> loss: 0.0003943624558486572, self.slope: [1.01509718 1.01516113], self.intercept: 1.0012798274979025\n",
      "iteration - 1168 -> loss: 0.0003943319117109756, self.slope: [1.01510949 1.01517349], self.intercept: 1.0012808830655837\n",
      "iteration - 1169 -> loss: 0.000394301372469157, self.slope: [1.01512179 1.01518586], self.intercept: 1.0012819385681835\n",
      "iteration - 1170 -> loss: 0.0003942708381219854, self.slope: [1.01513409 1.01519822], self.intercept: 1.0012829940057129\n",
      "iteration - 1171 -> loss: 0.00039424030866825726, self.slope: [1.01514639 1.01521059], self.intercept: 1.0012840493781783\n",
      "iteration - 1172 -> loss: 0.00039420978410679655, self.slope: [1.01515869 1.01522295], self.intercept: 1.0012851046855884\n",
      "iteration - 1173 -> loss: 0.00039417926443641746, self.slope: [1.01517099 1.01523531], self.intercept: 1.0012861599279521\n",
      "iteration - 1174 -> loss: 0.00039414874965592624, self.slope: [1.01518329 1.01524767], self.intercept: 1.001287215105279\n",
      "iteration - 1175 -> loss: 0.00039411823976410803, self.slope: [1.01519558 1.01526003], self.intercept: 1.0012882702175778\n",
      "iteration - 1176 -> loss: 0.00039408773475980047, self.slope: [1.01520788 1.01527239], self.intercept: 1.0012893252648574\n",
      "iteration - 1177 -> loss: 0.00039405723464179055, self.slope: [1.01522017 1.01528474], self.intercept: 1.0012903802471251\n",
      "iteration - 1178 -> loss: 0.0003940267394089017, self.slope: [1.01523247 1.0152971 ], self.intercept: 1.001291435164392\n",
      "iteration - 1179 -> loss: 0.0003939962490599246, self.slope: [1.01524476 1.01530946], self.intercept: 1.001292490016665\n",
      "iteration - 1180 -> loss: 0.0003939657635937054, self.slope: [1.01525705 1.01532181], self.intercept: 1.0012935448039533\n",
      "iteration - 1181 -> loss: 0.0003939352830090139, self.slope: [1.01526934 1.01533416], self.intercept: 1.001294599526266\n",
      "iteration - 1182 -> loss: 0.0003939048073047007, self.slope: [1.01528163 1.01534652], self.intercept: 1.0012956541836113\n",
      "iteration - 1183 -> loss: 0.0003938743364795748, self.slope: [1.01529392 1.01535887], self.intercept: 1.001296708775999\n",
      "iteration - 1184 -> loss: 0.0003938438705323994, self.slope: [1.01530621 1.01537122], self.intercept: 1.0012977633034377\n",
      "iteration - 1185 -> loss: 0.00039381340946202404, self.slope: [1.01531849 1.01538357], self.intercept: 1.0012988177659339\n",
      "iteration - 1186 -> loss: 0.000393782953267261, self.slope: [1.01533078 1.01539592], self.intercept: 1.0012998721634985\n",
      "iteration - 1187 -> loss: 0.00039375250194692487, self.slope: [1.01534306 1.01540826], self.intercept: 1.0013009264961406\n",
      "iteration - 1188 -> loss: 0.00039372205549982283, self.slope: [1.01535535 1.01542061], self.intercept: 1.0013019807638686\n",
      "iteration - 1189 -> loss: 0.0003936916139247636, self.slope: [1.01536763 1.01543296], self.intercept: 1.0013030349666907\n",
      "iteration - 1190 -> loss: 0.0003936611772205721, self.slope: [1.01537991 1.0154453 ], self.intercept: 1.0013040891046159\n",
      "iteration - 1191 -> loss: 0.0003936307453860509, self.slope: [1.01539219 1.01545765], self.intercept: 1.0013051431776532\n",
      "iteration - 1192 -> loss: 0.000393600318420043, self.slope: [1.01540447 1.01546999], self.intercept: 1.0013061971858106\n",
      "iteration - 1193 -> loss: 0.0003935698963213169, self.slope: [1.01541675 1.01548233], self.intercept: 1.001307251129098\n",
      "iteration - 1194 -> loss: 0.0003935394790887362, self.slope: [1.01542903 1.01549467], self.intercept: 1.0013083050075229\n",
      "iteration - 1195 -> loss: 0.0003935090667210941, self.slope: [1.01544131 1.01550701], self.intercept: 1.001309358821095\n",
      "iteration - 1196 -> loss: 0.0003934786592172026, self.slope: [1.01545358 1.01551935], self.intercept: 1.0013104125698225\n",
      "iteration - 1197 -> loss: 0.0003934482565758965, self.slope: [1.01546586 1.01553169], self.intercept: 1.0013114662537137\n",
      "iteration - 1198 -> loss: 0.0003934178587959658, self.slope: [1.01547813 1.01554402], self.intercept: 1.0013125198727781\n",
      "iteration - 1199 -> loss: 0.0003933874658762624, self.slope: [1.0154904  1.01555636], self.intercept: 1.0013135734270244\n",
      "iteration - 1200 -> loss: 0.000393357077815587, self.slope: [1.01550268 1.01556869], self.intercept: 1.001314626916462\n",
      "iteration - 1201 -> loss: 0.0003933266946127405, self.slope: [1.01551495 1.01558103], self.intercept: 1.0013156803410983\n",
      "iteration - 1202 -> loss: 0.00039329631626658016, self.slope: [1.01552722 1.01559336], self.intercept: 1.0013167337009428\n",
      "iteration - 1203 -> loss: 0.0003932659427758701, self.slope: [1.01553948 1.01560569], self.intercept: 1.001317786996004\n",
      "iteration - 1204 -> loss: 0.0003932355741395038, self.slope: [1.01555175 1.01561802], self.intercept: 1.0013188402262896\n",
      "iteration - 1205 -> loss: 0.00039320521035624836, self.slope: [1.01556402 1.01563035], self.intercept: 1.0013198933918095\n",
      "iteration - 1206 -> loss: 0.0003931748514249391, self.slope: [1.01557629 1.01564268], self.intercept: 1.0013209464925727\n",
      "iteration - 1207 -> loss: 0.00039314449734441354, self.slope: [1.01558855 1.01565501], self.intercept: 1.001321999528588\n",
      "iteration - 1208 -> loss: 0.0003931141481134591, self.slope: [1.01560081 1.01566734], self.intercept: 1.0013230524998629\n",
      "iteration - 1209 -> loss: 0.0003930838037309064, self.slope: [1.01561308 1.01567966], self.intercept: 1.0013241054064066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 1210 -> loss: 0.0003930534641955955, self.slope: [1.01562534 1.01569199], self.intercept: 1.0013251582482274\n",
      "iteration - 1211 -> loss: 0.0003930231295063315, self.slope: [1.0156376  1.01570431], self.intercept: 1.0013262110253356\n",
      "iteration - 1212 -> loss: 0.000392992799661947, self.slope: [1.01564986 1.01571664], self.intercept: 1.0013272637377386\n",
      "iteration - 1213 -> loss: 0.0003929624746612806, self.slope: [1.01566212 1.01572896], self.intercept: 1.0013283163854465\n",
      "iteration - 1214 -> loss: 0.0003929321545031128, self.slope: [1.01567438 1.01574128], self.intercept: 1.0013293689684668\n",
      "iteration - 1215 -> loss: 0.00039290183918630337, self.slope: [1.01568663 1.0157536 ], self.intercept: 1.001330421486808\n",
      "iteration - 1216 -> loss: 0.0003928715287096625, self.slope: [1.01569889 1.01576592], self.intercept: 1.0013314739404788\n",
      "iteration - 1217 -> loss: 0.0003928412230720347, self.slope: [1.01571114 1.01577824], self.intercept: 1.001332526329489\n",
      "iteration - 1218 -> loss: 0.0003928109222722061, self.slope: [1.0157234  1.01579055], self.intercept: 1.0013335786538462\n",
      "iteration - 1219 -> loss: 0.0003927806263090496, self.slope: [1.01573565 1.01580287], self.intercept: 1.001334630913561\n",
      "iteration - 1220 -> loss: 0.0003927503351813464, self.slope: [1.0157479  1.01581519], self.intercept: 1.0013356831086402\n",
      "iteration - 1221 -> loss: 0.000392720048887965, self.slope: [1.01576015 1.0158275 ], self.intercept: 1.0013367352390918\n",
      "iteration - 1222 -> loss: 0.00039268976742769154, self.slope: [1.0157724  1.01583981], self.intercept: 1.0013377873049247\n",
      "iteration - 1223 -> loss: 0.00039265949079937397, self.slope: [1.01578465 1.01585213], self.intercept: 1.0013388393061495\n",
      "iteration - 1224 -> loss: 0.0003926292190018457, self.slope: [1.0157969  1.01586444], self.intercept: 1.0013398912427736\n",
      "iteration - 1225 -> loss: 0.0003925989520339239, self.slope: [1.01580915 1.01587675], self.intercept: 1.0013409431148064\n",
      "iteration - 1226 -> loss: 0.0003925686898944359, self.slope: [1.01582139 1.01588906], self.intercept: 1.001341994922255\n",
      "iteration - 1227 -> loss: 0.00039253843258220557, self.slope: [1.01583364 1.01590137], self.intercept: 1.00134304666513\n",
      "iteration - 1228 -> loss: 0.0003925081800960837, self.slope: [1.01584588 1.01591367], self.intercept: 1.0013440983434394\n",
      "iteration - 1229 -> loss: 0.00039247793243488155, self.slope: [1.01585813 1.01592598], self.intercept: 1.0013451499571913\n",
      "iteration - 1230 -> loss: 0.0003924476895974408, self.slope: [1.01587037 1.01593829], self.intercept: 1.0013462015063956\n",
      "iteration - 1231 -> loss: 0.00039241745158258236, self.slope: [1.01588261 1.01595059], self.intercept: 1.0013472529910599\n",
      "iteration - 1232 -> loss: 0.00039238721838912705, self.slope: [1.01589485 1.01596289], self.intercept: 1.0013483044111937\n",
      "iteration - 1233 -> loss: 0.00039235699001591463, self.slope: [1.01590709 1.0159752 ], self.intercept: 1.001349355766805\n",
      "iteration - 1234 -> loss: 0.000392326766461798, self.slope: [1.01591933 1.0159875 ], self.intercept: 1.0013504070579031\n",
      "iteration - 1235 -> loss: 0.00039229654772557826, self.slope: [1.01593157 1.0159998 ], self.intercept: 1.0013514582844965\n",
      "iteration - 1236 -> loss: 0.0003922663338060961, self.slope: [1.0159438 1.0160121], self.intercept: 1.0013525094465925\n",
      "iteration - 1237 -> loss: 0.00039223612470219477, self.slope: [1.01595604 1.0160244 ], self.intercept: 1.001353560544201\n",
      "iteration - 1238 -> loss: 0.00039220592041269356, self.slope: [1.01596827 1.0160367 ], self.intercept: 1.001354611577331\n",
      "iteration - 1239 -> loss: 0.00039217572093644073, self.slope: [1.0159805  1.01604899], self.intercept: 1.001355662545991\n",
      "iteration - 1240 -> loss: 0.00039214552627224187, self.slope: [1.01599274 1.01606129], self.intercept: 1.0013567134501888\n",
      "iteration - 1241 -> loss: 0.00039211533641896523, self.slope: [1.01600497 1.01607358], self.intercept: 1.001357764289934\n",
      "iteration - 1242 -> loss: 0.00039208515137541, self.slope: [1.0160172  1.01608588], self.intercept: 1.001358815065235\n",
      "iteration - 1243 -> loss: 0.00039205497114044386, self.slope: [1.01602943 1.01609817], self.intercept: 1.0013598657761007\n",
      "iteration - 1244 -> loss: 0.00039202479571290354, self.slope: [1.01604166 1.01611046], self.intercept: 1.001360916422538\n",
      "iteration - 1245 -> loss: 0.00039199462509159356, self.slope: [1.01605388 1.01612275], self.intercept: 1.0013619670045582\n",
      "iteration - 1246 -> loss: 0.0003919644592753592, self.slope: [1.01606611 1.01613504], self.intercept: 1.0013630175221684\n",
      "iteration - 1247 -> loss: 0.0003919342982630475, self.slope: [1.01607834 1.01614733], self.intercept: 1.0013640679753784\n",
      "iteration - 1248 -> loss: 0.0003919041420534766, self.slope: [1.01609056 1.01615962], self.intercept: 1.0013651183641927\n",
      "iteration - 1249 -> loss: 0.0003918739906455135, self.slope: [1.01610278 1.01617191], self.intercept: 1.0013661686886253\n",
      "iteration - 1250 -> loss: 0.0003918438440379933, self.slope: [1.01611501 1.01618419], self.intercept: 1.0013672189486837\n",
      "iteration - 1251 -> loss: 0.0003918137022297171, self.slope: [1.01612723 1.01619648], self.intercept: 1.0013682691443757\n",
      "iteration - 1252 -> loss: 0.00039178356521955333, self.slope: [1.01613945 1.01620876], self.intercept: 1.0013693192757085\n",
      "iteration - 1253 -> loss: 0.00039175343300632605, self.slope: [1.01615167 1.01622105], self.intercept: 1.0013703693426916\n",
      "iteration - 1254 -> loss: 0.00039172330558888776, self.slope: [1.01616389 1.01623333], self.intercept: 1.0013714193453356\n",
      "iteration - 1255 -> loss: 0.0003916931829660778, self.slope: [1.0161761  1.01624561], self.intercept: 1.001372469283648\n",
      "iteration - 1256 -> loss: 0.0003916630651367082, self.slope: [1.01618832 1.01625789], self.intercept: 1.0013735191576365\n",
      "iteration - 1257 -> loss: 0.00039163295209964754, self.slope: [1.01620054 1.01627017], self.intercept: 1.001374568967309\n",
      "iteration - 1258 -> loss: 0.0003916028438537405, self.slope: [1.01621275 1.01628245], self.intercept: 1.0013756187126763\n",
      "iteration - 1259 -> loss: 0.00039157274039779513, self.slope: [1.01622496 1.01629472], self.intercept: 1.0013766683937462\n",
      "iteration - 1260 -> loss: 0.00039154264173068735, self.slope: [1.01623718 1.016307  ], self.intercept: 1.0013777180105266\n",
      "iteration - 1261 -> loss: 0.00039151254785123324, self.slope: [1.01624939 1.01631928], self.intercept: 1.0013787675630288\n",
      "iteration - 1262 -> loss: 0.0003914824587583, self.slope: [1.0162616  1.01633155], self.intercept: 1.0013798170512596\n",
      "iteration - 1263 -> loss: 0.00039145237445070496, self.slope: [1.01627381 1.01634382], self.intercept: 1.0013808664752262\n",
      "iteration - 1264 -> loss: 0.00039142229492729926, self.slope: [1.01628602 1.0163561 ], self.intercept: 1.0013819158349389\n",
      "iteration - 1265 -> loss: 0.0003913922201869231, self.slope: [1.01629823 1.01636837], self.intercept: 1.0013829651304063\n",
      "iteration - 1266 -> loss: 0.00039136215022844185, self.slope: [1.01631043 1.01638064], self.intercept: 1.0013840143616357\n",
      "iteration - 1267 -> loss: 0.00039133208505067065, self.slope: [1.01632264 1.01639291], self.intercept: 1.0013850635286365\n",
      "iteration - 1268 -> loss: 0.00039130202465246177, self.slope: [1.01633484 1.01640518], self.intercept: 1.0013861126314165\n",
      "iteration - 1269 -> loss: 0.0003912719690326615, self.slope: [1.01634705 1.01641745], self.intercept: 1.0013871616699872\n",
      "iteration - 1270 -> loss: 0.00039124191819011944, self.slope: [1.01635925 1.01642971], self.intercept: 1.0013882106443548\n",
      "iteration - 1271 -> loss: 0.00039121187212367675, self.slope: [1.01637145 1.01644198], self.intercept: 1.0013892595545264\n",
      "iteration - 1272 -> loss: 0.00039118183083217963, self.slope: [1.01638365 1.01645424], self.intercept: 1.0013903084005145\n",
      "iteration - 1273 -> loss: 0.00039115179431448296, self.slope: [1.01639585 1.01646651], self.intercept: 1.0013913571823267\n",
      "iteration - 1274 -> loss: 0.00039112176256941687, self.slope: [1.01640805 1.01647877], self.intercept: 1.001392405899969\n",
      "iteration - 1275 -> loss: 0.0003910917355958337, self.slope: [1.01642025 1.01649103], self.intercept: 1.001393454553452\n",
      "iteration - 1276 -> loss: 0.0003910617133925775, self.slope: [1.01643245 1.01650329], self.intercept: 1.001394503142783\n",
      "iteration - 1277 -> loss: 0.0003910316959585108, self.slope: [1.01644464 1.01651555], self.intercept: 1.0013955516679727\n",
      "iteration - 1278 -> loss: 0.0003910016832924674, self.slope: [1.01645684 1.01652781], self.intercept: 1.0013966001290286\n",
      "iteration - 1279 -> loss: 0.0003909716753932925, self.slope: [1.01646903 1.01654007], self.intercept: 1.0013976485259595\n",
      "iteration - 1280 -> loss: 0.0003909416722598463, self.slope: [1.01648122 1.01655233], self.intercept: 1.0013986968587734\n",
      "iteration - 1281 -> loss: 0.00039091167389098286, self.slope: [1.01649342 1.01656458], self.intercept: 1.0013997451274803\n",
      "iteration - 1282 -> loss: 0.00039088168028552554, self.slope: [1.01650561 1.01657684], self.intercept: 1.0014007933320865\n",
      "iteration - 1283 -> loss: 0.0003908516914423448, self.slope: [1.0165178  1.01658909], self.intercept: 1.0014018414726022\n",
      "iteration - 1284 -> loss: 0.0003908217073603107, self.slope: [1.01652999 1.01660135], self.intercept: 1.001402889549036\n",
      "iteration - 1285 -> loss: 0.0003907917280382132, self.slope: [1.01654218 1.0166136 ], self.intercept: 1.001403937561395\n",
      "iteration - 1286 -> loss: 0.0003907617534749629, self.slope: [1.01655436 1.01662585], self.intercept: 1.0014049855096894\n",
      "iteration - 1287 -> loss: 0.00039073178366937566, self.slope: [1.01656655 1.0166381 ], self.intercept: 1.0014060333939263\n",
      "iteration - 1288 -> loss: 0.00039070181862032287, self.slope: [1.01657873 1.01665035], self.intercept: 1.001407081214117\n",
      "iteration - 1289 -> loss: 0.0003906718583266369, self.slope: [1.01659092 1.0166626 ], self.intercept: 1.0014081289702672\n",
      "iteration - 1290 -> loss: 0.0003906419027871844, self.slope: [1.0166031  1.01667484], self.intercept: 1.0014091766623874\n",
      "iteration - 1291 -> loss: 0.00039061195200082395, self.slope: [1.01661528 1.01668709], self.intercept: 1.001410224290485\n",
      "iteration - 1292 -> loss: 0.00039058200596639057, self.slope: [1.01662747 1.01669934], self.intercept: 1.0014112718545685\n",
      "iteration - 1293 -> loss: 0.0003905520646827489, self.slope: [1.01663965 1.01671158], self.intercept: 1.0014123193546474\n",
      "iteration - 1294 -> loss: 0.00039052212814877097, self.slope: [1.01665183 1.01672382], self.intercept: 1.0014133667907288\n",
      "iteration - 1295 -> loss: 0.0003904921963632632, self.slope: [1.016664   1.01673607], self.intercept: 1.001414414162821\n",
      "iteration - 1296 -> loss: 0.00039046226932512194, self.slope: [1.01667618 1.01674831], self.intercept: 1.001415461470936\n",
      "iteration - 1297 -> loss: 0.00039043234703317305, self.slope: [1.01668836 1.01676055], self.intercept: 1.0014165087150786\n",
      "iteration - 1298 -> loss: 0.0003904024294863109, self.slope: [1.01670053 1.01677279], self.intercept: 1.0014175558952598\n",
      "iteration - 1299 -> loss: 0.00039037251668334194, self.slope: [1.01671271 1.01678503], self.intercept: 1.0014186030114869\n",
      "iteration - 1300 -> loss: 0.00039034260862316436, self.slope: [1.01672488 1.01679727], self.intercept: 1.0014196500637687\n",
      "iteration - 1301 -> loss: 0.00039031270530462273, self.slope: [1.01673705 1.0168095 ], self.intercept: 1.0014206970521138\n",
      "iteration - 1302 -> loss: 0.00039028280672656087, self.slope: [1.01674923 1.01682174], self.intercept: 1.001421743976529\n",
      "iteration - 1303 -> loss: 0.0003902529128878413, self.slope: [1.0167614  1.01683397], self.intercept: 1.0014227908370252\n",
      "iteration - 1304 -> loss: 0.00039022302378733715, self.slope: [1.01677357 1.01684621], self.intercept: 1.0014238376336118\n",
      "iteration - 1305 -> loss: 0.0003901931394238678, self.slope: [1.01678573 1.01685844], self.intercept: 1.0014248843662952\n",
      "iteration - 1306 -> loss: 0.00039016325979633, self.slope: [1.0167979  1.01687067], self.intercept: 1.0014259310350861\n",
      "iteration - 1307 -> loss: 0.00039013338490356293, self.slope: [1.01681007 1.0168829 ], self.intercept: 1.0014269776399911\n",
      "iteration - 1308 -> loss: 0.00039010351474444096, self.slope: [1.01682223 1.01689513], self.intercept: 1.00142802418102\n",
      "iteration - 1309 -> loss: 0.00039007364931783057, self.slope: [1.0168344  1.01690736], self.intercept: 1.0014290706581792\n",
      "iteration - 1310 -> loss: 0.0003900437886225577, self.slope: [1.01684656 1.01691959], self.intercept: 1.0014301170714786\n",
      "iteration - 1311 -> loss: 0.0003900139326574945, self.slope: [1.01685873 1.01693182], self.intercept: 1.0014311634209265\n",
      "iteration - 1312 -> loss: 0.00038998408142151836, self.slope: [1.01687089 1.01694404], self.intercept: 1.0014322097065327\n",
      "iteration - 1313 -> loss: 0.0003899542349134663, self.slope: [1.01688305 1.01695627], self.intercept: 1.0014332559283037\n",
      "iteration - 1314 -> loss: 0.00038992439313222354, self.slope: [1.01689521 1.01696849], self.intercept: 1.00143430208625\n",
      "iteration - 1315 -> loss: 0.00038989455607665104, self.slope: [1.01690737 1.01698072], self.intercept: 1.001435348180379\n",
      "iteration - 1316 -> loss: 0.000389864723745584, self.slope: [1.01691953 1.01699294], self.intercept: 1.0014363942106985\n",
      "iteration - 1317 -> loss: 0.0003898348961379068, self.slope: [1.01693168 1.01700516], self.intercept: 1.001437440177218\n",
      "iteration - 1318 -> loss: 0.00038980507325248146, self.slope: [1.01694384 1.01701738], self.intercept: 1.001438486079946\n",
      "iteration - 1319 -> loss: 0.00038977525508814806, self.slope: [1.01695599 1.0170296 ], self.intercept: 1.0014395319188913\n",
      "iteration - 1320 -> loss: 0.0003897454416438152, self.slope: [1.01696815 1.01704182], self.intercept: 1.0014405776940618\n",
      "iteration - 1321 -> loss: 0.0003897156329182927, self.slope: [1.0169803  1.01705404], self.intercept: 1.0014416234054673\n",
      "iteration - 1322 -> loss: 0.0003896858289104975, self.slope: [1.01699245 1.01706625], self.intercept: 1.0014426690531155\n",
      "iteration - 1323 -> loss: 0.0003896560296192518, self.slope: [1.0170046  1.01707847], self.intercept: 1.001443714637013\n",
      "iteration - 1324 -> loss: 0.0003896262350434397, self.slope: [1.01701675 1.01709068], self.intercept: 1.0014447601571699\n",
      "iteration - 1325 -> loss: 0.00038959644518193675, self.slope: [1.0170289 1.0171029], self.intercept: 1.0014458056135958\n",
      "iteration - 1326 -> loss: 0.00038956666003357835, self.slope: [1.01704105 1.01711511], self.intercept: 1.0014468510062977\n",
      "iteration - 1327 -> loss: 0.000389536879597249, self.slope: [1.0170532  1.01712732], self.intercept: 1.0014478963352842\n",
      "iteration - 1328 -> loss: 0.00038950710387181424, self.slope: [1.01706535 1.01713953], self.intercept: 1.0014489416005639\n",
      "iteration - 1329 -> loss: 0.0003894773328561414, self.slope: [1.01707749 1.01715174], self.intercept: 1.0014499868021463\n",
      "iteration - 1330 -> loss: 0.00038944756654910436, self.slope: [1.01708964 1.01716395], self.intercept: 1.0014510319400403\n",
      "iteration - 1331 -> loss: 0.0003894178049495572, self.slope: [1.01710178 1.01717616], self.intercept: 1.0014520770142525\n",
      "iteration - 1332 -> loss: 0.0003893880480563746, self.slope: [1.01711392 1.01718837], self.intercept: 1.0014531220247926\n",
      "iteration - 1333 -> loss: 0.0003893582958684187, self.slope: [1.01712606 1.01720057], self.intercept: 1.0014541669716692\n",
      "iteration - 1334 -> loss: 0.000389328548384566, self.slope: [1.0171382  1.01721278], self.intercept: 1.0014552118548887\n",
      "iteration - 1335 -> loss: 0.0003892988056036819, self.slope: [1.01715034 1.01722498], self.intercept: 1.0014562566744625\n",
      "iteration - 1336 -> loss: 0.0003892690675246271, self.slope: [1.01716248 1.01723719], self.intercept: 1.001457301430398\n",
      "iteration - 1337 -> loss: 0.0003892393341463054, self.slope: [1.01717462 1.01724939], self.intercept: 1.0014583461227031\n",
      "iteration - 1338 -> loss: 0.0003892096054675448, self.slope: [1.01718676 1.01726159], self.intercept: 1.0014593907513862\n",
      "iteration - 1339 -> loss: 0.00038917988148723235, self.slope: [1.01719889 1.01727379], self.intercept: 1.0014604353164567\n",
      "iteration - 1340 -> loss: 0.00038915016220423913, self.slope: [1.01721103 1.01728599], self.intercept: 1.0014614798179227\n",
      "iteration - 1341 -> loss: 0.0003891204476174436, self.slope: [1.01722316 1.01729819], self.intercept: 1.0014625242557942\n",
      "iteration - 1342 -> loss: 0.0003890907377257061, self.slope: [1.01723529 1.01731039], self.intercept: 1.0014635686300766\n",
      "iteration - 1343 -> loss: 0.00038906103252788924, self.slope: [1.01724743 1.01732258], self.intercept: 1.0014646129407798\n",
      "iteration - 1344 -> loss: 0.0003890313320229, self.slope: [1.01725956 1.01733478], self.intercept: 1.0014656571879135\n",
      "iteration - 1345 -> loss: 0.0003890016362095924, self.slope: [1.01727169 1.01734697], self.intercept: 1.0014667013714837\n",
      "iteration - 1346 -> loss: 0.0003889719450868092, self.slope: [1.01728381 1.01735917], self.intercept: 1.0014677454914998\n",
      "iteration - 1347 -> loss: 0.0003889422586534809, self.slope: [1.01729594 1.01737136], self.intercept: 1.001468789547971\n",
      "iteration - 1348 -> loss: 0.00038891257690843486, self.slope: [1.01730807 1.01738355], self.intercept: 1.0014698335409058\n",
      "iteration - 1349 -> loss: 0.0003888828998505581, self.slope: [1.0173202  1.01739574], self.intercept: 1.0014708774703127\n",
      "iteration - 1350 -> loss: 0.000388853227478735, self.slope: [1.01733232 1.01740793], self.intercept: 1.0014719213362002\n",
      "iteration - 1351 -> loss: 0.00038882355979182623, self.slope: [1.01734445 1.01742012], self.intercept: 1.0014729651385763\n",
      "iteration - 1352 -> loss: 0.0003887938967887253, self.slope: [1.01735657 1.01743231], self.intercept: 1.0014740088774492\n",
      "iteration - 1353 -> loss: 0.00038876423846828905, self.slope: [1.01736869 1.0174445 ], self.intercept: 1.0014750525528278\n",
      "iteration - 1354 -> loss: 0.0003887345848294143, self.slope: [1.01738081 1.01745668], self.intercept: 1.0014760961647213\n",
      "iteration - 1355 -> loss: 0.00038870493587094527, self.slope: [1.01739293 1.01746887], self.intercept: 1.0014771397131366\n",
      "iteration - 1356 -> loss: 0.0003886752915917946, self.slope: [1.01740505 1.01748105], self.intercept: 1.0014781831980821\n",
      "iteration - 1357 -> loss: 0.00038864565199080777, self.slope: [1.01741717 1.01749323], self.intercept: 1.0014792266195673\n",
      "iteration - 1358 -> loss: 0.00038861601706688935, self.slope: [1.01742929 1.01750542], self.intercept: 1.0014802699776013\n",
      "iteration - 1359 -> loss: 0.0003885863868188915, self.slope: [1.0174414 1.0175176], self.intercept: 1.0014813132721916\n",
      "iteration - 1360 -> loss: 0.0003885567612457227, self.slope: [1.01745352 1.01752978], self.intercept: 1.001482356503346\n",
      "iteration - 1361 -> loss: 0.00038852714034622304, self.slope: [1.01746563 1.01754196], self.intercept: 1.0014833996710726\n",
      "iteration - 1362 -> loss: 0.00038849752411929936, self.slope: [1.01747775 1.01755414], self.intercept: 1.001484442775382\n",
      "iteration - 1363 -> loss: 0.0003884679125638187, self.slope: [1.01748986 1.01756631], self.intercept: 1.0014854858162816\n",
      "iteration - 1364 -> loss: 0.00038843830567866826, self.slope: [1.01750197 1.01757849], self.intercept: 1.0014865287937782\n",
      "iteration - 1365 -> loss: 0.00038840870346272224, self.slope: [1.01751408 1.01759067], self.intercept: 1.0014875717078837\n",
      "iteration - 1366 -> loss: 0.000388379105914876, self.slope: [1.01752619 1.01760284], self.intercept: 1.001488614558604\n",
      "iteration - 1367 -> loss: 0.0003883495130339852, self.slope: [1.0175383  1.01761501], self.intercept: 1.0014896573459486\n",
      "iteration - 1368 -> loss: 0.0003883199248189372, self.slope: [1.01755041 1.01762719], self.intercept: 1.0014907000699238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 1369 -> loss: 0.00038829034126862795, self.slope: [1.01756251 1.01763936], self.intercept: 1.0014917427305408\n",
      "iteration - 1370 -> loss: 0.00038826076238192135, self.slope: [1.01757462 1.01765153], self.intercept: 1.0014927853278075\n",
      "iteration - 1371 -> loss: 0.00038823118815770996, self.slope: [1.01758672 1.0176637 ], self.intercept: 1.0014938278617311\n",
      "iteration - 1372 -> loss: 0.0003882016185948936, self.slope: [1.01759883 1.01767587], self.intercept: 1.0014948703323199\n",
      "iteration - 1373 -> loss: 0.000388172053692315, self.slope: [1.01761093 1.01768804], self.intercept: 1.0014959127395848\n",
      "iteration - 1374 -> loss: 0.00038814249344887823, self.slope: [1.01762303 1.0177002 ], self.intercept: 1.0014969550835324\n",
      "iteration - 1375 -> loss: 0.0003881129378634759, self.slope: [1.01763513 1.01771237], self.intercept: 1.0014979973641707\n",
      "iteration - 1376 -> loss: 0.0003880833869349784, self.slope: [1.01764723 1.01772453], self.intercept: 1.001499039581509\n",
      "iteration - 1377 -> loss: 0.00038805384066227885, self.slope: [1.01765933 1.0177367 ], self.intercept: 1.0015000817355548\n",
      "iteration - 1378 -> loss: 0.0003880242990442449, self.slope: [1.01767143 1.01774886], self.intercept: 1.0015011238263172\n",
      "iteration - 1379 -> loss: 0.0003879947620797888, self.slope: [1.01768353 1.01776102], self.intercept: 1.001502165853805\n",
      "iteration - 1380 -> loss: 0.00038796522976777164, self.slope: [1.01769562 1.01777318], self.intercept: 1.0015032078180253\n",
      "iteration - 1381 -> loss: 0.00038793570210708976, self.slope: [1.01770772 1.01778534], self.intercept: 1.0015042497189885\n",
      "iteration - 1382 -> loss: 0.00038790617909662786, self.slope: [1.01771981 1.0177975 ], self.intercept: 1.001505291556701\n",
      "iteration - 1383 -> loss: 0.00038787666073525454, self.slope: [1.01773191 1.01780966], self.intercept: 1.0015063333311733\n",
      "iteration - 1384 -> loss: 0.00038784714702189555, self.slope: [1.017744   1.01782182], self.intercept: 1.0015073750424122\n",
      "iteration - 1385 -> loss: 0.0003878176379554005, self.slope: [1.01775609 1.01783398], self.intercept: 1.001508416690427\n",
      "iteration - 1386 -> loss: 0.000387788133534675, self.slope: [1.01776818 1.01784613], self.intercept: 1.0015094582752253\n",
      "iteration - 1387 -> loss: 0.00038775863375860726, self.slope: [1.01778027 1.01785829], self.intercept: 1.0015104997968147\n",
      "iteration - 1388 -> loss: 0.00038772913862608193, self.slope: [1.01779236 1.01787044], self.intercept: 1.0015115412552054\n",
      "iteration - 1389 -> loss: 0.00038769964813599055, self.slope: [1.01780445 1.01788259], self.intercept: 1.0015125826504059\n",
      "iteration - 1390 -> loss: 0.00038767016228721335, self.slope: [1.01781653 1.01789475], self.intercept: 1.0015136239824238\n",
      "iteration - 1391 -> loss: 0.0003876406810786473, self.slope: [1.01782862 1.0179069 ], self.intercept: 1.0015146652512668\n",
      "iteration - 1392 -> loss: 0.000387611204509172, self.slope: [1.0178407  1.01791905], self.intercept: 1.0015157064569449\n",
      "iteration - 1393 -> loss: 0.0003875817325776971, self.slope: [1.01785279 1.01793119], self.intercept: 1.0015167475994646\n",
      "iteration - 1394 -> loss: 0.00038755226528309247, self.slope: [1.01786487 1.01794334], self.intercept: 1.0015177886788347\n",
      "iteration - 1395 -> loss: 0.0003875228026242615, self.slope: [1.01787695 1.01795549], self.intercept: 1.0015188296950654\n",
      "iteration - 1396 -> loss: 0.00038749334460008717, self.slope: [1.01788903 1.01796764], self.intercept: 1.0015198706481643\n",
      "iteration - 1397 -> loss: 0.00038746389120946896, self.slope: [1.01790111 1.01797978], self.intercept: 1.0015209115381383\n",
      "iteration - 1398 -> loss: 0.0003874344424512897, self.slope: [1.01791319 1.01799193], self.intercept: 1.0015219523649967\n",
      "iteration - 1399 -> loss: 0.0003874049983244441, self.slope: [1.01792527 1.01800407], self.intercept: 1.0015229931287473\n",
      "iteration - 1400 -> loss: 0.0003873755588278361, self.slope: [1.01793734 1.01801621], self.intercept: 1.0015240338293998\n",
      "iteration - 1401 -> loss: 0.00038734612396034156, self.slope: [1.01794942 1.01802835], self.intercept: 1.0015250744669624\n",
      "iteration - 1402 -> loss: 0.00038731669372084413, self.slope: [1.0179615  1.01804049], self.intercept: 1.0015261150414432\n",
      "iteration - 1403 -> loss: 0.0003872872681082683, self.slope: [1.01797357 1.01805263], self.intercept: 1.0015271555528502\n",
      "iteration - 1404 -> loss: 0.00038725784712149845, self.slope: [1.01798564 1.01806477], self.intercept: 1.001528196001192\n",
      "iteration - 1405 -> loss: 0.00038722843075941836, self.slope: [1.01799772 1.01807691], self.intercept: 1.0015292363864754\n",
      "iteration - 1406 -> loss: 0.00038719901902092174, self.slope: [1.01800979 1.01808904], self.intercept: 1.0015302767087109\n",
      "iteration - 1407 -> loss: 0.00038716961190491826, self.slope: [1.01802186 1.01810118], self.intercept: 1.0015313169679065\n",
      "iteration - 1408 -> loss: 0.0003871402094102824, self.slope: [1.01803393 1.01811332], self.intercept: 1.0015323571640704\n",
      "iteration - 1409 -> loss: 0.00038711081153592404, self.slope: [1.01804599 1.01812545], self.intercept: 1.001533397297211\n",
      "iteration - 1410 -> loss: 0.00038708141828075677, self.slope: [1.01805806 1.01813758], self.intercept: 1.0015344373673374\n",
      "iteration - 1411 -> loss: 0.0003870520296436413, self.slope: [1.01807013 1.01814971], self.intercept: 1.0015354773744556\n",
      "iteration - 1412 -> loss: 0.00038702264562348593, self.slope: [1.01808219 1.01816184], self.intercept: 1.0015365173185757\n",
      "iteration - 1413 -> loss: 0.0003869932662191826, self.slope: [1.01809426 1.01817397], self.intercept: 1.0015375571997065\n",
      "iteration - 1414 -> loss: 0.0003869638914296644, self.slope: [1.01810632 1.0181861 ], self.intercept: 1.001538597017856\n",
      "iteration - 1415 -> loss: 0.00038693452125377844, self.slope: [1.01811838 1.01819823], self.intercept: 1.001539636773033\n",
      "iteration - 1416 -> loss: 0.00038690515569045965, self.slope: [1.01813045 1.01821036], self.intercept: 1.0015406764652441\n",
      "iteration - 1417 -> loss: 0.0003868757947385932, self.slope: [1.01814251 1.01822249], self.intercept: 1.0015417160944997\n",
      "iteration - 1418 -> loss: 0.00038684643839706934, self.slope: [1.01815457 1.01823461], self.intercept: 1.0015427556608056\n",
      "iteration - 1419 -> loss: 0.0003868170866647997, self.slope: [1.01816662 1.01824673], self.intercept: 1.001543795164173\n",
      "iteration - 1420 -> loss: 0.0003867877395406756, self.slope: [1.01817868 1.01825886], self.intercept: 1.001544834604608\n",
      "iteration - 1421 -> loss: 0.0003867583970235987, self.slope: [1.01819074 1.01827098], self.intercept: 1.0015458739821206\n",
      "iteration - 1422 -> loss: 0.00038672905911247906, self.slope: [1.0182028 1.0182831], self.intercept: 1.001546913296717\n",
      "iteration - 1423 -> loss: 0.0003866997258062172, self.slope: [1.01821485 1.01829522], self.intercept: 1.0015479525484066\n",
      "iteration - 1424 -> loss: 0.00038667039710369605, self.slope: [1.0182269  1.01830734], self.intercept: 1.001548991737199\n",
      "iteration - 1425 -> loss: 0.000386641073003829, self.slope: [1.01823896 1.01831946], self.intercept: 1.0015500308631005\n",
      "iteration - 1426 -> loss: 0.0003866117535055139, self.slope: [1.01825101 1.01833158], self.intercept: 1.0015510699261219\n",
      "iteration - 1427 -> loss: 0.00038658243860765725, self.slope: [1.01826306 1.0183437 ], self.intercept: 1.0015521089262704\n",
      "iteration - 1428 -> loss: 0.000386553128309155, self.slope: [1.01827511 1.01835581], self.intercept: 1.0015531478635538\n",
      "iteration - 1429 -> loss: 0.0003865238226089153, self.slope: [1.01828716 1.01836793], self.intercept: 1.001554186737981\n",
      "iteration - 1430 -> loss: 0.0003864945215058445, self.slope: [1.01829921 1.01838004], self.intercept: 1.0015552255495592\n",
      "iteration - 1431 -> loss: 0.00038646522499882665, self.slope: [1.01831126 1.01839215], self.intercept: 1.0015562642982982\n",
      "iteration - 1432 -> loss: 0.0003864359330868104, self.slope: [1.0183233  1.01840427], self.intercept: 1.0015573029842055\n",
      "iteration - 1433 -> loss: 0.00038640664576864076, self.slope: [1.01833535 1.01841638], self.intercept: 1.0015583416072897\n",
      "iteration - 1434 -> loss: 0.00038637736304325093, self.slope: [1.01834739 1.01842849], self.intercept: 1.0015593801675589\n",
      "iteration - 1435 -> loss: 0.0003863480849095562, self.slope: [1.01835943 1.0184406 ], self.intercept: 1.0015604186650213\n",
      "iteration - 1436 -> loss: 0.0003863188113664457, self.slope: [1.01837148 1.0184527 ], self.intercept: 1.0015614570996865\n",
      "iteration - 1437 -> loss: 0.0003862895424128251, self.slope: [1.01838352 1.01846481], self.intercept: 1.001562495471561\n",
      "iteration - 1438 -> loss: 0.0003862602780476183, self.slope: [1.01839556 1.01847692], self.intercept: 1.0015635337806539\n",
      "iteration - 1439 -> loss: 0.0003862310182697008, self.slope: [1.0184076  1.01848902], self.intercept: 1.0015645720269728\n",
      "iteration - 1440 -> loss: 0.0003862017630779981, self.slope: [1.01841964 1.01850113], self.intercept: 1.0015656102105281\n",
      "iteration - 1441 -> loss: 0.0003861725124714366, self.slope: [1.01843168 1.01851323], self.intercept: 1.0015666483313252\n",
      "iteration - 1442 -> loss: 0.00038614326644888697, self.slope: [1.01844371 1.01852533], self.intercept: 1.0015676863893743\n",
      "iteration - 1443 -> loss: 0.00038611402500928177, self.slope: [1.01845575 1.01853744], self.intercept: 1.0015687243846836\n",
      "iteration - 1444 -> loss: 0.0003860847881515053, self.slope: [1.01846778 1.01854954], self.intercept: 1.00156976231726\n",
      "iteration - 1445 -> loss: 0.0003860555558744811, self.slope: [1.01847982 1.01856164], self.intercept: 1.0015708001871142\n",
      "iteration - 1446 -> loss: 0.0003860263281771289, self.slope: [1.01849185 1.01857374], self.intercept: 1.0015718379942515\n",
      "iteration - 1447 -> loss: 0.0003859971050583287, self.slope: [1.01850388 1.01858583], self.intercept: 1.0015728757386833\n",
      "iteration - 1448 -> loss: 0.00038596788651702843, self.slope: [1.01851591 1.01859793], self.intercept: 1.0015739134204156\n",
      "iteration - 1449 -> loss: 0.00038593867255210093, self.slope: [1.01852794 1.01861003], self.intercept: 1.0015749510394587\n",
      "iteration - 1450 -> loss: 0.0003859094631624753, self.slope: [1.01853997 1.01862212], self.intercept: 1.0015759885958193\n",
      "iteration - 1451 -> loss: 0.00038588025834704754, self.slope: [1.018552   1.01863422], self.intercept: 1.0015770260895078\n",
      "iteration - 1452 -> loss: 0.0003858510581047489, self.slope: [1.01856403 1.01864631], self.intercept: 1.0015780635205296\n",
      "iteration - 1453 -> loss: 0.0003858218624344693, self.slope: [1.01857605 1.0186584 ], self.intercept: 1.0015791008888946\n",
      "iteration - 1454 -> loss: 0.0003857926713351366, self.slope: [1.01858808 1.01867049], self.intercept: 1.0015801381946117\n",
      "iteration - 1455 -> loss: 0.0003857634848056584, self.slope: [1.0186001  1.01868258], self.intercept: 1.001581175437687\n",
      "iteration - 1456 -> loss: 0.0003857343028449506, self.slope: [1.01861213 1.01869467], self.intercept: 1.0015822126181286\n",
      "iteration - 1457 -> loss: 0.00038570512545191645, self.slope: [1.01862415 1.01870676], self.intercept: 1.0015832497359485\n",
      "iteration - 1458 -> loss: 0.0003856759526254746, self.slope: [1.01863617 1.01871885], self.intercept: 1.0015842867911517\n",
      "iteration - 1459 -> loss: 0.00038564678436452435, self.slope: [1.01864819 1.01873094], self.intercept: 1.0015853237837484\n",
      "iteration - 1460 -> loss: 0.00038561762066798477, self.slope: [1.01866021 1.01874302], self.intercept: 1.001586360713747\n",
      "iteration - 1461 -> loss: 0.00038558846153479527, self.slope: [1.01867223 1.01875511], self.intercept: 1.0015873975811531\n",
      "iteration - 1462 -> loss: 0.0003855593069638431, self.slope: [1.01868425 1.01876719], self.intercept: 1.0015884343859778\n",
      "iteration - 1463 -> loss: 0.0003855301569540583, self.slope: [1.01869627 1.01877927], self.intercept: 1.001589471128228\n",
      "iteration - 1464 -> loss: 0.000385501011504334, self.slope: [1.01870828 1.01879136], self.intercept: 1.001590507807911\n",
      "iteration - 1465 -> loss: 0.00038547187061360066, self.slope: [1.0187203  1.01880344], self.intercept: 1.0015915444250358\n",
      "iteration - 1466 -> loss: 0.0003854427342807897, self.slope: [1.01873231 1.01881552], self.intercept: 1.0015925809796116\n",
      "iteration - 1467 -> loss: 0.0003854136025047833, self.slope: [1.01874432 1.0188276 ], self.intercept: 1.0015936174716458\n",
      "iteration - 1468 -> loss: 0.00038538447528452106, self.slope: [1.01875634 1.01883967], self.intercept: 1.0015946539011484\n",
      "iteration - 1469 -> loss: 0.0003853553526189159, self.slope: [1.01876835 1.01885175], self.intercept: 1.0015956902681253\n",
      "iteration - 1470 -> loss: 0.00038532623450686436, self.slope: [1.01878036 1.01886383], self.intercept: 1.001596726572586\n",
      "iteration - 1471 -> loss: 0.0003852971209473114, self.slope: [1.01879237 1.0188759 ], self.intercept: 1.0015977628145383\n",
      "iteration - 1472 -> loss: 0.00038526801193916404, self.slope: [1.01880437 1.01888798], self.intercept: 1.0015987989939918\n",
      "iteration - 1473 -> loss: 0.0003852389074813311, self.slope: [1.01881638 1.01890005], self.intercept: 1.001599835110953\n",
      "iteration - 1474 -> loss: 0.00038520980757276253, self.slope: [1.01882839 1.01891212], self.intercept: 1.001600871165431\n",
      "iteration - 1475 -> loss: 0.00038518071221233104, self.slope: [1.01884039 1.0189242 ], self.intercept: 1.0016019071574325\n",
      "iteration - 1476 -> loss: 0.000385151621398983, self.slope: [1.0188524  1.01893627], self.intercept: 1.0016029430869673\n",
      "iteration - 1477 -> loss: 0.0003851225351316319, self.slope: [1.0188644  1.01894834], self.intercept: 1.0016039789540443\n",
      "iteration - 1478 -> loss: 0.00038509345340920746, self.slope: [1.0188764 1.0189604], self.intercept: 1.0016050147586701\n",
      "iteration - 1479 -> loss: 0.0003850643762306326, self.slope: [1.01888841 1.01897247], self.intercept: 1.0016060505008537\n",
      "iteration - 1480 -> loss: 0.00038503530359481253, self.slope: [1.01890041 1.01898454], self.intercept: 1.0016070861806028\n",
      "iteration - 1481 -> loss: 0.00038500623550065296, self.slope: [1.01891241 1.01899661], self.intercept: 1.0016081217979265\n",
      "iteration - 1482 -> loss: 0.0003849771719471075, self.slope: [1.01892441 1.01900867], self.intercept: 1.0016091573528345\n",
      "iteration - 1483 -> loss: 0.0003849481129330949, self.slope: [1.0189364  1.01902073], self.intercept: 1.0016101928453327\n",
      "iteration - 1484 -> loss: 0.000384919058457512, self.slope: [1.0189484 1.0190328], self.intercept: 1.0016112282754293\n",
      "iteration - 1485 -> loss: 0.0003848900085192977, self.slope: [1.0189604  1.01904486], self.intercept: 1.0016122636431326\n",
      "iteration - 1486 -> loss: 0.00038486096311736315, self.slope: [1.01897239 1.01905692], self.intercept: 1.001613298948451\n",
      "iteration - 1487 -> loss: 0.00038483192225066063, self.slope: [1.01898439 1.01906898], self.intercept: 1.0016143341913952\n",
      "iteration - 1488 -> loss: 0.0003848028859180893, self.slope: [1.01899638 1.01908104], self.intercept: 1.0016153693719694\n",
      "iteration - 1489 -> loss: 0.0003847738541185627, self.slope: [1.01900837 1.0190931 ], self.intercept: 1.0016164044901839\n",
      "iteration - 1490 -> loss: 0.00038474482685103346, self.slope: [1.01902036 1.01910516], self.intercept: 1.0016174395460464\n",
      "iteration - 1491 -> loss: 0.0003847158041143947, self.slope: [1.01903235 1.01911721], self.intercept: 1.0016184745395669\n",
      "iteration - 1492 -> loss: 0.00038468678590760063, self.slope: [1.01904434 1.01912927], self.intercept: 1.001619509470752\n",
      "iteration - 1493 -> loss: 0.00038465777222954143, self.slope: [1.01905633 1.01914133], self.intercept: 1.0016205443396091\n",
      "iteration - 1494 -> loss: 0.00038462876307919833, self.slope: [1.01906832 1.01915338], self.intercept: 1.0016215791461467\n",
      "iteration - 1495 -> loss: 0.00038459975845542575, self.slope: [1.0190803  1.01916543], self.intercept: 1.0016226138903745\n",
      "iteration - 1496 -> loss: 0.00038457075835720043, self.slope: [1.01909229 1.01917748], self.intercept: 1.0016236485723\n",
      "iteration - 1497 -> loss: 0.0003845417627834326, self.slope: [1.01910427 1.01918954], self.intercept: 1.0016246831919315\n",
      "iteration - 1498 -> loss: 0.000384512771733061, self.slope: [1.01911626 1.01920159], self.intercept: 1.001625717749277\n",
      "iteration - 1499 -> loss: 0.0003844837852049962, self.slope: [1.01912824 1.01921364], self.intercept: 1.0016267522443452\n",
      "iteration - 1500 -> loss: 0.00038445480319816336, self.slope: [1.01914022 1.01922568], self.intercept: 1.0016277866771441\n",
      "iteration - 1501 -> loss: 0.00038442582571150463, self.slope: [1.0191522  1.01923773], self.intercept: 1.0016288210476805\n",
      "iteration - 1502 -> loss: 0.0003843968527439398, self.slope: [1.01916418 1.01924978], self.intercept: 1.001629855355965\n",
      "iteration - 1503 -> loss: 0.00038436788429439627, self.slope: [1.01917616 1.01926182], self.intercept: 1.0016308896020052\n",
      "iteration - 1504 -> loss: 0.0003843389203618142, self.slope: [1.01918814 1.01927387], self.intercept: 1.0016319237858076\n",
      "iteration - 1505 -> loss: 0.00038430996094509904, self.slope: [1.01920012 1.01928591], self.intercept: 1.0016329579073822\n",
      "iteration - 1506 -> loss: 0.0003842810060431899, self.slope: [1.01921209 1.01929795], self.intercept: 1.0016339919667365\n",
      "iteration - 1507 -> loss: 0.0003842520556550404, self.slope: [1.01922407 1.01931   ], self.intercept: 1.0016350259638802\n",
      "iteration - 1508 -> loss: 0.0003842231097795537, self.slope: [1.01923604 1.01932204], self.intercept: 1.0016360598988179\n",
      "iteration - 1509 -> loss: 0.00038419416841566236, self.slope: [1.01924802 1.01933408], self.intercept: 1.0016370937715615\n",
      "iteration - 1510 -> loss: 0.00038416523156232065, self.slope: [1.01925999 1.01934612], self.intercept: 1.001638127582117\n",
      "iteration - 1511 -> loss: 0.0003841362992184114, self.slope: [1.01927196 1.01935815], self.intercept: 1.0016391613304918\n",
      "iteration - 1512 -> loss: 0.0003841073713829143, self.slope: [1.01928393 1.01937019], self.intercept: 1.0016401950166969\n",
      "iteration - 1513 -> loss: 0.000384078448054733, self.slope: [1.0192959  1.01938223], self.intercept: 1.0016412286407395\n",
      "iteration - 1514 -> loss: 0.00038404952923281645, self.slope: [1.01930787 1.01939426], self.intercept: 1.0016422622026278\n",
      "iteration - 1515 -> loss: 0.00038402061491608805, self.slope: [1.01931984 1.0194063 ], self.intercept: 1.001643295702368\n",
      "iteration - 1516 -> loss: 0.00038399170510347553, self.slope: [1.0193318  1.01941833], self.intercept: 1.0016443291399693\n",
      "iteration - 1517 -> loss: 0.00038396279979391925, self.slope: [1.01934377 1.01943036], self.intercept: 1.001645362515442\n",
      "iteration - 1518 -> loss: 0.0003839338989863661, self.slope: [1.01935573 1.01944239], self.intercept: 1.0016463958287927\n",
      "iteration - 1519 -> loss: 0.0003839050026797226, self.slope: [1.0193677  1.01945442], self.intercept: 1.001647429080029\n",
      "iteration - 1520 -> loss: 0.0003838761108729478, self.slope: [1.01937966 1.01946645], self.intercept: 1.0016484622691602\n",
      "iteration - 1521 -> loss: 0.00038384722356494183, self.slope: [1.01939162 1.01947848], self.intercept: 1.0016494953961939\n",
      "iteration - 1522 -> loss: 0.00038381834075467867, self.slope: [1.01940358 1.01949051], self.intercept: 1.001650528461138\n",
      "iteration - 1523 -> loss: 0.0003837894624410675, self.slope: [1.01941555 1.01950254], self.intercept: 1.0016515614640005\n",
      "iteration - 1524 -> loss: 0.0003837605886230678, self.slope: [1.0194275  1.01951456], self.intercept: 1.00165259440479\n",
      "iteration - 1525 -> loss: 0.0003837317192995897, self.slope: [1.01943946 1.01952659], self.intercept: 1.0016536272835148\n",
      "iteration - 1526 -> loss: 0.0003837028544695779, self.slope: [1.01945142 1.01953861], self.intercept: 1.0016546601001837\n",
      "iteration - 1527 -> loss: 0.00038367399413196486, self.slope: [1.01946338 1.01955064], self.intercept: 1.0016556928548046\n",
      "iteration - 1528 -> loss: 0.0003836451382857082, self.slope: [1.01947533 1.01956266], self.intercept: 1.001656725547384\n",
      "iteration - 1529 -> loss: 0.0003836162869297298, self.slope: [1.01948729 1.01957468], self.intercept: 1.0016577581779318\n",
      "iteration - 1530 -> loss: 0.0003835874400629566, self.slope: [1.01949924 1.0195867 ], self.intercept: 1.0016587907464551\n",
      "iteration - 1531 -> loss: 0.0003835585976843399, self.slope: [1.01951119 1.01959872], self.intercept: 1.001659823252964\n",
      "iteration - 1532 -> loss: 0.00038352975979281554, self.slope: [1.01952314 1.01961074], self.intercept: 1.0016608556974649\n",
      "iteration - 1533 -> loss: 0.00038350092638732633, self.slope: [1.0195351  1.01962276], self.intercept: 1.0016618880799653\n",
      "iteration - 1534 -> loss: 0.0003834720974668, self.slope: [1.01954705 1.01963477], self.intercept: 1.0016629204004743\n",
      "iteration - 1535 -> loss: 0.00038344327303019765, self.slope: [1.01955899 1.01964679], self.intercept: 1.0016639526590003\n",
      "iteration - 1536 -> loss: 0.0003834144530764328, self.slope: [1.01957094 1.0196588 ], self.intercept: 1.0016649848555501\n",
      "iteration - 1537 -> loss: 0.0003833856376044531, self.slope: [1.01958289 1.01967082], self.intercept: 1.0016660169901344\n",
      "iteration - 1538 -> loss: 0.00038335682661319955, self.slope: [1.01959484 1.01968283], self.intercept: 1.0016670490627602\n",
      "iteration - 1539 -> loss: 0.00038332802010161606, self.slope: [1.01960678 1.01969484], self.intercept: 1.0016680810734342\n",
      "iteration - 1540 -> loss: 0.00038329921806864607, self.slope: [1.01961872 1.01970685], self.intercept: 1.001669113022166\n",
      "iteration - 1541 -> loss: 0.00038327042051322326, self.slope: [1.01963067 1.01971886], self.intercept: 1.0016701449089631\n",
      "iteration - 1542 -> loss: 0.00038324162743430334, self.slope: [1.01964261 1.01973087], self.intercept: 1.001671176733835\n",
      "iteration - 1543 -> loss: 0.00038321283883080204, self.slope: [1.01965455 1.01974288], self.intercept: 1.001672208496788\n",
      "iteration - 1544 -> loss: 0.0003831840547016761, self.slope: [1.01966649 1.01975489], self.intercept: 1.0016732401978319\n",
      "iteration - 1545 -> loss: 0.000383155275045878, self.slope: [1.01967843 1.0197669 ], self.intercept: 1.0016742718369727\n",
      "iteration - 1546 -> loss: 0.00038312649986233985, self.slope: [1.01969037 1.0197789 ], self.intercept: 1.0016753034142214\n",
      "iteration - 1547 -> loss: 0.00038309772915000193, self.slope: [1.01970231 1.01979091], self.intercept: 1.001676334929583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 1548 -> loss: 0.0003830689629078099, self.slope: [1.01971424 1.01980291], self.intercept: 1.001677366383069\n",
      "iteration - 1549 -> loss: 0.0003830402011347232, self.slope: [1.01972618 1.01981491], self.intercept: 1.0016783977746828\n",
      "iteration - 1550 -> loss: 0.00038301144382966627, self.slope: [1.01973812 1.01982691], self.intercept: 1.0016794291044355\n",
      "iteration - 1551 -> loss: 0.00038298269099159676, self.slope: [1.01975005 1.01983892], self.intercept: 1.0016804603723368\n",
      "iteration - 1552 -> loss: 0.000382953942619426, self.slope: [1.01976198 1.01985092], self.intercept: 1.001681491578394\n",
      "iteration - 1553 -> loss: 0.0003829251987121475, self.slope: [1.01977391 1.01986291], self.intercept: 1.0016825227226132\n",
      "iteration - 1554 -> loss: 0.00038289645926867065, self.slope: [1.01978585 1.01987491], self.intercept: 1.0016835538050046\n",
      "iteration - 1555 -> loss: 0.00038286772428798425, self.slope: [1.01979778 1.01988691], self.intercept: 1.0016845848255747\n",
      "iteration - 1556 -> loss: 0.00038283899376898825, self.slope: [1.0198097  1.01989891], self.intercept: 1.0016856157843332\n",
      "iteration - 1557 -> loss: 0.00038281026771065446, self.slope: [1.01982163 1.0199109 ], self.intercept: 1.001686646681287\n",
      "iteration - 1558 -> loss: 0.0003827815461119103, self.slope: [1.01983356 1.0199229 ], self.intercept: 1.001687677516446\n",
      "iteration - 1559 -> loss: 0.0003827528289717184, self.slope: [1.01984549 1.01993489], self.intercept: 1.0016887082898154\n",
      "iteration - 1560 -> loss: 0.00038272411628903366, self.slope: [1.01985741 1.01994688], self.intercept: 1.0016897390014052\n",
      "iteration - 1561 -> loss: 0.0003826954080627833, self.slope: [1.01986934 1.01995887], self.intercept: 1.0016907696512232\n",
      "iteration - 1562 -> loss: 0.00038266670429192387, self.slope: [1.01988126 1.01997086], self.intercept: 1.0016918002392767\n",
      "iteration - 1563 -> loss: 0.00038263800497542023, self.slope: [1.01989318 1.01998285], self.intercept: 1.0016928307655748\n",
      "iteration - 1564 -> loss: 0.00038260931011219017, self.slope: [1.0199051  1.01999484], self.intercept: 1.0016938612301252\n",
      "iteration - 1565 -> loss: 0.0003825806197012131, self.slope: [1.01991703 1.02000683], self.intercept: 1.0016948916329362\n",
      "iteration - 1566 -> loss: 0.0003825519337414216, self.slope: [1.01992895 1.02001882], self.intercept: 1.0016959219740154\n",
      "iteration - 1567 -> loss: 0.00038252325223176657, self.slope: [1.01994086 1.02003081], self.intercept: 1.0016969522533719\n",
      "iteration - 1568 -> loss: 0.00038249457517120167, self.slope: [1.01995278 1.02004279], self.intercept: 1.0016979824710128\n",
      "iteration - 1569 -> loss: 0.0003824659025586739, self.slope: [1.0199647  1.02005477], self.intercept: 1.001699012626947\n",
      "iteration - 1570 -> loss: 0.000382437234393134, self.slope: [1.01997662 1.02006676], self.intercept: 1.0017000427211833\n",
      "iteration - 1571 -> loss: 0.000382408570673535, self.slope: [1.01998853 1.02007874], self.intercept: 1.001701072753728\n",
      "iteration - 1572 -> loss: 0.00038237991139883603, self.slope: [1.02000045 1.02009072], self.intercept: 1.0017021027245891\n",
      "iteration - 1573 -> loss: 0.0003823512565679764, self.slope: [1.02001236 1.0201027 ], self.intercept: 1.0017031326337749\n",
      "iteration - 1574 -> loss: 0.0003823226061799171, self.slope: [1.02002427 1.02011468], self.intercept: 1.001704162481294\n",
      "iteration - 1575 -> loss: 0.0003822939602336164, self.slope: [1.02003618 1.02012666], self.intercept: 1.0017051922671545\n",
      "iteration - 1576 -> loss: 0.0003822653187280032, self.slope: [1.02004809 1.02013864], self.intercept: 1.0017062219913646\n",
      "iteration - 1577 -> loss: 0.00038223668166205107, self.slope: [1.02006    1.02015062], self.intercept: 1.0017072516539323\n",
      "iteration - 1578 -> loss: 0.000382208049034716, self.slope: [1.02007191 1.02016259], self.intercept: 1.001708281254867\n",
      "iteration - 1579 -> loss: 0.00038217942084493417, self.slope: [1.02008382 1.02017457], self.intercept: 1.001709310794176\n",
      "iteration - 1580 -> loss: 0.00038215079709168334, self.slope: [1.02009573 1.02018654], self.intercept: 1.0017103402718655\n",
      "iteration - 1581 -> loss: 0.0003821221777738828, self.slope: [1.02010763 1.02019852], self.intercept: 1.001711369687945\n",
      "iteration - 1582 -> loss: 0.00038209356289052457, self.slope: [1.02011954 1.02021049], self.intercept: 1.0017123990424222\n",
      "iteration - 1583 -> loss: 0.0003820649524405452, self.slope: [1.02013144 1.02022246], self.intercept: 1.001713428335306\n",
      "iteration - 1584 -> loss: 0.0003820363464229008, self.slope: [1.02014334 1.02023443], self.intercept: 1.0017144575666037\n",
      "iteration - 1585 -> loss: 0.0003820077448365508, self.slope: [1.02015525 1.0202464 ], self.intercept: 1.0017154867363214\n",
      "iteration - 1586 -> loss: 0.00038197914768044476, self.slope: [1.02016715 1.02025837], self.intercept: 1.0017165158444714\n",
      "iteration - 1587 -> loss: 0.00038195055495355884, self.slope: [1.02017905 1.02027034], self.intercept: 1.0017175448910585\n",
      "iteration - 1588 -> loss: 0.0003819219666548227, self.slope: [1.02019095 1.0202823 ], self.intercept: 1.0017185738760919\n",
      "iteration - 1589 -> loss: 0.0003818933827832222, self.slope: [1.02020285 1.02029427], self.intercept: 1.0017196027995814\n",
      "iteration - 1590 -> loss: 0.00038186480333767876, self.slope: [1.02021474 1.02030623], self.intercept: 1.0017206316615324\n",
      "iteration - 1591 -> loss: 0.00038183622831718144, self.slope: [1.02022664 1.0203182 ], self.intercept: 1.001721660461955\n",
      "iteration - 1592 -> loss: 0.00038180765772068386, self.slope: [1.02023854 1.02033016], self.intercept: 1.0017226892008548\n",
      "iteration - 1593 -> loss: 0.0003817790915471481, self.slope: [1.02025043 1.02034212], self.intercept: 1.0017237178782417\n",
      "iteration - 1594 -> loss: 0.00038175052979550357, self.slope: [1.02026232 1.02035408], self.intercept: 1.0017247464941232\n",
      "iteration - 1595 -> loss: 0.0003817219724647228, self.slope: [1.02027422 1.02036604], self.intercept: 1.0017257750485076\n",
      "iteration - 1596 -> loss: 0.0003816934195537858, self.slope: [1.02028611 1.020378  ], self.intercept: 1.0017268035414024\n",
      "iteration - 1597 -> loss: 0.0003816648710616241, self.slope: [1.020298   1.02038996], self.intercept: 1.001727831972818\n",
      "iteration - 1598 -> loss: 0.0003816363269872344, self.slope: [1.02030989 1.02040192], self.intercept: 1.00172886034276\n",
      "iteration - 1599 -> loss: 0.00038160778732955155, self.slope: [1.02032178 1.02041388], self.intercept: 1.0017298886512367\n",
      "iteration - 1600 -> loss: 0.0003815792520875189, self.slope: [1.02033367 1.02042583], self.intercept: 1.0017309168982553\n",
      "iteration - 1601 -> loss: 0.0003815507212601177, self.slope: [1.02034556 1.02043779], self.intercept: 1.001731945083827\n",
      "iteration - 1602 -> loss: 0.00038152219484632405, self.slope: [1.02035744 1.02044974], self.intercept: 1.0017329732079554\n",
      "iteration - 1603 -> loss: 0.00038149367284509003, self.slope: [1.02036933 1.02046169], self.intercept: 1.0017340012706513\n",
      "iteration - 1604 -> loss: 0.00038146515525535864, self.slope: [1.02038121 1.02047365], self.intercept: 1.0017350292719227\n",
      "iteration - 1605 -> loss: 0.00038143664207612065, self.slope: [1.0203931 1.0204856], self.intercept: 1.0017360572117768\n",
      "iteration - 1606 -> loss: 0.0003814081333063188, self.slope: [1.02040498 1.02049755], self.intercept: 1.001737085090223\n",
      "iteration - 1607 -> loss: 0.00038137962894492424, self.slope: [1.02041686 1.0205095 ], self.intercept: 1.0017381129072684\n",
      "iteration - 1608 -> loss: 0.0003813511289908951, self.slope: [1.02042874 1.02052145], self.intercept: 1.0017391406629215\n",
      "iteration - 1609 -> loss: 0.00038132263344319614, self.slope: [1.02044062 1.02053339], self.intercept: 1.0017401683571903\n",
      "iteration - 1610 -> loss: 0.00038129414230080093, self.slope: [1.0204525  1.02054534], self.intercept: 1.0017411959900817\n",
      "iteration - 1611 -> loss: 0.0003812656555626684, self.slope: [1.02046438 1.02055729], self.intercept: 1.0017422235616043\n",
      "iteration - 1612 -> loss: 0.00038123717322775217, self.slope: [1.02047625 1.02056923], self.intercept: 1.0017432510717665\n",
      "iteration - 1613 -> loss: 0.0003812086952950192, self.slope: [1.02048813 1.02058118], self.intercept: 1.001744278520577\n",
      "iteration - 1614 -> loss: 0.00038118022176347207, self.slope: [1.02050001 1.02059312], self.intercept: 1.001745305908042\n",
      "iteration - 1615 -> loss: 0.00038115175263203085, self.slope: [1.02051188 1.02060506], self.intercept: 1.0017463332341705\n",
      "iteration - 1616 -> loss: 0.0003811232878996701, self.slope: [1.02052375 1.020617  ], self.intercept: 1.0017473604989717\n",
      "iteration - 1617 -> loss: 0.00038109482756536027, self.slope: [1.02053563 1.02062894], self.intercept: 1.0017483877024516\n",
      "iteration - 1618 -> loss: 0.00038106637162809055, self.slope: [1.0205475  1.02064088], self.intercept: 1.001749414844618\n",
      "iteration - 1619 -> loss: 0.00038103792008680886, self.slope: [1.02055937 1.02065282], self.intercept: 1.0017504419254795\n",
      "iteration - 1620 -> loss: 0.00038100947294046096, self.slope: [1.02057124 1.02066476], self.intercept: 1.001751468945045\n",
      "iteration - 1621 -> loss: 0.0003809810301880571, self.slope: [1.02058311 1.02067669], self.intercept: 1.0017524959033222\n",
      "iteration - 1622 -> loss: 0.00038095259182853984, self.slope: [1.02059497 1.02068863], self.intercept: 1.0017535228003178\n",
      "iteration - 1623 -> loss: 0.0003809241578608693, self.slope: [1.02060684 1.02070056], self.intercept: 1.001754549636042\n",
      "iteration - 1624 -> loss: 0.00038089572828403916, self.slope: [1.02061871 1.0207125 ], self.intercept: 1.0017555764105022\n",
      "iteration - 1625 -> loss: 0.0003808673030970044, self.slope: [1.02063057 1.02072443], self.intercept: 1.001756603123706\n",
      "iteration - 1626 -> loss: 0.00038083888229872354, self.slope: [1.02064244 1.02073636], self.intercept: 1.0017576297756607\n",
      "iteration - 1627 -> loss: 0.00038081046588819606, self.slope: [1.0206543  1.02074829], self.intercept: 1.0017586563663747\n",
      "iteration - 1628 -> loss: 0.0003807820538643621, self.slope: [1.02066616 1.02076022], self.intercept: 1.0017596828958564\n",
      "iteration - 1629 -> loss: 0.00038075364622621436, self.slope: [1.02067802 1.02077215], self.intercept: 1.001760709364115\n",
      "iteration - 1630 -> loss: 0.0003807252429727162, self.slope: [1.02068988 1.02078408], self.intercept: 1.0017617357711555\n",
      "iteration - 1631 -> loss: 0.0003806968441028251, self.slope: [1.02070174 1.02079601], self.intercept: 1.001762762116988\n",
      "iteration - 1632 -> loss: 0.00038066844961553027, self.slope: [1.0207136  1.02080794], self.intercept: 1.0017637884016206\n",
      "iteration - 1633 -> loss: 0.00038064005950978497, self.slope: [1.02072546 1.02081986], self.intercept: 1.00176481462506\n",
      "iteration - 1634 -> loss: 0.0003806116737845794, self.slope: [1.02073732 1.02083179], self.intercept: 1.0017658407873147\n",
      "iteration - 1635 -> loss: 0.0003805832924388735, self.slope: [1.02074917 1.02084371], self.intercept: 1.0017668668883921\n",
      "iteration - 1636 -> loss: 0.00038055491547164794, self.slope: [1.02076103 1.02085563], self.intercept: 1.001767892928302\n",
      "iteration - 1637 -> loss: 0.0003805265428818694, self.slope: [1.02077288 1.02086755], self.intercept: 1.0017689189070529\n",
      "iteration - 1638 -> loss: 0.0003804981746685135, self.slope: [1.02078473 1.02087948], self.intercept: 1.0017699448246502\n",
      "iteration - 1639 -> loss: 0.0003804698108305533, self.slope: [1.02079659 1.0208914 ], self.intercept: 1.0017709706811018\n",
      "iteration - 1640 -> loss: 0.00038044145136697296, self.slope: [1.02080844 1.02090332], self.intercept: 1.0017719964764187\n",
      "iteration - 1641 -> loss: 0.0003804130962767362, self.slope: [1.02082029 1.02091523], self.intercept: 1.0017730222106067\n",
      "iteration - 1642 -> loss: 0.00038038474555881596, self.slope: [1.02083214 1.02092715], self.intercept: 1.001774047883672\n",
      "iteration - 1643 -> loss: 0.0003803563992121921, self.slope: [1.02084399 1.02093907], self.intercept: 1.0017750734956263\n",
      "iteration - 1644 -> loss: 0.00038032805723583167, self.slope: [1.02085583 1.02095098], self.intercept: 1.0017760990464748\n",
      "iteration - 1645 -> loss: 0.0003802997196287124, self.slope: [1.02086768 1.0209629 ], self.intercept: 1.001777124536227\n",
      "iteration - 1646 -> loss: 0.00038027138638981837, self.slope: [1.02087953 1.02097481], self.intercept: 1.0017781499648901\n",
      "iteration - 1647 -> loss: 0.00038024305751812427, self.slope: [1.02089137 1.02098672], self.intercept: 1.0017791753324738\n",
      "iteration - 1648 -> loss: 0.00038021473301260675, self.slope: [1.02090321 1.02099864], self.intercept: 1.0017802006389835\n",
      "iteration - 1649 -> loss: 0.00038018641287221983, self.slope: [1.02091506 1.02101055], self.intercept: 1.0017812258844285\n",
      "iteration - 1650 -> loss: 0.0003801580970959654, self.slope: [1.0209269  1.02102246], self.intercept: 1.0017822510688157\n",
      "iteration - 1651 -> loss: 0.0003801297856828242, self.slope: [1.02093874 1.02103437], self.intercept: 1.0017832761921543\n",
      "iteration - 1652 -> loss: 0.00038010147863176203, self.slope: [1.02095058 1.02104627], self.intercept: 1.0017843012544523\n",
      "iteration - 1653 -> loss: 0.00038007317594175664, self.slope: [1.02096242 1.02105818], self.intercept: 1.001785326255717\n",
      "iteration - 1654 -> loss: 0.00038004487761179, self.slope: [1.02097426 1.02107009], self.intercept: 1.0017863511959575\n",
      "iteration - 1655 -> loss: 0.0003800165836408386, self.slope: [1.0209861  1.02108199], self.intercept: 1.0017873760751796\n",
      "iteration - 1656 -> loss: 0.00037998829402789263, self.slope: [1.02099793 1.0210939 ], self.intercept: 1.0017884008933926\n",
      "iteration - 1657 -> loss: 0.0003799600087719076, self.slope: [1.02100977 1.0211058 ], self.intercept: 1.0017894256506048\n",
      "iteration - 1658 -> loss: 0.0003799317278718763, self.slope: [1.0210216  1.02111771], self.intercept: 1.0017904503468242\n",
      "iteration - 1659 -> loss: 0.0003799034513267848, self.slope: [1.02103344 1.02112961], self.intercept: 1.0017914749820576\n",
      "iteration - 1660 -> loss: 0.0003798751791356203, self.slope: [1.02104527 1.02114151], self.intercept: 1.0017924995563134\n",
      "iteration - 1661 -> loss: 0.00037984691129733266, self.slope: [1.0210571  1.02115341], self.intercept: 1.001793524069601\n",
      "iteration - 1662 -> loss: 0.00037981864781093584, self.slope: [1.02106893 1.02116531], self.intercept: 1.0017945485219262\n",
      "iteration - 1663 -> loss: 0.00037979038867537777, self.slope: [1.02108076 1.02117721], self.intercept: 1.001795572913299\n",
      "iteration - 1664 -> loss: 0.0003797621338896714, self.slope: [1.02109259 1.0211891 ], self.intercept: 1.0017965972437244\n",
      "iteration - 1665 -> loss: 0.0003797338834527844, self.slope: [1.02110442 1.021201  ], self.intercept: 1.0017976215132123\n",
      "iteration - 1666 -> loss: 0.0003797056373636959, self.slope: [1.02111625 1.0212129 ], self.intercept: 1.0017986457217711\n",
      "iteration - 1667 -> loss: 0.0003796773956213915, self.slope: [1.02112807 1.02122479], self.intercept: 1.0017996698694078\n",
      "iteration - 1668 -> loss: 0.00037964915822487425, self.slope: [1.0211399  1.02123668], self.intercept: 1.0018006939561306\n",
      "iteration - 1669 -> loss: 0.0003796209251730914, self.slope: [1.02115172 1.02124858], self.intercept: 1.0018017179819487\n",
      "iteration - 1670 -> loss: 0.00037959269646504687, self.slope: [1.02116355 1.02126047], self.intercept: 1.0018027419468674\n",
      "iteration - 1671 -> loss: 0.0003795644720997273, self.slope: [1.02117537 1.02127236], self.intercept: 1.0018037658508976\n",
      "iteration - 1672 -> loss: 0.0003795362520760889, self.slope: [1.02118719 1.02128425], self.intercept: 1.0018047896940439\n",
      "iteration - 1673 -> loss: 0.00037950803639318005, self.slope: [1.02119901 1.02129614], self.intercept: 1.0018058134763175\n",
      "iteration - 1674 -> loss: 0.00037947982504990915, self.slope: [1.02121083 1.02130803], self.intercept: 1.0018068371977253\n",
      "iteration - 1675 -> loss: 0.00037945161804529175, self.slope: [1.02122265 1.02131991], self.intercept: 1.001807860858273\n",
      "iteration - 1676 -> loss: 0.00037942341537833377, self.slope: [1.02123447 1.0213318 ], self.intercept: 1.0018088844579698\n",
      "iteration - 1677 -> loss: 0.00037939521704800217, self.slope: [1.02124629 1.02134369], self.intercept: 1.0018099079968237\n",
      "iteration - 1678 -> loss: 0.0003793670230532897, self.slope: [1.0212581  1.02135557], self.intercept: 1.0018109314748442\n",
      "iteration - 1679 -> loss: 0.00037933883339316416, self.slope: [1.02126992 1.02136746], self.intercept: 1.001811954892038\n",
      "iteration - 1680 -> loss: 0.00037931064806664603, self.slope: [1.02128173 1.02137934], self.intercept: 1.0018129782484124\n",
      "iteration - 1681 -> loss: 0.0003792824670726711, self.slope: [1.02129355 1.02139122], self.intercept: 1.0018140015439763\n",
      "iteration - 1682 -> loss: 0.0003792542904102844, self.slope: [1.02130536 1.0214031 ], self.intercept: 1.0018150247787376\n",
      "iteration - 1683 -> loss: 0.0003792261180784371, self.slope: [1.02131717 1.02141498], self.intercept: 1.0018160479527034\n",
      "iteration - 1684 -> loss: 0.00037919795007613924, self.slope: [1.02132898 1.02142686], self.intercept: 1.0018170710658816\n",
      "iteration - 1685 -> loss: 0.00037916978640233605, self.slope: [1.02134079 1.02143874], self.intercept: 1.0018180941182822\n",
      "iteration - 1686 -> loss: 0.0003791416270560665, self.slope: [1.0213526  1.02145062], self.intercept: 1.0018191171099098\n",
      "iteration - 1687 -> loss: 0.0003791134720363003, self.slope: [1.02136441 1.02146249], self.intercept: 1.0018201400407747\n",
      "iteration - 1688 -> loss: 0.00037908532134203136, self.slope: [1.02137622 1.02147437], self.intercept: 1.0018211629108846\n",
      "iteration - 1689 -> loss: 0.00037905717497223307, self.slope: [1.02138802 1.02148624], self.intercept: 1.0018221857202463\n",
      "iteration - 1690 -> loss: 0.0003790290329259296, self.slope: [1.02139983 1.02149812], self.intercept: 1.0018232084688679\n",
      "iteration - 1691 -> loss: 0.00037900089520207826, self.slope: [1.02141163 1.02150999], self.intercept: 1.0018242311567571\n",
      "iteration - 1692 -> loss: 0.0003789727617996459, self.slope: [1.02142343 1.02152186], self.intercept: 1.001825253783923\n",
      "iteration - 1693 -> loss: 0.0003789446327177007, self.slope: [1.02143524 1.02153373], self.intercept: 1.001826276350372\n",
      "iteration - 1694 -> loss: 0.00037891650795515876, self.slope: [1.02144704 1.0215456 ], self.intercept: 1.0018272988561137\n",
      "iteration - 1695 -> loss: 0.00037888838751105316, self.slope: [1.02145884 1.02155747], self.intercept: 1.0018283213011547\n",
      "iteration - 1696 -> loss: 0.00037886027138436465, self.slope: [1.02147064 1.02156934], self.intercept: 1.0018293436855035\n",
      "iteration - 1697 -> loss: 0.0003788321595740881, self.slope: [1.02148244 1.02158121], self.intercept: 1.0018303660091696\n",
      "iteration - 1698 -> loss: 0.00037880405207920813, self.slope: [1.02149424 1.02159307], self.intercept: 1.0018313882721566\n",
      "iteration - 1699 -> loss: 0.0003787759488987271, self.slope: [1.02150603 1.02160494], self.intercept: 1.0018324104744754\n",
      "iteration - 1700 -> loss: 0.0003787478500316383, self.slope: [1.02151783 1.02161681], self.intercept: 1.0018334326161324\n",
      "iteration - 1701 -> loss: 0.00037871975547692, self.slope: [1.02152962 1.02162867], self.intercept: 1.0018344546971374\n",
      "iteration - 1702 -> loss: 0.00037869166523357765, self.slope: [1.02154142 1.02164053], self.intercept: 1.0018354767174986\n",
      "iteration - 1703 -> loss: 0.0003786635793006056, self.slope: [1.02155321 1.02165239], self.intercept: 1.0018364986772215\n",
      "iteration - 1704 -> loss: 0.0003786354976770013, self.slope: [1.021565   1.02166426], self.intercept: 1.0018375205763148\n",
      "iteration - 1705 -> loss: 0.00037860742036175483, self.slope: [1.0215768  1.02167612], self.intercept: 1.001838542414787\n",
      "iteration - 1706 -> loss: 0.00037857934735385746, self.slope: [1.02158859 1.02168797], self.intercept: 1.0018395641926459\n",
      "iteration - 1707 -> loss: 0.000378551278652298, self.slope: [1.02160038 1.02169983], self.intercept: 1.0018405859098993\n",
      "iteration - 1708 -> loss: 0.00037852321425609054, self.slope: [1.02161217 1.02171169], self.intercept: 1.0018416075665544\n",
      "iteration - 1709 -> loss: 0.00037849515416420794, self.slope: [1.02162395 1.02172355], self.intercept: 1.0018426291626192\n",
      "iteration - 1710 -> loss: 0.00037846709837567724, self.slope: [1.02163574 1.0217354 ], self.intercept: 1.0018436506981017\n",
      "iteration - 1711 -> loss: 0.00037843904688947326, self.slope: [1.02164753 1.02174726], self.intercept: 1.0018446721730092\n",
      "iteration - 1712 -> loss: 0.0003784109997046048, self.slope: [1.02165931 1.02175911], self.intercept: 1.0018456935873512\n",
      "iteration - 1713 -> loss: 0.00037838295682004726, self.slope: [1.0216711  1.02177097], self.intercept: 1.001846714941134\n",
      "iteration - 1714 -> loss: 0.00037835491823480754, self.slope: [1.02168288 1.02178282], self.intercept: 1.001847736234367\n",
      "iteration - 1715 -> loss: 0.00037832688394791016, self.slope: [1.02169466 1.02179467], self.intercept: 1.001848757467057\n",
      "iteration - 1716 -> loss: 0.00037829885395830923, self.slope: [1.02170644 1.02180652], self.intercept: 1.001849778639211\n",
      "iteration - 1717 -> loss: 0.00037827082826504135, self.slope: [1.02171822 1.02181837], self.intercept: 1.0018507997508395\n",
      "iteration - 1718 -> loss: 0.00037824280686710036, self.slope: [1.02173    1.02183022], self.intercept: 1.0018518208019482\n",
      "iteration - 1719 -> loss: 0.00037821478976343773, self.slope: [1.02174178 1.02184206], self.intercept: 1.0018528417925456\n",
      "iteration - 1720 -> loss: 0.00037818677695311055, self.slope: [1.02175356 1.02185391], self.intercept: 1.0018538627226397\n",
      "iteration - 1721 -> loss: 0.00037815876843508593, self.slope: [1.02176534 1.02186576], self.intercept: 1.0018548835922376\n",
      "iteration - 1722 -> loss: 0.0003781307642083852, self.slope: [1.02177711 1.0218776 ], self.intercept: 1.0018559044013482\n",
      "iteration - 1723 -> loss: 0.0003781027642719931, self.slope: [1.02178889 1.02188945], self.intercept: 1.0018569251499783\n",
      "iteration - 1724 -> loss: 0.00037807476862491475, self.slope: [1.02180066 1.02190129], self.intercept: 1.0018579458381351\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 1725 -> loss: 0.0003780467772661511, self.slope: [1.02181244 1.02191313], self.intercept: 1.0018589664658288\n",
      "iteration - 1726 -> loss: 0.0003780187901946942, self.slope: [1.02182421 1.02192497], self.intercept: 1.0018599870330671\n",
      "iteration - 1727 -> loss: 0.0003779908074095709, self.slope: [1.02183598 1.02193681], self.intercept: 1.0018610075398549\n",
      "iteration - 1728 -> loss: 0.0003779628289097628, self.slope: [1.02184775 1.02194865], self.intercept: 1.0018620279862023\n",
      "iteration - 1729 -> loss: 0.00037793485469427864, self.slope: [1.02185952 1.02196049], self.intercept: 1.0018630483721174\n",
      "iteration - 1730 -> loss: 0.0003779068847621125, self.slope: [1.02187129 1.02197233], self.intercept: 1.001864068697608\n",
      "iteration - 1731 -> loss: 0.00037787891911227165, self.slope: [1.02188306 1.02198417], self.intercept: 1.0018650889626797\n",
      "iteration - 1732 -> loss: 0.0003778509577437561, self.slope: [1.02189482 1.021996  ], self.intercept: 1.001866109167342\n",
      "iteration - 1733 -> loss: 0.00037782300065559624, self.slope: [1.02190659 1.02200784], self.intercept: 1.0018671293116033\n",
      "iteration - 1734 -> loss: 0.00037779504784675043, self.slope: [1.02191835 1.02201967], self.intercept: 1.0018681493954713\n",
      "iteration - 1735 -> loss: 0.0003777670993162424, self.slope: [1.02193012 1.0220315 ], self.intercept: 1.001869169418953\n",
      "iteration - 1736 -> loss: 0.00037773915506310465, self.slope: [1.02194188 1.02204334], self.intercept: 1.0018701893820565\n",
      "iteration - 1737 -> loss: 0.0003777112150862886, self.slope: [1.02195364 1.02205517], self.intercept: 1.0018712092847897\n",
      "iteration - 1738 -> loss: 0.00037768327938482677, self.slope: [1.02196541 1.022067  ], self.intercept: 1.0018722291271593\n",
      "iteration - 1739 -> loss: 0.00037765534795773984, self.slope: [1.02197717 1.02207883], self.intercept: 1.0018732489091748\n",
      "iteration - 1740 -> loss: 0.0003776274208040124, self.slope: [1.02198893 1.02209066], self.intercept: 1.0018742686308433\n",
      "iteration - 1741 -> loss: 0.00037759949792265726, self.slope: [1.02200069 1.02210248], self.intercept: 1.001875288292173\n",
      "iteration - 1742 -> loss: 0.000377571579312687, self.slope: [1.02201244 1.02211431], self.intercept: 1.0018763078931707\n",
      "iteration - 1743 -> loss: 0.0003775436649730906, self.slope: [1.0220242  1.02212614], self.intercept: 1.001877327433846\n",
      "iteration - 1744 -> loss: 0.00037751575490288785, self.slope: [1.02203596 1.02213796], self.intercept: 1.001878346914205\n",
      "iteration - 1745 -> loss: 0.0003774878491010797, self.slope: [1.02204771 1.02214979], self.intercept: 1.0018793663342571\n",
      "iteration - 1746 -> loss: 0.0003774599475666793, self.slope: [1.02205947 1.02216161], self.intercept: 1.0018803856940102\n",
      "iteration - 1747 -> loss: 0.0003774320502986811, self.slope: [1.02207122 1.02217343], self.intercept: 1.001881404993471\n",
      "iteration - 1748 -> loss: 0.00037740415729612336, self.slope: [1.02208297 1.02218525], self.intercept: 1.001882424232645\n",
      "iteration - 1749 -> loss: 0.00037737626855798077, self.slope: [1.02209472 1.02219708], self.intercept: 1.0018834434115438\n",
      "iteration - 1750 -> loss: 0.0003773483840832809, self.slope: [1.02210647 1.02220889], self.intercept: 1.0018844625301728\n",
      "iteration - 1751 -> loss: 0.00037732050387103257, self.slope: [1.02211822 1.02222071], self.intercept: 1.00188548158854\n",
      "iteration - 1752 -> loss: 0.0003772926279202286, self.slope: [1.02212997 1.02223253], self.intercept: 1.0018865005866555\n",
      "iteration - 1753 -> loss: 0.00037726475622989716, self.slope: [1.02214172 1.02224435], self.intercept: 1.0018875195245258\n",
      "iteration - 1754 -> loss: 0.0003772368887990418, self.slope: [1.02215347 1.02225616], self.intercept: 1.0018885384021585\n",
      "iteration - 1755 -> loss: 0.0003772090256266751, self.slope: [1.02216521 1.02226798], self.intercept: 1.0018895572195625\n",
      "iteration - 1756 -> loss: 0.00037718116671178915, self.slope: [1.02217696 1.02227979], self.intercept: 1.0018905759767422\n",
      "iteration - 1757 -> loss: 0.0003771533120534205, self.slope: [1.0221887  1.02229161], self.intercept: 1.001891594673709\n",
      "iteration - 1758 -> loss: 0.00037712546165056746, self.slope: [1.02220045 1.02230342], self.intercept: 1.001892613310471\n",
      "iteration - 1759 -> loss: 0.0003770976155022482, self.slope: [1.02221219 1.02231523], self.intercept: 1.0018936318870335\n",
      "iteration - 1760 -> loss: 0.00037706977360746325, self.slope: [1.02222393 1.02232704], self.intercept: 1.0018946504034032\n",
      "iteration - 1761 -> loss: 0.0003770419359652282, self.slope: [1.02223567 1.02233885], self.intercept: 1.0018956688595906\n",
      "iteration - 1762 -> loss: 0.0003770141025745851, self.slope: [1.02224741 1.02235066], self.intercept: 1.001896687255603\n",
      "iteration - 1763 -> loss: 0.00037698627343449293, self.slope: [1.02225915 1.02236247], self.intercept: 1.0018977055914475\n",
      "iteration - 1764 -> loss: 0.0003769584485439942, self.slope: [1.02227089 1.02237428], self.intercept: 1.001898723867133\n",
      "iteration - 1765 -> loss: 0.0003769306279020964, self.slope: [1.02228262 1.02238608], self.intercept: 1.0018997420826672\n",
      "iteration - 1766 -> loss: 0.0003769028115078288, self.slope: [1.02229436 1.02239789], self.intercept: 1.0019007602380559\n",
      "iteration - 1767 -> loss: 0.00037687499936018794, self.slope: [1.0223061  1.02240969], self.intercept: 1.0019017783333086\n",
      "iteration - 1768 -> loss: 0.0003768471914581959, self.slope: [1.02231783 1.0224215 ], self.intercept: 1.001902796368434\n",
      "iteration - 1769 -> loss: 0.0003768193878008761, self.slope: [1.02232956 1.0224333 ], self.intercept: 1.0019038143434376\n",
      "iteration - 1770 -> loss: 0.0003767915883872104, self.slope: [1.0223413 1.0224451], self.intercept: 1.0019048322583284\n",
      "iteration - 1771 -> loss: 0.00037676379321625, self.slope: [1.02235303 1.0224569 ], self.intercept: 1.0019058501131142\n",
      "iteration - 1772 -> loss: 0.00037673600228698556, self.slope: [1.02236476 1.0224687 ], self.intercept: 1.001906867907802\n",
      "iteration - 1773 -> loss: 0.00037670821559843284, self.slope: [1.02237649 1.0224805 ], self.intercept: 1.0019078856423995\n",
      "iteration - 1774 -> loss: 0.00037668043314962587, self.slope: [1.02238822 1.0224923 ], self.intercept: 1.0019089033169155\n",
      "iteration - 1775 -> loss: 0.00037665265493958585, self.slope: [1.02239995 1.0225041 ], self.intercept: 1.001909920931357\n",
      "iteration - 1776 -> loss: 0.00037662488096729357, self.slope: [1.02241167 1.02251589], self.intercept: 1.0019109384857319\n",
      "iteration - 1777 -> loss: 0.00037659711123182377, self.slope: [1.0224234  1.02252769], self.intercept: 1.0019119559800493\n",
      "iteration - 1778 -> loss: 0.00037656934573213334, self.slope: [1.02243512 1.02253948], self.intercept: 1.001912973414316\n",
      "iteration - 1779 -> loss: 0.00037654158446726293, self.slope: [1.02244685 1.02255128], self.intercept: 1.001913990788538\n",
      "iteration - 1780 -> loss: 0.0003765138274362341, self.slope: [1.02245857 1.02256307], self.intercept: 1.0019150081027255\n",
      "iteration - 1781 -> loss: 0.00037648607463808265, self.slope: [1.02247029 1.02257486], self.intercept: 1.0019160253568857\n",
      "iteration - 1782 -> loss: 0.0003764583260717923, self.slope: [1.02248202 1.02258665], self.intercept: 1.0019170425510249\n",
      "iteration - 1783 -> loss: 0.0003764305817363996, self.slope: [1.02249374 1.02259845], self.intercept: 1.0019180596851527\n",
      "iteration - 1784 -> loss: 0.0003764028416309254, self.slope: [1.02250546 1.02261023], self.intercept: 1.0019190767592752\n",
      "iteration - 1785 -> loss: 0.00037637510575437615, self.slope: [1.02251718 1.02262202], self.intercept: 1.0019200937734012\n",
      "iteration - 1786 -> loss: 0.00037634737410578316, self.slope: [1.02252889 1.02263381], self.intercept: 1.0019211107275374\n",
      "iteration - 1787 -> loss: 0.0003763196466841648, self.slope: [1.02254061 1.0226456 ], self.intercept: 1.0019221276216934\n",
      "iteration - 1788 -> loss: 0.00037629192348855235, self.slope: [1.02255233 1.02265738], self.intercept: 1.0019231444558756\n",
      "iteration - 1789 -> loss: 0.00037626420451794014, self.slope: [1.02256404 1.02266917], self.intercept: 1.0019241612300929\n",
      "iteration - 1790 -> loss: 0.0003762364897713789, self.slope: [1.02257576 1.02268095], self.intercept: 1.0019251779443514\n",
      "iteration - 1791 -> loss: 0.0003762087792478552, self.slope: [1.02258747 1.02269274], self.intercept: 1.00192619459866\n",
      "iteration - 1792 -> loss: 0.00037618107294643406, self.slope: [1.02259918 1.02270452], self.intercept: 1.0019272111930264\n",
      "iteration - 1793 -> loss: 0.0003761533708660979, self.slope: [1.02261089 1.0227163 ], self.intercept: 1.0019282277274582\n",
      "iteration - 1794 -> loss: 0.0003761256730058794, self.slope: [1.02262261 1.02272808], self.intercept: 1.0019292442019636\n",
      "iteration - 1795 -> loss: 0.00037609797936482425, self.slope: [1.02263432 1.02273986], self.intercept: 1.0019302606165492\n",
      "iteration - 1796 -> loss: 0.0003760702899419124, self.slope: [1.02264602 1.02275164], self.intercept: 1.0019312769712232\n",
      "iteration - 1797 -> loss: 0.00037604260473621384, self.slope: [1.02265773 1.02276342], self.intercept: 1.0019322932659935\n",
      "iteration - 1798 -> loss: 0.00037601492374671593, self.slope: [1.02266944 1.02277519], self.intercept: 1.0019333095008682\n",
      "iteration - 1799 -> loss: 0.0003759872469724558, self.slope: [1.02268115 1.02278697], self.intercept: 1.0019343256758528\n",
      "iteration - 1800 -> loss: 0.00037595957441247585, self.slope: [1.02269285 1.02279874], self.intercept: 1.0019353417909582\n",
      "iteration - 1801 -> loss: 0.00037593190606577555, self.slope: [1.02270456 1.02281052], self.intercept: 1.0019363578461895\n",
      "iteration - 1802 -> loss: 0.00037590424193137655, self.slope: [1.02271626 1.02282229], self.intercept: 1.0019373738415578\n",
      "iteration - 1803 -> loss: 0.0003758765820083217, self.slope: [1.02272796 1.02283406], self.intercept: 1.0019383897770675\n",
      "iteration - 1804 -> loss: 0.00037584892629561787, self.slope: [1.02273966 1.02284583], self.intercept: 1.0019394056527287\n",
      "iteration - 1805 -> loss: 0.0003758212747923009, self.slope: [1.02275137 1.02285761], self.intercept: 1.0019404214685477\n",
      "iteration - 1806 -> loss: 0.00037579362749740405, self.slope: [1.02276307 1.02286938], self.intercept: 1.001941437224533\n",
      "iteration - 1807 -> loss: 0.0003757659844099372, self.slope: [1.02277476 1.02288114], self.intercept: 1.001942452920691\n",
      "iteration - 1808 -> loss: 0.0003757383455289435, self.slope: [1.02278646 1.02289291], self.intercept: 1.0019434685570296\n",
      "iteration - 1809 -> loss: 0.0003757107108534318, self.slope: [1.02279816 1.02290468], self.intercept: 1.0019444841335559\n",
      "iteration - 1810 -> loss: 0.0003756830803824527, self.slope: [1.02280986 1.02291645], self.intercept: 1.0019454996502801\n",
      "iteration - 1811 -> loss: 0.00037565545411500614, self.slope: [1.02282155 1.02292821], self.intercept: 1.001946515107208\n",
      "iteration - 1812 -> loss: 0.0003756278320501396, self.slope: [1.02283325 1.02293998], self.intercept: 1.0019475305043481\n",
      "iteration - 1813 -> loss: 0.00037560021418686857, self.slope: [1.02284494 1.02295174], self.intercept: 1.001948545841707\n",
      "iteration - 1814 -> loss: 0.0003755726005242261, self.slope: [1.02285663 1.0229635 ], self.intercept: 1.001949561119294\n",
      "iteration - 1815 -> loss: 0.00037554499106125363, self.slope: [1.02286833 1.02297526], self.intercept: 1.0019505763371177\n",
      "iteration - 1816 -> loss: 0.00037551738579695077, self.slope: [1.02288002 1.02298702], self.intercept: 1.001951591495184\n",
      "iteration - 1817 -> loss: 0.00037548978473038203, self.slope: [1.02289171 1.02299878], self.intercept: 1.001952606593499\n",
      "iteration - 1818 -> loss: 0.00037546218786054306, self.slope: [1.0229034  1.02301054], self.intercept: 1.0019536216320721\n",
      "iteration - 1819 -> loss: 0.0003754345951864907, self.slope: [1.02291508 1.0230223 ], self.intercept: 1.0019546366109107\n",
      "iteration - 1820 -> loss: 0.0003754070067072429, self.slope: [1.02292677 1.02303406], self.intercept: 1.001955651530025\n",
      "iteration - 1821 -> loss: 0.0003753794224218103, self.slope: [1.02293846 1.02304582], self.intercept: 1.0019566663894182\n",
      "iteration - 1822 -> loss: 0.00037535184232927887, self.slope: [1.02295014 1.02305757], self.intercept: 1.0019576811891013\n",
      "iteration - 1823 -> loss: 0.0003753242664286116, self.slope: [1.02296183 1.02306933], self.intercept: 1.0019586959290823\n",
      "iteration - 1824 -> loss: 0.0003752966947188858, self.slope: [1.02297351 1.02308108], self.intercept: 1.0019597106093663\n",
      "iteration - 1825 -> loss: 0.00037526912719912104, self.slope: [1.0229852  1.02309283], self.intercept: 1.0019607252299636\n",
      "iteration - 1826 -> loss: 0.0003752415638683356, self.slope: [1.02299688 1.02310458], self.intercept: 1.00196173979088\n",
      "iteration - 1827 -> loss: 0.00037521400472559206, self.slope: [1.02300856 1.02311634], self.intercept: 1.0019627542921243\n",
      "iteration - 1828 -> loss: 0.00037518644976988974, self.slope: [1.02302024 1.02312809], self.intercept: 1.0019637687337035\n",
      "iteration - 1829 -> loss: 0.0003751588990002858, self.slope: [1.02303192 1.02313984], self.intercept: 1.0019647831156242\n",
      "iteration - 1830 -> loss: 0.00037513135241581285, self.slope: [1.0230436  1.02315158], self.intercept: 1.0019657974378962\n",
      "iteration - 1831 -> loss: 0.00037510381001548633, self.slope: [1.02305528 1.02316333], self.intercept: 1.0019668117005263\n",
      "iteration - 1832 -> loss: 0.0003750762717983427, self.slope: [1.02306695 1.02317508], self.intercept: 1.0019678259035223\n",
      "iteration - 1833 -> loss: 0.00037504873776342414, self.slope: [1.02307863 1.02318682], self.intercept: 1.0019688400468907\n",
      "iteration - 1834 -> loss: 0.00037502120790976185, self.slope: [1.0230903  1.02319857], self.intercept: 1.0019698541306414\n",
      "iteration - 1835 -> loss: 0.0003749936822363898, self.slope: [1.02310198 1.02321031], self.intercept: 1.0019708681547796\n",
      "iteration - 1836 -> loss: 0.0003749661607423377, self.slope: [1.02311365 1.02322206], self.intercept: 1.0019718821193158\n",
      "iteration - 1837 -> loss: 0.00037493864342665897, self.slope: [1.02312532 1.0232338 ], self.intercept: 1.0019728960242555\n",
      "iteration - 1838 -> loss: 0.0003749111302883695, self.slope: [1.02313699 1.02324554], self.intercept: 1.0019739098696065\n",
      "iteration - 1839 -> loss: 0.00037488362132652236, self.slope: [1.02314866 1.02325728], self.intercept: 1.0019749236553777\n",
      "iteration - 1840 -> loss: 0.00037485611654013476, self.slope: [1.02316033 1.02326902], self.intercept: 1.0019759373815764\n",
      "iteration - 1841 -> loss: 0.000374828615928258, self.slope: [1.023172   1.02328076], self.intercept: 1.0019769510482093\n",
      "iteration - 1842 -> loss: 0.0003748011194899306, self.slope: [1.02318367 1.0232925 ], self.intercept: 1.0019779646552847\n",
      "iteration - 1843 -> loss: 0.0003747736272241675, self.slope: [1.02319534 1.02330423], self.intercept: 1.0019789782028108\n",
      "iteration - 1844 -> loss: 0.00037474613913001113, self.slope: [1.023207   1.02331597], self.intercept: 1.0019799916907948\n",
      "iteration - 1845 -> loss: 0.00037471865520651704, self.slope: [1.02321867 1.02332771], self.intercept: 1.0019810051192428\n",
      "iteration - 1846 -> loss: 0.0003746911754527307, self.slope: [1.02323033 1.02333944], self.intercept: 1.0019820184881654\n",
      "iteration - 1847 -> loss: 0.00037466369986765045, self.slope: [1.023242   1.02335117], self.intercept: 1.0019830317975669\n",
      "iteration - 1848 -> loss: 0.0003746362284503495, self.slope: [1.02325366 1.02336291], self.intercept: 1.0019840450474575\n",
      "iteration - 1849 -> loss: 0.00037460876119986894, self.slope: [1.02326532 1.02337464], self.intercept: 1.0019850582378438\n",
      "iteration - 1850 -> loss: 0.0003745812981152149, self.slope: [1.02327698 1.02338637], self.intercept: 1.001986071368736\n",
      "iteration - 1851 -> loss: 0.0003745538391954372, self.slope: [1.02328864 1.0233981 ], self.intercept: 1.0019870844401373\n",
      "iteration - 1852 -> loss: 0.00037452638443960474, self.slope: [1.0233003  1.02340983], self.intercept: 1.001988097452058\n",
      "iteration - 1853 -> loss: 0.0003744989338467283, self.slope: [1.02331196 1.02342156], self.intercept: 1.0019891104045064\n",
      "iteration - 1854 -> loss: 0.00037447148741584187, self.slope: [1.02332361 1.02343328], self.intercept: 1.001990123297489\n",
      "iteration - 1855 -> loss: 0.00037444404514601896, self.slope: [1.02333527 1.02344501], self.intercept: 1.0019911361310128\n",
      "iteration - 1856 -> loss: 0.00037441660703626346, self.slope: [1.02334693 1.02345673], self.intercept: 1.001992148905086\n",
      "iteration - 1857 -> loss: 0.0003743891730856614, self.slope: [1.02335858 1.02346846], self.intercept: 1.001993161619717\n",
      "iteration - 1858 -> loss: 0.0003743617432932062, self.slope: [1.02337023 1.02348018], self.intercept: 1.001994174274913\n",
      "iteration - 1859 -> loss: 0.00037433431765797743, self.slope: [1.02338189 1.02349191], self.intercept: 1.001995186870681\n",
      "iteration - 1860 -> loss: 0.0003743068961789961, self.slope: [1.02339354 1.02350363], self.intercept: 1.00199619940703\n",
      "iteration - 1861 -> loss: 0.00037427947885528695, self.slope: [1.02340519 1.02351535], self.intercept: 1.0019972118839664\n",
      "iteration - 1862 -> loss: 0.00037425206568593195, self.slope: [1.02341684 1.02352707], self.intercept: 1.001998224301497\n",
      "iteration - 1863 -> loss: 0.00037422465666996253, self.slope: [1.02342849 1.02353879], self.intercept: 1.0019992366596315\n",
      "iteration - 1864 -> loss: 0.00037419725180639035, self.slope: [1.02344014 1.02355051], self.intercept: 1.0020002489583772\n",
      "iteration - 1865 -> loss: 0.0003741698510943078, self.slope: [1.02345178 1.02356222], self.intercept: 1.0020012611977407\n",
      "iteration - 1866 -> loss: 0.00037414245453273073, self.slope: [1.02346343 1.02357394], self.intercept: 1.0020022733777298\n",
      "iteration - 1867 -> loss: 0.0003741150621207098, self.slope: [1.02347508 1.02358566], self.intercept: 1.0020032854983525\n",
      "iteration - 1868 -> loss: 0.000374087673857285, self.slope: [1.02348672 1.02359737], self.intercept: 1.0020042975596162\n",
      "iteration - 1869 -> loss: 0.0003740602897414968, self.slope: [1.02349836 1.02360909], self.intercept: 1.0020053095615287\n",
      "iteration - 1870 -> loss: 0.00037403290977240563, self.slope: [1.02351001 1.0236208 ], self.intercept: 1.0020063215040966\n",
      "iteration - 1871 -> loss: 0.000374005533949033, self.slope: [1.02352165 1.02363251], self.intercept: 1.0020073333873292\n",
      "iteration - 1872 -> loss: 0.00037397816227044954, self.slope: [1.02353329 1.02364422], self.intercept: 1.0020083452112327\n",
      "iteration - 1873 -> loss: 0.0003739507947356994, self.slope: [1.02354493 1.02365593], self.intercept: 1.0020093569758162\n",
      "iteration - 1874 -> loss: 0.0003739234313437929, self.slope: [1.02355657 1.02366764], self.intercept: 1.0020103686810873\n",
      "iteration - 1875 -> loss: 0.0003738960720938304, self.slope: [1.02356821 1.02367935], self.intercept: 1.0020113803270512\n",
      "iteration - 1876 -> loss: 0.00037386871698483155, self.slope: [1.02357985 1.02369106], self.intercept: 1.002012391913718\n",
      "iteration - 1877 -> loss: 0.00037384136601583117, self.slope: [1.02359148 1.02370277], self.intercept: 1.0020134034410937\n",
      "iteration - 1878 -> loss: 0.00037381401918588566, self.slope: [1.02360312 1.02371447], self.intercept: 1.002014414909187\n",
      "iteration - 1879 -> loss: 0.000373786676494053, self.slope: [1.02361475 1.02372618], self.intercept: 1.0020154263180052\n",
      "iteration - 1880 -> loss: 0.0003737593379393761, self.slope: [1.02362639 1.02373788], self.intercept: 1.0020164376675555\n",
      "iteration - 1881 -> loss: 0.0003737320035208977, self.slope: [1.02363802 1.02374959], self.intercept: 1.0020174489578466\n",
      "iteration - 1882 -> loss: 0.0003737046732376573, self.slope: [1.02364965 1.02376129], self.intercept: 1.0020184601888849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 1883 -> loss: 0.0003736773470887318, self.slope: [1.02366128 1.02377299], self.intercept: 1.0020194713606776\n",
      "iteration - 1884 -> loss: 0.00037365002507315894, self.slope: [1.02367291 1.02378469], self.intercept: 1.002020482473234\n",
      "iteration - 1885 -> loss: 0.00037362270718997097, self.slope: [1.02368454 1.02379639], self.intercept: 1.0020214935265621\n",
      "iteration - 1886 -> loss: 0.00037359539343822883, self.slope: [1.02369617 1.02380809], self.intercept: 1.0020225045206665\n",
      "iteration - 1887 -> loss: 0.00037356808381699074, self.slope: [1.0237078  1.02381979], self.intercept: 1.002023515455557\n",
      "iteration - 1888 -> loss: 0.00037354077832528037, self.slope: [1.02371943 1.02383149], self.intercept: 1.0020245263312413\n",
      "iteration - 1889 -> loss: 0.0003735134769621953, self.slope: [1.02373105 1.02384318], self.intercept: 1.0020255371477265\n",
      "iteration - 1890 -> loss: 0.00037348617972674013, self.slope: [1.02374268 1.02385488], self.intercept: 1.0020265479050192\n",
      "iteration - 1891 -> loss: 0.0003734588866180068, self.slope: [1.0237543  1.02386657], self.intercept: 1.0020275586031282\n",
      "iteration - 1892 -> loss: 0.0003734315976350047, self.slope: [1.02376592 1.02387827], self.intercept: 1.0020285692420607\n",
      "iteration - 1893 -> loss: 0.00037340431277680763, self.slope: [1.02377755 1.02388996], self.intercept: 1.0020295798218242\n",
      "iteration - 1894 -> loss: 0.00037337703204246947, self.slope: [1.02378917 1.02390165], self.intercept: 1.0020305903424267\n",
      "iteration - 1895 -> loss: 0.00037334975543104013, self.slope: [1.02380079 1.02391334], self.intercept: 1.0020316008038763\n",
      "iteration - 1896 -> loss: 0.00037332248294157696, self.slope: [1.02381241 1.02392503], self.intercept: 1.0020326112061795\n",
      "iteration - 1897 -> loss: 0.00037329521457311025, self.slope: [1.02382403 1.02393672], self.intercept: 1.0020336215493444\n",
      "iteration - 1898 -> loss: 0.0003732679503247262, self.slope: [1.02383565 1.02394841], self.intercept: 1.0020346318333764\n",
      "iteration - 1899 -> loss: 0.0003732406901954379, self.slope: [1.02384726 1.0239601 ], self.intercept: 1.0020356420582843\n",
      "iteration - 1900 -> loss: 0.00037321343418434994, self.slope: [1.02385888 1.02397179], self.intercept: 1.0020366522240785\n",
      "iteration - 1901 -> loss: 0.0003731861822904692, self.slope: [1.02387049 1.02398347], self.intercept: 1.0020376623307645\n",
      "iteration - 1902 -> loss: 0.0003731589345128698, self.slope: [1.02388211 1.02399516], self.intercept: 1.0020386723783496\n",
      "iteration - 1903 -> loss: 0.0003731316908506165, self.slope: [1.02389372 1.02400684], self.intercept: 1.0020396823668416\n",
      "iteration - 1904 -> loss: 0.0003731044513027545, self.slope: [1.02390533 1.02401852], self.intercept: 1.0020406922962477\n",
      "iteration - 1905 -> loss: 0.0003730772158683232, self.slope: [1.02391695 1.02403021], self.intercept: 1.0020417021665762\n",
      "iteration - 1906 -> loss: 0.0003730499845464145, self.slope: [1.02392856 1.02404189], self.intercept: 1.002042711977835\n",
      "iteration - 1907 -> loss: 0.0003730227573360464, self.slope: [1.02394017 1.02405357], self.intercept: 1.0020437217300302\n",
      "iteration - 1908 -> loss: 0.0003729955342362894, self.slope: [1.02395178 1.02406525], self.intercept: 1.0020447314231702\n",
      "iteration - 1909 -> loss: 0.0003729683152462314, self.slope: [1.02396338 1.02407693], self.intercept: 1.0020457410572614\n",
      "iteration - 1910 -> loss: 0.0003729411003648768, self.slope: [1.02397499 1.02408861], self.intercept: 1.0020467506323136\n",
      "iteration - 1911 -> loss: 0.00037291388959132394, self.slope: [1.0239866  1.02410028], self.intercept: 1.0020477601483335\n",
      "iteration - 1912 -> loss: 0.00037288668292459026, self.slope: [1.0239982  1.02411196], self.intercept: 1.0020487696053282\n",
      "iteration - 1913 -> loss: 0.0003728594803637542, self.slope: [1.02400981 1.02412364], self.intercept: 1.002049779003306\n",
      "iteration - 1914 -> loss: 0.00037283228190788844, self.slope: [1.02402141 1.02413531], self.intercept: 1.0020507883422722\n",
      "iteration - 1915 -> loss: 0.0003728050875560425, self.slope: [1.02403302 1.02414698], self.intercept: 1.0020517976222376\n",
      "iteration - 1916 -> loss: 0.0003727778973072434, self.slope: [1.02404462 1.02415866], self.intercept: 1.0020528068432066\n",
      "iteration - 1917 -> loss: 0.0003727507111605989, self.slope: [1.02405622 1.02417033], self.intercept: 1.002053816005189\n",
      "iteration - 1918 -> loss: 0.00037272352911513575, self.slope: [1.02406782 1.024182  ], self.intercept: 1.0020548251081915\n",
      "iteration - 1919 -> loss: 0.0003726963511699168, self.slope: [1.02407942 1.02419367], self.intercept: 1.0020558341522219\n",
      "iteration - 1920 -> loss: 0.0003726691773240162, self.slope: [1.02409102 1.02420534], self.intercept: 1.0020568431372878\n",
      "iteration - 1921 -> loss: 0.00037264200757650227, self.slope: [1.02410261 1.02421701], self.intercept: 1.0020578520633965\n",
      "iteration - 1922 -> loss: 0.0003726148419263764, self.slope: [1.02411421 1.02422868], self.intercept: 1.002058860930556\n",
      "iteration - 1923 -> loss: 0.0003725876803727619, self.slope: [1.02412581 1.02424034], self.intercept: 1.0020598697387728\n",
      "iteration - 1924 -> loss: 0.0003725605229146922, self.slope: [1.0241374  1.02425201], self.intercept: 1.0020608784880565\n",
      "iteration - 1925 -> loss: 0.0003725333695512558, self.slope: [1.024149   1.02426367], self.intercept: 1.0020618871784115\n",
      "iteration - 1926 -> loss: 0.0003725062202814707, self.slope: [1.02416059 1.02427534], self.intercept: 1.002062895809847\n",
      "iteration - 1927 -> loss: 0.00037247907510441276, self.slope: [1.02417218 1.024287  ], self.intercept: 1.0020639043823716\n",
      "iteration - 1928 -> loss: 0.0003724519340191626, self.slope: [1.02418377 1.02429866], self.intercept: 1.002064912895991\n",
      "iteration - 1929 -> loss: 0.00037242479702477577, self.slope: [1.02419536 1.02431032], self.intercept: 1.0020659213507135\n",
      "iteration - 1930 -> loss: 0.00037239766412031083, self.slope: [1.02420695 1.02432198], self.intercept: 1.002066929746546\n",
      "iteration - 1931 -> loss: 0.00037237053530481866, self.slope: [1.02421854 1.02433364], self.intercept: 1.0020679380834983\n",
      "iteration - 1932 -> loss: 0.0003723434105773785, self.slope: [1.02423013 1.0243453 ], self.intercept: 1.0020689463615755\n",
      "iteration - 1933 -> loss: 0.0003723162899370551, self.slope: [1.02424172 1.02435696], self.intercept: 1.0020699545807872\n",
      "iteration - 1934 -> loss: 0.00037228917338288155, self.slope: [1.0242533  1.02436862], self.intercept: 1.002070962741139\n",
      "iteration - 1935 -> loss: 0.000372262060913974, self.slope: [1.02426489 1.02438027], self.intercept: 1.0020719708426387\n",
      "iteration - 1936 -> loss: 0.0003722349525293611, self.slope: [1.02427647 1.02439193], self.intercept: 1.0020729788852951\n",
      "iteration - 1937 -> loss: 0.0003722078482281141, self.slope: [1.02428806 1.02440358], self.intercept: 1.0020739868691144\n",
      "iteration - 1938 -> loss: 0.0003721807480093004, self.slope: [1.02429964 1.02441524], self.intercept: 1.0020749947941043\n",
      "iteration - 1939 -> loss: 0.00037215365187197297, self.slope: [1.02431122 1.02442689], self.intercept: 1.0020760026602733\n",
      "iteration - 1940 -> loss: 0.0003721265598152022, self.slope: [1.0243228  1.02443854], self.intercept: 1.002077010467628\n",
      "iteration - 1941 -> loss: 0.0003720994718380823, self.slope: [1.02433438 1.02445019], self.intercept: 1.002078018216176\n",
      "iteration - 1942 -> loss: 0.00037207238793962474, self.slope: [1.02434596 1.02446184], self.intercept: 1.0020790259059227\n",
      "iteration - 1943 -> loss: 0.0003720453081189517, self.slope: [1.02435754 1.02447349], self.intercept: 1.0020800335368798\n",
      "iteration - 1944 -> loss: 0.00037201823237509627, self.slope: [1.02436912 1.02448514], self.intercept: 1.0020810411090517\n",
      "iteration - 1945 -> loss: 0.00037199116070713516, self.slope: [1.02438069 1.02449679], self.intercept: 1.0020820486224487\n",
      "iteration - 1946 -> loss: 0.00037196409311411794, self.slope: [1.02439227 1.02450844], self.intercept: 1.0020830560770748\n",
      "iteration - 1947 -> loss: 0.0003719370295951497, self.slope: [1.02440384 1.02452008], self.intercept: 1.0020840634729404\n",
      "iteration - 1948 -> loss: 0.0003719099701492607, self.slope: [1.02441542 1.02453173], self.intercept: 1.0020850708100517\n",
      "iteration - 1949 -> loss: 0.00037188291477554506, self.slope: [1.02442699 1.02454337], self.intercept: 1.0020860780884169\n",
      "iteration - 1950 -> loss: 0.0003718558634730479, self.slope: [1.02443856 1.02455501], self.intercept: 1.0020870853080424\n",
      "iteration - 1951 -> loss: 0.0003718288162408576, self.slope: [1.02445013 1.02456666], self.intercept: 1.0020880924689355\n",
      "iteration - 1952 -> loss: 0.00037180177307804483, self.slope: [1.0244617 1.0245783], self.intercept: 1.0020890995711054\n",
      "iteration - 1953 -> loss: 0.0003717747339836601, self.slope: [1.02447327 1.02458994], self.intercept: 1.0020901066145593\n",
      "iteration - 1954 -> loss: 0.00037174769895678505, self.slope: [1.02448484 1.02460158], self.intercept: 1.002091113599303\n",
      "iteration - 1955 -> loss: 0.00037172066799646616, self.slope: [1.02449641 1.02461322], self.intercept: 1.0020921205253466\n",
      "iteration - 1956 -> loss: 0.00037169364110182357, self.slope: [1.02450798 1.02462486], self.intercept: 1.002093127392696\n",
      "iteration - 1957 -> loss: 0.0003716666182718808, self.slope: [1.02451954 1.02463649], self.intercept: 1.0020941342013574\n",
      "iteration - 1958 -> loss: 0.0003716395995057288, self.slope: [1.02453111 1.02464813], self.intercept: 1.0020951409513386\n",
      "iteration - 1959 -> loss: 0.000371612584802442, self.slope: [1.02454267 1.02465976], self.intercept: 1.0020961476426482\n",
      "iteration - 1960 -> loss: 0.0003715855741610645, self.slope: [1.02455423 1.0246714 ], self.intercept: 1.0020971542752943\n",
      "iteration - 1961 -> loss: 0.0003715585675806957, self.slope: [1.0245658  1.02468303], self.intercept: 1.002098160849285\n",
      "iteration - 1962 -> loss: 0.0003715315650604003, self.slope: [1.02457736 1.02469467], self.intercept: 1.0020991673646247\n",
      "iteration - 1963 -> loss: 0.0003715045665992437, self.slope: [1.02458892 1.0247063 ], self.intercept: 1.0021001738213249\n",
      "iteration - 1964 -> loss: 0.0003714775721963142, self.slope: [1.02460048 1.02471793], self.intercept: 1.0021011802193907\n",
      "iteration - 1965 -> loss: 0.00037145058185067707, self.slope: [1.02461204 1.02472956], self.intercept: 1.002102186558829\n",
      "iteration - 1966 -> loss: 0.00037142359556138733, self.slope: [1.0246236  1.02474119], self.intercept: 1.0021031928396487\n",
      "iteration - 1967 -> loss: 0.0003713966133275286, self.slope: [1.02463515 1.02475282], self.intercept: 1.0021041990618553\n",
      "iteration - 1968 -> loss: 0.00037136963514818836, self.slope: [1.02464671 1.02476444], self.intercept: 1.0021052052254569\n",
      "iteration - 1969 -> loss: 0.0003713426610224177, self.slope: [1.02465826 1.02477607], self.intercept: 1.0021062113304624\n",
      "iteration - 1970 -> loss: 0.00037131569094931436, self.slope: [1.02466982 1.0247877 ], self.intercept: 1.0021072173768804\n",
      "iteration - 1971 -> loss: 0.00037128872492792704, self.slope: [1.02468137 1.02479932], self.intercept: 1.0021082233647152\n",
      "iteration - 1972 -> loss: 0.00037126176295736667, self.slope: [1.02469293 1.02481095], self.intercept: 1.0021092292939766\n",
      "iteration - 1973 -> loss: 0.00037123480503666555, self.slope: [1.02470448 1.02482257], self.intercept: 1.0021102351646691\n",
      "iteration - 1974 -> loss: 0.0003712078511649269, self.slope: [1.02471603 1.02483419], self.intercept: 1.0021112409768023\n",
      "iteration - 1975 -> loss: 0.00037118090134121014, self.slope: [1.02472758 1.02484581], self.intercept: 1.002112246730383\n",
      "iteration - 1976 -> loss: 0.0003711539555645904, self.slope: [1.02473913 1.02485743], self.intercept: 1.002113252425419\n",
      "iteration - 1977 -> loss: 0.0003711270138341715, self.slope: [1.02475068 1.02486905], self.intercept: 1.0021142580619204\n",
      "iteration - 1978 -> loss: 0.0003711000761490044, self.slope: [1.02476222 1.02488067], self.intercept: 1.0021152636398907\n",
      "iteration - 1979 -> loss: 0.0003710731425081641, self.slope: [1.02477377 1.02489229], self.intercept: 1.0021162691593382\n",
      "iteration - 1980 -> loss: 0.00037104621291074647, self.slope: [1.02478532 1.02490391], self.intercept: 1.00211727462027\n",
      "iteration - 1981 -> loss: 0.0003710192873557934, self.slope: [1.02479686 1.02491552], self.intercept: 1.002118280022696\n",
      "iteration - 1982 -> loss: 0.0003709923658424226, self.slope: [1.02480841 1.02492714], self.intercept: 1.0021192853666208\n",
      "iteration - 1983 -> loss: 0.00037096544836969994, self.slope: [1.02481995 1.02493875], self.intercept: 1.002120290652053\n",
      "iteration - 1984 -> loss: 0.00037093853493667153, self.slope: [1.02483149 1.02495037], self.intercept: 1.0021212958790011\n",
      "iteration - 1985 -> loss: 0.0003709116255424571, self.slope: [1.02484303 1.02496198], self.intercept: 1.0021223010474716\n",
      "iteration - 1986 -> loss: 0.0003708847201861142, self.slope: [1.02485457 1.02497359], self.intercept: 1.0021233061574715\n",
      "iteration - 1987 -> loss: 0.00037085781886672285, self.slope: [1.02486611 1.0249852 ], self.intercept: 1.0021243112090084\n",
      "iteration - 1988 -> loss: 0.00037083092158337656, self.slope: [1.02487765 1.02499681], self.intercept: 1.0021253162020893\n",
      "iteration - 1989 -> loss: 0.00037080402833514073, self.slope: [1.02488919 1.02500842], self.intercept: 1.0021263211367244\n",
      "iteration - 1990 -> loss: 0.00037077713912109586, self.slope: [1.02490073 1.02502003], self.intercept: 1.0021273260129184\n",
      "iteration - 1991 -> loss: 0.00037075025394033657, self.slope: [1.02491226 1.02503164], self.intercept: 1.0021283308306792\n",
      "iteration - 1992 -> loss: 0.000370723372791919, self.slope: [1.0249238  1.02504325], self.intercept: 1.0021293355900147\n",
      "iteration - 1993 -> loss: 0.0003706964956749363, self.slope: [1.02493533 1.02505485], self.intercept: 1.0021303402909323\n",
      "iteration - 1994 -> loss: 0.0003706696225884655, self.slope: [1.02494687 1.02506646], self.intercept: 1.0021313449334401\n",
      "iteration - 1995 -> loss: 0.0003706427535315865, self.slope: [1.0249584  1.02507806], self.intercept: 1.0021323495175438\n",
      "iteration - 1996 -> loss: 0.00037061588850338624, self.slope: [1.02496993 1.02508966], self.intercept: 1.0021333540432518\n",
      "iteration - 1997 -> loss: 0.00037058902750296117, self.slope: [1.02498146 1.02510127], self.intercept: 1.0021343585105713\n",
      "iteration - 1998 -> loss: 0.00037056217052935296, self.slope: [1.02499299 1.02511287], self.intercept: 1.0021353629195089\n",
      "iteration - 1999 -> loss: 0.00037053531758168704, self.slope: [1.02500452 1.02512447], self.intercept: 1.0021363672700743\n",
      "iteration - 2000 -> loss: 0.0003705084686590126, self.slope: [1.02501605 1.02513607], self.intercept: 1.0021373715622734\n",
      "iteration - 2001 -> loss: 0.0003704816237604157, self.slope: [1.02502758 1.02514767], self.intercept: 1.0021383757961133\n",
      "iteration - 2002 -> loss: 0.00037045478288501874, self.slope: [1.0250391  1.02515927], self.intercept: 1.0021393799716019\n",
      "iteration - 2003 -> loss: 0.00037042794603184726, self.slope: [1.02505063 1.02517086], self.intercept: 1.0021403840887468\n",
      "iteration - 2004 -> loss: 0.00037040111320002804, self.slope: [1.02506215 1.02518246], self.intercept: 1.0021413881475552\n",
      "iteration - 2005 -> loss: 0.00037037428438861826, self.slope: [1.02507368 1.02519406], self.intercept: 1.0021423921480355\n",
      "iteration - 2006 -> loss: 0.00037034745959671933, self.slope: [1.0250852  1.02520565], self.intercept: 1.0021433960901935\n",
      "iteration - 2007 -> loss: 0.0003703206388234169, self.slope: [1.02509672 1.02521725], self.intercept: 1.0021443999740376\n",
      "iteration - 2008 -> loss: 0.0003702938220677801, self.slope: [1.02510824 1.02522884], self.intercept: 1.0021454037995758\n",
      "iteration - 2009 -> loss: 0.000370267009328909, self.slope: [1.02511976 1.02524043], self.intercept: 1.002146407566815\n",
      "iteration - 2010 -> loss: 0.0003702402006058705, self.slope: [1.02513128 1.02525202], self.intercept: 1.0021474112757618\n",
      "iteration - 2011 -> loss: 0.0003702133958977821, self.slope: [1.0251428  1.02526361], self.intercept: 1.0021484149264248\n",
      "iteration - 2012 -> loss: 0.000370186595203688, self.slope: [1.02515432 1.0252752 ], self.intercept: 1.0021494185188093\n",
      "iteration - 2013 -> loss: 0.00037015979852270266, self.slope: [1.02516584 1.02528679], self.intercept: 1.0021504220529247\n",
      "iteration - 2014 -> loss: 0.00037013300585390083, self.slope: [1.02517735 1.02529838], self.intercept: 1.0021514255287771\n",
      "iteration - 2015 -> loss: 0.0003701062171963841, self.slope: [1.02518887 1.02530997], self.intercept: 1.0021524289463764\n",
      "iteration - 2016 -> loss: 0.00037007943254921286, self.slope: [1.02520038 1.02532155], self.intercept: 1.0021534323057268\n",
      "iteration - 2017 -> loss: 0.0003700526519114994, self.slope: [1.0252119  1.02533314], self.intercept: 1.0021544356068377\n",
      "iteration - 2018 -> loss: 0.000370025875282324, self.slope: [1.02522341 1.02534472], self.intercept: 1.0021554388497154\n",
      "iteration - 2019 -> loss: 0.00036999910266076734, self.slope: [1.02523492 1.0253563 ], self.intercept: 1.002156442034368\n",
      "iteration - 2020 -> loss: 0.00036997233404592573, self.slope: [1.02524643 1.02536789], self.intercept: 1.0021574451608024\n",
      "iteration - 2021 -> loss: 0.00036994556943688496, self.slope: [1.02525794 1.02537947], self.intercept: 1.002158448229028\n",
      "iteration - 2022 -> loss: 0.0003699188088327288, self.slope: [1.02526945 1.02539105], self.intercept: 1.0021594512390486\n",
      "iteration - 2023 -> loss: 0.00036989205223255875, self.slope: [1.02528096 1.02540263], self.intercept: 1.002160454190874\n",
      "iteration - 2024 -> loss: 0.00036986529963543494, self.slope: [1.02529247 1.02541421], self.intercept: 1.0021614570845117\n",
      "iteration - 2025 -> loss: 0.0003698385510404957, self.slope: [1.02530397 1.02542579], self.intercept: 1.0021624599199686\n",
      "iteration - 2026 -> loss: 0.0003698118064467763, self.slope: [1.02531548 1.02543737], self.intercept: 1.0021634626972515\n",
      "iteration - 2027 -> loss: 0.000369785065853402, self.slope: [1.02532698 1.02544894], self.intercept: 1.0021644654163682\n",
      "iteration - 2028 -> loss: 0.0003697583292594561, self.slope: [1.02533849 1.02546052], self.intercept: 1.0021654680773264\n",
      "iteration - 2029 -> loss: 0.00036973159666401636, self.slope: [1.02534999 1.02547209], self.intercept: 1.0021664706801334\n",
      "iteration - 2030 -> loss: 0.0003697048680662037, self.slope: [1.02536149 1.02548367], self.intercept: 1.0021674732247974\n",
      "iteration - 2031 -> loss: 0.0003696781434650707, self.slope: [1.02537299 1.02549524], self.intercept: 1.0021684757113234\n",
      "iteration - 2032 -> loss: 0.00036965142285973017, self.slope: [1.02538449 1.02550681], self.intercept: 1.0021694781397203\n",
      "iteration - 2033 -> loss: 0.0003696247062492711, self.slope: [1.02539599 1.02551838], self.intercept: 1.002170480509994\n",
      "iteration - 2034 -> loss: 0.00036959799363277506, self.slope: [1.02540749 1.02552995], self.intercept: 1.0021714828221542\n",
      "iteration - 2035 -> loss: 0.0003695712850093677, self.slope: [1.02541899 1.02554152], self.intercept: 1.0021724850762068\n",
      "iteration - 2036 -> loss: 0.000369544580378093, self.slope: [1.02543049 1.02555309], self.intercept: 1.0021734872721595\n",
      "iteration - 2037 -> loss: 0.00036951787973809664, self.slope: [1.02544198 1.02556466], self.intercept: 1.0021744894100206\n",
      "iteration - 2038 -> loss: 0.00036949118308842875, self.slope: [1.02545348 1.02557623], self.intercept: 1.0021754914897953\n",
      "iteration - 2039 -> loss: 0.00036946449042819394, self.slope: [1.02546497 1.0255878 ], self.intercept: 1.0021764935114923\n",
      "iteration - 2040 -> loss: 0.000369437801756488, self.slope: [1.02547647 1.02559936], self.intercept: 1.0021774954751201\n",
      "iteration - 2041 -> loss: 0.0003694111170724309, self.slope: [1.02548796 1.02561093], self.intercept: 1.0021784973806849\n",
      "iteration - 2042 -> loss: 0.0003693844363750528, self.slope: [1.02549945 1.02562249], self.intercept: 1.002179499228194\n",
      "iteration - 2043 -> loss: 0.0003693577596635049, self.slope: [1.02551094 1.02563405], self.intercept: 1.0021805010176545\n",
      "iteration - 2044 -> loss: 0.0003693310869368712, self.slope: [1.02552243 1.02564561], self.intercept: 1.0021815027490748\n",
      "iteration - 2045 -> loss: 0.00036930441819422994, self.slope: [1.02553392 1.02565718], self.intercept: 1.0021825044224633\n",
      "iteration - 2046 -> loss: 0.0003692777534346844, self.slope: [1.02554541 1.02566874], self.intercept: 1.0021835060378235\n",
      "iteration - 2047 -> loss: 0.00036925109265733267, self.slope: [1.0255569 1.0256803], self.intercept: 1.0021845075951654\n",
      "iteration - 2048 -> loss: 0.00036922443586128237, self.slope: [1.02556838 1.02569185], self.intercept: 1.002185509094496\n",
      "iteration - 2049 -> loss: 0.0003691977830455994, self.slope: [1.02557987 1.02570341], self.intercept: 1.0021865105358223\n",
      "iteration - 2050 -> loss: 0.0003691711342093987, self.slope: [1.02559135 1.02571497], self.intercept: 1.0021875119191517\n",
      "iteration - 2051 -> loss: 0.00036914448935180145, self.slope: [1.02560284 1.02572652], self.intercept: 1.002188513244491\n",
      "iteration - 2052 -> loss: 0.0003691178484718494, self.slope: [1.02561432 1.02573808], self.intercept: 1.002189514511848\n",
      "iteration - 2053 -> loss: 0.00036909121156867566, self.slope: [1.0256258  1.02574963], self.intercept: 1.0021905157212307\n",
      "iteration - 2054 -> loss: 0.0003690645786413843, self.slope: [1.02563728 1.02576119], self.intercept: 1.0021915168726458\n",
      "iteration - 2055 -> loss: 0.000369037949689046, self.slope: [1.02564877 1.02577274], self.intercept: 1.0021925179661015\n",
      "iteration - 2056 -> loss: 0.00036901132471076694, self.slope: [1.02566024 1.02578429], self.intercept: 1.0021935190016042\n",
      "iteration - 2057 -> loss: 0.00036898470370565396, self.slope: [1.02567172 1.02579584], self.intercept: 1.002194519979163\n",
      "iteration - 2058 -> loss: 0.0003689580866728055, self.slope: [1.0256832  1.02580739], self.intercept: 1.0021955208987834\n",
      "iteration - 2059 -> loss: 0.0003689314736113281, self.slope: [1.02569468 1.02581894], self.intercept: 1.002196521760473\n",
      "iteration - 2060 -> loss: 0.00036890486452029935, self.slope: [1.02570615 1.02583049], self.intercept: 1.00219752256424\n",
      "iteration - 2061 -> loss: 0.0003688782593988226, self.slope: [1.02571763 1.02584204], self.intercept: 1.0021985233100923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 2062 -> loss: 0.0003688516582460169, self.slope: [1.0257291  1.02585359], self.intercept: 1.0021995239980355\n",
      "iteration - 2063 -> loss: 0.0003688250610609505, self.slope: [1.02574058 1.02586513], self.intercept: 1.0022005246280759\n",
      "iteration - 2064 -> loss: 0.00036879846784275937, self.slope: [1.02575205 1.02587668], self.intercept: 1.0022015252002225\n",
      "iteration - 2065 -> loss: 0.00036877187859052173, self.slope: [1.02576352 1.02588822], self.intercept: 1.0022025257144824\n",
      "iteration - 2066 -> loss: 0.0003687452933033529, self.slope: [1.02577499 1.02589976], self.intercept: 1.0022035261708642\n",
      "iteration - 2067 -> loss: 0.00036871871198032716, self.slope: [1.02578646 1.02591131], self.intercept: 1.0022045265693735\n",
      "iteration - 2068 -> loss: 0.0003686921346205671, self.slope: [1.02579793 1.02592285], self.intercept: 1.0022055269100185\n",
      "iteration - 2069 -> loss: 0.0003686655612231825, self.slope: [1.0258094  1.02593439], self.intercept: 1.0022065271928058\n",
      "iteration - 2070 -> loss: 0.0003686389917872532, self.slope: [1.02582087 1.02594593], self.intercept: 1.0022075274177427\n",
      "iteration - 2071 -> loss: 0.0003686124263119052, self.slope: [1.02583234 1.02595747], self.intercept: 1.0022085275848374\n",
      "iteration - 2072 -> loss: 0.00036858586479619385, self.slope: [1.0258438  1.02596901], self.intercept: 1.0022095276940972\n",
      "iteration - 2073 -> loss: 0.00036855930723928655, self.slope: [1.02585527 1.02598054], self.intercept: 1.0022105277455282\n",
      "iteration - 2074 -> loss: 0.0003685327536402416, self.slope: [1.02586673 1.02599208], self.intercept: 1.0022115277391395\n",
      "iteration - 2075 -> loss: 0.0003685062039981778, self.slope: [1.02587819 1.02600361], self.intercept: 1.002212527674937\n",
      "iteration - 2076 -> loss: 0.00036847965831219914, self.slope: [1.02588966 1.02601515], self.intercept: 1.0022135275529274\n",
      "iteration - 2077 -> loss: 0.00036845311658140293, self.slope: [1.02590112 1.02602668], self.intercept: 1.0022145273731193\n",
      "iteration - 2078 -> loss: 0.0003684265788048821, self.slope: [1.02591258 1.02603822], self.intercept: 1.0022155271355204\n",
      "iteration - 2079 -> loss: 0.00036840004498177764, self.slope: [1.02592404 1.02604975], self.intercept: 1.0022165268401368\n",
      "iteration - 2080 -> loss: 0.00036837351511115015, self.slope: [1.0259355  1.02606128], self.intercept: 1.0022175264869764\n",
      "iteration - 2081 -> loss: 0.00036834698919214814, self.slope: [1.02594696 1.02607281], self.intercept: 1.0022185260760472\n",
      "iteration - 2082 -> loss: 0.0003683204672238323, self.slope: [1.02595841 1.02608434], self.intercept: 1.0022195256073565\n",
      "iteration - 2083 -> loss: 0.00036829394920533825, self.slope: [1.02596987 1.02609587], self.intercept: 1.0022205250809102\n",
      "iteration - 2084 -> loss: 0.0003682674351357838, self.slope: [1.02598132 1.0261074 ], self.intercept: 1.0022215244967172\n",
      "iteration - 2085 -> loss: 0.00036824092501422335, self.slope: [1.02599278 1.02611892], self.intercept: 1.0022225238547826\n",
      "iteration - 2086 -> loss: 0.00036821441883979565, self.slope: [1.02600423 1.02613045], self.intercept: 1.0022235231551149\n",
      "iteration - 2087 -> loss: 0.00036818791661162684, self.slope: [1.02601569 1.02614198], self.intercept: 1.0022245223977218\n",
      "iteration - 2088 -> loss: 0.0003681614183287898, self.slope: [1.02602714 1.0261535 ], self.intercept: 1.0022255215826108\n",
      "iteration - 2089 -> loss: 0.0003681349239903933, self.slope: [1.02603859 1.02616502], self.intercept: 1.0022265207097882\n",
      "iteration - 2090 -> loss: 0.0003681084335955788, self.slope: [1.02605004 1.02617655], self.intercept: 1.0022275197792616\n",
      "iteration - 2091 -> loss: 0.0003680819471434265, self.slope: [1.02606149 1.02618807], self.intercept: 1.002228518791038\n",
      "iteration - 2092 -> loss: 0.0003680554646330345, self.slope: [1.02607294 1.02619959], self.intercept: 1.0022295177451266\n",
      "iteration - 2093 -> loss: 0.00036802898606354034, self.slope: [1.02608439 1.02621111], self.intercept: 1.0022305166415317\n",
      "iteration - 2094 -> loss: 0.00036800251143401485, self.slope: [1.02609583 1.02622263], self.intercept: 1.0022315154802632\n",
      "iteration - 2095 -> loss: 0.00036797604074360305, self.slope: [1.02610728 1.02623415], self.intercept: 1.0022325142613266\n",
      "iteration - 2096 -> loss: 0.00036794957399139734, self.slope: [1.02611872 1.02624567], self.intercept: 1.0022335129847302\n",
      "iteration - 2097 -> loss: 0.0003679231111765042, self.slope: [1.02613017 1.02625718], self.intercept: 1.0022345116504827\n",
      "iteration - 2098 -> loss: 0.0003678966522980387, self.slope: [1.02614161 1.0262687 ], self.intercept: 1.002235510258588\n",
      "iteration - 2099 -> loss: 0.00036787019735511544, self.slope: [1.02615305 1.02628021], self.intercept: 1.0022365088090555\n",
      "iteration - 2100 -> loss: 0.0003678437463468355, self.slope: [1.0261645  1.02629173], self.intercept: 1.0022375073018917\n",
      "iteration - 2101 -> loss: 0.00036781729927231504, self.slope: [1.02617594 1.02630324], self.intercept: 1.0022385057371044\n",
      "iteration - 2102 -> loss: 0.0003677908561306548, self.slope: [1.02618738 1.02631475], self.intercept: 1.002239504114699\n",
      "iteration - 2103 -> loss: 0.00036776441692098116, self.slope: [1.02619882 1.02632627], self.intercept: 1.0022405024346863\n",
      "iteration - 2104 -> loss: 0.00036773798164237826, self.slope: [1.02621025 1.02633778], self.intercept: 1.0022415006970706\n",
      "iteration - 2105 -> loss: 0.00036771155029399115, self.slope: [1.02622169 1.02634929], self.intercept: 1.002242498901861\n",
      "iteration - 2106 -> loss: 0.0003676851228749067, self.slope: [1.02623313 1.0263608 ], self.intercept: 1.0022434970490637\n",
      "iteration - 2107 -> loss: 0.00036765869938425394, self.slope: [1.02624456 1.0263723 ], self.intercept: 1.0022444951386866\n",
      "iteration - 2108 -> loss: 0.00036763227982113735, self.slope: [1.026256   1.02638381], self.intercept: 1.0022454931707367\n",
      "iteration - 2109 -> loss: 0.00036760586418466487, self.slope: [1.02626743 1.02639532], self.intercept: 1.0022464911452202\n",
      "iteration - 2110 -> loss: 0.00036757945247394805, self.slope: [1.02627887 1.02640682], self.intercept: 1.0022474890621462\n",
      "iteration - 2111 -> loss: 0.0003675530446881129, self.slope: [1.0262903  1.02641833], self.intercept: 1.0022484869215218\n",
      "iteration - 2112 -> loss: 0.0003675266408262633, self.slope: [1.02630173 1.02642983], self.intercept: 1.0022494847233532\n",
      "iteration - 2113 -> loss: 0.0003675002408875248, self.slope: [1.02631316 1.02644134], self.intercept: 1.0022504824676475\n",
      "iteration - 2114 -> loss: 0.000367473844870976, self.slope: [1.02632459 1.02645284], self.intercept: 1.0022514801544145\n",
      "iteration - 2115 -> loss: 0.0003674474527757642, self.slope: [1.02633602 1.02646434], self.intercept: 1.0022524777836586\n",
      "iteration - 2116 -> loss: 0.0003674210646010103, self.slope: [1.02634745 1.02647584], self.intercept: 1.0022534753553878\n",
      "iteration - 2117 -> loss: 0.000367394680345806, self.slope: [1.02635887 1.02648734], self.intercept: 1.0022544728696092\n",
      "iteration - 2118 -> loss: 0.00036736830000926404, self.slope: [1.0263703  1.02649884], self.intercept: 1.0022554703263313\n",
      "iteration - 2119 -> loss: 0.00036734192359051795, self.slope: [1.02638173 1.02651034], self.intercept: 1.0022564677255608\n",
      "iteration - 2120 -> loss: 0.00036731555108865496, self.slope: [1.02639315 1.02652184], self.intercept: 1.0022574650673033\n",
      "iteration - 2121 -> loss: 0.00036728918250283633, self.slope: [1.02640457 1.02653333], self.intercept: 1.0022584623515687\n",
      "iteration - 2122 -> loss: 0.00036726281783212985, self.slope: [1.026416   1.02654483], self.intercept: 1.0022594595783623\n",
      "iteration - 2123 -> loss: 0.0003672364570756768, self.slope: [1.02642742 1.02655632], self.intercept: 1.0022604567476925\n",
      "iteration - 2124 -> loss: 0.0003672101002326022, self.slope: [1.02643884 1.02656782], self.intercept: 1.0022614538595653\n",
      "iteration - 2125 -> loss: 0.00036718374730200574, self.slope: [1.02645026 1.02657931], self.intercept: 1.0022624509139886\n",
      "iteration - 2126 -> loss: 0.00036715739828300923, self.slope: [1.02646168 1.0265908 ], self.intercept: 1.0022634479109707\n",
      "iteration - 2127 -> loss: 0.0003671310531747292, self.slope: [1.0264731  1.02660229], self.intercept: 1.0022644448505174\n",
      "iteration - 2128 -> loss: 0.0003671047119762798, self.slope: [1.02648452 1.02661378], self.intercept: 1.0022654417326358\n",
      "iteration - 2129 -> loss: 0.0003670783746868018, self.slope: [1.02649593 1.02662527], self.intercept: 1.002266438557333\n",
      "iteration - 2130 -> loss: 0.0003670520413053623, self.slope: [1.02650735 1.02663676], self.intercept: 1.0022674353246173\n",
      "iteration - 2131 -> loss: 0.0003670257118311339, self.slope: [1.02651876 1.02664825], self.intercept: 1.0022684320344968\n",
      "iteration - 2132 -> loss: 0.00036699938626321284, self.slope: [1.02653018 1.02665974], self.intercept: 1.0022694286869767\n",
      "iteration - 2133 -> loss: 0.0003669730646007034, self.slope: [1.02654159 1.02667122], self.intercept: 1.0022704252820664\n",
      "iteration - 2134 -> loss: 0.0003669467468427507, self.slope: [1.02655301 1.02668271], self.intercept: 1.002271421819771\n",
      "iteration - 2135 -> loss: 0.00036692043298846536, self.slope: [1.02656442 1.02669419], self.intercept: 1.0022724183000964\n",
      "iteration - 2136 -> loss: 0.0003668941230369589, self.slope: [1.02657583 1.02670568], self.intercept: 1.0022734147230554\n",
      "iteration - 2137 -> loss: 0.0003668678169873571, self.slope: [1.02658724 1.02671716], self.intercept: 1.0022744110886508\n",
      "iteration - 2138 -> loss: 0.0003668415148387816, self.slope: [1.02659865 1.02672864], self.intercept: 1.0022754073968887\n",
      "iteration - 2139 -> loss: 0.0003668152165903396, self.slope: [1.02661006 1.02674012], self.intercept: 1.002276403647779\n",
      "iteration - 2140 -> loss: 0.00036678892224118896, self.slope: [1.02662146 1.0267516 ], self.intercept: 1.0022773998413288\n",
      "iteration - 2141 -> loss: 0.00036676263179041385, self.slope: [1.02663287 1.02676308], self.intercept: 1.0022783959775459\n",
      "iteration - 2142 -> loss: 0.0003667363452371349, self.slope: [1.02664428 1.02677456], self.intercept: 1.0022793920564361\n",
      "iteration - 2143 -> loss: 0.00036671006258050617, self.slope: [1.02665568 1.02678604], self.intercept: 1.0022803880780065\n",
      "iteration - 2144 -> loss: 0.00036668378381961547, self.slope: [1.02666708 1.02679752], self.intercept: 1.002281384042266\n",
      "iteration - 2145 -> loss: 0.00036665750895358977, self.slope: [1.02667849 1.02680899], self.intercept: 1.0022823799492202\n",
      "iteration - 2146 -> loss: 0.0003666312379815736, self.slope: [1.02668989 1.02682047], self.intercept: 1.0022833757988758\n",
      "iteration - 2147 -> loss: 0.0003666049709026798, self.slope: [1.02670129 1.02683194], self.intercept: 1.0022843715912408\n",
      "iteration - 2148 -> loss: 0.000366578707716016, self.slope: [1.02671269 1.02684342], self.intercept: 1.0022853673263248\n",
      "iteration - 2149 -> loss: 0.0003665524484207064, self.slope: [1.02672409 1.02685489], self.intercept: 1.0022863630041325\n",
      "iteration - 2150 -> loss: 0.00036652619301589926, self.slope: [1.02673549 1.02686636], self.intercept: 1.0022873586246697\n",
      "iteration - 2151 -> loss: 0.00036649994150069436, self.slope: [1.02674689 1.02687783], self.intercept: 1.0022883541879466\n",
      "iteration - 2152 -> loss: 0.0003664736938742396, self.slope: [1.02675829 1.0268893 ], self.intercept: 1.0022893496939684\n",
      "iteration - 2153 -> loss: 0.0003664474501356243, self.slope: [1.02676968 1.02690077], self.intercept: 1.0022903451427432\n",
      "iteration - 2154 -> loss: 0.0003664212102840195, self.slope: [1.02678108 1.02691224], self.intercept: 1.0022913405342777\n",
      "iteration - 2155 -> loss: 0.0003663949743185011, self.slope: [1.02679247 1.02692371], self.intercept: 1.0022923358685798\n",
      "iteration - 2156 -> loss: 0.0003663687422382119, self.slope: [1.02680387 1.02693518], self.intercept: 1.0022933311456557\n",
      "iteration - 2157 -> loss: 0.0003663425140422903, self.slope: [1.02681526 1.02694664], self.intercept: 1.002294326365514\n",
      "iteration - 2158 -> loss: 0.00036631628972985187, self.slope: [1.02682665 1.02695811], self.intercept: 1.0022953215281607\n",
      "iteration - 2159 -> loss: 0.00036629006930002895, self.slope: [1.02683804 1.02696957], self.intercept: 1.0022963166336036\n",
      "iteration - 2160 -> loss: 0.0003662638527519344, self.slope: [1.02684943 1.02698104], self.intercept: 1.0022973116818492\n",
      "iteration - 2161 -> loss: 0.0003662376400847039, self.slope: [1.02686082 1.0269925 ], self.intercept: 1.0022983066729059\n",
      "iteration - 2162 -> loss: 0.000366211431297467, self.slope: [1.02687221 1.02700396], self.intercept: 1.002299301606781\n",
      "iteration - 2163 -> loss: 0.0003661852263893379, self.slope: [1.0268836  1.02701542], self.intercept: 1.0023002964834793\n",
      "iteration - 2164 -> loss: 0.0003661590253594483, self.slope: [1.02689499 1.02702688], self.intercept: 1.0023012913030103\n",
      "iteration - 2165 -> loss: 0.0003661328282069261, self.slope: [1.02690637 1.02703834], self.intercept: 1.0023022860653807\n",
      "iteration - 2166 -> loss: 0.0003661066349309119, self.slope: [1.02691776 1.0270498 ], self.intercept: 1.002303280770598\n",
      "iteration - 2167 -> loss: 0.0003660804455305265, self.slope: [1.02692914 1.02706126], self.intercept: 1.0023042754186702\n",
      "iteration - 2168 -> loss: 0.00036605426000488745, self.slope: [1.02694053 1.02707271], self.intercept: 1.0023052700096007\n",
      "iteration - 2169 -> loss: 0.00036602807835312424, self.slope: [1.02695191 1.02708417], self.intercept: 1.0023062645434004\n",
      "iteration - 2170 -> loss: 0.00036600190057437703, self.slope: [1.02696329 1.02709562], self.intercept: 1.0023072590200741\n",
      "iteration - 2171 -> loss: 0.0003659757266677599, self.slope: [1.02697467 1.02710708], self.intercept: 1.0023082534396306\n",
      "iteration - 2172 -> loss: 0.0003659495566324143, self.slope: [1.02698605 1.02711853], self.intercept: 1.0023092478020776\n",
      "iteration - 2173 -> loss: 0.00036592339046749177, self.slope: [1.02699743 1.02712999], self.intercept: 1.00231024210742\n",
      "iteration - 2174 -> loss: 0.00036589722817208166, self.slope: [1.02700881 1.02714144], self.intercept: 1.0023112363556668\n",
      "iteration - 2175 -> loss: 0.00036587106974531476, self.slope: [1.02702019 1.02715289], self.intercept: 1.0023122305468237\n",
      "iteration - 2176 -> loss: 0.00036584491518633404, self.slope: [1.02703156 1.02716434], self.intercept: 1.002313224680898\n",
      "iteration - 2177 -> loss: 0.00036581876449427286, self.slope: [1.02704294 1.02717579], self.intercept: 1.002314218757898\n",
      "iteration - 2178 -> loss: 0.0003657926176682898, self.slope: [1.02705432 1.02718724], self.intercept: 1.0023152127778319\n",
      "iteration - 2179 -> loss: 0.0003657664747074578, self.slope: [1.02706569 1.02719868], self.intercept: 1.0023162067407054\n",
      "iteration - 2180 -> loss: 0.0003657403356109555, self.slope: [1.02707706 1.02721013], self.intercept: 1.0023172006465246\n",
      "iteration - 2181 -> loss: 0.0003657142003778815, self.slope: [1.02708844 1.02722158], self.intercept: 1.0023181944952981\n",
      "iteration - 2182 -> loss: 0.00036568806900738783, self.slope: [1.02709981 1.02723302], self.intercept: 1.0023191882870328\n",
      "iteration - 2183 -> loss: 0.00036566194149860286, self.slope: [1.02711118 1.02724447], self.intercept: 1.002320182021736\n",
      "iteration - 2184 -> loss: 0.0003656358178506434, self.slope: [1.02712255 1.02725591], self.intercept: 1.0023211756994146\n",
      "iteration - 2185 -> loss: 0.0003656096980626733, self.slope: [1.02713392 1.02726735], self.intercept: 1.0023221693200761\n",
      "iteration - 2186 -> loss: 0.0003655835821338048, self.slope: [1.02714529 1.02727879], self.intercept: 1.0023231628837286\n",
      "iteration - 2187 -> loss: 0.0003655574700631728, self.slope: [1.02715665 1.02729023], self.intercept: 1.002324156390377\n",
      "iteration - 2188 -> loss: 0.000365531361849912, self.slope: [1.02716802 1.02730167], self.intercept: 1.002325149840029\n",
      "iteration - 2189 -> loss: 0.00036550525749314727, self.slope: [1.02717939 1.02731311], self.intercept: 1.0023261432326922\n",
      "iteration - 2190 -> loss: 0.0003654791569920328, self.slope: [1.02719075 1.02732455], self.intercept: 1.0023271365683746\n",
      "iteration - 2191 -> loss: 0.00036545306034567975, self.slope: [1.02720212 1.02733599], self.intercept: 1.0023281298470819\n",
      "iteration - 2192 -> loss: 0.0003654269675532486, self.slope: [1.02721348 1.02734743], self.intercept: 1.0023291230688218\n",
      "iteration - 2193 -> loss: 0.0003654008786138448, self.slope: [1.02722484 1.02735886], self.intercept: 1.0023301162336022\n",
      "iteration - 2194 -> loss: 0.0003653747935266273, self.slope: [1.0272362 1.0273703], self.intercept: 1.002331109341429\n",
      "iteration - 2195 -> loss: 0.000365348712290699, self.slope: [1.02724756 1.02738173], self.intercept: 1.0023321023923106\n",
      "iteration - 2196 -> loss: 0.00036532263490524796, self.slope: [1.02725892 1.02739316], self.intercept: 1.002333095386253\n",
      "iteration - 2197 -> loss: 0.00036529656136937566, self.slope: [1.02727028 1.0274046 ], self.intercept: 1.0023340883232639\n",
      "iteration - 2198 -> loss: 0.0003652704916822075, self.slope: [1.02728164 1.02741603], self.intercept: 1.002335081203351\n",
      "iteration - 2199 -> loss: 0.00036524442584290486, self.slope: [1.027293   1.02742746], self.intercept: 1.0023360740265213\n",
      "iteration - 2200 -> loss: 0.00036521836385059614, self.slope: [1.02730435 1.02743889], self.intercept: 1.00233706679278\n",
      "iteration - 2201 -> loss: 0.0003651923057044078, self.slope: [1.02731571 1.02745032], self.intercept: 1.002338059502136\n",
      "iteration - 2202 -> loss: 0.00036516625140349144, self.slope: [1.02732707 1.02746175], self.intercept: 1.0023390521545958\n",
      "iteration - 2203 -> loss: 0.00036514020094697663, self.slope: [1.02733842 1.02747317], self.intercept: 1.0023400447501671\n",
      "iteration - 2204 -> loss: 0.00036511415433400314, self.slope: [1.02734977 1.0274846 ], self.intercept: 1.002341037288857\n",
      "iteration - 2205 -> loss: 0.0003650881115637105, self.slope: [1.02736112 1.02749603], self.intercept: 1.0023420297706729\n",
      "iteration - 2206 -> loss: 0.0003650620726352235, self.slope: [1.02737248 1.02750745], self.intercept: 1.0023430221956202\n",
      "iteration - 2207 -> loss: 0.0003650360375477088, self.slope: [1.02738383 1.02751888], self.intercept: 1.0023440145637084\n",
      "iteration - 2208 -> loss: 0.0003650100063002667, self.slope: [1.02739518 1.0275303 ], self.intercept: 1.0023450068749433\n",
      "iteration - 2209 -> loss: 0.00036498397889208153, self.slope: [1.02740653 1.02754172], self.intercept: 1.0023459991293322\n",
      "iteration - 2210 -> loss: 0.00036495795532224927, self.slope: [1.02741787 1.02755314], self.intercept: 1.0023469913268832\n",
      "iteration - 2211 -> loss: 0.0003649319355899231, self.slope: [1.02742922 1.02756456], self.intercept: 1.0023479834676012\n",
      "iteration - 2212 -> loss: 0.0003649059196942689, self.slope: [1.02744057 1.02757598], self.intercept: 1.002348975551495\n",
      "iteration - 2213 -> loss: 0.0003648799076343815, self.slope: [1.02745191 1.0275874 ], self.intercept: 1.002349967578571\n",
      "iteration - 2214 -> loss: 0.00036485389940943283, self.slope: [1.02746326 1.02759882], self.intercept: 1.0023509595488374\n",
      "iteration - 2215 -> loss: 0.00036482789501855614, self.slope: [1.0274746  1.02761024], self.intercept: 1.0023519514623003\n",
      "iteration - 2216 -> loss: 0.00036480189446088675, self.slope: [1.02748594 1.02762165], self.intercept: 1.0023529433189675\n",
      "iteration - 2217 -> loss: 0.000364775897735581, self.slope: [1.02749729 1.02763307], self.intercept: 1.0023539351188453\n",
      "iteration - 2218 -> loss: 0.00036474990484175435, self.slope: [1.02750863 1.02764449], self.intercept: 1.0023549268619414\n",
      "iteration - 2219 -> loss: 0.0003647239157785697, self.slope: [1.02751997 1.0276559 ], self.intercept: 1.0023559185482633\n",
      "iteration - 2220 -> loss: 0.0003646979305451624, self.slope: [1.02753131 1.02766731], self.intercept: 1.002356910177817\n",
      "iteration - 2221 -> loss: 0.0003646719491406726, self.slope: [1.02754265 1.02767873], self.intercept: 1.0023579017506108\n",
      "iteration - 2222 -> loss: 0.0003646459715642466, self.slope: [1.02755398 1.02769014], self.intercept: 1.00235889326665\n",
      "iteration - 2223 -> loss: 0.0003646199978150269, self.slope: [1.02756532 1.02770155], self.intercept: 1.0023598847259436\n",
      "iteration - 2224 -> loss: 0.0003645940278921493, self.slope: [1.02757666 1.02771296], self.intercept: 1.0023608761284981\n",
      "iteration - 2225 -> loss: 0.00036456806179475476, self.slope: [1.02758799 1.02772437], self.intercept: 1.00236186747432\n",
      "iteration - 2226 -> loss: 0.000364542099521995, self.slope: [1.02759933 1.02773577], self.intercept: 1.0023628587634181\n",
      "iteration - 2227 -> loss: 0.00036451614107301585, self.slope: [1.02761066 1.02774718], self.intercept: 1.0023638499957976\n",
      "iteration - 2228 -> loss: 0.00036449018644695534, self.slope: [1.02762199 1.02775859], self.intercept: 1.0023648411714663\n",
      "iteration - 2229 -> loss: 0.00036446423564294824, self.slope: [1.02763333 1.02776999], self.intercept: 1.0023658322904316\n",
      "iteration - 2230 -> loss: 0.0003644382886601619, self.slope: [1.02764466 1.0277814 ], self.intercept: 1.0023668233526999\n",
      "iteration - 2231 -> loss: 0.0003644123454977269, self.slope: [1.02765599 1.0277928 ], self.intercept: 1.002367814358278\n",
      "iteration - 2232 -> loss: 0.0003643864061547879, self.slope: [1.02766732 1.02780421], self.intercept: 1.002368805307173\n",
      "iteration - 2233 -> loss: 0.0003643604706304845, self.slope: [1.02767865 1.02781561], self.intercept: 1.002369796199393\n",
      "iteration - 2234 -> loss: 0.0003643345389239775, self.slope: [1.02768997 1.02782701], self.intercept: 1.0023707870349456\n",
      "iteration - 2235 -> loss: 0.0003643086110344034, self.slope: [1.0277013  1.02783841], self.intercept: 1.002371777813838\n",
      "iteration - 2236 -> loss: 0.0003642826869608957, self.slope: [1.02771263 1.02784981], self.intercept: 1.0023727685360742\n",
      "iteration - 2237 -> loss: 0.0003642567667026223, self.slope: [1.02772395 1.02786121], self.intercept: 1.0023737592016644\n",
      "iteration - 2238 -> loss: 0.0003642308502587114, self.slope: [1.02773528 1.02787261], self.intercept: 1.0023747498106164\n",
      "iteration - 2239 -> loss: 0.000364204937628336, self.slope: [1.0277466  1.02788401], self.intercept: 1.0023757403629345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 2240 -> loss: 0.00036417902881060214, self.slope: [1.02775792 1.0278954 ], self.intercept: 1.0023767308586269\n",
      "iteration - 2241 -> loss: 0.0003641531238046924, self.slope: [1.02776924 1.0279068 ], self.intercept: 1.0023777212976996\n",
      "iteration - 2242 -> loss: 0.0003641272226097441, self.slope: [1.02778057 1.02791819], self.intercept: 1.0023787116801612\n",
      "iteration - 2243 -> loss: 0.0003641013252248992, self.slope: [1.02779189 1.02792959], self.intercept: 1.0023797020060177\n",
      "iteration - 2244 -> loss: 0.0003640754316493008, self.slope: [1.0278032  1.02794098], self.intercept: 1.0023806922752785\n",
      "iteration - 2245 -> loss: 0.00036404954188212876, self.slope: [1.02781452 1.02795237], self.intercept: 1.00238168248795\n",
      "iteration - 2246 -> loss: 0.0003640236559224962, self.slope: [1.02782584 1.02796377], self.intercept: 1.0023826726440375\n",
      "iteration - 2247 -> loss: 0.00036399777376955523, self.slope: [1.02783716 1.02797516], self.intercept: 1.002383662743548\n",
      "iteration - 2248 -> loss: 0.0003639718954224809, self.slope: [1.02784847 1.02798655], self.intercept: 1.00238465278649\n",
      "iteration - 2249 -> loss: 0.00036394602088038805, self.slope: [1.02785979 1.02799793], self.intercept: 1.0023856427728697\n",
      "iteration - 2250 -> loss: 0.0003639201501424523, self.slope: [1.0278711  1.02800932], self.intercept: 1.0023866327026953\n",
      "iteration - 2251 -> loss: 0.00036389428320778976, self.slope: [1.02788242 1.02802071], self.intercept: 1.0023876225759725\n",
      "iteration - 2252 -> loss: 0.0003638684200755996, self.slope: [1.02789373 1.0280321 ], self.intercept: 1.0023886123927084\n",
      "iteration - 2253 -> loss: 0.0003638425607450009, self.slope: [1.02790504 1.02804348], self.intercept: 1.00238960215291\n",
      "iteration - 2254 -> loss: 0.00036381670521514907, self.slope: [1.02791635 1.02805487], self.intercept: 1.0023905918565854\n",
      "iteration - 2255 -> loss: 0.00036379085348519475, self.slope: [1.02792766 1.02806625], self.intercept: 1.0023915815037412\n",
      "iteration - 2256 -> loss: 0.00036376500555429124, self.slope: [1.02793897 1.02807764], self.intercept: 1.0023925710943848\n",
      "iteration - 2257 -> loss: 0.0003637391614215773, self.slope: [1.02795028 1.02808902], self.intercept: 1.0023935606285224\n",
      "iteration - 2258 -> loss: 0.00036371332108621577, self.slope: [1.02796159 1.0281004 ], self.intercept: 1.0023945501061624\n",
      "iteration - 2259 -> loss: 0.00036368748454736676, self.slope: [1.0279729  1.02811178], self.intercept: 1.00239553952731\n",
      "iteration - 2260 -> loss: 0.00036366165180417307, self.slope: [1.0279842  1.02812316], self.intercept: 1.0023965288919736\n",
      "iteration - 2261 -> loss: 0.0003636358228557762, self.slope: [1.02799551 1.02813454], self.intercept: 1.0023975182001599\n",
      "iteration - 2262 -> loss: 0.00036360999770135516, self.slope: [1.02800681 1.02814592], self.intercept: 1.0023985074518762\n",
      "iteration - 2263 -> loss: 0.0003635841763400303, self.slope: [1.02801811 1.0281573 ], self.intercept: 1.0023994966471288\n",
      "iteration - 2264 -> loss: 0.00036355835877099267, self.slope: [1.02802942 1.02816867], self.intercept: 1.0024004857859266\n",
      "iteration - 2265 -> loss: 0.00036353254499334946, self.slope: [1.02804072 1.02818005], self.intercept: 1.0024014748682746\n",
      "iteration - 2266 -> loss: 0.0003635067350062873, self.slope: [1.02805202 1.02819142], self.intercept: 1.0024024638941798\n",
      "iteration - 2267 -> loss: 0.0003634809288089603, self.slope: [1.02806332 1.0282028 ], self.intercept: 1.00240345286365\n",
      "iteration - 2268 -> loss: 0.0003634551264005018, self.slope: [1.02807462 1.02821417], self.intercept: 1.0024044417766933\n",
      "iteration - 2269 -> loss: 0.0003634293277800961, self.slope: [1.02808592 1.02822554], self.intercept: 1.0024054306333152\n",
      "iteration - 2270 -> loss: 0.00036340353294685623, self.slope: [1.02809721 1.02823691], self.intercept: 1.0024064194335232\n",
      "iteration - 2271 -> loss: 0.00036337774189996633, self.slope: [1.02810851 1.02824829], self.intercept: 1.0024074081773244\n",
      "iteration - 2272 -> loss: 0.0003633519546385796, self.slope: [1.02811981 1.02825966], self.intercept: 1.0024083968647266\n",
      "iteration - 2273 -> loss: 0.00036332617116184953, self.slope: [1.0281311  1.02827102], self.intercept: 1.0024093854957357\n",
      "iteration - 2274 -> loss: 0.00036330039146892303, self.slope: [1.0281424  1.02828239], self.intercept: 1.0024103740703605\n",
      "iteration - 2275 -> loss: 0.0003632746155589451, self.slope: [1.02815369 1.02829376], self.intercept: 1.002411362588606\n",
      "iteration - 2276 -> loss: 0.00036324884343111514, self.slope: [1.02816498 1.02830513], self.intercept: 1.0024123510504792\n",
      "iteration - 2277 -> loss: 0.0003632230750845577, self.slope: [1.02817627 1.02831649], self.intercept: 1.0024133394559889\n",
      "iteration - 2278 -> loss: 0.0003631973105184298, self.slope: [1.02818757 1.02832786], self.intercept: 1.0024143278051385\n",
      "iteration - 2279 -> loss: 0.0003631715497318875, self.slope: [1.02819886 1.02833922], self.intercept: 1.0024153160979392\n",
      "iteration - 2280 -> loss: 0.00036314579272410033, self.slope: [1.02821014 1.02835059], self.intercept: 1.0024163043343957\n",
      "iteration - 2281 -> loss: 0.0003631200394942203, self.slope: [1.02822143 1.02836195], self.intercept: 1.0024172925145158\n",
      "iteration - 2282 -> loss: 0.00036309429004139043, self.slope: [1.02823272 1.02837331], self.intercept: 1.0024182806383073\n",
      "iteration - 2283 -> loss: 0.000363068544364784, self.slope: [1.02824401 1.02838467], self.intercept: 1.002419268705777\n",
      "iteration - 2284 -> loss: 0.00036304280246355654, self.slope: [1.02825529 1.02839603], self.intercept: 1.0024202567169296\n",
      "iteration - 2285 -> loss: 0.0003630170643368722, self.slope: [1.02826658 1.02840739], self.intercept: 1.0024212446717748\n",
      "iteration - 2286 -> loss: 0.00036299132998388853, self.slope: [1.02827786 1.02841875], self.intercept: 1.0024222325703187\n",
      "iteration - 2287 -> loss: 0.0003629655994037467, self.slope: [1.02828915 1.02843011], self.intercept: 1.002423220412569\n",
      "iteration - 2288 -> loss: 0.00036293987259560965, self.slope: [1.02830043 1.02844146], self.intercept: 1.0024242081985308\n",
      "iteration - 2289 -> loss: 0.0003629141495586674, self.slope: [1.02831171 1.02845282], self.intercept: 1.0024251959282129\n",
      "iteration - 2290 -> loss: 0.00036288843029204593, self.slope: [1.02832299 1.02846417], self.intercept: 1.0024261836016215\n",
      "iteration - 2291 -> loss: 0.00036286271479492115, self.slope: [1.02833427 1.02847553], self.intercept: 1.0024271712187642\n",
      "iteration - 2292 -> loss: 0.0003628370030664284, self.slope: [1.02834555 1.02848688], self.intercept: 1.0024281587796466\n",
      "iteration - 2293 -> loss: 0.0003628112951057772, self.slope: [1.02835683 1.02849824], self.intercept: 1.0024291462842778\n",
      "iteration - 2294 -> loss: 0.0003627855909120801, self.slope: [1.02836811 1.02850959], self.intercept: 1.0024301337326638\n",
      "iteration - 2295 -> loss: 0.0003627598904845256, self.slope: [1.02837938 1.02852094], self.intercept: 1.002431121124811\n",
      "iteration - 2296 -> loss: 0.00036273419382225336, self.slope: [1.02839066 1.02853229], self.intercept: 1.002432108460728\n",
      "iteration - 2297 -> loss: 0.00036270850092444656, self.slope: [1.02840193 1.02854364], self.intercept: 1.0024330957404204\n",
      "iteration - 2298 -> loss: 0.0003626828117902542, self.slope: [1.02841321 1.02855499], self.intercept: 1.0024340829638962\n",
      "iteration - 2299 -> loss: 0.00036265712641884355, self.slope: [1.02842448 1.02856633], self.intercept: 1.0024350701311608\n",
      "iteration - 2300 -> loss: 0.0003626314448093659, self.slope: [1.02843575 1.02857768], self.intercept: 1.0024360572422237\n",
      "iteration - 2301 -> loss: 0.00036260576696099965, self.slope: [1.02844703 1.02858903], self.intercept: 1.0024370442970887\n",
      "iteration - 2302 -> loss: 0.00036258009287289274, self.slope: [1.0284583  1.02860037], self.intercept: 1.0024380312957646\n",
      "iteration - 2303 -> loss: 0.0003625544225442169, self.slope: [1.02846957 1.02861172], self.intercept: 1.0024390182382583\n",
      "iteration - 2304 -> loss: 0.0003625287559741349, self.slope: [1.02848084 1.02862306], self.intercept: 1.0024400051245783\n",
      "iteration - 2305 -> loss: 0.0003625030931618077, self.slope: [1.0284921 1.0286344], self.intercept: 1.0024409919547292\n",
      "iteration - 2306 -> loss: 0.00036247743410639714, self.slope: [1.02850337 1.02864575], self.intercept: 1.0024419787287189\n",
      "iteration - 2307 -> loss: 0.00036245177880706936, self.slope: [1.02851464 1.02865709], self.intercept: 1.0024429654465543\n",
      "iteration - 2308 -> loss: 0.00036242612726300314, self.slope: [1.0285259  1.02866843], self.intercept: 1.0024439521082424\n",
      "iteration - 2309 -> loss: 0.00036240047947332717, self.slope: [1.02853717 1.02867977], self.intercept: 1.0024449387137901\n",
      "iteration - 2310 -> loss: 0.00036237483543723247, self.slope: [1.02854843 1.0286911 ], self.intercept: 1.0024459252632054\n",
      "iteration - 2311 -> loss: 0.00036234919515387704, self.slope: [1.0285597  1.02870244], self.intercept: 1.002446911756494\n",
      "iteration - 2312 -> loss: 0.0003623235586224223, self.slope: [1.02857096 1.02871378], self.intercept: 1.0024478981936635\n",
      "iteration - 2313 -> loss: 0.00036229792584204493, self.slope: [1.02858222 1.02872512], self.intercept: 1.00244888457472\n",
      "iteration - 2314 -> loss: 0.0003622722968119174, self.slope: [1.02859348 1.02873645], self.intercept: 1.0024498708996712\n",
      "iteration - 2315 -> loss: 0.0003622466715311657, self.slope: [1.02860474 1.02874779], self.intercept: 1.002450857168525\n",
      "iteration - 2316 -> loss: 0.000362221049998998, self.slope: [1.028616   1.02875912], self.intercept: 1.002451843381287\n",
      "iteration - 2317 -> loss: 0.0003621954322145682, self.slope: [1.02862726 1.02877045], self.intercept: 1.0024528295379638\n",
      "iteration - 2318 -> loss: 0.00036216981817703407, self.slope: [1.02863852 1.02878178], self.intercept: 1.002453815638564\n",
      "iteration - 2319 -> loss: 0.0003621442078855575, self.slope: [1.02864977 1.02879312], self.intercept: 1.002454801683093\n",
      "iteration - 2320 -> loss: 0.0003621186013393309, self.slope: [1.02866103 1.02880445], self.intercept: 1.00245578767156\n",
      "iteration - 2321 -> loss: 0.00036209299853748827, self.slope: [1.02867228 1.02881578], self.intercept: 1.0024567736039698\n",
      "iteration - 2322 -> loss: 0.00036206739947923104, self.slope: [1.02868354 1.0288271 ], self.intercept: 1.0024577594803297\n",
      "iteration - 2323 -> loss: 0.00036204180416370417, self.slope: [1.02869479 1.02883843], self.intercept: 1.0024587453006484\n",
      "iteration - 2324 -> loss: 0.0003620162125900842, self.slope: [1.02870604 1.02884976], self.intercept: 1.0024597310649308\n",
      "iteration - 2325 -> loss: 0.0003619906247575344, self.slope: [1.0287173  1.02886109], self.intercept: 1.0024607167731843\n",
      "iteration - 2326 -> loss: 0.0003619650406652472, self.slope: [1.02872855 1.02887241], self.intercept: 1.0024617024254152\n",
      "iteration - 2327 -> loss: 0.00036193946031234643, self.slope: [1.0287398  1.02888374], self.intercept: 1.0024626880216336\n",
      "iteration - 2328 -> loss: 0.0003619138836980242, self.slope: [1.02875105 1.02889506], self.intercept: 1.0024636735618433\n",
      "iteration - 2329 -> loss: 0.0003618883108214762, self.slope: [1.0287623  1.02890638], self.intercept: 1.0024646590460529\n",
      "iteration - 2330 -> loss: 0.00036186274168184, self.slope: [1.02877354 1.02891771], self.intercept: 1.002465644474268\n",
      "iteration - 2331 -> loss: 0.00036183717627827886, self.slope: [1.02878479 1.02892903], self.intercept: 1.0024666298464966\n",
      "iteration - 2332 -> loss: 0.0003618116146099637, self.slope: [1.02879604 1.02894035], self.intercept: 1.0024676151627456\n",
      "iteration - 2333 -> loss: 0.00036178605667612057, self.slope: [1.02880728 1.02895167], self.intercept: 1.0024686004230208\n",
      "iteration - 2334 -> loss: 0.0003617605024758413, self.slope: [1.02881852 1.02896299], self.intercept: 1.002469585627331\n",
      "iteration - 2335 -> loss: 0.0003617349520083451, self.slope: [1.02882977 1.0289743 ], self.intercept: 1.002470570775681\n",
      "iteration - 2336 -> loss: 0.0003617094052727734, self.slope: [1.02884101 1.02898562], self.intercept: 1.0024715558680797\n",
      "iteration - 2337 -> loss: 0.00036168386226835493, self.slope: [1.02885225 1.02899694], self.intercept: 1.002472540904534\n",
      "iteration - 2338 -> loss: 0.0003616583229941824, self.slope: [1.02886349 1.02900825], self.intercept: 1.0024735258850497\n",
      "iteration - 2339 -> loss: 0.0003616327874494882, self.slope: [1.02887473 1.02901957], self.intercept: 1.0024745108096345\n",
      "iteration - 2340 -> loss: 0.0003616072556334114, self.slope: [1.02888597 1.02903088], self.intercept: 1.0024754956782949\n",
      "iteration - 2341 -> loss: 0.0003615817275451313, self.slope: [1.02889721 1.0290422 ], self.intercept: 1.0024764804910364\n",
      "iteration - 2342 -> loss: 0.00036155620318382937, self.slope: [1.02890845 1.02905351], self.intercept: 1.002477465247869\n",
      "iteration - 2343 -> loss: 0.0003615306825486796, self.slope: [1.02891969 1.02906482], self.intercept: 1.0024784499487975\n",
      "iteration - 2344 -> loss: 0.0003615051656388492, self.slope: [1.02893092 1.02907613], self.intercept: 1.002479434593831\n",
      "iteration - 2345 -> loss: 0.0003614796524535015, self.slope: [1.02894216 1.02908744], self.intercept: 1.0024804191829748\n",
      "iteration - 2346 -> loss: 0.00036145414299180686, self.slope: [1.02895339 1.02909875], self.intercept: 1.0024814037162362\n",
      "iteration - 2347 -> loss: 0.00036142863725297186, self.slope: [1.02896463 1.02911006], self.intercept: 1.0024823881936227\n",
      "iteration - 2348 -> loss: 0.00036140313523614536, self.slope: [1.02897586 1.02912136], self.intercept: 1.0024833726151383\n",
      "iteration - 2349 -> loss: 0.000361377636940506, self.slope: [1.02898709 1.02913267], self.intercept: 1.002484356980794\n",
      "iteration - 2350 -> loss: 0.0003613521423652224, self.slope: [1.02899832 1.02914398], self.intercept: 1.0024853412905943\n",
      "iteration - 2351 -> loss: 0.00036132665150948035, self.slope: [1.02900955 1.02915528], self.intercept: 1.002486325544546\n",
      "iteration - 2352 -> loss: 0.00036130116437244807, self.slope: [1.02902078 1.02916659], self.intercept: 1.002487309742658\n",
      "iteration - 2353 -> loss: 0.00036127568095330187, self.slope: [1.02903201 1.02917789], self.intercept: 1.002488293884935\n",
      "iteration - 2354 -> loss: 0.00036125020125121087, self.slope: [1.02904324 1.02918919], self.intercept: 1.002489277971385\n",
      "iteration - 2355 -> loss: 0.0003612247252653697, self.slope: [1.02905446 1.02920049], self.intercept: 1.0024902620020146\n",
      "iteration - 2356 -> loss: 0.0003611992529949492, self.slope: [1.02906569 1.0292118 ], self.intercept: 1.0024912459768323\n",
      "iteration - 2357 -> loss: 0.0003611737844391038, self.slope: [1.02907691 1.0292231 ], self.intercept: 1.002492229895843\n",
      "iteration - 2358 -> loss: 0.00036114831959702153, self.slope: [1.02908814 1.02923439], self.intercept: 1.0024932137590536\n",
      "iteration - 2359 -> loss: 0.0003611228584678907, self.slope: [1.02909936 1.02924569], self.intercept: 1.002494197566473\n",
      "iteration - 2360 -> loss: 0.00036109740105087334, self.slope: [1.02911059 1.02925699], self.intercept: 1.0024951813181053\n",
      "iteration - 2361 -> loss: 0.0003610719473451653, self.slope: [1.02912181 1.02926829], self.intercept: 1.0024961650139597\n",
      "iteration - 2362 -> loss: 0.00036104649734992493, self.slope: [1.02913303 1.02927958], self.intercept: 1.0024971486540433\n",
      "iteration - 2363 -> loss: 0.00036102105106433505, self.slope: [1.02914425 1.02929088], self.intercept: 1.0024981322383613\n",
      "iteration - 2364 -> loss: 0.0003609956084875679, self.slope: [1.02915547 1.02930217], self.intercept: 1.002499115766921\n",
      "iteration - 2365 -> loss: 0.0003609701696188142, self.slope: [1.02916669 1.02931347], self.intercept: 1.0025000992397297\n",
      "iteration - 2366 -> loss: 0.0003609447344572424, self.slope: [1.0291779  1.02932476], self.intercept: 1.0025010826567937\n",
      "iteration - 2367 -> loss: 0.0003609193030020535, self.slope: [1.02918912 1.02933605], self.intercept: 1.0025020660181212\n",
      "iteration - 2368 -> loss: 0.000360893875252403, self.slope: [1.02920034 1.02934734], self.intercept: 1.002503049323719\n",
      "iteration - 2369 -> loss: 0.0003608684512074676, self.slope: [1.02921155 1.02935863], self.intercept: 1.0025040325735937\n",
      "iteration - 2370 -> loss: 0.0003608430308664435, self.slope: [1.02922277 1.02936992], self.intercept: 1.0025050157677518\n",
      "iteration - 2371 -> loss: 0.00036081761422849314, self.slope: [1.02923398 1.02938121], self.intercept: 1.0025059989062013\n",
      "iteration - 2372 -> loss: 0.0003607922012928187, self.slope: [1.02924519 1.0293925 ], self.intercept: 1.002506981988948\n",
      "iteration - 2373 -> loss: 0.0003607667920585689, self.slope: [1.02925641 1.02940379], self.intercept: 1.002507965015999\n",
      "iteration - 2374 -> loss: 0.0003607413865249489, self.slope: [1.02926762 1.02941507], self.intercept: 1.0025089479873595\n",
      "iteration - 2375 -> loss: 0.0003607159846911423, self.slope: [1.02927883 1.02942636], self.intercept: 1.0025099309030412\n",
      "iteration - 2376 -> loss: 0.0003606905865563043, self.slope: [1.02929004 1.02943764], self.intercept: 1.0025109137630464\n",
      "iteration - 2377 -> loss: 0.0003606651921196237, self.slope: [1.02930125 1.02944893], self.intercept: 1.002511896567383\n",
      "iteration - 2378 -> loss: 0.000360639801380312, self.slope: [1.02931245 1.02946021], self.intercept: 1.0025128793160583\n",
      "iteration - 2379 -> loss: 0.00036061441433752635, self.slope: [1.02932366 1.02947149], self.intercept: 1.0025138620090803\n",
      "iteration - 2380 -> loss: 0.0003605890309904403, self.slope: [1.02933487 1.02948277], self.intercept: 1.0025148446464534\n",
      "iteration - 2381 -> loss: 0.00036056365133825015, self.slope: [1.02934607 1.02949405], self.intercept: 1.0025158272281876\n",
      "iteration - 2382 -> loss: 0.00036053827538014163, self.slope: [1.02935728 1.02950533], self.intercept: 1.0025168097542878\n",
      "iteration - 2383 -> loss: 0.00036051290311526894, self.slope: [1.02936848 1.02951661], self.intercept: 1.0025177922247608\n",
      "iteration - 2384 -> loss: 0.00036048753454286076, self.slope: [1.02937968 1.02952789], self.intercept: 1.0025187746396131\n",
      "iteration - 2385 -> loss: 0.00036046216966206747, self.slope: [1.02939089 1.02953917], self.intercept: 1.002519756998853\n",
      "iteration - 2386 -> loss: 0.0003604368084720729, self.slope: [1.02940209 1.02955044], self.intercept: 1.0025207393024884\n",
      "iteration - 2387 -> loss: 0.00036041145097207147, self.slope: [1.02941329 1.02956172], self.intercept: 1.0025217215505233\n",
      "iteration - 2388 -> loss: 0.00036038609716124143, self.slope: [1.02942449 1.02957299], self.intercept: 1.0025227037429671\n",
      "iteration - 2389 -> loss: 0.00036036074703876884, self.slope: [1.02943569 1.02958427], self.intercept: 1.002523685879826\n",
      "iteration - 2390 -> loss: 0.0003603354006038446, self.slope: [1.02944688 1.02959554], self.intercept: 1.0025246679611053\n",
      "iteration - 2391 -> loss: 0.0003603100578556381, self.slope: [1.02945808 1.02960681], self.intercept: 1.0025256499868136\n",
      "iteration - 2392 -> loss: 0.00036028471879335865, self.slope: [1.02946928 1.02961808], self.intercept: 1.002526631956956\n",
      "iteration - 2393 -> loss: 0.00036025938341615016, self.slope: [1.02948047 1.02962936], self.intercept: 1.0025276138715407\n",
      "iteration - 2394 -> loss: 0.00036023405172323395, self.slope: [1.02949167 1.02964063], self.intercept: 1.0025285957305763\n",
      "iteration - 2395 -> loss: 0.000360208723713783, self.slope: [1.02950286 1.02965189], self.intercept: 1.0025295775340652\n",
      "iteration - 2396 -> loss: 0.00036018339938698884, self.slope: [1.02951406 1.02966316], self.intercept: 1.0025305592820182\n",
      "iteration - 2397 -> loss: 0.00036015807874203727, self.slope: [1.02952525 1.02967443], self.intercept: 1.00253154097444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 2398 -> loss: 0.0003601327617781048, self.slope: [1.02953644 1.0296857 ], self.intercept: 1.0025325226113388\n",
      "iteration - 2399 -> loss: 0.00036010744849436337, self.slope: [1.02954763 1.02969696], self.intercept: 1.0025335041927206\n",
      "iteration - 2400 -> loss: 0.00036008213889004553, self.slope: [1.02955882 1.02970823], self.intercept: 1.002534485718592\n",
      "iteration - 2401 -> loss: 0.0003600568329643052, self.slope: [1.02957001 1.02971949], self.intercept: 1.002535467188962\n",
      "iteration - 2402 -> loss: 0.0003600315307163295, self.slope: [1.0295812  1.02973076], self.intercept: 1.0025364486038342\n",
      "iteration - 2403 -> loss: 0.0003600062321453202, self.slope: [1.02959238 1.02974202], self.intercept: 1.0025374299632186\n",
      "iteration - 2404 -> loss: 0.0003599809372504573, self.slope: [1.02960357 1.02975328], self.intercept: 1.002538411267121\n",
      "iteration - 2405 -> loss: 0.00035995564603092756, self.slope: [1.02961476 1.02976454], self.intercept: 1.0025393925155466\n",
      "iteration - 2406 -> loss: 0.00035993035848590964, self.slope: [1.02962594 1.0297758 ], self.intercept: 1.0025403737085044\n",
      "iteration - 2407 -> loss: 0.00035990507461461894, self.slope: [1.02963713 1.02978706], self.intercept: 1.0025413548460003\n",
      "iteration - 2408 -> loss: 0.0003598797944162088, self.slope: [1.02964831 1.02979832], self.intercept: 1.0025423359280423\n",
      "iteration - 2409 -> loss: 0.00035985451788990474, self.slope: [1.02965949 1.02980958], self.intercept: 1.0025433169546358\n",
      "iteration - 2410 -> loss: 0.0003598292450348691, self.slope: [1.02967067 1.02982083], self.intercept: 1.0025442979257877\n",
      "iteration - 2411 -> loss: 0.0003598039758502968, self.slope: [1.02968185 1.02983209], self.intercept: 1.0025452788415068\n",
      "iteration - 2412 -> loss: 0.0003597787103353873, self.slope: [1.02969303 1.02984335], self.intercept: 1.0025462597017962\n",
      "iteration - 2413 -> loss: 0.00035975344848932037, self.slope: [1.02970421 1.0298546 ], self.intercept: 1.0025472405066664\n",
      "iteration - 2414 -> loss: 0.0003597281903112912, self.slope: [1.02971539 1.02986585], self.intercept: 1.0025482212561223\n",
      "iteration - 2415 -> loss: 0.00035970293580047703, self.slope: [1.02972657 1.02987711], self.intercept: 1.0025492019501723\n",
      "iteration - 2416 -> loss: 0.00035967768495608483, self.slope: [1.02973775 1.02988836], self.intercept: 1.0025501825888214\n",
      "iteration - 2417 -> loss: 0.0003596524377773084, self.slope: [1.02974892 1.02989961], self.intercept: 1.0025511631720767\n",
      "iteration - 2418 -> loss: 0.0003596271942633327, self.slope: [1.0297601  1.02991086], self.intercept: 1.0025521436999452\n",
      "iteration - 2419 -> loss: 0.0003596019544133305, self.slope: [1.02977127 1.02992211], self.intercept: 1.0025531241724364\n",
      "iteration - 2420 -> loss: 0.00035957671822651826, self.slope: [1.02978244 1.02993336], self.intercept: 1.002554104589553\n",
      "iteration - 2421 -> loss: 0.0003595514857020789, self.slope: [1.02979362 1.02994461], self.intercept: 1.0025550849513045\n",
      "iteration - 2422 -> loss: 0.00035952625683921053, self.slope: [1.02980479 1.02995585], self.intercept: 1.0025560652576961\n",
      "iteration - 2423 -> loss: 0.0003595010316370786, self.slope: [1.02981596 1.0299671 ], self.intercept: 1.0025570455087354\n",
      "iteration - 2424 -> loss: 0.0003594758100949273, self.slope: [1.02982713 1.02997835], self.intercept: 1.00255802570443\n",
      "iteration - 2425 -> loss: 0.0003594505922119022, self.slope: [1.0298383  1.02998959], self.intercept: 1.0025590058447853\n",
      "iteration - 2426 -> loss: 0.00035942537798721105, self.slope: [1.02984947 1.03000083], self.intercept: 1.0025599859298093\n",
      "iteration - 2427 -> loss: 0.00035940016742005276, self.slope: [1.02986064 1.03001208], self.intercept: 1.0025609659595096\n",
      "iteration - 2428 -> loss: 0.00035937496050960624, self.slope: [1.0298718  1.03002332], self.intercept: 1.0025619459338915\n",
      "iteration - 2429 -> loss: 0.00035934975725508656, self.slope: [1.02988297 1.03003456], self.intercept: 1.002562925852962\n",
      "iteration - 2430 -> loss: 0.0003593245576556632, self.slope: [1.02989413 1.0300458 ], self.intercept: 1.0025639057167288\n",
      "iteration - 2431 -> loss: 0.00035929936171055007, self.slope: [1.0299053  1.03005704], self.intercept: 1.0025648855251978\n",
      "iteration - 2432 -> loss: 0.00035927416941894505, self.slope: [1.02991646 1.03006828], self.intercept: 1.002565865278376\n",
      "iteration - 2433 -> loss: 0.0003592489807800102, self.slope: [1.02992762 1.03007952], self.intercept: 1.0025668449762708\n",
      "iteration - 2434 -> loss: 0.00035922379579297566, self.slope: [1.02993879 1.03009076], self.intercept: 1.0025678246188892\n",
      "iteration - 2435 -> loss: 0.00035919861445702153, self.slope: [1.02994995 1.03010199], self.intercept: 1.0025688042062357\n",
      "iteration - 2436 -> loss: 0.0003591734367713421, self.slope: [1.02996111 1.03011323], self.intercept: 1.0025697837383205\n",
      "iteration - 2437 -> loss: 0.00035914826273515145, self.slope: [1.02997227 1.03012446], self.intercept: 1.0025707632151457\n",
      "iteration - 2438 -> loss: 0.0003591230923476208, self.slope: [1.02998343 1.0301357 ], self.intercept: 1.0025717426367247\n",
      "iteration - 2439 -> loss: 0.00035909792560794127, self.slope: [1.02999458 1.03014693], self.intercept: 1.0025727220030594\n",
      "iteration - 2440 -> loss: 0.0003590727625153273, self.slope: [1.03000574 1.03015817], self.intercept: 1.0025737013141578\n",
      "iteration - 2441 -> loss: 0.0003590476030689856, self.slope: [1.0300169 1.0301694], self.intercept: 1.0025746805700262\n",
      "iteration - 2442 -> loss: 0.000359022447268085, self.slope: [1.03002805 1.03018063], self.intercept: 1.002575659770673\n",
      "iteration - 2443 -> loss: 0.00035899729511184415, self.slope: [1.03003921 1.03019186], self.intercept: 1.002576638916104\n",
      "iteration - 2444 -> loss: 0.0003589721465994375, self.slope: [1.03005036 1.03020309], self.intercept: 1.0025776180063257\n",
      "iteration - 2445 -> loss: 0.0003589470017300752, self.slope: [1.03006151 1.03021432], self.intercept: 1.0025785970413457\n",
      "iteration - 2446 -> loss: 0.0003589218605029659, self.slope: [1.03007267 1.03022554], self.intercept: 1.0025795760211698\n",
      "iteration - 2447 -> loss: 0.0003588967229172944, self.slope: [1.03008382 1.03023677], self.intercept: 1.0025805549458053\n",
      "iteration - 2448 -> loss: 0.0003588715889722679, self.slope: [1.03009497 1.030248  ], self.intercept: 1.0025815338152597\n",
      "iteration - 2449 -> loss: 0.0003588464586670855, self.slope: [1.03010612 1.03025922], self.intercept: 1.0025825126295405\n",
      "iteration - 2450 -> loss: 0.00035882133200093147, self.slope: [1.03011727 1.03027045], self.intercept: 1.002583491388652\n",
      "iteration - 2451 -> loss: 0.0003587962089730063, self.slope: [1.03012842 1.03028167], self.intercept: 1.002584470092604\n",
      "iteration - 2452 -> loss: 0.0003587710895825305, self.slope: [1.03013956 1.03029289], self.intercept: 1.0025854487414008\n",
      "iteration - 2453 -> loss: 0.0003587459738286719, self.slope: [1.03015071 1.03030412], self.intercept: 1.0025864273350493\n",
      "iteration - 2454 -> loss: 0.000358720861710664, self.slope: [1.03016185 1.03031534], self.intercept: 1.002587405873558\n",
      "iteration - 2455 -> loss: 0.0003586957532276726, self.slope: [1.030173   1.03032656], self.intercept: 1.0025883843569323\n",
      "iteration - 2456 -> loss: 0.00035867064837892136, self.slope: [1.03018414 1.03033778], self.intercept: 1.0025893627851779\n",
      "iteration - 2457 -> loss: 0.0003586455471636062, self.slope: [1.03019529 1.030349  ], self.intercept: 1.0025903411583035\n",
      "iteration - 2458 -> loss: 0.0003586204495809295, self.slope: [1.03020643 1.03036022], self.intercept: 1.0025913194763167\n",
      "iteration - 2459 -> loss: 0.00035859535563007104, self.slope: [1.03021757 1.03037143], self.intercept: 1.0025922977392214\n",
      "iteration - 2460 -> loss: 0.00035857026531026535, self.slope: [1.03022871 1.03038265], self.intercept: 1.002593275947028\n",
      "iteration - 2461 -> loss: 0.00035854517862070535, self.slope: [1.03023985 1.03039386], self.intercept: 1.0025942540997403\n",
      "iteration - 2462 -> loss: 0.00035852009556055283, self.slope: [1.03025099 1.03040508], self.intercept: 1.0025952321973657\n",
      "iteration - 2463 -> loss: 0.00035849501612906365, self.slope: [1.03026213 1.03041629], self.intercept: 1.002596210239912\n",
      "iteration - 2464 -> loss: 0.0003584699403254006, self.slope: [1.03027327 1.03042751], self.intercept: 1.0025971882273852\n",
      "iteration - 2465 -> loss: 0.0003584448681487868, self.slope: [1.0302844  1.03043872], self.intercept: 1.0025981661597918\n",
      "iteration - 2466 -> loss: 0.000358419799598431, self.slope: [1.03029554 1.03044993], self.intercept: 1.0025991440371393\n",
      "iteration - 2467 -> loss: 0.0003583947346735134, self.slope: [1.03030667 1.03046114], self.intercept: 1.0026001218594354\n",
      "iteration - 2468 -> loss: 0.0003583696733732561, self.slope: [1.03031781 1.03047235], self.intercept: 1.0026010996266852\n",
      "iteration - 2469 -> loss: 0.0003583446156968457, self.slope: [1.03032894 1.03048356], self.intercept: 1.002602077338896\n",
      "iteration - 2470 -> loss: 0.00035831956164350114, self.slope: [1.03034007 1.03049477], self.intercept: 1.0026030549960738\n",
      "iteration - 2471 -> loss: 0.00035829451121241473, self.slope: [1.03035121 1.03050598], self.intercept: 1.0026040325982277\n",
      "iteration - 2472 -> loss: 0.00035826946440278596, self.slope: [1.03036234 1.03051718], self.intercept: 1.002605010145363\n",
      "iteration - 2473 -> loss: 0.00035824442121383553, self.slope: [1.03037347 1.03052839], self.intercept: 1.0026059876374844\n",
      "iteration - 2474 -> loss: 0.0003582193816447786, self.slope: [1.0303846 1.0305396], self.intercept: 1.0026069650746012\n",
      "iteration - 2475 -> loss: 0.0003581943456947796, self.slope: [1.03039573 1.0305508 ], self.intercept: 1.002607942456719\n",
      "iteration - 2476 -> loss: 0.00035816931336306193, self.slope: [1.03040685 1.030562  ], self.intercept: 1.0026089197838455\n",
      "iteration - 2477 -> loss: 0.00035814428464884233, self.slope: [1.03041798 1.03057321], self.intercept: 1.002609897055988\n",
      "iteration - 2478 -> loss: 0.00035811925955130607, self.slope: [1.03042911 1.03058441], self.intercept: 1.0026108742731514\n",
      "iteration - 2479 -> loss: 0.00035809423806969096, self.slope: [1.03044023 1.03059561], self.intercept: 1.0026118514353421\n",
      "iteration - 2480 -> loss: 0.00035806922020315836, self.slope: [1.03045136 1.03060681], self.intercept: 1.0026128285425708\n",
      "iteration - 2481 -> loss: 0.0003580442059509515, self.slope: [1.03046248 1.03061801], self.intercept: 1.0026138055948406\n",
      "iteration - 2482 -> loss: 0.0003580191953122492, self.slope: [1.0304736  1.03062921], self.intercept: 1.0026147825921599\n",
      "iteration - 2483 -> loss: 0.000357994188286286, self.slope: [1.03048473 1.03064041], self.intercept: 1.0026157595345344\n",
      "iteration - 2484 -> loss: 0.00035796918487225057, self.slope: [1.03049585 1.0306516 ], self.intercept: 1.002616736421972\n",
      "iteration - 2485 -> loss: 0.00035794418506933975, self.slope: [1.03050697 1.0306628 ], self.intercept: 1.0026177132544805\n",
      "iteration - 2486 -> loss: 0.0003579191888767847, self.slope: [1.03051809 1.030674  ], self.intercept: 1.002618690032063\n",
      "iteration - 2487 -> loss: 0.00035789419629377094, self.slope: [1.03052921 1.03068519], self.intercept: 1.0026196667547291\n",
      "iteration - 2488 -> loss: 0.0003578692073195215, self.slope: [1.03054032 1.03069639], self.intercept: 1.0026206434224847\n",
      "iteration - 2489 -> loss: 0.0003578442219532412, self.slope: [1.03055144 1.03070758], self.intercept: 1.0026216200353362\n",
      "iteration - 2490 -> loss: 0.0003578192401941366, self.slope: [1.03056256 1.03071877], self.intercept: 1.0026225965932913\n",
      "iteration - 2491 -> loss: 0.0003577942620414188, self.slope: [1.03057367 1.03072996], self.intercept: 1.0026235730963562\n",
      "iteration - 2492 -> loss: 0.00035776928749427656, self.slope: [1.03058479 1.03074115], self.intercept: 1.0026245495445372\n",
      "iteration - 2493 -> loss: 0.00035774431655194797, self.slope: [1.0305959  1.03075234], self.intercept: 1.00262552593784\n",
      "iteration - 2494 -> loss: 0.00035771934921362275, self.slope: [1.03060701 1.03076353], self.intercept: 1.0026265022762748\n",
      "iteration - 2495 -> loss: 0.00035769438547852105, self.slope: [1.03061813 1.03077472], self.intercept: 1.002627478559846\n",
      "iteration - 2496 -> loss: 0.00035766942534584586, self.slope: [1.03062924 1.03078591], self.intercept: 1.0026284547885602\n",
      "iteration - 2497 -> loss: 0.00035764446881481456, self.slope: [1.03064035 1.0307971 ], self.intercept: 1.0026294309624249\n",
      "iteration - 2498 -> loss: 0.0003576195158846242, self.slope: [1.03065146 1.03080828], self.intercept: 1.002630407081447\n",
      "iteration - 2499 -> loss: 0.0003575945665544986, self.slope: [1.03066257 1.03081947], self.intercept: 1.002631383145632\n",
      "iteration - 2500 -> loss: 0.0003575696208236366, self.slope: [1.03067368 1.03083065], self.intercept: 1.0026323591549877\n",
      "iteration - 2501 -> loss: 0.00035754467869125484, self.slope: [1.03068478 1.03084183], self.intercept: 1.0026333351095207\n",
      "iteration - 2502 -> loss: 0.0003575197401565551, self.slope: [1.03069589 1.03085302], self.intercept: 1.0026343110092375\n",
      "iteration - 2503 -> loss: 0.00035749480521876377, self.slope: [1.030707  1.0308642], self.intercept: 1.0026352868541448\n",
      "iteration - 2504 -> loss: 0.00035746987387708665, self.slope: [1.0307181  1.03087538], self.intercept: 1.0026362626442502\n",
      "iteration - 2505 -> loss: 0.0003574449461307226, self.slope: [1.03072921 1.03088656], self.intercept: 1.0026372383795594\n",
      "iteration - 2506 -> loss: 0.00035742002197889386, self.slope: [1.03074031 1.03089774], self.intercept: 1.0026382140600787\n",
      "iteration - 2507 -> loss: 0.0003573951014208255, self.slope: [1.03075141 1.03090892], self.intercept: 1.002639189685815\n",
      "iteration - 2508 -> loss: 0.00035737018445571283, self.slope: [1.03076251 1.0309201 ], self.intercept: 1.002640165256777\n",
      "iteration - 2509 -> loss: 0.00035734527108276937, self.slope: [1.03077362 1.03093127], self.intercept: 1.0026411407729707\n",
      "iteration - 2510 -> loss: 0.00035732036130120987, self.slope: [1.03078472 1.03094245], self.intercept: 1.0026421162344024\n",
      "iteration - 2511 -> loss: 0.0003572954551102526, self.slope: [1.03079582 1.03095363], self.intercept: 1.0026430916410776\n",
      "iteration - 2512 -> loss: 0.000357270552509108, self.slope: [1.03080691 1.0309648 ], self.intercept: 1.0026440669930046\n",
      "iteration - 2513 -> loss: 0.00035724565349697286, self.slope: [1.03081801 1.03097598], self.intercept: 1.002645042290189\n",
      "iteration - 2514 -> loss: 0.00035722075807310093, self.slope: [1.03082911 1.03098715], self.intercept: 1.0026460175326382\n",
      "iteration - 2515 -> loss: 0.0003571958662366519, self.slope: [1.0308402  1.03099832], self.intercept: 1.0026469927203585\n",
      "iteration - 2516 -> loss: 0.0003571709779868835, self.slope: [1.0308513  1.03100949], self.intercept: 1.0026479678533577\n",
      "iteration - 2517 -> loss: 0.00035714609332298863, self.slope: [1.03086239 1.03102066], self.intercept: 1.0026489429316405\n",
      "iteration - 2518 -> loss: 0.0003571212122441951, self.slope: [1.03087349 1.03103183], self.intercept: 1.0026499179552155\n",
      "iteration - 2519 -> loss: 0.00035709633474971357, self.slope: [1.03088458 1.031043  ], self.intercept: 1.0026508929240878\n",
      "iteration - 2520 -> loss: 0.00035707146083874584, self.slope: [1.03089567 1.03105417], self.intercept: 1.0026518678382668\n",
      "iteration - 2521 -> loss: 0.0003570465905105276, self.slope: [1.03090677 1.03106534], self.intercept: 1.0026528426977563\n",
      "iteration - 2522 -> loss: 0.00035702172376426614, self.slope: [1.03091786 1.03107651], self.intercept: 1.002653817502565\n",
      "iteration - 2523 -> loss: 0.00035699686059917216, self.slope: [1.03092895 1.03108767], self.intercept: 1.0026547922526976\n",
      "iteration - 2524 -> loss: 0.000356972001014468, self.slope: [1.03094003 1.03109884], self.intercept: 1.0026557669481635\n",
      "iteration - 2525 -> loss: 0.00035694714500936095, self.slope: [1.03095112 1.03111   ], self.intercept: 1.0026567415889662\n",
      "iteration - 2526 -> loss: 0.0003569222925830645, self.slope: [1.03096221 1.03112117], self.intercept: 1.0026577161751151\n",
      "iteration - 2527 -> loss: 0.0003568974437348267, self.slope: [1.0309733  1.03113233], self.intercept: 1.0026586907066166\n",
      "iteration - 2528 -> loss: 0.000356872598463815, self.slope: [1.03098438 1.03114349], self.intercept: 1.0026596651834763\n",
      "iteration - 2529 -> loss: 0.0003568477567692853, self.slope: [1.03099547 1.03115465], self.intercept: 1.002660639605701\n",
      "iteration - 2530 -> loss: 0.00035682291865047206, self.slope: [1.03100655 1.03116581], self.intercept: 1.0026616139732976\n",
      "iteration - 2531 -> loss: 0.0003567980841065183, self.slope: [1.03101763 1.03117697], self.intercept: 1.0026625882862714\n",
      "iteration - 2532 -> loss: 0.00035677325313671017, self.slope: [1.03102872 1.03118813], self.intercept: 1.0026635625446314\n",
      "iteration - 2533 -> loss: 0.00035674842574024394, self.slope: [1.0310398  1.03119929], self.intercept: 1.0026645367483855\n",
      "iteration - 2534 -> loss: 0.0003567236019163151, self.slope: [1.03105088 1.03121045], self.intercept: 1.002665510897537\n",
      "iteration - 2535 -> loss: 0.00035669878166418967, self.slope: [1.03106196 1.0312216 ], self.intercept: 1.0026664849920945\n",
      "iteration - 2536 -> loss: 0.0003566739649830596, self.slope: [1.03107304 1.03123276], self.intercept: 1.0026674590320643\n",
      "iteration - 2537 -> loss: 0.0003566491518721251, self.slope: [1.03108412 1.03124391], self.intercept: 1.0026684330174531\n",
      "iteration - 2538 -> loss: 0.00035662434233063085, self.slope: [1.0310952  1.03125507], self.intercept: 1.002669406948267\n",
      "iteration - 2539 -> loss: 0.00035659953635779854, self.slope: [1.03110627 1.03126622], self.intercept: 1.0026703808245128\n",
      "iteration - 2540 -> loss: 0.00035657473395282307, self.slope: [1.03111735 1.03127737], self.intercept: 1.0026713546461978\n",
      "iteration - 2541 -> loss: 0.0003565499351149599, self.slope: [1.03112842 1.03128852], self.intercept: 1.0026723284133283\n",
      "iteration - 2542 -> loss: 0.00035652513984340563, self.slope: [1.0311395  1.03129967], self.intercept: 1.0026733021259118\n",
      "iteration - 2543 -> loss: 0.0003565003481373782, self.slope: [1.03115057 1.03131083], self.intercept: 1.002674275783953\n",
      "iteration - 2544 -> loss: 0.0003564755599961024, self.slope: [1.03116164 1.03132197], self.intercept: 1.0026752493874604\n",
      "iteration - 2545 -> loss: 0.0003564507754188123, self.slope: [1.03117272 1.03133312], self.intercept: 1.0026762229364419\n",
      "iteration - 2546 -> loss: 0.00035642599440469694, self.slope: [1.03118379 1.03134427], self.intercept: 1.0026771964309016\n",
      "iteration - 2547 -> loss: 0.0003564012169530277, self.slope: [1.03119486 1.03135542], self.intercept: 1.0026781698708462\n",
      "iteration - 2548 -> loss: 0.00035637644306298196, self.slope: [1.03120593 1.03136656], self.intercept: 1.0026791432562834\n",
      "iteration - 2549 -> loss: 0.000356351672733797, self.slope: [1.031217   1.03137771], self.intercept: 1.0026801165872197\n",
      "iteration - 2550 -> loss: 0.00035632690596468876, self.slope: [1.03122806 1.03138885], self.intercept: 1.0026810898636627\n",
      "iteration - 2551 -> loss: 0.00035630214275488134, self.slope: [1.03123913 1.0314    ], self.intercept: 1.0026820630856175\n",
      "iteration - 2552 -> loss: 0.0003562773831035991, self.slope: [1.0312502  1.03141114], self.intercept: 1.002683036253091\n",
      "iteration - 2553 -> loss: 0.00035625262701006544, self.slope: [1.03126126 1.03142228], self.intercept: 1.00268400936609\n",
      "iteration - 2554 -> loss: 0.0003562278744735098, self.slope: [1.03127233 1.03143342], self.intercept: 1.0026849824246236\n",
      "iteration - 2555 -> loss: 0.0003562031254931642, self.slope: [1.03128339 1.03144456], self.intercept: 1.002685955428694\n",
      "iteration - 2556 -> loss: 0.00035617838006819926, self.slope: [1.03129446 1.0314557 ], self.intercept: 1.002686928378311\n",
      "iteration - 2557 -> loss: 0.00035615363819790983, self.slope: [1.03130552 1.03146684], self.intercept: 1.0026879012734808\n",
      "iteration - 2558 -> loss: 0.00035612889988147434, self.slope: [1.03131658 1.03147798], self.intercept: 1.0026888741142086\n",
      "iteration - 2559 -> loss: 0.00035610416511812224, self.slope: [1.03132764 1.03148912], self.intercept: 1.002689846900502\n",
      "iteration - 2560 -> loss: 0.000356079433907098, self.slope: [1.0313387  1.03150026], self.intercept: 1.0026908196323687\n",
      "iteration - 2561 -> loss: 0.00035605470624759807, self.slope: [1.03134976 1.03151139], self.intercept: 1.0026917923098142\n",
      "iteration - 2562 -> loss: 0.00035602998213885495, self.slope: [1.03136082 1.03152253], self.intercept: 1.0026927649328456\n",
      "iteration - 2563 -> loss: 0.0003560052615801251, self.slope: [1.03137188 1.03153366], self.intercept: 1.0026937375014675\n",
      "iteration - 2564 -> loss: 0.0003559805445705843, self.slope: [1.03138293 1.03154479], self.intercept: 1.0026947100156902\n",
      "iteration - 2565 -> loss: 0.00035595583110949967, self.slope: [1.03139399 1.03155593], self.intercept: 1.002695682475519\n",
      "iteration - 2566 -> loss: 0.0003559311211960507, self.slope: [1.03140504 1.03156706], self.intercept: 1.0026966548809597\n",
      "iteration - 2567 -> loss: 0.0003559064148295051, self.slope: [1.0314161  1.03157819], self.intercept: 1.0026976272320194\n",
      "iteration - 2568 -> loss: 0.00035588171200909015, self.slope: [1.03142715 1.03158932], self.intercept: 1.0026985995287045\n",
      "iteration - 2569 -> loss: 0.0003558570127340014, self.slope: [1.03143821 1.03160045], self.intercept: 1.0026995717710219\n",
      "iteration - 2570 -> loss: 0.00035583231700348416, self.slope: [1.03144926 1.03161158], self.intercept: 1.0027005439589791\n",
      "iteration - 2571 -> loss: 0.00035580762481673863, self.slope: [1.03146031 1.03162271], self.intercept: 1.0027015160925818\n",
      "iteration - 2572 -> loss: 0.0003557829361730428, self.slope: [1.03147136 1.03163383], self.intercept: 1.0027024881718363\n",
      "iteration - 2573 -> loss: 0.00035575825107158775, self.slope: [1.03148241 1.03164496], self.intercept: 1.00270346019675\n",
      "iteration - 2574 -> loss: 0.0003557335695115955, self.slope: [1.03149346 1.03165608], self.intercept: 1.0027044321673284\n",
      "iteration - 2575 -> loss: 0.0003557088914923154, self.slope: [1.03150451 1.03166721], self.intercept: 1.0027054040835786\n",
      "iteration - 2576 -> loss: 0.0003556842170129818, self.slope: [1.03151555 1.03167833], self.intercept: 1.002706375945508\n",
      "iteration - 2577 -> loss: 0.0003556595460727815, self.slope: [1.0315266  1.03168946], self.intercept: 1.0027073477531239\n",
      "iteration - 2578 -> loss: 0.0003556348786709856, self.slope: [1.03153764 1.03170058], self.intercept: 1.002708319506432\n",
      "iteration - 2579 -> loss: 0.00035561021480679975, self.slope: [1.03154869 1.0317117 ], self.intercept: 1.0027092912054376\n",
      "iteration - 2580 -> loss: 0.0003555855544794616, self.slope: [1.03155973 1.03172282], self.intercept: 1.0027102628501496\n",
      "iteration - 2581 -> loss: 0.0003555608976881839, self.slope: [1.03157078 1.03173394], self.intercept: 1.0027112344405746\n",
      "iteration - 2582 -> loss: 0.00035553624443222077, self.slope: [1.03158182 1.03174506], self.intercept: 1.0027122059767166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 2583 -> loss: 0.0003555115947107946, self.slope: [1.03159286 1.03175618], self.intercept: 1.0027131774585842\n",
      "iteration - 2584 -> loss: 0.0003554869485231156, self.slope: [1.0316039 1.0317673], self.intercept: 1.0027141488861837\n",
      "iteration - 2585 -> loss: 0.0003554623058684351, self.slope: [1.03161494 1.03177841], self.intercept: 1.002715120259522\n",
      "iteration - 2586 -> loss: 0.0003554376667459773, self.slope: [1.03162598 1.03178953], self.intercept: 1.0027160915786044\n",
      "iteration - 2587 -> loss: 0.0003554130311549844, self.slope: [1.03163702 1.03180064], self.intercept: 1.00271706284344\n",
      "iteration - 2588 -> loss: 0.0003553883990946614, self.slope: [1.03164806 1.03181176], self.intercept: 1.0027180340540345\n",
      "iteration - 2589 -> loss: 0.0003553637705642457, self.slope: [1.03165909 1.03182287], self.intercept: 1.002719005210392\n",
      "iteration - 2590 -> loss: 0.0003553391455629688, self.slope: [1.03167013 1.03183398], self.intercept: 1.0027199763125223\n",
      "iteration - 2591 -> loss: 0.0003553145240900815, self.slope: [1.03168116 1.0318451 ], self.intercept: 1.0027209473604315\n",
      "iteration - 2592 -> loss: 0.00035528990614480205, self.slope: [1.0316922  1.03185621], self.intercept: 1.0027219183541254\n",
      "iteration - 2593 -> loss: 0.00035526529172635505, self.slope: [1.03170323 1.03186732], self.intercept: 1.0027228892936098\n",
      "iteration - 2594 -> loss: 0.0003552406808339836, self.slope: [1.03171427 1.03187843], self.intercept: 1.002723860178893\n",
      "iteration - 2595 -> loss: 0.00035521607346691457, self.slope: [1.0317253  1.03188954], self.intercept: 1.0027248310099812\n",
      "iteration - 2596 -> loss: 0.00035519146962438027, self.slope: [1.03173633 1.03190064], self.intercept: 1.002725801786881\n",
      "iteration - 2597 -> loss: 0.0003551668693056007, self.slope: [1.03174736 1.03191175], self.intercept: 1.0027267725095985\n",
      "iteration - 2598 -> loss: 0.00035514227250982403, self.slope: [1.03175839 1.03192286], self.intercept: 1.002727743178141\n",
      "iteration - 2599 -> loss: 0.00035511767923628436, self.slope: [1.03176942 1.03193396], self.intercept: 1.0027287137925136\n",
      "iteration - 2600 -> loss: 0.00035509308948420955, self.slope: [1.03178045 1.03194507], self.intercept: 1.002729684352725\n",
      "iteration - 2601 -> loss: 0.0003550685032528459, self.slope: [1.03179147 1.03195617], self.intercept: 1.0027306548587815\n",
      "iteration - 2602 -> loss: 0.0003550439205414039, self.slope: [1.0318025  1.03196728], self.intercept: 1.002731625310688\n",
      "iteration - 2603 -> loss: 0.00035501934134913866, self.slope: [1.03181352 1.03197838], self.intercept: 1.0027325957084516\n",
      "iteration - 2604 -> loss: 0.0003549947656752508, self.slope: [1.03182455 1.03198948], self.intercept: 1.0027335660520815\n",
      "iteration - 2605 -> loss: 0.00035497019351901984, self.slope: [1.03183557 1.03200058], self.intercept: 1.002734536341581\n",
      "iteration - 2606 -> loss: 0.0003549456248796519, self.slope: [1.0318466  1.03201168], self.intercept: 1.002735506576958\n",
      "iteration - 2607 -> loss: 0.00035492105975639776, self.slope: [1.03185762 1.03202278], self.intercept: 1.0027364767582194\n",
      "iteration - 2608 -> loss: 0.000354896498148477, self.slope: [1.03186864 1.03203388], self.intercept: 1.0027374468853718\n",
      "iteration - 2609 -> loss: 0.0003548719400551376, self.slope: [1.03187966 1.03204498], self.intercept: 1.0027384169584213\n",
      "iteration - 2610 -> loss: 0.00035484738547558877, self.slope: [1.03189068 1.03205608], self.intercept: 1.0027393869773742\n",
      "iteration - 2611 -> loss: 0.0003548228344091061, self.slope: [1.0319017  1.03206717], self.intercept: 1.0027403569422388\n",
      "iteration - 2612 -> loss: 0.00035479828685490303, self.slope: [1.03191272 1.03207827], self.intercept: 1.0027413268530188\n",
      "iteration - 2613 -> loss: 0.00035477374281220504, self.slope: [1.03192374 1.03208936], self.intercept: 1.0027422967097233\n",
      "iteration - 2614 -> loss: 0.0003547492022802813, self.slope: [1.03193475 1.03210046], self.intercept: 1.0027432665123581\n",
      "iteration - 2615 -> loss: 0.00035472466525834386, self.slope: [1.03194577 1.03211155], self.intercept: 1.0027442362609298\n",
      "iteration - 2616 -> loss: 0.00035470013174562656, self.slope: [1.03195679 1.03212264], self.intercept: 1.002745205955445\n",
      "iteration - 2617 -> loss: 0.0003546756017413769, self.slope: [1.0319678  1.03213373], self.intercept: 1.0027461755959093\n",
      "iteration - 2618 -> loss: 0.00035465107524483086, self.slope: [1.03197881 1.03214482], self.intercept: 1.0027471451823309\n",
      "iteration - 2619 -> loss: 0.00035462655225521685, self.slope: [1.03198983 1.03215591], self.intercept: 1.0027481147147166\n",
      "iteration - 2620 -> loss: 0.0003546020327717937, self.slope: [1.03200084 1.032167  ], self.intercept: 1.0027490841930697\n",
      "iteration - 2621 -> loss: 0.00035457751679377614, self.slope: [1.03201185 1.03217809], self.intercept: 1.0027500536174005\n",
      "iteration - 2622 -> loss: 0.00035455300432041844, self.slope: [1.03202286 1.03218918], self.intercept: 1.002751022987715\n",
      "iteration - 2623 -> loss: 0.0003545284953509599, self.slope: [1.03203387 1.03220027], self.intercept: 1.0027519923040191\n",
      "iteration - 2624 -> loss: 0.00035450398988460337, self.slope: [1.03204488 1.03221135], self.intercept: 1.0027529615663178\n",
      "iteration - 2625 -> loss: 0.00035447948792064203, self.slope: [1.03205589 1.03222244], self.intercept: 1.0027539307746205\n",
      "iteration - 2626 -> loss: 0.00035445498945828183, self.slope: [1.0320669  1.03223352], self.intercept: 1.0027548999289315\n",
      "iteration - 2627 -> loss: 0.0003544304944967661, self.slope: [1.0320779 1.0322446], self.intercept: 1.002755869029258\n",
      "iteration - 2628 -> loss: 0.00035440600303534236, self.slope: [1.03208891 1.03225569], self.intercept: 1.002756838075609\n",
      "iteration - 2629 -> loss: 0.00035438151507323566, self.slope: [1.03209991 1.03226677], self.intercept: 1.002757807067988\n",
      "iteration - 2630 -> loss: 0.000354357030609707, self.slope: [1.03211092 1.03227785], self.intercept: 1.0027587760064034\n",
      "iteration - 2631 -> loss: 0.0003543325496439799, self.slope: [1.03212192 1.03228893], self.intercept: 1.0027597448908607\n",
      "iteration - 2632 -> loss: 0.0003543080721752911, self.slope: [1.03213292 1.03230001], self.intercept: 1.0027607137213657\n",
      "iteration - 2633 -> loss: 0.0003542835982028996, self.slope: [1.03214392 1.03231109], self.intercept: 1.0027616824979275\n",
      "iteration - 2634 -> loss: 0.0003542591277260399, self.slope: [1.03215493 1.03232217], self.intercept: 1.002762651220551\n",
      "iteration - 2635 -> loss: 0.0003542346607439523, self.slope: [1.03216593 1.03233325], self.intercept: 1.002763619889242\n",
      "iteration - 2636 -> loss: 0.00035421019725586007, self.slope: [1.03217693 1.03234432], self.intercept: 1.0027645885040075\n",
      "iteration - 2637 -> loss: 0.00035418573726103437, self.slope: [1.03218792 1.0323554 ], self.intercept: 1.002765557064857\n",
      "iteration - 2638 -> loss: 0.0003541612807586944, self.slope: [1.03219892 1.03236647], self.intercept: 1.002766525571793\n",
      "iteration - 2639 -> loss: 0.0003541368277480902, self.slope: [1.03220992 1.03237755], self.intercept: 1.002767494024824\n",
      "iteration - 2640 -> loss: 0.0003541123782284621, self.slope: [1.03222091 1.03238862], self.intercept: 1.0027684624239561\n",
      "iteration - 2641 -> loss: 0.0003540879321990419, self.slope: [1.03223191 1.03239969], self.intercept: 1.0027694307691963\n",
      "iteration - 2642 -> loss: 0.0003540634896591191, self.slope: [1.0322429  1.03241077], self.intercept: 1.0027703990605505\n",
      "iteration - 2643 -> loss: 0.00035403905060787927, self.slope: [1.0322539  1.03242184], self.intercept: 1.002771367298026\n",
      "iteration - 2644 -> loss: 0.0003540146150445893, self.slope: [1.03226489 1.03243291], self.intercept: 1.0027723354816287\n",
      "iteration - 2645 -> loss: 0.00035399018296848996, self.slope: [1.03227588 1.03244398], self.intercept: 1.002773303611366\n",
      "iteration - 2646 -> loss: 0.00035396575437883965, self.slope: [1.03228688 1.03245505], self.intercept: 1.002774271687243\n",
      "iteration - 2647 -> loss: 0.0003539413292748549, self.slope: [1.03229787 1.03246611], self.intercept: 1.002775239709267\n",
      "iteration - 2648 -> loss: 0.00035391690765579164, self.slope: [1.03230886 1.03247718], self.intercept: 1.0027762076774442\n",
      "iteration - 2649 -> loss: 0.000353892489520894, self.slope: [1.03231985 1.03248825], self.intercept: 1.002777175591783\n",
      "iteration - 2650 -> loss: 0.00035386807486940475, self.slope: [1.03233083 1.03249931], self.intercept: 1.0027781434522884\n",
      "iteration - 2651 -> loss: 0.00035384366370059026, self.slope: [1.03234182 1.03251038], self.intercept: 1.0027791112589683\n",
      "iteration - 2652 -> loss: 0.00035381925601366346, self.slope: [1.03235281 1.03252144], self.intercept: 1.0027800790118273\n",
      "iteration - 2653 -> loss: 0.0003537948518078831, self.slope: [1.03236379 1.0325325 ], self.intercept: 1.0027810467108726\n",
      "iteration - 2654 -> loss: 0.00035377045108249357, self.slope: [1.03237478 1.03254357], self.intercept: 1.0027820143561106\n",
      "iteration - 2655 -> loss: 0.0003537460538367463, self.slope: [1.03238576 1.03255463], self.intercept: 1.002782981947549\n",
      "iteration - 2656 -> loss: 0.0003537216600698547, self.slope: [1.03239675 1.03256569], self.intercept: 1.0027839494851942\n",
      "iteration - 2657 -> loss: 0.0003536972697811233, self.slope: [1.03240773 1.03257675], self.intercept: 1.0027849169690508\n",
      "iteration - 2658 -> loss: 0.00035367288296974574, self.slope: [1.03241871 1.03258781], self.intercept: 1.002785884399127\n",
      "iteration - 2659 -> loss: 0.0003536484996350075, self.slope: [1.03242969 1.03259887], self.intercept: 1.0027868517754295\n",
      "iteration - 2660 -> loss: 0.00035362411977612107, self.slope: [1.03244067 1.03260993], self.intercept: 1.0027878190979629\n",
      "iteration - 2661 -> loss: 0.00035359974339234975, self.slope: [1.03245165 1.03262098], self.intercept: 1.002788786366736\n",
      "iteration - 2662 -> loss: 0.00035357537048294615, self.slope: [1.03246263 1.03263204], self.intercept: 1.002789753581754\n",
      "iteration - 2663 -> loss: 0.00035355100104713917, self.slope: [1.03247361 1.03264309], self.intercept: 1.0027907207430231\n",
      "iteration - 2664 -> loss: 0.0003535266350841869, self.slope: [1.03248459 1.03265415], self.intercept: 1.00279168785055\n",
      "iteration - 2665 -> loss: 0.0003535022725933387, self.slope: [1.03249556 1.0326652 ], self.intercept: 1.0027926549043438\n",
      "iteration - 2666 -> loss: 0.00035347791357385366, self.slope: [1.03250654 1.03267626], self.intercept: 1.002793621904408\n",
      "iteration - 2667 -> loss: 0.00035345355802494227, self.slope: [1.03251751 1.03268731], self.intercept: 1.0027945888507512\n",
      "iteration - 2668 -> loss: 0.00035342920594590475, self.slope: [1.03252849 1.03269836], self.intercept: 1.002795555743378\n",
      "iteration - 2669 -> loss: 0.0003534048573359482, self.slope: [1.03253946 1.03270941], self.intercept: 1.002796522582297\n",
      "iteration - 2670 -> loss: 0.0003533805121943304, self.slope: [1.03255043 1.03272046], self.intercept: 1.0027974893675122\n",
      "iteration - 2671 -> loss: 0.000353356170520319, self.slope: [1.03256141 1.03273151], self.intercept: 1.0027984560990313\n",
      "iteration - 2672 -> loss: 0.0003533318323131422, self.slope: [1.03257238 1.03274256], self.intercept: 1.0027994227768613\n",
      "iteration - 2673 -> loss: 0.0003533074975720546, self.slope: [1.03258335 1.03275361], self.intercept: 1.002800389401008\n",
      "iteration - 2674 -> loss: 0.00035328316629630276, self.slope: [1.03259432 1.03276465], self.intercept: 1.0028013559714795\n",
      "iteration - 2675 -> loss: 0.00035325883848514504, self.slope: [1.03260529 1.0327757 ], self.intercept: 1.002802322488281\n",
      "iteration - 2676 -> loss: 0.0003532345141378413, self.slope: [1.03261625 1.03278674], self.intercept: 1.0028032889514193\n",
      "iteration - 2677 -> loss: 0.00035321019325362823, self.slope: [1.03262722 1.03279779], self.intercept: 1.0028042553609022\n",
      "iteration - 2678 -> loss: 0.0003531858758317463, self.slope: [1.03263819 1.03280883], self.intercept: 1.002805221716733\n",
      "iteration - 2679 -> loss: 0.00035316156187144987, self.slope: [1.03264915 1.03281988], self.intercept: 1.0028061880189203\n",
      "iteration - 2680 -> loss: 0.00035313725137200465, self.slope: [1.03266012 1.03283092], self.intercept: 1.0028071542674701\n",
      "iteration - 2681 -> loss: 0.0003531129443326418, self.slope: [1.03267108 1.03284196], self.intercept: 1.002808120462389\n",
      "iteration - 2682 -> loss: 0.0003530886407526509, self.slope: [1.03268204 1.032853  ], self.intercept: 1.0028090866036834\n",
      "iteration - 2683 -> loss: 0.00035306434063123697, self.slope: [1.03269301 1.03286404], self.intercept: 1.0028100526913604\n",
      "iteration - 2684 -> loss: 0.00035304004396766745, self.slope: [1.03270397 1.03287508], self.intercept: 1.0028110187254275\n",
      "iteration - 2685 -> loss: 0.00035301575076120975, self.slope: [1.03271493 1.03288612], self.intercept: 1.0028119847058887\n",
      "iteration - 2686 -> loss: 0.00035299146101111636, self.slope: [1.03272589 1.03289715], self.intercept: 1.0028129506327526\n",
      "iteration - 2687 -> loss: 0.00035296717471660797, self.slope: [1.03273685 1.03290819], self.intercept: 1.0028139165060246\n",
      "iteration - 2688 -> loss: 0.00035294289187695377, self.slope: [1.03274781 1.03291923], self.intercept: 1.002814882325711\n",
      "iteration - 2689 -> loss: 0.0003529186124914337, self.slope: [1.03275876 1.03293026], self.intercept: 1.0028158480918188\n",
      "iteration - 2690 -> loss: 0.00035289433655925716, self.slope: [1.03276972 1.0329413 ], self.intercept: 1.002816813804354\n",
      "iteration - 2691 -> loss: 0.0003528700640796995, self.slope: [1.03278068 1.03295233], self.intercept: 1.0028177794633246\n",
      "iteration - 2692 -> loss: 0.00035284579505202586, self.slope: [1.03279163 1.03296336], self.intercept: 1.0028187450687351\n",
      "iteration - 2693 -> loss: 0.0003528215294754798, self.slope: [1.03280259 1.0329744 ], self.intercept: 1.0028197106205938\n",
      "iteration - 2694 -> loss: 0.0003527972673492919, self.slope: [1.03281354 1.03298543], self.intercept: 1.0028206761189051\n",
      "iteration - 2695 -> loss: 0.00035277300867274646, self.slope: [1.03282449 1.03299646], self.intercept: 1.0028216415636775\n",
      "iteration - 2696 -> loss: 0.00035274875344508703, self.slope: [1.03283544 1.03300749], self.intercept: 1.0028226069549164\n",
      "iteration - 2697 -> loss: 0.00035272450166556364, self.slope: [1.0328464  1.03301852], self.intercept: 1.002823572292628\n",
      "iteration - 2698 -> loss: 0.00035270025333344543, self.slope: [1.03285735 1.03302954], self.intercept: 1.0028245375768194\n",
      "iteration - 2699 -> loss: 0.0003526760084479825, self.slope: [1.0328683  1.03304057], self.intercept: 1.0028255028074966\n",
      "iteration - 2700 -> loss: 0.0003526517670084175, self.slope: [1.03287924 1.0330516 ], self.intercept: 1.0028264679846657\n",
      "iteration - 2701 -> loss: 0.0003526275290140159, self.slope: [1.03289019 1.03306262], self.intercept: 1.002827433108336\n",
      "iteration - 2702 -> loss: 0.0003526032944640302, self.slope: [1.03290114 1.03307365], self.intercept: 1.0028283981785115\n",
      "iteration - 2703 -> loss: 0.000352579063357716, self.slope: [1.03291209 1.03308467], self.intercept: 1.0028293631951988\n",
      "iteration - 2704 -> loss: 0.000352554835694348, self.slope: [1.03292303 1.0330957 ], self.intercept: 1.0028303281584041\n",
      "iteration - 2705 -> loss: 0.00035253061147314196, self.slope: [1.03293398 1.03310672], self.intercept: 1.0028312930681358\n",
      "iteration - 2706 -> loss: 0.00035250639069339754, self.slope: [1.03294492 1.03311774], self.intercept: 1.0028322579243987\n",
      "iteration - 2707 -> loss: 0.0003524821733543418, self.slope: [1.03295586 1.03312876], self.intercept: 1.002833222727199\n",
      "iteration - 2708 -> loss: 0.0003524579594552422, self.slope: [1.03296681 1.03313978], self.intercept: 1.0028341874765443\n",
      "iteration - 2709 -> loss: 0.00035243374899537444, self.slope: [1.03297775 1.0331508 ], self.intercept: 1.002835152172441\n",
      "iteration - 2710 -> loss: 0.00035240954197394725, self.slope: [1.03298869 1.03316182], self.intercept: 1.0028361168148943\n",
      "iteration - 2711 -> loss: 0.00035238533839027477, self.slope: [1.03299963 1.03317284], self.intercept: 1.0028370814039125\n",
      "iteration - 2712 -> loss: 0.00035236113824357147, self.slope: [1.03301057 1.03318386], self.intercept: 1.002838045939501\n",
      "iteration - 2713 -> loss: 0.00035233694153312666, self.slope: [1.03302151 1.03319487], self.intercept: 1.002839010421667\n",
      "iteration - 2714 -> loss: 0.00035231274825816644, self.slope: [1.03303245 1.03320589], self.intercept: 1.0028399748504155\n",
      "iteration - 2715 -> loss: 0.0003522885584179812, self.slope: [1.03304338 1.0332169 ], self.intercept: 1.0028409392257551\n",
      "iteration - 2716 -> loss: 0.0003522643720118106, self.slope: [1.03305432 1.03322792], self.intercept: 1.0028419035476903\n",
      "iteration - 2717 -> loss: 0.0003522401890389275, self.slope: [1.03306526 1.03323893], self.intercept: 1.0028428678162293\n",
      "iteration - 2718 -> loss: 0.0003522160094985618, self.slope: [1.03307619 1.03324994], self.intercept: 1.0028438320313768\n",
      "iteration - 2719 -> loss: 0.00035219183339000253, self.slope: [1.03308712 1.03326096], self.intercept: 1.00284479619314\n",
      "iteration - 2720 -> loss: 0.00035216766071250903, self.slope: [1.03309806 1.03327197], self.intercept: 1.0028457603015242\n",
      "iteration - 2721 -> loss: 0.0003521434914653236, self.slope: [1.03310899 1.03328298], self.intercept: 1.0028467243565389\n",
      "iteration - 2722 -> loss: 0.0003521193256477141, self.slope: [1.03311992 1.03329399], self.intercept: 1.0028476883581892\n",
      "iteration - 2723 -> loss: 0.000352095163258944, self.slope: [1.03313085 1.033305  ], self.intercept: 1.0028486523064801\n",
      "iteration - 2724 -> loss: 0.00035207100429827254, self.slope: [1.03314178 1.033316  ], self.intercept: 1.0028496162014182\n",
      "iteration - 2725 -> loss: 0.00035204684876495113, self.slope: [1.03315271 1.03332701], self.intercept: 1.0028505800430112\n",
      "iteration - 2726 -> loss: 0.0003520226966582551, self.slope: [1.03316364 1.03333802], self.intercept: 1.0028515438312666\n",
      "iteration - 2727 -> loss: 0.00035199854797743265, self.slope: [1.03317457 1.03334902], self.intercept: 1.0028525075661885\n",
      "iteration - 2728 -> loss: 0.0003519744027217606, self.slope: [1.0331855  1.03336003], self.intercept: 1.002853471247785\n",
      "iteration - 2729 -> loss: 0.00035195026089048274, self.slope: [1.03319642 1.03337103], self.intercept: 1.002854434876062\n",
      "iteration - 2730 -> loss: 0.0003519261224828719, self.slope: [1.03320735 1.03338204], self.intercept: 1.0028553984510258\n",
      "iteration - 2731 -> loss: 0.000351901987498188, self.slope: [1.03321827 1.03339304], self.intercept: 1.0028563619726816\n",
      "iteration - 2732 -> loss: 0.0003518778559356861, self.slope: [1.0332292  1.03340404], self.intercept: 1.0028573254410371\n",
      "iteration - 2733 -> loss: 0.00035185372779463793, self.slope: [1.03324012 1.03341504], self.intercept: 1.0028582888560988\n",
      "iteration - 2734 -> loss: 0.0003518296030742978, self.slope: [1.03325104 1.03342604], self.intercept: 1.0028592522178728\n",
      "iteration - 2735 -> loss: 0.00035180548177393494, self.slope: [1.03326196 1.03343704], self.intercept: 1.0028602155263664\n",
      "iteration - 2736 -> loss: 0.00035178136389282306, self.slope: [1.03327288 1.03344804], self.intercept: 1.0028611787815862\n",
      "iteration - 2737 -> loss: 0.00035175724943020334, self.slope: [1.0332838  1.03345904], self.intercept: 1.0028621419835375\n",
      "iteration - 2738 -> loss: 0.0003517331383853656, self.slope: [1.03329472 1.03347003], self.intercept: 1.0028631051322272\n",
      "iteration - 2739 -> loss: 0.0003517090307575185, self.slope: [1.03330564 1.03348103], self.intercept: 1.0028640682276604\n",
      "iteration - 2740 -> loss: 0.0003516849265459849, self.slope: [1.03331656 1.03349203], self.intercept: 1.0028650312698464\n",
      "iteration - 2741 -> loss: 0.00035166082575000776, self.slope: [1.03332747 1.03350302], self.intercept: 1.0028659942587876\n",
      "iteration - 2742 -> loss: 0.0003516367283688525, self.slope: [1.03333839 1.03351402], self.intercept: 1.0028669571944948\n",
      "iteration - 2743 -> loss: 0.00035161263440177065, self.slope: [1.03334931 1.03352501], self.intercept: 1.002867920076973\n",
      "iteration - 2744 -> loss: 0.00035158854384805297, self.slope: [1.03336022 1.033536  ], self.intercept: 1.002868882906229\n",
      "iteration - 2745 -> loss: 0.0003515644567069525, self.slope: [1.03337113 1.03354699], self.intercept: 1.0028698456822671\n",
      "iteration - 2746 -> loss: 0.00035154037297773486, self.slope: [1.03338205 1.03355798], self.intercept: 1.0028708084050952\n",
      "iteration - 2747 -> loss: 0.0003515162926596412, self.slope: [1.03339296 1.03356897], self.intercept: 1.002871771074719\n",
      "iteration - 2748 -> loss: 0.00035149221575197197, self.slope: [1.03340387 1.03357996], self.intercept: 1.002872733691145\n",
      "iteration - 2749 -> loss: 0.00035146814225397375, self.slope: [1.03341478 1.03359095], self.intercept: 1.0028736962543816\n",
      "iteration - 2750 -> loss: 0.0003514440721649293, self.slope: [1.03342569 1.03360194], self.intercept: 1.0028746587644348\n",
      "iteration - 2751 -> loss: 0.00035142000548407724, self.slope: [1.0334366  1.03361293], self.intercept: 1.0028756212213084\n",
      "iteration - 2752 -> loss: 0.0003513959422107145, self.slope: [1.03344751 1.03362391], self.intercept: 1.0028765836250106\n",
      "iteration - 2753 -> loss: 0.00035137188234408626, self.slope: [1.03345842 1.0336349 ], self.intercept: 1.0028775459755477\n",
      "iteration - 2754 -> loss: 0.0003513478258834634, self.slope: [1.03346932 1.03364588], self.intercept: 1.0028785082729257\n",
      "iteration - 2755 -> loss: 0.0003513237728281273, self.slope: [1.03348023 1.03365687], self.intercept: 1.0028794705171518\n",
      "iteration - 2756 -> loss: 0.0003512997231773348, self.slope: [1.03349113 1.03366785], self.intercept: 1.002880432708231\n",
      "iteration - 2757 -> loss: 0.00035127567693032957, self.slope: [1.03350204 1.03367883], self.intercept: 1.002881394846171\n",
      "iteration - 2758 -> loss: 0.00035125163408642065, self.slope: [1.03351294 1.03368981], self.intercept: 1.0028823569309786\n",
      "iteration - 2759 -> loss: 0.00035122759464485047, self.slope: [1.03352384 1.0337008 ], self.intercept: 1.0028833189626591\n",
      "iteration - 2760 -> loss: 0.0003512035586048903, self.slope: [1.03353475 1.03371178], self.intercept: 1.0028842809412204\n",
      "iteration - 2761 -> loss: 0.0003511795259658205, self.slope: [1.03354565 1.03372276], self.intercept: 1.002885242866668\n",
      "iteration - 2762 -> loss: 0.00035115549672690323, self.slope: [1.03355655 1.03373373], self.intercept: 1.0028862047390061\n",
      "iteration - 2763 -> loss: 0.00035113147088740006, self.slope: [1.03356745 1.03374471], self.intercept: 1.0028871665582446\n",
      "iteration - 2764 -> loss: 0.0003511074484465899, self.slope: [1.03357835 1.03375569], self.intercept: 1.0028881283243891\n",
      "iteration - 2765 -> loss: 0.00035108342940372175, self.slope: [1.03358924 1.03376667], self.intercept: 1.0028890900374443\n",
      "iteration - 2766 -> loss: 0.0003510594137580919, self.slope: [1.03360014 1.03377764], self.intercept: 1.0028900516974166\n",
      "iteration - 2767 -> loss: 0.00035103540150895486, self.slope: [1.03361104 1.03378862], self.intercept: 1.0028910133043158\n",
      "iteration - 2768 -> loss: 0.0003510113926555847, self.slope: [1.03362193 1.03379959], self.intercept: 1.0028919748581455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 2769 -> loss: 0.0003509873871972443, self.slope: [1.03363283 1.03381056], self.intercept: 1.0028929363589125\n",
      "iteration - 2770 -> loss: 0.0003509633851332229, self.slope: [1.03364372 1.03382154], self.intercept: 1.002893897806622\n",
      "iteration - 2771 -> loss: 0.0003509393864627596, self.slope: [1.03365462 1.03383251], self.intercept: 1.0028948592012836\n",
      "iteration - 2772 -> loss: 0.00035091539118516085, self.slope: [1.03366551 1.03384348], self.intercept: 1.0028958205429008\n",
      "iteration - 2773 -> loss: 0.00035089139929967155, self.slope: [1.0336764  1.03385445], self.intercept: 1.0028967818314811\n",
      "iteration - 2774 -> loss: 0.0003508674108055711, self.slope: [1.03368729 1.03386542], self.intercept: 1.0028977430670305\n",
      "iteration - 2775 -> loss: 0.0003508434257021335, self.slope: [1.03369818 1.03387639], self.intercept: 1.002898704249557\n",
      "iteration - 2776 -> loss: 0.0003508194439886286, self.slope: [1.03370907 1.03388735], self.intercept: 1.0028996653790658\n",
      "iteration - 2777 -> loss: 0.00035079546566431493, self.slope: [1.03371996 1.03389832], self.intercept: 1.0029006264555624\n",
      "iteration - 2778 -> loss: 0.00035077149072849207, self.slope: [1.03373085 1.03390929], self.intercept: 1.0029015874790548\n",
      "iteration - 2779 -> loss: 0.00035074751918039664, self.slope: [1.03374174 1.03392025], self.intercept: 1.0029025484495488\n",
      "iteration - 2780 -> loss: 0.0003507235510193456, self.slope: [1.03375262 1.03393122], self.intercept: 1.0029035093670504\n",
      "iteration - 2781 -> loss: 0.0003506995862445656, self.slope: [1.03376351 1.03394218], self.intercept: 1.0029044702315675\n",
      "iteration - 2782 -> loss: 0.0003506756248553539, self.slope: [1.03377439 1.03395314], self.intercept: 1.0029054310431036\n",
      "iteration - 2783 -> loss: 0.00035065166685099055, self.slope: [1.03378528 1.03396411], self.intercept: 1.0029063918016672\n",
      "iteration - 2784 -> loss: 0.0003506277122307314, self.slope: [1.03379616 1.03397507], self.intercept: 1.0029073525072634\n",
      "iteration - 2785 -> loss: 0.00035060376099385745, self.slope: [1.03380704 1.03398603], self.intercept: 1.0029083131599006\n",
      "iteration - 2786 -> loss: 0.00035057981313962975, self.slope: [1.03381792 1.03399699], self.intercept: 1.0029092737595828\n",
      "iteration - 2787 -> loss: 0.000350555868667342, self.slope: [1.03382881 1.03400795], self.intercept: 1.0029102343063176\n",
      "iteration - 2788 -> loss: 0.000350531927576266, self.slope: [1.03383969 1.03401891], self.intercept: 1.0029111948001108\n",
      "iteration - 2789 -> loss: 0.0003505079898656608, self.slope: [1.03385057 1.03402987], self.intercept: 1.0029121552409697\n",
      "iteration - 2790 -> loss: 0.00035048405553480356, self.slope: [1.03386144 1.03404082], self.intercept: 1.0029131156288993\n",
      "iteration - 2791 -> loss: 0.0003504601245829807, self.slope: [1.03387232 1.03405178], self.intercept: 1.0029140759639086\n",
      "iteration - 2792 -> loss: 0.0003504361970094651, self.slope: [1.0338832  1.03406273], self.intercept: 1.0029150362460022\n",
      "iteration - 2793 -> loss: 0.00035041227281352565, self.slope: [1.03389408 1.03407369], self.intercept: 1.0029159964751855\n",
      "iteration - 2794 -> loss: 0.00035038835199444377, self.slope: [1.03390495 1.03408464], self.intercept: 1.002916956651467\n",
      "iteration - 2795 -> loss: 0.00035036443455147844, self.slope: [1.03391583 1.0340956 ], self.intercept: 1.0029179167748514\n",
      "iteration - 2796 -> loss: 0.0003503405204839192, self.slope: [1.0339267  1.03410655], self.intercept: 1.0029188768453456\n",
      "iteration - 2797 -> loss: 0.00035031660979105347, self.slope: [1.03393757 1.0341175 ], self.intercept: 1.0029198368629564\n",
      "iteration - 2798 -> loss: 0.00035029270247213524, self.slope: [1.03394845 1.03412845], self.intercept: 1.0029207968276899\n",
      "iteration - 2799 -> loss: 0.00035026879852644347, self.slope: [1.03395932 1.0341394 ], self.intercept: 1.0029217567395523\n",
      "iteration - 2800 -> loss: 0.0003502448979532772, self.slope: [1.03397019 1.03415035], self.intercept: 1.00292271659855\n",
      "iteration - 2801 -> loss: 0.0003502210007518881, self.slope: [1.03398106 1.0341613 ], self.intercept: 1.0029236764046894\n",
      "iteration - 2802 -> loss: 0.0003501971069215507, self.slope: [1.03399193 1.03417225], self.intercept: 1.0029246361579773\n",
      "iteration - 2803 -> loss: 0.0003501732164615506, self.slope: [1.0340028 1.0341832], self.intercept: 1.0029255958584193\n",
      "iteration - 2804 -> loss: 0.00035014932937118924, self.slope: [1.03401366 1.03419414], self.intercept: 1.002926555506023\n",
      "iteration - 2805 -> loss: 0.0003501254456497215, self.slope: [1.03402453 1.03420509], self.intercept: 1.0029275151007935\n",
      "iteration - 2806 -> loss: 0.0003501015652963953, self.slope: [1.0340354  1.03421603], self.intercept: 1.0029284746427378\n",
      "iteration - 2807 -> loss: 0.00035007768831054985, self.slope: [1.03404626 1.03422698], self.intercept: 1.002929434131862\n",
      "iteration - 2808 -> loss: 0.00035005381469142274, self.slope: [1.03405713 1.03423792], self.intercept: 1.0029303935681733\n",
      "iteration - 2809 -> loss: 0.0003500299444383147, self.slope: [1.03406799 1.03424886], self.intercept: 1.0029313529516768\n",
      "iteration - 2810 -> loss: 0.00035000607755047026, self.slope: [1.03407886 1.0342598 ], self.intercept: 1.0029323122823781\n",
      "iteration - 2811 -> loss: 0.0003499822140271939, self.slope: [1.03408972 1.03427074], self.intercept: 1.0029332715602852\n",
      "iteration - 2812 -> loss: 0.00034995835386777074, self.slope: [1.03410058 1.03428168], self.intercept: 1.0029342307854048\n",
      "iteration - 2813 -> loss: 0.0003499344970714595, self.slope: [1.03411144 1.03429262], self.intercept: 1.0029351899577423\n",
      "iteration - 2814 -> loss: 0.0003499106436375553, self.slope: [1.0341223  1.03430356], self.intercept: 1.0029361490773032\n",
      "iteration - 2815 -> loss: 0.00034988679356532466, self.slope: [1.03413316 1.0343145 ], self.intercept: 1.0029371081440948\n",
      "iteration - 2816 -> loss: 0.00034986294685407127, self.slope: [1.03414402 1.03432544], self.intercept: 1.0029380671581236\n",
      "iteration - 2817 -> loss: 0.00034983910350303113, self.slope: [1.03415488 1.03433637], self.intercept: 1.0029390261193964\n",
      "iteration - 2818 -> loss: 0.0003498152635115242, self.slope: [1.03416573 1.03434731], self.intercept: 1.0029399850279186\n",
      "iteration - 2819 -> loss: 0.0003497914268788251, self.slope: [1.03417659 1.03435824], self.intercept: 1.0029409438836958\n",
      "iteration - 2820 -> loss: 0.0003497675936042202, self.slope: [1.03418745 1.03436918], self.intercept: 1.0029419026867366\n",
      "iteration - 2821 -> loss: 0.0003497437636869347, self.slope: [1.0341983  1.03438011], self.intercept: 1.0029428614370455\n",
      "iteration - 2822 -> loss: 0.00034971993712633944, self.slope: [1.03420915 1.03439104], self.intercept: 1.0029438201346312\n",
      "iteration - 2823 -> loss: 0.00034969611392165513, self.slope: [1.03422001 1.03440198], self.intercept: 1.0029447787794972\n",
      "iteration - 2824 -> loss: 0.00034967229407216694, self.slope: [1.03423086 1.03441291], self.intercept: 1.002945737371651\n",
      "iteration - 2825 -> loss: 0.00034964847757717283, self.slope: [1.03424171 1.03442384], self.intercept: 1.0029466959111009\n",
      "iteration - 2826 -> loss: 0.00034962466443594494, self.slope: [1.03425256 1.03443477], self.intercept: 1.0029476543978497\n",
      "iteration - 2827 -> loss: 0.00034960085464777176, self.slope: [1.03426341 1.0344457 ], self.intercept: 1.002948612831906\n",
      "iteration - 2828 -> loss: 0.0003495770482119364, self.slope: [1.03427426 1.03445662], self.intercept: 1.0029495712132752\n",
      "iteration - 2829 -> loss: 0.0003495532451277144, self.slope: [1.03428511 1.03446755], self.intercept: 1.0029505295419647\n",
      "iteration - 2830 -> loss: 0.0003495294453944039, self.slope: [1.03429596 1.03447848], self.intercept: 1.0029514878179802\n",
      "iteration - 2831 -> loss: 0.00034950564901125886, self.slope: [1.0343068 1.0344894], self.intercept: 1.0029524460413275\n",
      "iteration - 2832 -> loss: 0.00034948185597758765, self.slope: [1.03431765 1.03450033], self.intercept: 1.0029534042120132\n",
      "iteration - 2833 -> loss: 0.00034945806629266675, self.slope: [1.0343285  1.03451125], self.intercept: 1.0029543623300432\n",
      "iteration - 2834 -> loss: 0.0003494342799557735, self.slope: [1.03433934 1.03452218], self.intercept: 1.0029553203954238\n",
      "iteration - 2835 -> loss: 0.00034941049696621344, self.slope: [1.03435018 1.0345331 ], self.intercept: 1.0029562784081634\n",
      "iteration - 2836 -> loss: 0.0003493867173232346, self.slope: [1.03436103 1.03454402], self.intercept: 1.0029572363682662\n",
      "iteration - 2837 -> loss: 0.00034936294102613395, self.slope: [1.03437187 1.03455494], self.intercept: 1.0029581942757393\n",
      "iteration - 2838 -> loss: 0.0003493391680742107, self.slope: [1.03438271 1.03456586], self.intercept: 1.0029591521305892\n",
      "iteration - 2839 -> loss: 0.0003493153984667453, self.slope: [1.03439355 1.03457678], self.intercept: 1.0029601099328223\n",
      "iteration - 2840 -> loss: 0.0003492916322030132, self.slope: [1.03440439 1.0345877 ], self.intercept: 1.0029610676824434\n",
      "iteration - 2841 -> loss: 0.00034926786928230353, self.slope: [1.03441523 1.03459862], self.intercept: 1.0029620253794604\n",
      "iteration - 2842 -> loss: 0.00034924410970390917, self.slope: [1.03442607 1.03460954], self.intercept: 1.0029629830238782\n",
      "iteration - 2843 -> loss: 0.0003492203534670934, self.slope: [1.03443691 1.03462045], self.intercept: 1.0029639406157052\n",
      "iteration - 2844 -> loss: 0.00034919660057117224, self.slope: [1.03444775 1.03463137], self.intercept: 1.0029648981549457\n",
      "iteration - 2845 -> loss: 0.0003491728510154092, self.slope: [1.03445858 1.03464228], self.intercept: 1.0029658556416072\n",
      "iteration - 2846 -> loss: 0.00034914910479909094, self.slope: [1.03446942 1.0346532 ], self.intercept: 1.0029668130756948\n",
      "iteration - 2847 -> loss: 0.0003491253619215063, self.slope: [1.03448025 1.03466411], self.intercept: 1.0029677704572173\n",
      "iteration - 2848 -> loss: 0.0003491016223819659, self.slope: [1.03449109 1.03467502], self.intercept: 1.0029687277861772\n",
      "iteration - 2849 -> loss: 0.00034907788617971895, self.slope: [1.03450192 1.03468594], self.intercept: 1.002969685062585\n",
      "iteration - 2850 -> loss: 0.0003490541533140751, self.slope: [1.03451275 1.03469685], self.intercept: 1.0029706422864453\n",
      "iteration - 2851 -> loss: 0.00034903042378430323, self.slope: [1.03452358 1.03470776], self.intercept: 1.002971599457763\n",
      "iteration - 2852 -> loss: 0.00034900669758972005, self.slope: [1.03453441 1.03471867], self.intercept: 1.002972556576546\n",
      "iteration - 2853 -> loss: 0.00034898297472956834, self.slope: [1.03454524 1.03472958], self.intercept: 1.0029735136428015\n",
      "iteration - 2854 -> loss: 0.00034895925520319644, self.slope: [1.03455607 1.03474048], self.intercept: 1.0029744706565324\n",
      "iteration - 2855 -> loss: 0.0003489355390098362, self.slope: [1.0345669  1.03475139], self.intercept: 1.002975427617748\n",
      "iteration - 2856 -> loss: 0.00034891182614880565, self.slope: [1.03457773 1.0347623 ], self.intercept: 1.0029763845264537\n",
      "iteration - 2857 -> loss: 0.0003488881166193759, self.slope: [1.03458856 1.0347732 ], self.intercept: 1.0029773413826548\n",
      "iteration - 2858 -> loss: 0.00034886441042084775, self.slope: [1.03459938 1.03478411], self.intercept: 1.0029782981863606\n",
      "iteration - 2859 -> loss: 0.0003488407075525147, self.slope: [1.03461021 1.03479501], self.intercept: 1.0029792549375738\n",
      "iteration - 2860 -> loss: 0.00034881700801363394, self.slope: [1.03462103 1.03480592], self.intercept: 1.0029802116363027\n",
      "iteration - 2861 -> loss: 0.0003487933118035522, self.slope: [1.03463186 1.03481682], self.intercept: 1.0029811682825536\n",
      "iteration - 2862 -> loss: 0.0003487696189215192, self.slope: [1.03464268 1.03482772], self.intercept: 1.002982124876331\n",
      "iteration - 2863 -> loss: 0.0003487459293668147, self.slope: [1.0346535  1.03483862], self.intercept: 1.002983081417644\n",
      "iteration - 2864 -> loss: 0.00034872224313875364, self.slope: [1.03466432 1.03484952], self.intercept: 1.0029840379064983\n",
      "iteration - 2865 -> loss: 0.0003486985602366103, self.slope: [1.03467514 1.03486042], self.intercept: 1.0029849943428975\n",
      "iteration - 2866 -> loss: 0.00034867488065967343, self.slope: [1.03468596 1.03487132], self.intercept: 1.0029859507268504\n",
      "iteration - 2867 -> loss: 0.0003486512044072529, self.slope: [1.03469678 1.03488222], self.intercept: 1.002986907058363\n",
      "iteration - 2868 -> loss: 0.00034862753147861026, self.slope: [1.0347076  1.03489312], self.intercept: 1.0029878633374396\n",
      "iteration - 2869 -> loss: 0.0003486038618730778, self.slope: [1.03471842 1.03490402], self.intercept: 1.00298881956409\n",
      "iteration - 2870 -> loss: 0.00034858019558989847, self.slope: [1.03472924 1.03491491], self.intercept: 1.002989775738317\n",
      "iteration - 2871 -> loss: 0.0003485565326283966, self.slope: [1.03474005 1.03492581], self.intercept: 1.002990731860129\n",
      "iteration - 2872 -> loss: 0.0003485328729878345, self.slope: [1.03475087 1.0349367 ], self.intercept: 1.0029916879295324\n",
      "iteration - 2873 -> loss: 0.00034850921666755103, self.slope: [1.03476168 1.0349476 ], self.intercept: 1.0029926439465322\n",
      "iteration - 2874 -> loss: 0.0003484855636667802, self.slope: [1.0347725  1.03495849], self.intercept: 1.0029935999111343\n",
      "iteration - 2875 -> loss: 0.00034846191398484814, self.slope: [1.03478331 1.03496938], self.intercept: 1.0029945558233466\n",
      "iteration - 2876 -> loss: 0.0003484382676210571, self.slope: [1.03479412 1.03498027], self.intercept: 1.0029955116831748\n",
      "iteration - 2877 -> loss: 0.00034841462457467216, self.slope: [1.03480493 1.03499116], self.intercept: 1.0029964674906247\n",
      "iteration - 2878 -> loss: 0.0003483909848450002, self.slope: [1.03481575 1.03500205], self.intercept: 1.002997423245704\n",
      "iteration - 2879 -> loss: 0.00034836734843133265, self.slope: [1.03482656 1.03501294], self.intercept: 1.0029983789484178\n",
      "iteration - 2880 -> loss: 0.0003483437153329553, self.slope: [1.03483737 1.03502383], self.intercept: 1.002999334598772\n",
      "iteration - 2881 -> loss: 0.00034832008554917836, self.slope: [1.03484817 1.03503472], self.intercept: 1.003000290196774\n",
      "iteration - 2882 -> loss: 0.00034829645907927557, self.slope: [1.03485898 1.03504561], self.intercept: 1.0030012457424282\n",
      "iteration - 2883 -> loss: 0.00034827283592253725, self.slope: [1.03486979 1.03505649], self.intercept: 1.0030022012357427\n",
      "iteration - 2884 -> loss: 0.0003482492160782856, self.slope: [1.0348806  1.03506738], self.intercept: 1.0030031566767246\n",
      "iteration - 2885 -> loss: 0.0003482255995457869, self.slope: [1.0348914  1.03507826], self.intercept: 1.003004112065379\n",
      "iteration - 2886 -> loss: 0.00034820198632434915, self.slope: [1.03490221 1.03508915], self.intercept: 1.0030050674017128\n",
      "iteration - 2887 -> loss: 0.00034817837641326876, self.slope: [1.03491301 1.03510003], self.intercept: 1.0030060226857291\n",
      "iteration - 2888 -> loss: 0.00034815476981183026, self.slope: [1.03492381 1.03511091], self.intercept: 1.0030069779174362\n",
      "iteration - 2889 -> loss: 0.0003481311665193278, self.slope: [1.03493462 1.03512179], self.intercept: 1.0030079330968404\n",
      "iteration - 2890 -> loss: 0.00034810756653506393, self.slope: [1.03494542 1.03513267], self.intercept: 1.00300888822395\n",
      "iteration - 2891 -> loss: 0.00034808396985832246, self.slope: [1.03495622 1.03514355], self.intercept: 1.0030098432987689\n",
      "iteration - 2892 -> loss: 0.0003480603764884215, self.slope: [1.03496702 1.03515443], self.intercept: 1.003010798321303\n",
      "iteration - 2893 -> loss: 0.0003480367864246324, self.slope: [1.03497782 1.03516531], self.intercept: 1.0030117532915606\n",
      "iteration - 2894 -> loss: 0.00034801319966626095, self.slope: [1.03498862 1.03517619], self.intercept: 1.0030127082095466\n",
      "iteration - 2895 -> loss: 0.0003479896162126097, self.slope: [1.03499941 1.03518707], self.intercept: 1.0030136630752666\n",
      "iteration - 2896 -> loss: 0.00034796603606295466, self.slope: [1.03501021 1.03519794], self.intercept: 1.0030146178887287\n",
      "iteration - 2897 -> loss: 0.00034794245921661337, self.slope: [1.03502101 1.03520882], self.intercept: 1.0030155726499383\n",
      "iteration - 2898 -> loss: 0.00034791888567287354, self.slope: [1.0350318  1.03521969], self.intercept: 1.0030165273589011\n",
      "iteration - 2899 -> loss: 0.000347895315431034, self.slope: [1.0350426  1.03523057], self.intercept: 1.0030174820156235\n",
      "iteration - 2900 -> loss: 0.00034787174849039724, self.slope: [1.03505339 1.03524144], self.intercept: 1.0030184366201123\n",
      "iteration - 2901 -> loss: 0.00034784818485025494, self.slope: [1.03506419 1.03525231], self.intercept: 1.0030193911723737\n",
      "iteration - 2902 -> loss: 0.0003478246245098925, self.slope: [1.03507498 1.03526318], self.intercept: 1.0030203456724134\n",
      "iteration - 2903 -> loss: 0.0003478010674686229, self.slope: [1.03508577 1.03527406], self.intercept: 1.003021300120239\n",
      "iteration - 2904 -> loss: 0.0003477775137257406, self.slope: [1.03509656 1.03528493], self.intercept: 1.0030222545158551\n",
      "iteration - 2905 -> loss: 0.0003477539632805428, self.slope: [1.03510735 1.0352958 ], self.intercept: 1.0030232088592683\n",
      "iteration - 2906 -> loss: 0.00034773041613231847, self.slope: [1.03511814 1.03530666], self.intercept: 1.0030241631504855\n",
      "iteration - 2907 -> loss: 0.00034770687228037833, self.slope: [1.03512893 1.03531753], self.intercept: 1.0030251173895124\n",
      "iteration - 2908 -> loss: 0.00034768333172402563, self.slope: [1.03513972 1.0353284 ], self.intercept: 1.003026071576356\n",
      "iteration - 2909 -> loss: 0.0003476597944625339, self.slope: [1.0351505  1.03533927], self.intercept: 1.0030270257110214\n",
      "iteration - 2910 -> loss: 0.00034763626049523613, self.slope: [1.03516129 1.03535013], self.intercept: 1.0030279797935164\n",
      "iteration - 2911 -> loss: 0.00034761272982140233, self.slope: [1.03517208 1.035361  ], self.intercept: 1.0030289338238467\n",
      "iteration - 2912 -> loss: 0.0003475892024403539, self.slope: [1.03518286 1.03537186], self.intercept: 1.0030298878020165\n",
      "iteration - 2913 -> loss: 0.0003475656783513659, self.slope: [1.03519365 1.03538272], self.intercept: 1.0030308417280338\n",
      "iteration - 2914 -> loss: 0.0003475421575537727, self.slope: [1.03520443 1.03539359], self.intercept: 1.0030317956019044\n",
      "iteration - 2915 -> loss: 0.0003475186400468353, self.slope: [1.03521521 1.03540445], self.intercept: 1.0030327494236349\n",
      "iteration - 2916 -> loss: 0.0003474951258298805, self.slope: [1.03522599 1.03541531], self.intercept: 1.0030337031932308\n",
      "iteration - 2917 -> loss: 0.000347471614902201, self.slope: [1.03523677 1.03542617], self.intercept: 1.0030346569106998\n",
      "iteration - 2918 -> loss: 0.00034744810726310084, self.slope: [1.03524756 1.03543703], self.intercept: 1.0030356105760476\n",
      "iteration - 2919 -> loss: 0.00034742460291185985, self.slope: [1.03525833 1.03544789], self.intercept: 1.0030365641892791\n",
      "iteration - 2920 -> loss: 0.00034740110184781453, self.slope: [1.03526911 1.03545875], self.intercept: 1.003037517750401\n",
      "iteration - 2921 -> loss: 0.0003473776040702385, self.slope: [1.03527989 1.03546961], self.intercept: 1.003038471259421\n",
      "iteration - 2922 -> loss: 0.0003473541095784491, self.slope: [1.03529067 1.03548046], self.intercept: 1.0030394247163452\n",
      "iteration - 2923 -> loss: 0.0003473306183717276, self.slope: [1.03530145 1.03549132], self.intercept: 1.0030403781211776\n",
      "iteration - 2924 -> loss: 0.00034730713044939964, self.slope: [1.03531222 1.03550217], self.intercept: 1.003041331473926\n",
      "iteration - 2925 -> loss: 0.0003472836458107648, self.slope: [1.035323   1.03551303], self.intercept: 1.0030422847745966\n",
      "iteration - 2926 -> loss: 0.0003472601644551121, self.slope: [1.03533377 1.03552388], self.intercept: 1.0030432380231957\n",
      "iteration - 2927 -> loss: 0.0003472366863817375, self.slope: [1.03534454 1.03553473], self.intercept: 1.0030441912197303\n",
      "iteration - 2928 -> loss: 0.00034721321158995224, self.slope: [1.03535532 1.03554559], self.intercept: 1.0030451443642052\n",
      "iteration - 2929 -> loss: 0.00034718974007907243, self.slope: [1.03536609 1.03555644], self.intercept: 1.0030460974566262\n",
      "iteration - 2930 -> loss: 0.00034716627184838385, self.slope: [1.03537686 1.03556729], self.intercept: 1.0030470504970004\n",
      "iteration - 2931 -> loss: 0.00034714280689720356, self.slope: [1.03538763 1.03557814], self.intercept: 1.003048003485335\n",
      "iteration - 2932 -> loss: 0.0003471193452248239, self.slope: [1.0353984  1.03558899], self.intercept: 1.0030489564216336\n",
      "iteration - 2933 -> loss: 0.00034709588683054884, self.slope: [1.03540917 1.03559984], self.intercept: 1.0030499093059055\n",
      "iteration - 2934 -> loss: 0.0003470724317137011, self.slope: [1.03541994 1.03561068], self.intercept: 1.0030508621381533\n",
      "iteration - 2935 -> loss: 0.00034704897987354675, self.slope: [1.03543071 1.03562153], self.intercept: 1.0030518149183862\n",
      "iteration - 2936 -> loss: 0.000347025531309425, self.slope: [1.03544147 1.03563238], self.intercept: 1.0030527676466099\n",
      "iteration - 2937 -> loss: 0.0003470020860206221, self.slope: [1.03545224 1.03564322], self.intercept: 1.0030537203228305\n",
      "iteration - 2938 -> loss: 0.0003469786440064467, self.slope: [1.035463   1.03565407], self.intercept: 1.0030546729470537\n",
      "iteration - 2939 -> loss: 0.0003469552052662142, self.slope: [1.03547377 1.03566491], self.intercept: 1.0030556255192857\n",
      "iteration - 2940 -> loss: 0.0003469317697992129, self.slope: [1.03548453 1.03567575], self.intercept: 1.0030565780395329\n",
      "iteration - 2941 -> loss: 0.0003469083376047577, self.slope: [1.03549529 1.0356866 ], self.intercept: 1.0030575305078009\n",
      "iteration - 2942 -> loss: 0.00034688490868214553, self.slope: [1.03550606 1.03569744], self.intercept: 1.0030584829240972\n",
      "iteration - 2943 -> loss: 0.00034686148303069445, self.slope: [1.03551682 1.03570828], self.intercept: 1.0030594352884274\n",
      "iteration - 2944 -> loss: 0.00034683806064969265, self.slope: [1.03552758 1.03571912], self.intercept: 1.0030603876007973\n",
      "iteration - 2945 -> loss: 0.00034681464153846236, self.slope: [1.03553834 1.03572996], self.intercept: 1.0030613398612134\n",
      "iteration - 2946 -> loss: 0.00034679122569631677, self.slope: [1.0355491 1.0357408], self.intercept: 1.0030622920696832\n",
      "iteration - 2947 -> loss: 0.0003467678131225413, self.slope: [1.03555986 1.03575164], self.intercept: 1.0030632442262102\n",
      "iteration - 2948 -> loss: 0.000346744403816423, self.slope: [1.03557061 1.03576247], self.intercept: 1.0030641963308025\n",
      "iteration - 2949 -> loss: 0.000346720997777327, self.slope: [1.03558137 1.03577331], self.intercept: 1.0030651483834663\n",
      "iteration - 2950 -> loss: 0.0003466975950045243, self.slope: [1.03559213 1.03578414], self.intercept: 1.003066100384207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 2951 -> loss: 0.00034667419549733105, self.slope: [1.03560288 1.03579498], self.intercept: 1.0030670523330298\n",
      "iteration - 2952 -> loss: 0.0003466507992550374, self.slope: [1.03561364 1.03580581], self.intercept: 1.003068004229942\n",
      "iteration - 2953 -> loss: 0.00034662740627695816, self.slope: [1.03562439 1.03581665], self.intercept: 1.0030689560749508\n",
      "iteration - 2954 -> loss: 0.0003466040165624297, self.slope: [1.03563514 1.03582748], self.intercept: 1.0030699078680623\n",
      "iteration - 2955 -> loss: 0.000346580630110734, self.slope: [1.03564589 1.03583831], self.intercept: 1.0030708596092823\n",
      "iteration - 2956 -> loss: 0.00034655724692115165, self.slope: [1.03565665 1.03584914], self.intercept: 1.0030718112986166\n",
      "iteration - 2957 -> loss: 0.0003465338669930463, self.slope: [1.0356674  1.03585997], self.intercept: 1.0030727629360707\n",
      "iteration - 2958 -> loss: 0.0003465104903257116, self.slope: [1.03567815 1.0358708 ], self.intercept: 1.0030737145216517\n",
      "iteration - 2959 -> loss: 0.000346487116918428, self.slope: [1.0356889  1.03588163], self.intercept: 1.0030746660553649\n",
      "iteration - 2960 -> loss: 0.0003464637467705279, self.slope: [1.03569964 1.03589246], self.intercept: 1.0030756175372173\n",
      "iteration - 2961 -> loss: 0.000346440379881323, self.slope: [1.03571039 1.03590329], self.intercept: 1.0030765689672145\n",
      "iteration - 2962 -> loss: 0.00034641701625011206, self.slope: [1.03572114 1.03591411], self.intercept: 1.0030775203453646\n",
      "iteration - 2963 -> loss: 0.000346393655876206, self.slope: [1.03573189 1.03592494], self.intercept: 1.0030784716716714\n",
      "iteration - 2964 -> loss: 0.0003463702987589162, self.slope: [1.03574263 1.03593577], self.intercept: 1.0030794229461428\n",
      "iteration - 2965 -> loss: 0.0003463469448975448, self.slope: [1.03575338 1.03594659], self.intercept: 1.0030803741687826\n",
      "iteration - 2966 -> loss: 0.0003463235942914126, self.slope: [1.03576412 1.03595741], self.intercept: 1.0030813253395983\n",
      "iteration - 2967 -> loss: 0.000346300246939834, self.slope: [1.03577486 1.03596824], self.intercept: 1.003082276458596\n",
      "iteration - 2968 -> loss: 0.0003462769028420931, self.slope: [1.03578561 1.03597906], self.intercept: 1.0030832275257844\n",
      "iteration - 2969 -> loss: 0.0003462535619975356, self.slope: [1.03579635 1.03598988], self.intercept: 1.0030841785411662\n",
      "iteration - 2970 -> loss: 0.000346230224405452, self.slope: [1.03580709 1.0360007 ], self.intercept: 1.0030851295047476\n",
      "iteration - 2971 -> loss: 0.0003462068900651599, self.slope: [1.03581783 1.03601152], self.intercept: 1.0030860804165365\n",
      "iteration - 2972 -> loss: 0.00034618355897596704, self.slope: [1.03582857 1.03602234], self.intercept: 1.0030870312765396\n",
      "iteration - 2973 -> loss: 0.0003461602311371745, self.slope: [1.03583931 1.03603316], self.intercept: 1.0030879820847602\n",
      "iteration - 2974 -> loss: 0.000346136906548115, self.slope: [1.03585004 1.03604398], self.intercept: 1.0030889328412078\n",
      "iteration - 2975 -> loss: 0.0003461135852080907, self.slope: [1.03586078 1.03605479], self.intercept: 1.003089883545887\n",
      "iteration - 2976 -> loss: 0.0003460902671164171, self.slope: [1.03587152 1.03606561], self.intercept: 1.0030908341988038\n",
      "iteration - 2977 -> loss: 0.00034606695227240087, self.slope: [1.03588225 1.03607642], self.intercept: 1.0030917847999639\n",
      "iteration - 2978 -> loss: 0.000346043640675349, self.slope: [1.03589299 1.03608724], self.intercept: 1.0030927353493748\n",
      "iteration - 2979 -> loss: 0.0003460203323245884, self.slope: [1.03590372 1.03609805], self.intercept: 1.0030936858470412\n",
      "iteration - 2980 -> loss: 0.0003459970272194219, self.slope: [1.03591446 1.03610887], self.intercept: 1.0030946362929714\n",
      "iteration - 2981 -> loss: 0.0003459737253591653, self.slope: [1.03592519 1.03611968], self.intercept: 1.0030955866871694\n",
      "iteration - 2982 -> loss: 0.0003459504267431378, self.slope: [1.03593592 1.03613049], self.intercept: 1.0030965370296425\n",
      "iteration - 2983 -> loss: 0.0003459271313706389, self.slope: [1.03594665 1.0361413 ], self.intercept: 1.003097487320396\n",
      "iteration - 2984 -> loss: 0.00034590383924099424, self.slope: [1.03595738 1.03615211], self.intercept: 1.0030984375594367\n",
      "iteration - 2985 -> loss: 0.0003458805503535153, self.slope: [1.03596811 1.03616292], self.intercept: 1.0030993877467709\n",
      "iteration - 2986 -> loss: 0.00034585726470752725, self.slope: [1.03597884 1.03617373], self.intercept: 1.0031003378824037\n",
      "iteration - 2987 -> loss: 0.0003458339823023022, self.slope: [1.03598957 1.03618454], self.intercept: 1.0031012879663426\n",
      "iteration - 2988 -> loss: 0.0003458107031372111, self.slope: [1.0360003  1.03619534], self.intercept: 1.0031022379985928\n",
      "iteration - 2989 -> loss: 0.00034578742721153797, self.slope: [1.03601102 1.03620615], self.intercept: 1.003103187979162\n",
      "iteration - 2990 -> loss: 0.00034576415452457947, self.slope: [1.03602175 1.03621696], self.intercept: 1.0031041379080536\n",
      "iteration - 2991 -> loss: 0.00034574088507569316, self.slope: [1.03603247 1.03622776], self.intercept: 1.0031050877852745\n",
      "iteration - 2992 -> loss: 0.00034571761886416184, self.slope: [1.0360432  1.03623857], self.intercept: 1.0031060376108334\n",
      "iteration - 2993 -> loss: 0.00034569435588931407, self.slope: [1.03605392 1.03624937], self.intercept: 1.0031069873847338\n",
      "iteration - 2994 -> loss: 0.0003456710961504618, self.slope: [1.03606464 1.03626017], self.intercept: 1.0031079371069824\n",
      "iteration - 2995 -> loss: 0.0003456478396469301, self.slope: [1.03607537 1.03627097], self.intercept: 1.0031088867775855\n",
      "iteration - 2996 -> loss: 0.00034562458637801835, self.slope: [1.03608609 1.03628178], self.intercept: 1.00310983639655\n",
      "iteration - 2997 -> loss: 0.0003456013363430535, self.slope: [1.03609681 1.03629258], self.intercept: 1.0031107859638815\n",
      "iteration - 2998 -> loss: 0.0003455780895413525, self.slope: [1.03610753 1.03630338], self.intercept: 1.0031117354795855\n",
      "iteration - 2999 -> loss: 0.000345554845972225, self.slope: [1.03611825 1.03631418], self.intercept: 1.0031126849436696\n",
      "iteration - 3000 -> loss: 0.00034553160563499175, self.slope: [1.03612897 1.03632497], self.intercept: 1.0031136343561387\n",
      "iteration - 3001 -> loss: 0.0003455083685289784, self.slope: [1.03613968 1.03633577], self.intercept: 1.0031145837169986\n",
      "iteration - 3002 -> loss: 0.0003454851346534727, self.slope: [1.0361504  1.03634657], self.intercept: 1.003115533026257\n",
      "iteration - 3003 -> loss: 0.00034546190400783444, self.slope: [1.03616112 1.03635736], self.intercept: 1.0031164822839194\n",
      "iteration - 3004 -> loss: 0.00034543867659136084, self.slope: [1.03617183 1.03636816], self.intercept: 1.0031174314899922\n",
      "iteration - 3005 -> loss: 0.00034541545240334895, self.slope: [1.03618255 1.03637895], self.intercept: 1.0031183806444817\n",
      "iteration - 3006 -> loss: 0.0003453922314431508, self.slope: [1.03619326 1.03638975], self.intercept: 1.003119329747392\n",
      "iteration - 3007 -> loss: 0.0003453690137100767, self.slope: [1.03620397 1.03640054], self.intercept: 1.0031202787987303\n",
      "iteration - 3008 -> loss: 0.0003453457992034201, self.slope: [1.03621468 1.03641133], self.intercept: 1.0031212277985024\n",
      "iteration - 3009 -> loss: 0.0003453225879225129, self.slope: [1.0362254  1.03642212], self.intercept: 1.0031221767467167\n",
      "iteration - 3010 -> loss: 0.0003452993798666884, self.slope: [1.03623611 1.03643292], self.intercept: 1.0031231256433772\n",
      "iteration - 3011 -> loss: 0.00034527617503524947, self.slope: [1.03624682 1.03644371], self.intercept: 1.0031240744884895\n",
      "iteration - 3012 -> loss: 0.00034525297342752196, self.slope: [1.03625753 1.03645449], self.intercept: 1.003125023282062\n",
      "iteration - 3013 -> loss: 0.0003452297750428251, self.slope: [1.03626824 1.03646528], self.intercept: 1.003125972024098\n",
      "iteration - 3014 -> loss: 0.000345206579880483, self.slope: [1.03627894 1.03647607], self.intercept: 1.0031269207146059\n",
      "iteration - 3015 -> loss: 0.0003451833879397941, self.slope: [1.03628965 1.03648686], self.intercept: 1.0031278693535897\n",
      "iteration - 3016 -> loss: 0.00034516019922010527, self.slope: [1.03630036 1.03649764], self.intercept: 1.003128817941057\n",
      "iteration - 3017 -> loss: 0.00034513701372072163, self.slope: [1.03631106 1.03650843], self.intercept: 1.0031297664770151\n",
      "iteration - 3018 -> loss: 0.00034511383144097095, self.slope: [1.03632177 1.03651922], self.intercept: 1.0031307149614683\n",
      "iteration - 3019 -> loss: 0.00034509065238015987, self.slope: [1.03633247 1.03653   ], self.intercept: 1.0031316633944243\n",
      "iteration - 3020 -> loss: 0.00034506747653762436, self.slope: [1.03634317 1.03654078], self.intercept: 1.0031326117758883\n",
      "iteration - 3021 -> loss: 0.0003450443039126713, self.slope: [1.03635388 1.03655157], self.intercept: 1.0031335601058646\n",
      "iteration - 3022 -> loss: 0.0003450211345046362, self.slope: [1.03636458 1.03656235], self.intercept: 1.0031345083843608\n",
      "iteration - 3023 -> loss: 0.0003449979683128256, self.slope: [1.03637528 1.03657313], self.intercept: 1.0031354566113833\n",
      "iteration - 3024 -> loss: 0.00034497480533659066, self.slope: [1.03638598 1.03658391], self.intercept: 1.00313640478694\n",
      "iteration - 3025 -> loss: 0.00034495164557519256, self.slope: [1.03639668 1.03659469], self.intercept: 1.0031373529110332\n",
      "iteration - 3026 -> loss: 0.00034492848902800894, self.slope: [1.03640738 1.03660547], self.intercept: 1.0031383009836725\n",
      "iteration - 3027 -> loss: 0.00034490533569434884, self.slope: [1.03641808 1.03661625], self.intercept: 1.0031392490048603\n",
      "iteration - 3028 -> loss: 0.0003448821855735359, self.slope: [1.03642877 1.03662702], self.intercept: 1.0031401969746057\n",
      "iteration - 3029 -> loss: 0.0003448590386648662, self.slope: [1.03643947 1.0366378 ], self.intercept: 1.003141144892913\n",
      "iteration - 3030 -> loss: 0.00034483589496767954, self.slope: [1.03645017 1.03664858], self.intercept: 1.0031420927597887\n",
      "iteration - 3031 -> loss: 0.0003448127544813258, self.slope: [1.03646086 1.03665935], self.intercept: 1.0031430405752397\n",
      "iteration - 3032 -> loss: 0.00034478961720507814, self.slope: [1.03647156 1.03667013], self.intercept: 1.0031439883392717\n",
      "iteration - 3033 -> loss: 0.0003447664831383024, self.slope: [1.03648225 1.0366809 ], self.intercept: 1.0031449360518914\n",
      "iteration - 3034 -> loss: 0.00034474335228029077, self.slope: [1.03649294 1.03669167], self.intercept: 1.0031458837131038\n",
      "iteration - 3035 -> loss: 0.00034472022463039644, self.slope: [1.03650363 1.03670244], self.intercept: 1.0031468313229162\n",
      "iteration - 3036 -> loss: 0.0003446971001878973, self.slope: [1.03651432 1.03671322], self.intercept: 1.0031477788813332\n",
      "iteration - 3037 -> loss: 0.00034467397895217273, self.slope: [1.03652502 1.03672399], self.intercept: 1.0031487263883627\n",
      "iteration - 3038 -> loss: 0.0003446508609225185, self.slope: [1.03653571 1.03673476], self.intercept: 1.0031496738440102\n",
      "iteration - 3039 -> loss: 0.0003446277460982496, self.slope: [1.03654639 1.03674553], self.intercept: 1.003150621248281\n",
      "iteration - 3040 -> loss: 0.000344604634478702, self.slope: [1.03655708 1.03675629], self.intercept: 1.0031515686011816\n",
      "iteration - 3041 -> loss: 0.0003445815260632092, self.slope: [1.03656777 1.03676706], self.intercept: 1.0031525159027188\n",
      "iteration - 3042 -> loss: 0.00034455842085107433, self.slope: [1.03657846 1.03677783], self.intercept: 1.0031534631528962\n",
      "iteration - 3043 -> loss: 0.00034453531884164306, self.slope: [1.03658914 1.0367886 ], self.intercept: 1.0031544103517243\n",
      "iteration - 3044 -> loss: 0.00034451222003422326, self.slope: [1.03659983 1.03679936], self.intercept: 1.0031553574992045\n",
      "iteration - 3045 -> loss: 0.0003444891244281559, self.slope: [1.03661051 1.03681013], self.intercept: 1.0031563045953453\n",
      "iteration - 3046 -> loss: 0.0003444660320227584, self.slope: [1.0366212  1.03682089], self.intercept: 1.0031572516401521\n",
      "iteration - 3047 -> loss: 0.0003444429428173531, self.slope: [1.03663188 1.03683165], self.intercept: 1.0031581986336342\n",
      "iteration - 3048 -> loss: 0.0003444198568112845, self.slope: [1.03664256 1.03684242], self.intercept: 1.003159145575792\n",
      "iteration - 3049 -> loss: 0.0003443967740038486, self.slope: [1.03665324 1.03685318], self.intercept: 1.0031600924666353\n",
      "iteration - 3050 -> loss: 0.00034437369439439786, self.slope: [1.03666392 1.03686394], self.intercept: 1.0031610393061687\n",
      "iteration - 3051 -> loss: 0.0003443506179822619, self.slope: [1.0366746 1.0368747], self.intercept: 1.0031619860943986\n",
      "iteration - 3052 -> loss: 0.00034432754476672295, self.slope: [1.03668528 1.03688546], self.intercept: 1.0031629328313332\n",
      "iteration - 3053 -> loss: 0.00034430447474716387, self.slope: [1.03669596 1.03689622], self.intercept: 1.0031638795169748\n",
      "iteration - 3054 -> loss: 0.0003442814079228774, self.slope: [1.03670664 1.03690698], self.intercept: 1.0031648261513317\n",
      "iteration - 3055 -> loss: 0.00034425834429319265, self.slope: [1.03671732 1.03691773], self.intercept: 1.0031657727344094\n",
      "iteration - 3056 -> loss: 0.00034423528385747125, self.slope: [1.03672799 1.03692849], self.intercept: 1.0031667192662155\n",
      "iteration - 3057 -> loss: 0.00034421222661499786, self.slope: [1.03673867 1.03693925], self.intercept: 1.0031676657467545\n",
      "iteration - 3058 -> loss: 0.00034418917256511856, self.slope: [1.03674934 1.03695   ], self.intercept: 1.0031686121760317\n",
      "iteration - 3059 -> loss: 0.00034416612170714726, self.slope: [1.03676002 1.03696076], self.intercept: 1.0031695585540554\n",
      "iteration - 3060 -> loss: 0.0003441430740404497, self.slope: [1.03677069 1.03697151], self.intercept: 1.003170504880829\n",
      "iteration - 3061 -> loss: 0.000344120029564303, self.slope: [1.03678136 1.03698226], self.intercept: 1.003171451156361\n",
      "iteration - 3062 -> loss: 0.00034409698827808665, self.slope: [1.03679204 1.03699302], self.intercept: 1.003172397380656\n",
      "iteration - 3063 -> loss: 0.0003440739501810932, self.slope: [1.03680271 1.03700377], self.intercept: 1.0031733435537213\n",
      "iteration - 3064 -> loss: 0.00034405091527265843, self.slope: [1.03681338 1.03701452], self.intercept: 1.0031742896755633\n",
      "iteration - 3065 -> loss: 0.00034402788355212605, self.slope: [1.03682405 1.03702527], self.intercept: 1.0031752357461863\n",
      "iteration - 3066 -> loss: 0.00034400485501880914, self.slope: [1.03683472 1.03703602], self.intercept: 1.003176181765598\n",
      "iteration - 3067 -> loss: 0.0003439818296720433, self.slope: [1.03684538 1.03704677], self.intercept: 1.0031771277338009\n",
      "iteration - 3068 -> loss: 0.0003439588075111693, self.slope: [1.03685605 1.03705751], self.intercept: 1.0031780736508047\n",
      "iteration - 3069 -> loss: 0.0003439357885355125, self.slope: [1.03686672 1.03706826], self.intercept: 1.0031790195166146\n",
      "iteration - 3070 -> loss: 0.0003439127727443762, self.slope: [1.03687738 1.03707901], self.intercept: 1.0031799653312365\n",
      "iteration - 3071 -> loss: 0.00034388976013711916, self.slope: [1.03688805 1.03708975], self.intercept: 1.0031809110946766\n",
      "iteration - 3072 -> loss: 0.0003438667507130644, self.slope: [1.03689871 1.0371005 ], self.intercept: 1.0031818568069422\n",
      "iteration - 3073 -> loss: 0.0003438437444715531, self.slope: [1.03690938 1.03711124], self.intercept: 1.0031828024680367\n",
      "iteration - 3074 -> loss: 0.00034382074141187867, self.slope: [1.03692004 1.03712199], self.intercept: 1.0031837480779668\n",
      "iteration - 3075 -> loss: 0.0003437977415334128, self.slope: [1.0369307  1.03713273], self.intercept: 1.0031846936367401\n",
      "iteration - 3076 -> loss: 0.00034377474483549193, self.slope: [1.03694136 1.03714347], self.intercept: 1.0031856391443619\n",
      "iteration - 3077 -> loss: 0.0003437517513174064, self.slope: [1.03695203 1.03715421], self.intercept: 1.003186584600837\n",
      "iteration - 3078 -> loss: 0.0003437287609785212, self.slope: [1.03696269 1.03716495], self.intercept: 1.003187530006173\n",
      "iteration - 3079 -> loss: 0.0003437057738181532, self.slope: [1.03697334 1.03717569], self.intercept: 1.0031884753603748\n",
      "iteration - 3080 -> loss: 0.00034368278983564973, self.slope: [1.036984   1.03718643], self.intercept: 1.003189420663449\n",
      "iteration - 3081 -> loss: 0.000343659809030319, self.slope: [1.03699466 1.03719717], self.intercept: 1.0031903659154005\n",
      "iteration - 3082 -> loss: 0.00034363683140149916, self.slope: [1.03700532 1.03720791], self.intercept: 1.0031913111162383\n",
      "iteration - 3083 -> loss: 0.0003436138569485538, self.slope: [1.03701597 1.03721864], self.intercept: 1.0031922562659668\n",
      "iteration - 3084 -> loss: 0.0003435908856707566, self.slope: [1.03702663 1.03722938], self.intercept: 1.003193201364591\n",
      "iteration - 3085 -> loss: 0.0003435679175674951, self.slope: [1.03703728 1.03724012], self.intercept: 1.0031941464121195\n",
      "iteration - 3086 -> loss: 0.0003435449526380805, self.slope: [1.03704794 1.03725085], self.intercept: 1.0031950914085561\n",
      "iteration - 3087 -> loss: 0.0003435219908818722, self.slope: [1.03705859 1.03726158], self.intercept: 1.0031960363539076\n",
      "iteration - 3088 -> loss: 0.00034349903229813724, self.slope: [1.03706924 1.03727232], self.intercept: 1.003196981248181\n",
      "iteration - 3089 -> loss: 0.00034347607688629746, self.slope: [1.0370799  1.03728305], self.intercept: 1.0031979260913824\n",
      "iteration - 3090 -> loss: 0.00034345312464560495, self.slope: [1.03709055 1.03729378], self.intercept: 1.0031988708835144\n",
      "iteration - 3091 -> loss: 0.0003434301755754552, self.slope: [1.0371012  1.03730451], self.intercept: 1.0031998156245858\n",
      "iteration - 3092 -> loss: 0.0003434072296751294, self.slope: [1.03711185 1.03731524], self.intercept: 1.0032007603146027\n",
      "iteration - 3093 -> loss: 0.0003433842869440134, self.slope: [1.0371225  1.03732597], self.intercept: 1.00320170495357\n",
      "iteration - 3094 -> loss: 0.00034336134738140905, self.slope: [1.03713314 1.0373367 ], self.intercept: 1.003202649541493\n",
      "iteration - 3095 -> loss: 0.0003433384109866656, self.slope: [1.03714379 1.03734743], self.intercept: 1.0032035940783801\n",
      "iteration - 3096 -> loss: 0.000343315477759088, self.slope: [1.03715444 1.03735816], self.intercept: 1.0032045385642367\n",
      "iteration - 3097 -> loss: 0.0003432925476980732, self.slope: [1.03716508 1.03736888], self.intercept: 1.003205482999069\n",
      "iteration - 3098 -> loss: 0.00034326962080289823, self.slope: [1.03717573 1.03737961], self.intercept: 1.0032064273828833\n",
      "iteration - 3099 -> loss: 0.00034324669707290825, self.slope: [1.03718637 1.03739033], self.intercept: 1.0032073717156833\n",
      "iteration - 3100 -> loss: 0.00034322377650748237, self.slope: [1.03719702 1.03740106], self.intercept: 1.003208315997477\n",
      "iteration - 3101 -> loss: 0.0003432008591059091, self.slope: [1.03720766 1.03741178], self.intercept: 1.0032092602282692\n",
      "iteration - 3102 -> loss: 0.0003431779448675451, self.slope: [1.0372183 1.0374225], self.intercept: 1.003210204408066\n",
      "iteration - 3103 -> loss: 0.00034315503379170635, self.slope: [1.03722894 1.03743323], self.intercept: 1.0032111485368753\n",
      "iteration - 3104 -> loss: 0.00034313212587777056, self.slope: [1.03723958 1.03744395], self.intercept: 1.0032120926147008\n",
      "iteration - 3105 -> loss: 0.00034310922112503557, self.slope: [1.03725022 1.03745467], self.intercept: 1.0032130366415486\n",
      "iteration - 3106 -> loss: 0.0003430863195328606, self.slope: [1.03726086 1.03746539], self.intercept: 1.0032139806174278\n",
      "iteration - 3107 -> loss: 0.00034306342110056404, self.slope: [1.0372715  1.03747611], self.intercept: 1.003214924542342\n",
      "iteration - 3108 -> loss: 0.0003430405258274861, self.slope: [1.03728214 1.03748683], self.intercept: 1.0032158684162977\n",
      "iteration - 3109 -> loss: 0.00034301763371298306, self.slope: [1.03729278 1.03749754], self.intercept: 1.003216812239301\n",
      "iteration - 3110 -> loss: 0.0003429947447563832, self.slope: [1.03730341 1.03750826], self.intercept: 1.0032177560113575\n",
      "iteration - 3111 -> loss: 0.00034297185895700765, self.slope: [1.03731405 1.03751898], self.intercept: 1.0032186997324735\n",
      "iteration - 3112 -> loss: 0.00034294897631422845, self.slope: [1.03732468 1.03752969], self.intercept: 1.0032196434026543\n",
      "iteration - 3113 -> loss: 0.0003429260968273479, self.slope: [1.03733532 1.03754041], self.intercept: 1.0032205870219064\n",
      "iteration - 3114 -> loss: 0.0003429032204957189, self.slope: [1.03734595 1.03755112], self.intercept: 1.003221530590236\n",
      "iteration - 3115 -> loss: 0.0003428803473186951, self.slope: [1.03735658 1.03756183], self.intercept: 1.0032224741076503\n",
      "iteration - 3116 -> loss: 0.00034285747729559813, self.slope: [1.03736721 1.03757255], self.intercept: 1.0032234175741528\n",
      "iteration - 3117 -> loss: 0.0003428346104257552, self.slope: [1.03737785 1.03758326], self.intercept: 1.0032243609897507\n",
      "iteration - 3118 -> loss: 0.00034281174670854444, self.slope: [1.03738848 1.03759397], self.intercept: 1.00322530435445\n",
      "iteration - 3119 -> loss: 0.0003427888861432681, self.slope: [1.0373991  1.03760468], self.intercept: 1.003226247668256\n",
      "iteration - 3120 -> loss: 0.0003427660287292885, self.slope: [1.03740973 1.03761539], self.intercept: 1.003227190931177\n",
      "iteration - 3121 -> loss: 0.0003427431744659211, self.slope: [1.03742036 1.0376261 ], self.intercept: 1.0032281341432168\n",
      "iteration - 3122 -> loss: 0.00034272032335253325, self.slope: [1.03743099 1.03763681], self.intercept: 1.0032290773043824\n",
      "iteration - 3123 -> loss: 0.0003426974753884399, self.slope: [1.03744162 1.03764751], self.intercept: 1.003230020414679\n",
      "iteration - 3124 -> loss: 0.00034267463057301037, self.slope: [1.03745224 1.03765822], self.intercept: 1.0032309634741134\n",
      "iteration - 3125 -> loss: 0.0003426517889055581, self.slope: [1.03746287 1.03766893], self.intercept: 1.0032319064826904\n",
      "iteration - 3126 -> loss: 0.0003426289503854338, self.slope: [1.03747349 1.03767963], self.intercept: 1.0032328494404161\n",
      "iteration - 3127 -> loss: 0.00034260611501197707, self.slope: [1.03748411 1.03769034], self.intercept: 1.0032337923472985\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 3128 -> loss: 0.0003425832827845369, self.slope: [1.03749474 1.03770104], self.intercept: 1.0032347352033422\n",
      "iteration - 3129 -> loss: 0.00034256045370242947, self.slope: [1.03750536 1.03771174], self.intercept: 1.0032356780085538\n",
      "iteration - 3130 -> loss: 0.0003425376277650449, self.slope: [1.03751598 1.03772245], self.intercept: 1.0032366207629375\n",
      "iteration - 3131 -> loss: 0.0003425148049716755, self.slope: [1.0375266  1.03773315], self.intercept: 1.0032375634665018\n",
      "iteration - 3132 -> loss: 0.00034249198532167554, self.slope: [1.03753722 1.03774385], self.intercept: 1.0032385061192515\n",
      "iteration - 3133 -> loss: 0.0003424691688144088, self.slope: [1.03754784 1.03775455], self.intercept: 1.0032394487211929\n",
      "iteration - 3134 -> loss: 0.0003424463554491926, self.slope: [1.03755846 1.03776525], self.intercept: 1.0032403912723313\n",
      "iteration - 3135 -> loss: 0.00034242354522536855, self.slope: [1.03756908 1.03777595], self.intercept: 1.0032413337726727\n",
      "iteration - 3136 -> loss: 0.00034240073814230046, self.slope: [1.03757969 1.03778664], self.intercept: 1.0032422762222233\n",
      "iteration - 3137 -> loss: 0.00034237793419933084, self.slope: [1.03759031 1.03779734], self.intercept: 1.0032432186209894\n",
      "iteration - 3138 -> loss: 0.0003423551333957757, self.slope: [1.03760093 1.03780804], self.intercept: 1.003244160968977\n",
      "iteration - 3139 -> loss: 0.00034233233573099486, self.slope: [1.03761154 1.03781873], self.intercept: 1.0032451032661913\n",
      "iteration - 3140 -> loss: 0.0003423095412043424, self.slope: [1.03762215 1.03782943], self.intercept: 1.0032460455126393\n",
      "iteration - 3141 -> loss: 0.00034228674981513405, self.slope: [1.03763277 1.03784012], self.intercept: 1.0032469877083259\n",
      "iteration - 3142 -> loss: 0.000342263961562742, self.slope: [1.03764338 1.03785082], self.intercept: 1.0032479298532566\n",
      "iteration - 3143 -> loss: 0.0003422411764464868, self.slope: [1.03765399 1.03786151], self.intercept: 1.0032488719474402\n",
      "iteration - 3144 -> loss: 0.00034221839446573024, self.slope: [1.0376646 1.0378722], self.intercept: 1.0032498139908816\n",
      "iteration - 3145 -> loss: 0.00034219561561978806, self.slope: [1.03767521 1.03788289], self.intercept: 1.003250755983585\n",
      "iteration - 3146 -> loss: 0.00034217283990806076, self.slope: [1.03768582 1.03789358], self.intercept: 1.0032516979255575\n",
      "iteration - 3147 -> loss: 0.00034215006732982026, self.slope: [1.03769643 1.03790427], self.intercept: 1.0032526398168058\n",
      "iteration - 3148 -> loss: 0.00034212729788447215, self.slope: [1.03770704 1.03791496], self.intercept: 1.0032535816573347\n",
      "iteration - 3149 -> loss: 0.00034210453157132827, self.slope: [1.03771765 1.03792565], self.intercept: 1.00325452344715\n",
      "iteration - 3150 -> loss: 0.00034208176838974104, self.slope: [1.03772825 1.03793634], self.intercept: 1.0032554651862597\n",
      "iteration - 3151 -> loss: 0.0003420590083390624, self.slope: [1.03773886 1.03794703], self.intercept: 1.0032564068746668\n",
      "iteration - 3152 -> loss: 0.00034203625141863926, self.slope: [1.03774947 1.03795771], self.intercept: 1.0032573485123788\n",
      "iteration - 3153 -> loss: 0.0003420134976278086, self.slope: [1.03776007 1.0379684 ], self.intercept: 1.0032582900994014\n",
      "iteration - 3154 -> loss: 0.0003419907469659123, self.slope: [1.03777067 1.03797908], self.intercept: 1.003259231635743\n",
      "iteration - 3155 -> loss: 0.00034196799943231104, self.slope: [1.03778128 1.03798977], self.intercept: 1.0032601731214066\n",
      "iteration - 3156 -> loss: 0.00034194525502632354, self.slope: [1.03779188 1.03800045], self.intercept: 1.0032611145563988\n",
      "iteration - 3157 -> loss: 0.0003419225137473175, self.slope: [1.03780248 1.03801113], self.intercept: 1.003262055940725\n",
      "iteration - 3158 -> loss: 0.00034189977559465306, self.slope: [1.03781308 1.03802181], self.intercept: 1.0032629972743923\n",
      "iteration - 3159 -> loss: 0.00034187704056765186, self.slope: [1.03782368 1.03803249], self.intercept: 1.0032639385574051\n",
      "iteration - 3160 -> loss: 0.00034185430866566556, self.slope: [1.03783428 1.03804318], self.intercept: 1.0032648797897723\n",
      "iteration - 3161 -> loss: 0.0003418315798880515, self.slope: [1.03784488 1.03805385], self.intercept: 1.0032658209714986\n",
      "iteration - 3162 -> loss: 0.00034180885423413973, self.slope: [1.03785548 1.03806453], self.intercept: 1.003266762102588\n",
      "iteration - 3163 -> loss: 0.0003417861317033088, self.slope: [1.03786607 1.03807521], self.intercept: 1.003267703183048\n",
      "iteration - 3164 -> loss: 0.0003417634122948624, self.slope: [1.03787667 1.03808589], self.intercept: 1.0032686442128853\n",
      "iteration - 3165 -> loss: 0.00034174069600819313, self.slope: [1.03788727 1.03809657], self.intercept: 1.0032695851921043\n",
      "iteration - 3166 -> loss: 0.0003417179828426174, self.slope: [1.03789786 1.03810724], self.intercept: 1.0032705261207107\n",
      "iteration - 3167 -> loss: 0.0003416952727974954, self.slope: [1.03790846 1.03811792], self.intercept: 1.0032714669987126\n",
      "iteration - 3168 -> loss: 0.0003416725658721765, self.slope: [1.03791905 1.03812859], self.intercept: 1.003272407826115\n",
      "iteration - 3169 -> loss: 0.00034164986206600004, self.slope: [1.03792964 1.03813927], self.intercept: 1.0032733486029235\n",
      "iteration - 3170 -> loss: 0.0003416271613783289, self.slope: [1.03794023 1.03814994], self.intercept: 1.0032742893291438\n",
      "iteration - 3171 -> loss: 0.0003416044638084978, self.slope: [1.03795083 1.03816061], self.intercept: 1.0032752300047816\n",
      "iteration - 3172 -> loss: 0.00034158176935587624, self.slope: [1.03796142 1.03817128], self.intercept: 1.0032761706298434\n",
      "iteration - 3173 -> loss: 0.00034155907801976834, self.slope: [1.03797201 1.03818195], self.intercept: 1.0032771112043353\n",
      "iteration - 3174 -> loss: 0.0003415363897995936, self.slope: [1.03798259 1.03819262], self.intercept: 1.0032780517282638\n",
      "iteration - 3175 -> loss: 0.00034151370469464156, self.slope: [1.03799318 1.03820329], self.intercept: 1.0032789922016336\n",
      "iteration - 3176 -> loss: 0.00034149102270427956, self.slope: [1.03800377 1.03821396], self.intercept: 1.0032799326244515\n",
      "iteration - 3177 -> loss: 0.00034146834382786493, self.slope: [1.03801436 1.03822463], self.intercept: 1.0032808729967226\n",
      "iteration - 3178 -> loss: 0.0003414456680647552, self.slope: [1.03802494 1.0382353 ], self.intercept: 1.0032818133184542\n",
      "iteration - 3179 -> loss: 0.00034142299541427843, self.slope: [1.03803553 1.03824596], self.intercept: 1.0032827535896518\n",
      "iteration - 3180 -> loss: 0.0003414003258758016, self.slope: [1.03804611 1.03825663], self.intercept: 1.0032836938103205\n",
      "iteration - 3181 -> loss: 0.000341377659448664, self.slope: [1.0380567 1.0382673], self.intercept: 1.0032846339804662\n",
      "iteration - 3182 -> loss: 0.0003413549961322343, self.slope: [1.03806728 1.03827796], self.intercept: 1.0032855741000948\n",
      "iteration - 3183 -> loss: 0.00034133233592586055, self.slope: [1.03807786 1.03828862], self.intercept: 1.0032865141692124\n",
      "iteration - 3184 -> loss: 0.0003413096788288678, self.slope: [1.03808844 1.03829929], self.intercept: 1.0032874541878267\n",
      "iteration - 3185 -> loss: 0.0003412870248406128, self.slope: [1.03809903 1.03830995], self.intercept: 1.003288394155941\n",
      "iteration - 3186 -> loss: 0.0003412643739604778, self.slope: [1.03810961 1.03832061], self.intercept: 1.0032893340735618\n",
      "iteration - 3187 -> loss: 0.00034124172618779853, self.slope: [1.03812019 1.03833127], self.intercept: 1.0032902739406973\n",
      "iteration - 3188 -> loss: 0.0003412190815219285, self.slope: [1.03813076 1.03834193], self.intercept: 1.0032912137573526\n",
      "iteration - 3189 -> loss: 0.00034119643996218646, self.slope: [1.03814134 1.03835259], self.intercept: 1.003292153523532\n",
      "iteration - 3190 -> loss: 0.00034117380150798266, self.slope: [1.03815192 1.03836325], self.intercept: 1.0032930932392412\n",
      "iteration - 3191 -> loss: 0.00034115116615863404, self.slope: [1.0381625  1.03837391], self.intercept: 1.0032940329044882\n",
      "iteration - 3192 -> loss: 0.0003411285339135063, self.slope: [1.03817307 1.03838456], self.intercept: 1.0032949725192786\n",
      "iteration - 3193 -> loss: 0.00034110590477194706, self.slope: [1.03818365 1.03839522], self.intercept: 1.0032959120836156\n",
      "iteration - 3194 -> loss: 0.0003410832787333079, self.slope: [1.03819422 1.03840588], self.intercept: 1.0032968515975085\n",
      "iteration - 3195 -> loss: 0.0003410606557969341, self.slope: [1.0382048  1.03841653], self.intercept: 1.0032977910609606\n",
      "iteration - 3196 -> loss: 0.0003410380359621927, self.slope: [1.03821537 1.03842719], self.intercept: 1.0032987304739789\n",
      "iteration - 3197 -> loss: 0.0003410154192284454, self.slope: [1.03822594 1.03843784], self.intercept: 1.0032996698365704\n",
      "iteration - 3198 -> loss: 0.0003409928055950077, self.slope: [1.03823651 1.03844849], self.intercept: 1.0033006091487406\n",
      "iteration - 3199 -> loss: 0.0003409701950612865, self.slope: [1.03824708 1.03845914], self.intercept: 1.0033015484104935\n",
      "iteration - 3200 -> loss: 0.00034094758762658967, self.slope: [1.03825765 1.0384698 ], self.intercept: 1.0033024876218362\n",
      "iteration - 3201 -> loss: 0.00034092498329030626, self.slope: [1.03826822 1.03848045], self.intercept: 1.0033034267827763\n",
      "iteration - 3202 -> loss: 0.0003409023820517563, self.slope: [1.03827879 1.0384911 ], self.intercept: 1.0033043658933187\n",
      "iteration - 3203 -> loss: 0.00034087978391034315, self.slope: [1.03828936 1.03850175], self.intercept: 1.0033053049534675\n",
      "iteration - 3204 -> loss: 0.00034085718886537215, self.slope: [1.03829992 1.03851239], self.intercept: 1.003306243963231\n",
      "iteration - 3205 -> loss: 0.0003408345969162255, self.slope: [1.03831049 1.03852304], self.intercept: 1.0033071829226146\n",
      "iteration - 3206 -> loss: 0.0003408120080622409, self.slope: [1.03832106 1.03853369], self.intercept: 1.0033081218316233\n",
      "iteration - 3207 -> loss: 0.00034078942230280273, self.slope: [1.03833162 1.03854433], self.intercept: 1.0033090606902628\n",
      "iteration - 3208 -> loss: 0.0003407668396372345, self.slope: [1.03834219 1.03855498], self.intercept: 1.0033099994985393\n",
      "iteration - 3209 -> loss: 0.0003407442600649027, self.slope: [1.03835275 1.03856563], self.intercept: 1.0033109382564591\n",
      "iteration - 3210 -> loss: 0.00034072168358516714, self.slope: [1.03836331 1.03857627], self.intercept: 1.0033118769640281\n",
      "iteration - 3211 -> loss: 0.00034069911019738233, self.slope: [1.03837387 1.03858691], self.intercept: 1.003312815621253\n",
      "iteration - 3212 -> loss: 0.0003406765399009112, self.slope: [1.03838444 1.03859756], self.intercept: 1.0033137542281394\n",
      "iteration - 3213 -> loss: 0.0003406539726950956, self.slope: [1.038395  1.0386082], self.intercept: 1.0033146927846914\n",
      "iteration - 3214 -> loss: 0.0003406314085793147, self.slope: [1.03840556 1.03861884], self.intercept: 1.003315631290917\n",
      "iteration - 3215 -> loss: 0.000340608847552907, self.slope: [1.03841611 1.03862948], self.intercept: 1.0033165697468198\n",
      "iteration - 3216 -> loss: 0.0003405862896152414, self.slope: [1.03842667 1.03864012], self.intercept: 1.0033175081524084\n",
      "iteration - 3217 -> loss: 0.0003405637347656489, self.slope: [1.03843723 1.03865076], self.intercept: 1.0033184465076865\n",
      "iteration - 3218 -> loss: 0.0003405411830035109, self.slope: [1.03844779 1.0386614 ], self.intercept: 1.0033193848126605\n",
      "iteration - 3219 -> loss: 0.0003405186343281859, self.slope: [1.03845834 1.03867203], self.intercept: 1.003320323067337\n",
      "iteration - 3220 -> loss: 0.00034049608873902316, self.slope: [1.0384689  1.03868267], self.intercept: 1.0033212612717213\n",
      "iteration - 3221 -> loss: 0.00034047354623538845, self.slope: [1.03847945 1.03869331], self.intercept: 1.003322199425821\n",
      "iteration - 3222 -> loss: 0.00034045100681663067, self.slope: [1.03849001 1.03870394], self.intercept: 1.003323137529639\n",
      "iteration - 3223 -> loss: 0.0003404284704821176, self.slope: [1.03850056 1.03871458], self.intercept: 1.0033240755831827\n",
      "iteration - 3224 -> loss: 0.00034040593723118345, self.slope: [1.03851111 1.03872521], self.intercept: 1.0033250135864586\n",
      "iteration - 3225 -> loss: 0.00034038340706322187, self.slope: [1.03852166 1.03873584], self.intercept: 1.0033259515394726\n",
      "iteration - 3226 -> loss: 0.00034036087997757654, self.slope: [1.03853222 1.03874648], self.intercept: 1.0033268894422296\n",
      "iteration - 3227 -> loss: 0.00034033835597360707, self.slope: [1.03854277 1.03875711], self.intercept: 1.0033278272947366\n",
      "iteration - 3228 -> loss: 0.0003403158350506616, self.slope: [1.03855332 1.03876774], self.intercept: 1.0033287650969989\n",
      "iteration - 3229 -> loss: 0.0003402933172081243, self.slope: [1.03856386 1.03877837], self.intercept: 1.0033297028490227\n",
      "iteration - 3230 -> loss: 0.0003402708024453199, self.slope: [1.03857441 1.038789  ], self.intercept: 1.003330640550813\n",
      "iteration - 3231 -> loss: 0.00034024829076163566, self.slope: [1.03858496 1.03879963], self.intercept: 1.0033315782023757\n",
      "iteration - 3232 -> loss: 0.00034022578215643336, self.slope: [1.03859551 1.03881026], self.intercept: 1.0033325158037187\n",
      "iteration - 3233 -> loss: 0.0003402032766290409, self.slope: [1.03860605 1.03882088], self.intercept: 1.003333453354845\n",
      "iteration - 3234 -> loss: 0.0003401807741788666, self.slope: [1.0386166  1.03883151], self.intercept: 1.003334390855762\n",
      "iteration - 3235 -> loss: 0.0003401582748052281, self.slope: [1.03862714 1.03884214], self.intercept: 1.0033353283064748\n",
      "iteration - 3236 -> loss: 0.0003401357785075035, self.slope: [1.03863769 1.03885276], self.intercept: 1.0033362657069902\n",
      "iteration - 3237 -> loss: 0.00034011328528506, self.slope: [1.03864823 1.03886339], self.intercept: 1.0033372030573138\n",
      "iteration - 3238 -> loss: 0.00034009079513724666, self.slope: [1.03865877 1.03887401], self.intercept: 1.003338140357452\n",
      "iteration - 3239 -> loss: 0.0003400683080634308, self.slope: [1.03866931 1.03888463], self.intercept: 1.0033390776074085\n",
      "iteration - 3240 -> loss: 0.00034004582406297246, self.slope: [1.03867985 1.03889526], self.intercept: 1.0033400148071925\n",
      "iteration - 3241 -> loss: 0.00034002334313524034, self.slope: [1.03869039 1.03890588], self.intercept: 1.003340951956806\n",
      "iteration - 3242 -> loss: 0.00034000086527958396, self.slope: [1.03870093 1.0389165 ], self.intercept: 1.0033418890562575\n",
      "iteration - 3243 -> loss: 0.0003399783904953609, self.slope: [1.03871147 1.03892712], self.intercept: 1.0033428261055533\n",
      "iteration - 3244 -> loss: 0.0003399559187819668, self.slope: [1.03872201 1.03893774], self.intercept: 1.0033437631046964\n",
      "iteration - 3245 -> loss: 0.0003399334501387178, self.slope: [1.03873255 1.03894836], self.intercept: 1.0033447000536946\n",
      "iteration - 3246 -> loss: 0.0003399109845650092, self.slope: [1.03874308 1.03895898], self.intercept: 1.003345636952555\n",
      "iteration - 3247 -> loss: 0.0003398885220601899, self.slope: [1.03875362 1.03896959], self.intercept: 1.0033465738012821\n",
      "iteration - 3248 -> loss: 0.0003398660626236208, self.slope: [1.03876415 1.03898021], self.intercept: 1.0033475105998817\n",
      "iteration - 3249 -> loss: 0.0003398436062546692, self.slope: [1.03877469 1.03899083], self.intercept: 1.0033484473483607\n",
      "iteration - 3250 -> loss: 0.00033982115295271535, self.slope: [1.03878522 1.03900144], self.intercept: 1.003349384046723\n",
      "iteration - 3251 -> loss: 0.00033979870271709435, self.slope: [1.03879575 1.03901206], self.intercept: 1.0033503206949752\n",
      "iteration - 3252 -> loss: 0.0003397762555471722, self.slope: [1.03880629 1.03902267], self.intercept: 1.0033512572931236\n",
      "iteration - 3253 -> loss: 0.0003397538114423218, self.slope: [1.03881682 1.03903328], self.intercept: 1.003352193841174\n",
      "iteration - 3254 -> loss: 0.0003397313704019226, self.slope: [1.03882735 1.0390439 ], self.intercept: 1.0033531303391328\n",
      "iteration - 3255 -> loss: 0.00033970893242532356, self.slope: [1.03883788 1.03905451], self.intercept: 1.003354066787005\n",
      "iteration - 3256 -> loss: 0.00033968649751187687, self.slope: [1.03884841 1.03906512], self.intercept: 1.003355003184796\n",
      "iteration - 3257 -> loss: 0.00033966406566095827, self.slope: [1.03885894 1.03907573], self.intercept: 1.0033559395325145\n",
      "iteration - 3258 -> loss: 0.00033964163687193996, self.slope: [1.03886946 1.03908634], self.intercept: 1.003356875830162\n",
      "iteration - 3259 -> loss: 0.0003396192111441729, self.slope: [1.03887999 1.03909695], self.intercept: 1.0033578120777475\n",
      "iteration - 3260 -> loss: 0.00033959678847701323, self.slope: [1.03889052 1.03910756], self.intercept: 1.0033587482752775\n",
      "iteration - 3261 -> loss: 0.00033957436886985305, self.slope: [1.03890104 1.03911816], self.intercept: 1.0033596844227557\n",
      "iteration - 3262 -> loss: 0.0003395519523220693, self.slope: [1.03891157 1.03912877], self.intercept: 1.0033606205201888\n",
      "iteration - 3263 -> loss: 0.00033952953883296927, self.slope: [1.03892209 1.03913938], self.intercept: 1.0033615565675813\n",
      "iteration - 3264 -> loss: 0.0003395071284019744, self.slope: [1.03893262 1.03914998], self.intercept: 1.0033624925649416\n",
      "iteration - 3265 -> loss: 0.0003394847210284146, self.slope: [1.03894314 1.03916058], self.intercept: 1.0033634285122723\n",
      "iteration - 3266 -> loss: 0.00033946231671166645, self.slope: [1.03895366 1.03917119], self.intercept: 1.0033643644095804\n",
      "iteration - 3267 -> loss: 0.00033943991545111745, self.slope: [1.03896418 1.03918179], self.intercept: 1.0033653002568732\n",
      "iteration - 3268 -> loss: 0.0003394175172461059, self.slope: [1.0389747  1.03919239], self.intercept: 1.0033662360541566\n",
      "iteration - 3269 -> loss: 0.0003393951220960081, self.slope: [1.03898522 1.039203  ], self.intercept: 1.0033671718014348\n",
      "iteration - 3270 -> loss: 0.00033937273000018877, self.slope: [1.03899574 1.0392136 ], self.intercept: 1.0033681074987144\n",
      "iteration - 3271 -> loss: 0.00033935034095802487, self.slope: [1.03900626 1.0392242 ], self.intercept: 1.003369043146001\n",
      "iteration - 3272 -> loss: 0.0003393279549688656, self.slope: [1.03901678 1.0392348 ], self.intercept: 1.003369978743301\n",
      "iteration - 3273 -> loss: 0.00033930557203208926, self.slope: [1.03902729 1.03924539], self.intercept: 1.0033709142906193\n",
      "iteration - 3274 -> loss: 0.00033928319214706737, self.slope: [1.03903781 1.03925599], self.intercept: 1.003371849787962\n",
      "iteration - 3275 -> loss: 0.00033926081531317106, self.slope: [1.03904832 1.03926659], self.intercept: 1.0033727852353362\n",
      "iteration - 3276 -> loss: 0.0003392384415297521, self.slope: [1.03905884 1.03927719], self.intercept: 1.0033737206327455\n",
      "iteration - 3277 -> loss: 0.00033921607079617213, self.slope: [1.03906935 1.03928778], self.intercept: 1.0033746559801995\n",
      "iteration - 3278 -> loss: 0.00033919370311182625, self.slope: [1.03907987 1.03929838], self.intercept: 1.0033755912777012\n",
      "iteration - 3279 -> loss: 0.0003391713384760726, self.slope: [1.03909038 1.03930897], self.intercept: 1.0033765265252557\n",
      "iteration - 3280 -> loss: 0.0003391489768882609, self.slope: [1.03910089 1.03931957], self.intercept: 1.0033774617228697\n",
      "iteration - 3281 -> loss: 0.000339126618347788, self.slope: [1.0391114  1.03933016], self.intercept: 1.0033783968705499\n",
      "iteration - 3282 -> loss: 0.0003391042628539943, self.slope: [1.03912191 1.03934075], self.intercept: 1.0033793319683013\n",
      "iteration - 3283 -> loss: 0.0003390819104062767, self.slope: [1.03913242 1.03935134], self.intercept: 1.00338026701613\n",
      "iteration - 3284 -> loss: 0.0003390595610039874, self.slope: [1.03914293 1.03936193], self.intercept: 1.003381202014043\n",
      "iteration - 3285 -> loss: 0.0003390372146465038, self.slope: [1.03915344 1.03937252], self.intercept: 1.003382136962044\n",
      "iteration - 3286 -> loss: 0.00033901487133319267, self.slope: [1.03916395 1.03938311], self.intercept: 1.0033830718601398\n",
      "iteration - 3287 -> loss: 0.00033899253106342407, self.slope: [1.03917445 1.0393937 ], self.intercept: 1.0033840067083362\n",
      "iteration - 3288 -> loss: 0.0003389701938365559, self.slope: [1.03918496 1.03940429], self.intercept: 1.0033849415066383\n",
      "iteration - 3289 -> loss: 0.00033894785965196575, self.slope: [1.03919547 1.03941488], self.intercept: 1.0033858762550532\n",
      "iteration - 3290 -> loss: 0.0003389255285090392, self.slope: [1.03920597 1.03942546], self.intercept: 1.0033868109535855\n",
      "iteration - 3291 -> loss: 0.0003389032004071394, self.slope: [1.03921647 1.03943605], self.intercept: 1.003387745602242\n",
      "iteration - 3292 -> loss: 0.0003388808753456073, self.slope: [1.03922698 1.03944664], self.intercept: 1.0033886802010274\n",
      "iteration - 3293 -> loss: 0.0003388585533238494, self.slope: [1.03923748 1.03945722], self.intercept: 1.0033896147499488\n",
      "iteration - 3294 -> loss: 0.0003388362343412375, self.slope: [1.03924798 1.0394678 ], self.intercept: 1.0033905492490125\n",
      "iteration - 3295 -> loss: 0.0003388139183971069, self.slope: [1.03925848 1.03947839], self.intercept: 1.0033914836982227\n",
      "iteration - 3296 -> loss: 0.0003387916054908836, self.slope: [1.03926898 1.03948897], self.intercept: 1.0033924180975853\n",
      "iteration - 3297 -> loss: 0.0003387692956218856, self.slope: [1.03927948 1.03949955], self.intercept: 1.003393352447106\n",
      "iteration - 3298 -> loss: 0.00033874698878950065, self.slope: [1.03928998 1.03951013], self.intercept: 1.0033942867467909\n",
      "iteration - 3299 -> loss: 0.00033872468499310997, self.slope: [1.03930048 1.03952071], self.intercept: 1.0033952209966477\n",
      "iteration - 3300 -> loss: 0.0003387023842320934, self.slope: [1.03931098 1.03953129], self.intercept: 1.0033961551966788\n",
      "iteration - 3301 -> loss: 0.0003386800865058121, self.slope: [1.03932147 1.03954187], self.intercept: 1.003397089346892\n",
      "iteration - 3302 -> loss: 0.00033865779181362847, self.slope: [1.03933197 1.03955245], self.intercept: 1.0033980234472948\n",
      "iteration - 3303 -> loss: 0.0003386355001549192, self.slope: [1.03934246 1.03956302], self.intercept: 1.00339895749789\n",
      "iteration - 3304 -> loss: 0.0003386132115290659, self.slope: [1.03935296 1.0395736 ], self.intercept: 1.0033998914986835\n",
      "iteration - 3305 -> loss: 0.0003385909259354372, self.slope: [1.03936345 1.03958418], self.intercept: 1.0034008254496827\n",
      "iteration - 3306 -> loss: 0.00033856864337340135, self.slope: [1.03937395 1.03959475], self.intercept: 1.0034017593508926\n",
      "iteration - 3307 -> loss: 0.00033854636384235, self.slope: [1.03938444 1.03960533], self.intercept: 1.0034026932023195\n",
      "iteration - 3308 -> loss: 0.00033852408734164367, self.slope: [1.03939493 1.0396159 ], self.intercept: 1.0034036270039695\n",
      "iteration - 3309 -> loss: 0.0003385018138706405, self.slope: [1.03940542 1.03962647], self.intercept: 1.0034045607558468\n",
      "iteration - 3310 -> loss: 0.0003384795434287384, self.slope: [1.03941591 1.03963705], self.intercept: 1.0034054944579585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 3311 -> loss: 0.00033845727601529283, self.slope: [1.0394264  1.03964762], self.intercept: 1.0034064281103097\n",
      "iteration - 3312 -> loss: 0.00033843501162970674, self.slope: [1.03943689 1.03965819], self.intercept: 1.003407361712909\n",
      "iteration - 3313 -> loss: 0.00033841275027130647, self.slope: [1.03944738 1.03966876], self.intercept: 1.0034082952657575\n",
      "iteration - 3314 -> loss: 0.0003383904919395093, self.slope: [1.03945786 1.03967933], self.intercept: 1.0034092287688643\n",
      "iteration - 3315 -> loss: 0.0003383682366336684, self.slope: [1.03946835 1.0396899 ], self.intercept: 1.003410162222234\n",
      "iteration - 3316 -> loss: 0.00033834598435315415, self.slope: [1.03947884 1.03970046], self.intercept: 1.0034110956258728\n",
      "iteration - 3317 -> loss: 0.0003383237350973811, self.slope: [1.03948932 1.03971103], self.intercept: 1.0034120289797852\n",
      "iteration - 3318 -> loss: 0.0003383014888656765, self.slope: [1.03949981 1.0397216 ], self.intercept: 1.0034129622839782\n",
      "iteration - 3319 -> loss: 0.0003382792456574343, self.slope: [1.03951029 1.03973216], self.intercept: 1.0034138955384584\n",
      "iteration - 3320 -> loss: 0.0003382570054720262, self.slope: [1.03952077 1.03974273], self.intercept: 1.0034148287432292\n",
      "iteration - 3321 -> loss: 0.00033823476830884046, self.slope: [1.03953125 1.03975329], self.intercept: 1.0034157618982977\n",
      "iteration - 3322 -> loss: 0.0003382125341672355, self.slope: [1.03954174 1.03976386], self.intercept: 1.0034166950036718\n",
      "iteration - 3323 -> loss: 0.0003381903030465975, self.slope: [1.03955222 1.03977442], self.intercept: 1.0034176280593556\n",
      "iteration - 3324 -> loss: 0.0003381680749463148, self.slope: [1.0395627  1.03978498], self.intercept: 1.0034185610653528\n",
      "iteration - 3325 -> loss: 0.00033814584986572666, self.slope: [1.03957318 1.03979554], self.intercept: 1.003419494021672\n",
      "iteration - 3326 -> loss: 0.0003381236278042438, self.slope: [1.03958366 1.03980611], self.intercept: 1.0034204269283178\n",
      "iteration - 3327 -> loss: 0.00033810140876122587, self.slope: [1.03959413 1.03981667], self.intercept: 1.0034213597852963\n",
      "iteration - 3328 -> loss: 0.0003380791927360497, self.slope: [1.03960461 1.03982722], self.intercept: 1.0034222925926122\n",
      "iteration - 3329 -> loss: 0.00033805697972811297, self.slope: [1.03961509 1.03983778], self.intercept: 1.0034232253502726\n",
      "iteration - 3330 -> loss: 0.0003380347697367606, self.slope: [1.03962556 1.03984834], self.intercept: 1.0034241580582823\n",
      "iteration - 3331 -> loss: 0.0003380125627613982, self.slope: [1.03963604 1.0398589 ], self.intercept: 1.0034250907166484\n",
      "iteration - 3332 -> loss: 0.00033799035880139705, self.slope: [1.03964651 1.03986946], self.intercept: 1.003426023325375\n",
      "iteration - 3333 -> loss: 0.000337968157856126, self.slope: [1.03965699 1.03988001], self.intercept: 1.0034269558844702\n",
      "iteration - 3334 -> loss: 0.00033794595992496295, self.slope: [1.03966746 1.03989057], self.intercept: 1.0034278883939387\n",
      "iteration - 3335 -> loss: 0.00033792376500727363, self.slope: [1.03967793 1.03990112], self.intercept: 1.003428820853784\n",
      "iteration - 3336 -> loss: 0.00033790157310246527, self.slope: [1.0396884  1.03991167], self.intercept: 1.003429753264015\n",
      "iteration - 3337 -> loss: 0.0003378793842099087, self.slope: [1.03969887 1.03992223], self.intercept: 1.003430685624635\n",
      "iteration - 3338 -> loss: 0.00033785719832896426, self.slope: [1.03970934 1.03993278], self.intercept: 1.0034316179356517\n",
      "iteration - 3339 -> loss: 0.00033783501545903247, self.slope: [1.03971981 1.03994333], self.intercept: 1.0034325501970713\n",
      "iteration - 3340 -> loss: 0.000337812835599482, self.slope: [1.03973028 1.03995388], self.intercept: 1.0034334824088977\n",
      "iteration - 3341 -> loss: 0.00033779065874968867, self.slope: [1.03974075 1.03996443], self.intercept: 1.0034344145711385\n",
      "iteration - 3342 -> loss: 0.0003377684849090476, self.slope: [1.03975122 1.03997498], self.intercept: 1.0034353466837975\n",
      "iteration - 3343 -> loss: 0.0003377463140769173, self.slope: [1.03976168 1.03998553], self.intercept: 1.0034362787468816\n",
      "iteration - 3344 -> loss: 0.0003377241462526763, self.slope: [1.03977215 1.03999608], self.intercept: 1.003437210760396\n",
      "iteration - 3345 -> loss: 0.00033770198143572233, self.slope: [1.03978261 1.04000663], self.intercept: 1.003438142724347\n",
      "iteration - 3346 -> loss: 0.0003376798196254252, self.slope: [1.03979308 1.04001717], self.intercept: 1.0034390746387396\n",
      "iteration - 3347 -> loss: 0.0003376576608211735, self.slope: [1.03980354 1.04002772], self.intercept: 1.0034400065035805\n",
      "iteration - 3348 -> loss: 0.0003376355050223285, self.slope: [1.039814   1.04003826], self.intercept: 1.0034409383188747\n",
      "iteration - 3349 -> loss: 0.00033761335222829667, self.slope: [1.03982447 1.04004881], self.intercept: 1.003441870084629\n",
      "iteration - 3350 -> loss: 0.00033759120243843867, self.slope: [1.03983493 1.04005935], self.intercept: 1.003442801800846\n",
      "iteration - 3351 -> loss: 0.0003375690556521425, self.slope: [1.03984539 1.0400699 ], self.intercept: 1.0034437334675366\n",
      "iteration - 3352 -> loss: 0.00033754691186878657, self.slope: [1.03985585 1.04008044], self.intercept: 1.003444665084704\n",
      "iteration - 3353 -> loss: 0.0003375247710877505, self.slope: [1.03986631 1.04009098], self.intercept: 1.0034455966523526\n",
      "iteration - 3354 -> loss: 0.0003375026333084153, self.slope: [1.03987677 1.04010152], self.intercept: 1.0034465281704898\n",
      "iteration - 3355 -> loss: 0.00033748049853017604, self.slope: [1.03988722 1.04011206], self.intercept: 1.0034474596391212\n",
      "iteration - 3356 -> loss: 0.00033745836675240867, self.slope: [1.03989768 1.0401226 ], self.intercept: 1.003448391058252\n",
      "iteration - 3357 -> loss: 0.00033743623797446705, self.slope: [1.03990814 1.04013314], self.intercept: 1.0034493224278873\n",
      "iteration - 3358 -> loss: 0.0003374141121957823, self.slope: [1.03991859 1.04014368], self.intercept: 1.0034502537480343\n",
      "iteration - 3359 -> loss: 0.00033739198941569915, self.slope: [1.03992905 1.04015422], self.intercept: 1.0034511850186985\n",
      "iteration - 3360 -> loss: 0.00033736986963359757, self.slope: [1.0399395  1.04016475], self.intercept: 1.0034521162398853\n",
      "iteration - 3361 -> loss: 0.0003373477528488807, self.slope: [1.03994996 1.04017529], self.intercept: 1.003453047411601\n",
      "iteration - 3362 -> loss: 0.000337325639060932, self.slope: [1.03996041 1.04018582], self.intercept: 1.0034539785338503\n",
      "iteration - 3363 -> loss: 0.0003373035282691225, self.slope: [1.03997086 1.04019636], self.intercept: 1.0034549096066394\n",
      "iteration - 3364 -> loss: 0.0003372814204728408, self.slope: [1.03998131 1.04020689], self.intercept: 1.003455840629974\n",
      "iteration - 3365 -> loss: 0.0003372593156714657, self.slope: [1.03999176 1.04021743], self.intercept: 1.0034567716038616\n",
      "iteration - 3366 -> loss: 0.00033723721386439483, self.slope: [1.04000221 1.04022796], self.intercept: 1.0034577025283047\n",
      "iteration - 3367 -> loss: 0.0003372151150509879, self.slope: [1.04001266 1.04023849], self.intercept: 1.0034586334033098\n",
      "iteration - 3368 -> loss: 0.00033719301923063624, self.slope: [1.04002311 1.04024902], self.intercept: 1.0034595642288848\n",
      "iteration - 3369 -> loss: 0.00033717092640273504, self.slope: [1.04003356 1.04025955], self.intercept: 1.0034604950050345\n",
      "iteration - 3370 -> loss: 0.0003371488365666549, self.slope: [1.04004401 1.04027008], self.intercept: 1.0034614257317642\n",
      "iteration - 3371 -> loss: 0.0003371267497217931, self.slope: [1.04005445 1.04028061], self.intercept: 1.0034623564090799\n",
      "iteration - 3372 -> loss: 0.0003371046658675367, self.slope: [1.0400649  1.04029114], self.intercept: 1.0034632870369866\n",
      "iteration - 3373 -> loss: 0.0003370825850032421, self.slope: [1.04007534 1.04030167], self.intercept: 1.0034642176154913\n",
      "iteration - 3374 -> loss: 0.00033706050712832986, self.slope: [1.04008579 1.04031219], self.intercept: 1.0034651481445966\n",
      "iteration - 3375 -> loss: 0.0003370384322421607, self.slope: [1.04009623 1.04032272], self.intercept: 1.0034660786243128\n",
      "iteration - 3376 -> loss: 0.0003370163603441238, self.slope: [1.04010667 1.04033324], self.intercept: 1.003467009054643\n",
      "iteration - 3377 -> loss: 0.00033699429143360643, self.slope: [1.04011712 1.04034377], self.intercept: 1.0034679394355928\n",
      "iteration - 3378 -> loss: 0.0003369722255099876, self.slope: [1.04012756 1.04035429], self.intercept: 1.003468869767169\n",
      "iteration - 3379 -> loss: 0.0003369501625726794, self.slope: [1.040138   1.04036482], self.intercept: 1.0034698000493791\n",
      "iteration - 3380 -> loss: 0.00033692810262104037, self.slope: [1.04014844 1.04037534], self.intercept: 1.0034707302822248\n",
      "iteration - 3381 -> loss: 0.00033690604565445227, self.slope: [1.04015888 1.04038586], self.intercept: 1.0034716604657128\n",
      "iteration - 3382 -> loss: 0.000336883991672325, self.slope: [1.04016932 1.04039638], self.intercept: 1.00347259059985\n",
      "iteration - 3383 -> loss: 0.00033686194067402623, self.slope: [1.04017975 1.0404069 ], self.intercept: 1.0034735206846432\n",
      "iteration - 3384 -> loss: 0.0003368398926589484, self.slope: [1.04019019 1.04041742], self.intercept: 1.0034744507200946\n",
      "iteration - 3385 -> loss: 0.0003368178476264836, self.slope: [1.04020063 1.04042794], self.intercept: 1.0034753807062111\n",
      "iteration - 3386 -> loss: 0.00033679580557601847, self.slope: [1.04021106 1.04043846], self.intercept: 1.0034763106429996\n",
      "iteration - 3387 -> loss: 0.00033677376650692245, self.slope: [1.0402215  1.04044898], self.intercept: 1.0034772405304666\n",
      "iteration - 3388 -> loss: 0.0003367517304186031, self.slope: [1.04023193 1.04045949], self.intercept: 1.0034781703686169\n",
      "iteration - 3389 -> loss: 0.00033672969731044243, self.slope: [1.04024237 1.04047001], self.intercept: 1.0034791001574561\n",
      "iteration - 3390 -> loss: 0.00033670766718180736, self.slope: [1.0402528  1.04048053], self.intercept: 1.0034800298969908\n",
      "iteration - 3391 -> loss: 0.0003366856400321104, self.slope: [1.04026323 1.04049104], self.intercept: 1.003480959587225\n",
      "iteration - 3392 -> loss: 0.0003366636158607421, self.slope: [1.04027366 1.04050155], self.intercept: 1.0034818892281665\n",
      "iteration - 3393 -> loss: 0.0003366415946670769, self.slope: [1.04028409 1.04051207], self.intercept: 1.0034828188198184\n",
      "iteration - 3394 -> loss: 0.0003366195764505047, self.slope: [1.04029452 1.04052258], self.intercept: 1.0034837483621872\n",
      "iteration - 3395 -> loss: 0.0003365975612104156, self.slope: [1.04030495 1.04053309], self.intercept: 1.0034846778552797\n",
      "iteration - 3396 -> loss: 0.0003365755489461873, self.slope: [1.04031538 1.0405436 ], self.intercept: 1.0034856072991005\n",
      "iteration - 3397 -> loss: 0.0003365535396572356, self.slope: [1.04032581 1.04055411], self.intercept: 1.003486536693656\n",
      "iteration - 3398 -> loss: 0.00033653153334291974, self.slope: [1.04033624 1.04056462], self.intercept: 1.003487466038953\n",
      "iteration - 3399 -> loss: 0.00033650953000264, self.slope: [1.04034666 1.04057513], self.intercept: 1.003488395334994\n",
      "iteration - 3400 -> loss: 0.000336487529635791, self.slope: [1.04035709 1.04058564], self.intercept: 1.0034893245817869\n",
      "iteration - 3401 -> loss: 0.000336465532241757, self.slope: [1.04036751 1.04059615], self.intercept: 1.0034902537793364\n",
      "iteration - 3402 -> loss: 0.00033644353781993026, self.slope: [1.04037794 1.04060666], self.intercept: 1.0034911829276514\n",
      "iteration - 3403 -> loss: 0.00033642154636970246, self.slope: [1.04038836 1.04061716], self.intercept: 1.0034921120267328\n",
      "iteration - 3404 -> loss: 0.0003363995578904551, self.slope: [1.04039879 1.04062767], self.intercept: 1.003493041076589\n",
      "iteration - 3405 -> loss: 0.00033637757238157774, self.slope: [1.04040921 1.04063817], self.intercept: 1.003493970077226\n",
      "iteration - 3406 -> loss: 0.00033635558984247265, self.slope: [1.04041963 1.04064868], self.intercept: 1.0034948990286496\n",
      "iteration - 3407 -> loss: 0.00033633361027251646, self.slope: [1.04043005 1.04065918], self.intercept: 1.003495827930864\n",
      "iteration - 3408 -> loss: 0.0003363116336711165, self.slope: [1.04044047 1.04066968], self.intercept: 1.003496756783876\n",
      "iteration - 3409 -> loss: 0.00033628966003763157, self.slope: [1.04045089 1.04068019], self.intercept: 1.0034976855876911\n",
      "iteration - 3410 -> loss: 0.000336267689371475, self.slope: [1.04046131 1.04069069], self.intercept: 1.0034986143423157\n",
      "iteration - 3411 -> loss: 0.0003362457216720493, self.slope: [1.04047173 1.04070119], self.intercept: 1.0034995430477531\n",
      "iteration - 3412 -> loss: 0.00033622375693873334, self.slope: [1.04048214 1.04071169], self.intercept: 1.0035004717040121\n",
      "iteration - 3413 -> loss: 0.000336201795170905, self.slope: [1.04049256 1.04072219], self.intercept: 1.0035014003110956\n",
      "iteration - 3414 -> loss: 0.0003361798363679662, self.slope: [1.04050298 1.04073269], self.intercept: 1.0035023288690108\n",
      "iteration - 3415 -> loss: 0.00033615788052932845, self.slope: [1.04051339 1.04074318], self.intercept: 1.0035032573777625\n",
      "iteration - 3416 -> loss: 0.00033613592765435214, self.slope: [1.04052381 1.04075368], self.intercept: 1.003504185837357\n",
      "iteration - 3417 -> loss: 0.00033611397774244546, self.slope: [1.04053422 1.04076418], self.intercept: 1.0035051142478009\n",
      "iteration - 3418 -> loss: 0.0003360920307930114, self.slope: [1.04054463 1.04077467], self.intercept: 1.0035060426090983\n",
      "iteration - 3419 -> loss: 0.00033607008680540287, self.slope: [1.04055504 1.04078517], self.intercept: 1.0035069709212552\n",
      "iteration - 3420 -> loss: 0.00033604814577905146, self.slope: [1.04056546 1.04079566], self.intercept: 1.0035078991842776\n",
      "iteration - 3421 -> loss: 0.0003360262077133291, self.slope: [1.04057587 1.04080616], self.intercept: 1.0035088273981723\n",
      "iteration - 3422 -> loss: 0.00033600427260764164, self.slope: [1.04058628 1.04081665], self.intercept: 1.0035097555629438\n",
      "iteration - 3423 -> loss: 0.00033598234046136675, self.slope: [1.04059669 1.04082714], self.intercept: 1.003510683678598\n",
      "iteration - 3424 -> loss: 0.00033596041127391716, self.slope: [1.04060709 1.04083763], self.intercept: 1.0035116117451406\n",
      "iteration - 3425 -> loss: 0.0003359384850446654, self.slope: [1.0406175  1.04084813], self.intercept: 1.003512539762577\n",
      "iteration - 3426 -> loss: 0.0003359165617730092, self.slope: [1.04062791 1.04085862], self.intercept: 1.0035134677309125\n",
      "iteration - 3427 -> loss: 0.00033589464145837236, self.slope: [1.04063832 1.0408691 ], self.intercept: 1.0035143956501538\n",
      "iteration - 3428 -> loss: 0.0003358727241001146, self.slope: [1.04064872 1.04087959], self.intercept: 1.0035153235203067\n",
      "iteration - 3429 -> loss: 0.0003358508096976294, self.slope: [1.04065913 1.04089008], self.intercept: 1.0035162513413745\n",
      "iteration - 3430 -> loss: 0.0003358288982503422, self.slope: [1.04066953 1.04090057], self.intercept: 1.0035171791133661\n",
      "iteration - 3431 -> loss: 0.0003358069897576002, self.slope: [1.04067994 1.04091106], self.intercept: 1.0035181068362848\n",
      "iteration - 3432 -> loss: 0.00033578508421883743, self.slope: [1.04069034 1.04092154], self.intercept: 1.0035190345101375\n",
      "iteration - 3433 -> loss: 0.0003357631816334368, self.slope: [1.04070074 1.04093203], self.intercept: 1.00351996213493\n",
      "iteration - 3434 -> loss: 0.0003357412820007831, self.slope: [1.04071114 1.04094251], self.intercept: 1.003520889710668\n",
      "iteration - 3435 -> loss: 0.00033571938532029293, self.slope: [1.04072154 1.040953  ], self.intercept: 1.0035218172373557\n",
      "iteration - 3436 -> loss: 0.0003356974915913385, self.slope: [1.04073194 1.04096348], self.intercept: 1.0035227447149997\n",
      "iteration - 3437 -> loss: 0.0003356756008133302, self.slope: [1.04074234 1.04097396], self.intercept: 1.003523672143606\n",
      "iteration - 3438 -> loss: 0.00033565371298565803, self.slope: [1.04075274 1.04098444], self.intercept: 1.0035245995231796\n",
      "iteration - 3439 -> loss: 0.00033563182810769496, self.slope: [1.04076314 1.04099492], self.intercept: 1.0035255268537262\n",
      "iteration - 3440 -> loss: 0.00033560994617887717, self.slope: [1.04077354 1.0410054 ], self.intercept: 1.0035264541352515\n",
      "iteration - 3441 -> loss: 0.0003355880671985845, self.slope: [1.04078393 1.04101588], self.intercept: 1.0035273813677619\n",
      "iteration - 3442 -> loss: 0.00033556619116621104, self.slope: [1.04079433 1.04102636], self.intercept: 1.0035283085512636\n",
      "iteration - 3443 -> loss: 0.0003355443180811407, self.slope: [1.04080473 1.04103684], self.intercept: 1.003529235685761\n",
      "iteration - 3444 -> loss: 0.0003355224479427967, self.slope: [1.04081512 1.04104732], self.intercept: 1.003530162771258\n",
      "iteration - 3445 -> loss: 0.0003355005807505543, self.slope: [1.04082551 1.0410578 ], self.intercept: 1.0035310898077643\n",
      "iteration - 3446 -> loss: 0.0003354787165038225, self.slope: [1.04083591 1.04106827], self.intercept: 1.0035320167952821\n",
      "iteration - 3447 -> loss: 0.0003354568552019824, self.slope: [1.0408463  1.04107875], self.intercept: 1.00353294373382\n",
      "iteration - 3448 -> loss: 0.0003354349968444487, self.slope: [1.04085669 1.04108922], self.intercept: 1.003533870623381\n",
      "iteration - 3449 -> loss: 0.0003354131414306201, self.slope: [1.04086708 1.0410997 ], self.intercept: 1.0035347974639723\n",
      "iteration - 3450 -> loss: 0.0003353912889598659, self.slope: [1.04087747 1.04111017], self.intercept: 1.0035357242555998\n",
      "iteration - 3451 -> loss: 0.000335369439431625, self.slope: [1.04088786 1.04112064], self.intercept: 1.0035366509982684\n",
      "iteration - 3452 -> loss: 0.0003353475928452559, self.slope: [1.04089825 1.04113111], self.intercept: 1.003537577691984\n",
      "iteration - 3453 -> loss: 0.00033532574920017497, self.slope: [1.04090864 1.04114159], self.intercept: 1.0035385043367524\n",
      "iteration - 3454 -> loss: 0.0003353039084957988, self.slope: [1.04091903 1.04115206], self.intercept: 1.0035394309325782\n",
      "iteration - 3455 -> loss: 0.0003352820707314842, self.slope: [1.04092941 1.04116253], self.intercept: 1.003540357479469\n",
      "iteration - 3456 -> loss: 0.0003352602359066647, self.slope: [1.0409398  1.04117299], self.intercept: 1.0035412839774291\n",
      "iteration - 3457 -> loss: 0.0003352384040207131, self.slope: [1.04095019 1.04118346], self.intercept: 1.0035422104264629\n",
      "iteration - 3458 -> loss: 0.0003352165750730693, self.slope: [1.04096057 1.04119393], self.intercept: 1.0035431368265777\n",
      "iteration - 3459 -> loss: 0.00033519474906306963, self.slope: [1.04097095 1.0412044 ], self.intercept: 1.0035440631777786\n",
      "iteration - 3460 -> loss: 0.0003351729259901705, self.slope: [1.04098134 1.04121486], self.intercept: 1.0035449894800719\n",
      "iteration - 3461 -> loss: 0.00033515110585374255, self.slope: [1.04099172 1.04122533], self.intercept: 1.0035459157334636\n",
      "iteration - 3462 -> loss: 0.00033512928865319286, self.slope: [1.0410021 1.0412358], self.intercept: 1.003546841937958\n",
      "iteration - 3463 -> loss: 0.00033510747438790555, self.slope: [1.04101248 1.04124626], self.intercept: 1.003547768093562\n",
      "iteration - 3464 -> loss: 0.0003350856630573169, self.slope: [1.04102286 1.04125672], self.intercept: 1.00354869420028\n",
      "iteration - 3465 -> loss: 0.0003350638546607885, self.slope: [1.04103324 1.04126719], self.intercept: 1.0035496202581184\n",
      "iteration - 3466 -> loss: 0.0003350420491977322, self.slope: [1.04104362 1.04127765], self.intercept: 1.0035505462670833\n",
      "iteration - 3467 -> loss: 0.0003350202466675634, self.slope: [1.041054   1.04128811], self.intercept: 1.0035514722271803\n",
      "iteration - 3468 -> loss: 0.00033499844706965217, self.slope: [1.04106438 1.04129857], self.intercept: 1.0035523981384145\n",
      "iteration - 3469 -> loss: 0.0003349766504034282, self.slope: [1.04107476 1.04130903], self.intercept: 1.0035533240007908\n",
      "iteration - 3470 -> loss: 0.0003349548566682936, self.slope: [1.04108513 1.04131949], self.intercept: 1.0035542498143148\n",
      "iteration - 3471 -> loss: 0.00033493306586362883, self.slope: [1.04109551 1.04132995], self.intercept: 1.003555175578993\n",
      "iteration - 3472 -> loss: 0.00033491127798884, self.slope: [1.04110588 1.04134041], self.intercept: 1.0035561012948302\n",
      "iteration - 3473 -> loss: 0.00033488949304334215, self.slope: [1.04111626 1.04135086], self.intercept: 1.0035570269618346\n",
      "iteration - 3474 -> loss: 0.0003348677110265007, self.slope: [1.04112663 1.04136132], self.intercept: 1.0035579525800091\n",
      "iteration - 3475 -> loss: 0.0003348459319377916, self.slope: [1.041137   1.04137178], self.intercept: 1.0035588781493607\n",
      "iteration - 3476 -> loss: 0.000334824155776529, self.slope: [1.04114737 1.04138223], self.intercept: 1.0035598036698938\n",
      "iteration - 3477 -> loss: 0.0003348023825421499, self.slope: [1.04115775 1.04139269], self.intercept: 1.0035607291416153\n",
      "iteration - 3478 -> loss: 0.00033478061223407893, self.slope: [1.04116812 1.04140314], self.intercept: 1.0035616545645298\n",
      "iteration - 3479 -> loss: 0.00033475884485170595, self.slope: [1.04117849 1.04141359], self.intercept: 1.0035625799386432\n",
      "iteration - 3480 -> loss: 0.0003347370803944133, self.slope: [1.04118886 1.04142405], self.intercept: 1.003563505263962\n",
      "iteration - 3481 -> loss: 0.00033471531886162707, self.slope: [1.04119922 1.0414345 ], self.intercept: 1.0035644305404907\n",
      "iteration - 3482 -> loss: 0.0003346935602527078, self.slope: [1.04120959 1.04144495], self.intercept: 1.003565355768236\n",
      "iteration - 3483 -> loss: 0.00033467180456712634, self.slope: [1.04121996 1.0414554 ], self.intercept: 1.0035662809472015\n",
      "iteration - 3484 -> loss: 0.000334650051804243, self.slope: [1.04123033 1.04146585], self.intercept: 1.003567206077395\n",
      "iteration - 3485 -> loss: 0.00033462830196345317, self.slope: [1.04124069 1.0414763 ], self.intercept: 1.0035681311588225\n",
      "iteration - 3486 -> loss: 0.0003346065550441931, self.slope: [1.04125106 1.04148675], self.intercept: 1.003569056191487\n",
      "iteration - 3487 -> loss: 0.0003345848110458455, self.slope: [1.04126142 1.04149719], self.intercept: 1.0035699811753953\n",
      "iteration - 3488 -> loss: 0.0003345630699678153, self.slope: [1.04127178 1.04150764], self.intercept: 1.0035709061105536\n",
      "iteration - 3489 -> loss: 0.00033454133180950847, self.slope: [1.04128215 1.04151809], self.intercept: 1.0035718309969681\n",
      "iteration - 3490 -> loss: 0.00033451959657032247, self.slope: [1.04129251 1.04152853], self.intercept: 1.0035727558346421\n",
      "iteration - 3491 -> loss: 0.0003344978642496605, self.slope: [1.04130287 1.04153898], self.intercept: 1.0035736806235835\n",
      "iteration - 3492 -> loss: 0.00033447613484695023, self.slope: [1.04131323 1.04154942], self.intercept: 1.0035746053637973\n",
      "iteration - 3493 -> loss: 0.00033445440836156844, self.slope: [1.04132359 1.04155986], self.intercept: 1.0035755300552887\n",
      "iteration - 3494 -> loss: 0.00033443268479292957, self.slope: [1.04133395 1.04157031], self.intercept: 1.0035764546980626\n",
      "iteration - 3495 -> loss: 0.00033441096414045524, self.slope: [1.04134431 1.04158075], self.intercept: 1.0035773792921254\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 3496 -> loss: 0.00033438924640352816, self.slope: [1.04135467 1.04159119], self.intercept: 1.0035783038374828\n",
      "iteration - 3497 -> loss: 0.00033436753158155944, self.slope: [1.04136502 1.04160163], self.intercept: 1.003579228334141\n",
      "iteration - 3498 -> loss: 0.00033434581967395257, self.slope: [1.04137538 1.04161207], self.intercept: 1.0035801527821049\n",
      "iteration - 3499 -> loss: 0.00033432411068011627, self.slope: [1.04138574 1.04162251], self.intercept: 1.0035810771813796\n",
      "iteration - 3500 -> loss: 0.0003343024045994635, self.slope: [1.04139609 1.04163295], self.intercept: 1.0035820015319719\n",
      "iteration - 3501 -> loss: 0.0003342807014313936, self.slope: [1.04140645 1.04164339], self.intercept: 1.0035829258338862\n",
      "iteration - 3502 -> loss: 0.0003342590011753085, self.slope: [1.0414168  1.04165382], self.intercept: 1.0035838500871288\n",
      "iteration - 3503 -> loss: 0.00033423730383060665, self.slope: [1.04142715 1.04166426], self.intercept: 1.0035847742917061\n",
      "iteration - 3504 -> loss: 0.0003342156093967185, self.slope: [1.04143751 1.04167469], self.intercept: 1.0035856984476226\n",
      "iteration - 3505 -> loss: 0.0003341939178730261, self.slope: [1.04144786 1.04168513], self.intercept: 1.0035866225548842\n",
      "iteration - 3506 -> loss: 0.0003341722292589525, self.slope: [1.04145821 1.04169556], self.intercept: 1.0035875466134965\n",
      "iteration - 3507 -> loss: 0.00033415054355389576, self.slope: [1.04146856 1.041706  ], self.intercept: 1.0035884706234643\n",
      "iteration - 3508 -> loss: 0.00033412886075727307, self.slope: [1.04147891 1.04171643], self.intercept: 1.003589394584794\n",
      "iteration - 3509 -> loss: 0.00033410718086848695, self.slope: [1.04148926 1.04172686], self.intercept: 1.003590318497492\n",
      "iteration - 3510 -> loss: 0.000334085503886932, self.slope: [1.0414996  1.04173729], self.intercept: 1.0035912423615605\n",
      "iteration - 3511 -> loss: 0.0003340638298120398, self.slope: [1.04150995 1.04174773], self.intercept: 1.0035921661770089\n",
      "iteration - 3512 -> loss: 0.000334042158643187, self.slope: [1.0415203  1.04175816], self.intercept: 1.003593089943841\n",
      "iteration - 3513 -> loss: 0.0003340204903798144, self.slope: [1.04153065 1.04176858], self.intercept: 1.0035940136620625\n",
      "iteration - 3514 -> loss: 0.00033399882502130085, self.slope: [1.04154099 1.04177901], self.intercept: 1.0035949373316804\n",
      "iteration - 3515 -> loss: 0.00033397716256708447, self.slope: [1.04155134 1.04178944], self.intercept: 1.003595860952699\n",
      "iteration - 3516 -> loss: 0.0003339555030165321, self.slope: [1.04156168 1.04179987], self.intercept: 1.0035967845251246\n",
      "iteration - 3517 -> loss: 0.00033393384636909586, self.slope: [1.04157202 1.0418103 ], self.intercept: 1.0035977080489615\n",
      "iteration - 3518 -> loss: 0.0003339121926241529, self.slope: [1.04158236 1.04182072], self.intercept: 1.0035986315242156\n",
      "iteration - 3519 -> loss: 0.00033389054178114164, self.slope: [1.04159271 1.04183115], self.intercept: 1.0035995549508936\n",
      "iteration - 3520 -> loss: 0.0003338688938394431, self.slope: [1.04160305 1.04184157], self.intercept: 1.0036004783290013\n",
      "iteration - 3521 -> loss: 0.0003338472487984731, self.slope: [1.04161339 1.041852  ], self.intercept: 1.0036014016585428\n",
      "iteration - 3522 -> loss: 0.00033382560665764583, self.slope: [1.04162373 1.04186242], self.intercept: 1.0036023249395236\n",
      "iteration - 3523 -> loss: 0.00033380396741636737, self.slope: [1.04163407 1.04187284], self.intercept: 1.0036032481719517\n",
      "iteration - 3524 -> loss: 0.00033378233107405415, self.slope: [1.04164441 1.04188326], self.intercept: 1.0036041713558292\n",
      "iteration - 3525 -> loss: 0.00033376069763010457, self.slope: [1.04165474 1.04189368], self.intercept: 1.0036050944911645\n",
      "iteration - 3526 -> loss: 0.000333739067083956, self.slope: [1.04166508 1.0419041 ], self.intercept: 1.0036060175779618\n",
      "iteration - 3527 -> loss: 0.00033371743943498707, self.slope: [1.04167542 1.04191452], self.intercept: 1.0036069406162258\n",
      "iteration - 3528 -> loss: 0.00033369581468260573, self.slope: [1.04168575 1.04192494], self.intercept: 1.0036078636059638\n",
      "iteration - 3529 -> loss: 0.00033367419282624114, self.slope: [1.04169609 1.04193536], self.intercept: 1.0036087865471814\n",
      "iteration - 3530 -> loss: 0.00033365257386530086, self.slope: [1.04170642 1.04194578], self.intercept: 1.0036097094398815\n",
      "iteration - 3531 -> loss: 0.00033363095779919425, self.slope: [1.04171675 1.0419562 ], self.intercept: 1.003610632284073\n",
      "iteration - 3532 -> loss: 0.00033360934462732387, self.slope: [1.04172709 1.04196661], self.intercept: 1.0036115550797613\n",
      "iteration - 3533 -> loss: 0.0003335877343491038, self.slope: [1.04173742 1.04197703], self.intercept: 1.0036124778269515\n",
      "iteration - 3534 -> loss: 0.00033356612696396537, self.slope: [1.04174775 1.04198744], self.intercept: 1.0036134005256478\n",
      "iteration - 3535 -> loss: 0.00033354452247127546, self.slope: [1.04175808 1.04199786], self.intercept: 1.0036143231758567\n",
      "iteration - 3536 -> loss: 0.0003335229208705032, self.slope: [1.04176841 1.04200827], self.intercept: 1.0036152457775822\n",
      "iteration - 3537 -> loss: 0.0003335013221610198, self.slope: [1.04177874 1.04201868], self.intercept: 1.0036161683308316\n",
      "iteration - 3538 -> loss: 0.0003334797263422476, self.slope: [1.04178907 1.0420291 ], self.intercept: 1.0036170908356106\n",
      "iteration - 3539 -> loss: 0.00033345813341359546, self.slope: [1.0417994  1.04203951], self.intercept: 1.0036180132919255\n",
      "iteration - 3540 -> loss: 0.00033343654337446944, self.slope: [1.04180972 1.04204992], self.intercept: 1.003618935699781\n",
      "iteration - 3541 -> loss: 0.00033341495622429905, self.slope: [1.04182005 1.04206033], self.intercept: 1.0036198580591822\n",
      "iteration - 3542 -> loss: 0.00033339337196249853, self.slope: [1.04183038 1.04207074], self.intercept: 1.003620780370133\n",
      "iteration - 3543 -> loss: 0.0003333717905884407, self.slope: [1.0418407  1.04208115], self.intercept: 1.0036217026326417\n",
      "iteration - 3544 -> loss: 0.00033335021210159605, self.slope: [1.04185103 1.04209155], self.intercept: 1.0036226248467135\n",
      "iteration - 3545 -> loss: 0.000333328636501351, self.slope: [1.04186135 1.04210196], self.intercept: 1.0036235470123538\n",
      "iteration - 3546 -> loss: 0.00033330706378711657, self.slope: [1.04187167 1.04211237], self.intercept: 1.003624469129567\n",
      "iteration - 3547 -> loss: 0.0003332854939582885, self.slope: [1.04188199 1.04212277], self.intercept: 1.0036253911983593\n",
      "iteration - 3548 -> loss: 0.00033326392701429875, self.slope: [1.04189232 1.04213318], self.intercept: 1.0036263132187355\n",
      "iteration - 3549 -> loss: 0.00033324236295458135, self.slope: [1.04190264 1.04214358], self.intercept: 1.003627235190703\n",
      "iteration - 3550 -> loss: 0.0003332208017785128, self.slope: [1.04191296 1.04215399], self.intercept: 1.0036281571142671\n",
      "iteration - 3551 -> loss: 0.0003331992434855134, self.slope: [1.04192328 1.04216439], self.intercept: 1.0036290789894318\n",
      "iteration - 3552 -> loss: 0.0003331776880750419, self.slope: [1.0419336  1.04217479], self.intercept: 1.003630000816204\n",
      "iteration - 3553 -> loss: 0.0003331561355464433, self.slope: [1.04194391 1.0421852 ], self.intercept: 1.0036309225945887\n",
      "iteration - 3554 -> loss: 0.00033313458589918384, self.slope: [1.04195423 1.0421956 ], self.intercept: 1.0036318443245904\n",
      "iteration - 3555 -> loss: 0.0003331130391326565, self.slope: [1.04196455 1.042206  ], self.intercept: 1.003632766006216\n",
      "iteration - 3556 -> loss: 0.00033309149524628006, self.slope: [1.04197486 1.0422164 ], self.intercept: 1.0036336876394714\n",
      "iteration - 3557 -> loss: 0.0003330699542394767, self.slope: [1.04198518 1.0422268 ], self.intercept: 1.0036346092243607\n",
      "iteration - 3558 -> loss: 0.00033304841611163773, self.slope: [1.04199549 1.04223719], self.intercept: 1.0036355307608902\n",
      "iteration - 3559 -> loss: 0.0003330268808621981, self.slope: [1.04200581 1.04224759], self.intercept: 1.0036364522490653\n",
      "iteration - 3560 -> loss: 0.00033300534849057503, self.slope: [1.04201612 1.04225799], self.intercept: 1.0036373736888926\n",
      "iteration - 3561 -> loss: 0.0003329838189961766, self.slope: [1.04202643 1.04226839], self.intercept: 1.0036382950803773\n",
      "iteration - 3562 -> loss: 0.00033296229237842227, self.slope: [1.04203675 1.04227878], self.intercept: 1.0036392164235222\n",
      "iteration - 3563 -> loss: 0.00033294076863673173, self.slope: [1.04204706 1.04228918], self.intercept: 1.0036401377183364\n",
      "iteration - 3564 -> loss: 0.0003329192477705005, self.slope: [1.04205737 1.04229957], self.intercept: 1.0036410589648244\n",
      "iteration - 3565 -> loss: 0.00033289772977917407, self.slope: [1.04206768 1.04230996], self.intercept: 1.0036419801629926\n",
      "iteration - 3566 -> loss: 0.0003328762146621494, self.slope: [1.04207799 1.04232036], self.intercept: 1.0036429013128434\n",
      "iteration - 3567 -> loss: 0.000332854702418849, self.slope: [1.04208829 1.04233075], self.intercept: 1.0036438224143849\n",
      "iteration - 3568 -> loss: 0.00033283319304868163, self.slope: [1.0420986  1.04234114], self.intercept: 1.0036447434676226\n",
      "iteration - 3569 -> loss: 0.00033281168655107524, self.slope: [1.04210891 1.04235153], self.intercept: 1.003645664472561\n",
      "iteration - 3570 -> loss: 0.0003327901829254418, self.slope: [1.04211922 1.04236192], self.intercept: 1.0036465854292056\n",
      "iteration - 3571 -> loss: 0.00033276868217119567, self.slope: [1.04212952 1.04237231], self.intercept: 1.0036475063375634\n",
      "iteration - 3572 -> loss: 0.0003327471842877585, self.slope: [1.04213983 1.0423827 ], self.intercept: 1.0036484271976376\n",
      "iteration - 3573 -> loss: 0.0003327256892745447, self.slope: [1.04215013 1.04239309], self.intercept: 1.0036493480094364\n",
      "iteration - 3574 -> loss: 0.0003327041971309796, self.slope: [1.04216043 1.04240347], self.intercept: 1.003650268772963\n",
      "iteration - 3575 -> loss: 0.0003326827078564653, self.slope: [1.04217074 1.04241386], self.intercept: 1.0036511894882243\n",
      "iteration - 3576 -> loss: 0.0003326612214504324, self.slope: [1.04218104 1.04242425], self.intercept: 1.003652110155226\n",
      "iteration - 3577 -> loss: 0.00033263973791228913, self.slope: [1.04219134 1.04243463], self.intercept: 1.0036530307739733\n",
      "iteration - 3578 -> loss: 0.00033261825724147873, self.slope: [1.04220164 1.04244502], self.intercept: 1.0036539513444718\n",
      "iteration - 3579 -> loss: 0.0003325967794374006, self.slope: [1.04221194 1.0424554 ], self.intercept: 1.0036548718667269\n",
      "iteration - 3580 -> loss: 0.00033257530449944795, self.slope: [1.04222224 1.04246578], self.intercept: 1.0036557923407425\n",
      "iteration - 3581 -> loss: 0.00033255383242708996, self.slope: [1.04223254 1.04247617], self.intercept: 1.0036567127665263\n",
      "iteration - 3582 -> loss: 0.00033253236321970753, self.slope: [1.04224284 1.04248655], self.intercept: 1.0036576331440832\n",
      "iteration - 3583 -> loss: 0.0003325108968767337, self.slope: [1.04225313 1.04249693], self.intercept: 1.0036585534734186\n",
      "iteration - 3584 -> loss: 0.00033248943339758816, self.slope: [1.04226343 1.04250731], self.intercept: 1.0036594737545368\n",
      "iteration - 3585 -> loss: 0.00033246797278168786, self.slope: [1.04227373 1.04251769], self.intercept: 1.0036603939874469\n",
      "iteration - 3586 -> loss: 0.0003324465150284651, self.slope: [1.04228402 1.04252807], self.intercept: 1.003661314172152\n",
      "iteration - 3587 -> loss: 0.0003324250601373114, self.slope: [1.04229432 1.04253845], self.intercept: 1.0036622343086579\n",
      "iteration - 3588 -> loss: 0.00033240360810766963, self.slope: [1.04230461 1.04254882], self.intercept: 1.0036631543969685\n",
      "iteration - 3589 -> loss: 0.00033238215893894647, self.slope: [1.0423149 1.0425592], self.intercept: 1.0036640744370922\n",
      "iteration - 3590 -> loss: 0.0003323607126305688, self.slope: [1.0423252  1.04256958], self.intercept: 1.003664994429033\n",
      "iteration - 3591 -> loss: 0.0003323392691819601, self.slope: [1.04233549 1.04257995], self.intercept: 1.0036659143727955\n",
      "iteration - 3592 -> loss: 0.00033231782859253616, self.slope: [1.04234578 1.04259033], self.intercept: 1.0036668342683865\n",
      "iteration - 3593 -> loss: 0.0003322963908617136, self.slope: [1.04235607 1.0426007 ], self.intercept: 1.0036677541158114\n",
      "iteration - 3594 -> loss: 0.00033227495598892384, self.slope: [1.04236636 1.04261108], self.intercept: 1.003668673915075\n",
      "iteration - 3595 -> loss: 0.0003322535239735682, self.slope: [1.04237665 1.04262145], self.intercept: 1.0036695936661841\n",
      "iteration - 3596 -> loss: 0.0003322320948151013, self.slope: [1.04238694 1.04263182], self.intercept: 1.0036705133691437\n",
      "iteration - 3597 -> loss: 0.0003322106685129008, self.slope: [1.04239722 1.04264219], self.intercept: 1.0036714330239596\n",
      "iteration - 3598 -> loss: 0.00033218924506643626, self.slope: [1.04240751 1.04265256], self.intercept: 1.0036723526306364\n",
      "iteration - 3599 -> loss: 0.00033216782447509813, self.slope: [1.0424178  1.04266293], self.intercept: 1.0036732721891795\n",
      "iteration - 3600 -> loss: 0.0003321464067383187, self.slope: [1.04242808 1.0426733 ], self.intercept: 1.0036741916995942\n",
      "iteration - 3601 -> loss: 0.000332124991855505, self.slope: [1.04243837 1.04268367], self.intercept: 1.0036751111618873\n",
      "iteration - 3602 -> loss: 0.00033210357982609256, self.slope: [1.04244865 1.04269404], self.intercept: 1.0036760305760655\n",
      "iteration - 3603 -> loss: 0.00033208217064949517, self.slope: [1.04245893 1.04270441], self.intercept: 1.00367694994213\n",
      "iteration - 3604 -> loss: 0.0003320607643251399, self.slope: [1.04246922 1.04271477], self.intercept: 1.0036778692600903\n",
      "iteration - 3605 -> loss: 0.00033203936085246614, self.slope: [1.0424795  1.04272514], self.intercept: 1.0036787885299487\n",
      "iteration - 3606 -> loss: 0.00033201796023086036, self.slope: [1.04248978 1.04273551], self.intercept: 1.0036797077517121\n",
      "iteration - 3607 -> loss: 0.0003319965624597659, self.slope: [1.04250006 1.04274587], self.intercept: 1.003680626925387\n",
      "iteration - 3608 -> loss: 0.0003319751675386258, self.slope: [1.04251034 1.04275623], self.intercept: 1.0036815460509796\n",
      "iteration - 3609 -> loss: 0.00033195377546681534, self.slope: [1.04252062 1.0427666 ], self.intercept: 1.0036824651284921\n",
      "iteration - 3610 -> loss: 0.00033193238624380046, self.slope: [1.0425309  1.04277696], self.intercept: 1.0036833841579336\n",
      "iteration - 3611 -> loss: 0.00033191099986898853, self.slope: [1.04254118 1.04278732], self.intercept: 1.003684303139306\n",
      "iteration - 3612 -> loss: 0.00033188961634178943, self.slope: [1.04255145 1.04279768], self.intercept: 1.0036852220726165\n",
      "iteration - 3613 -> loss: 0.00033186823566165954, self.slope: [1.04256173 1.04280804], self.intercept: 1.003686140957872\n",
      "iteration - 3614 -> loss: 0.0003318468578279792, self.slope: [1.04257201 1.0428184 ], self.intercept: 1.003687059795078\n",
      "iteration - 3615 -> loss: 0.0003318254828402228, self.slope: [1.04258228 1.04282876], self.intercept: 1.003687978584238\n",
      "iteration - 3616 -> loss: 0.0003318041106977751, self.slope: [1.04259256 1.04283912], self.intercept: 1.003688897325358\n",
      "iteration - 3617 -> loss: 0.0003317827414000774, self.slope: [1.04260283 1.04284948], self.intercept: 1.0036898160184435\n",
      "iteration - 3618 -> loss: 0.0003317613749465555, self.slope: [1.0426131  1.04285984], self.intercept: 1.0036907346634991\n",
      "iteration - 3619 -> loss: 0.0003317400113366147, self.slope: [1.04262337 1.04287019], self.intercept: 1.003691653260533\n",
      "iteration - 3620 -> loss: 0.0003317186505697095, self.slope: [1.04263365 1.04288055], self.intercept: 1.003692571809549\n",
      "iteration - 3621 -> loss: 0.0003316972926452396, self.slope: [1.04264392 1.0428909 ], self.intercept: 1.003693490310552\n",
      "iteration - 3622 -> loss: 0.00033167593756263796, self.slope: [1.04265419 1.04290126], self.intercept: 1.0036944087635484\n",
      "iteration - 3623 -> loss: 0.00033165458532134935, self.slope: [1.04266446 1.04291161], self.intercept: 1.003695327168542\n",
      "iteration - 3624 -> loss: 0.00033163323592076856, self.slope: [1.04267473 1.04292196], self.intercept: 1.0036962455255405\n",
      "iteration - 3625 -> loss: 0.0003316118893603414, self.slope: [1.04268499 1.04293232], self.intercept: 1.003697163834549\n",
      "iteration - 3626 -> loss: 0.0003315905456394804, self.slope: [1.04269526 1.04294267], self.intercept: 1.003698082095573\n",
      "iteration - 3627 -> loss: 0.00033156920475761536, self.slope: [1.04270553 1.04295302], self.intercept: 1.0036990003086166\n",
      "iteration - 3628 -> loss: 0.00033154786671418595, self.slope: [1.04271579 1.04296337], self.intercept: 1.0036999184736868\n",
      "iteration - 3629 -> loss: 0.0003315265315085947, self.slope: [1.04272606 1.04297372], self.intercept: 1.003700836590789\n",
      "iteration - 3630 -> loss: 0.00033150519914028077, self.slope: [1.04273632 1.04298407], self.intercept: 1.003701754659929\n",
      "iteration - 3631 -> loss: 0.00033148386960869233, self.slope: [1.04274659 1.04299442], self.intercept: 1.0037026726811098\n",
      "iteration - 3632 -> loss: 0.00033146254291320986, self.slope: [1.04275685 1.04300476], self.intercept: 1.0037035906543388\n",
      "iteration - 3633 -> loss: 0.00033144121905329484, self.slope: [1.04276712 1.04301511], self.intercept: 1.0037045085796215\n",
      "iteration - 3634 -> loss: 0.000331419898028363, self.slope: [1.04277738 1.04302546], self.intercept: 1.0037054264569625\n",
      "iteration - 3635 -> loss: 0.00033139857983783926, self.slope: [1.04278764 1.0430358 ], self.intercept: 1.0037063442863672\n",
      "iteration - 3636 -> loss: 0.00033137726448117063, self.slope: [1.0427979  1.04304615], self.intercept: 1.0037072620678429\n",
      "iteration - 3637 -> loss: 0.00033135595195774183, self.slope: [1.04280816 1.04305649], self.intercept: 1.0037081798013932\n",
      "iteration - 3638 -> loss: 0.0003313346422670149, self.slope: [1.04281842 1.04306684], self.intercept: 1.0037090974870246\n",
      "iteration - 3639 -> loss: 0.0003313133354084216, self.slope: [1.04282868 1.04307718], self.intercept: 1.0037100151247424\n",
      "iteration - 3640 -> loss: 0.00033129203138136144, self.slope: [1.04283893 1.04308752], self.intercept: 1.0037109327145515\n",
      "iteration - 3641 -> loss: 0.00033127073018528874, self.slope: [1.04284919 1.04309786], self.intercept: 1.0037118502564566\n",
      "iteration - 3642 -> loss: 0.00033124943181961656, self.slope: [1.04285945 1.0431082 ], self.intercept: 1.003712767750464\n",
      "iteration - 3643 -> loss: 0.0003312281362837717, self.slope: [1.0428697  1.04311854], self.intercept: 1.0037136851965824\n",
      "iteration - 3644 -> loss: 0.00033120684357720317, self.slope: [1.04287996 1.04312888], self.intercept: 1.0037146025948138\n",
      "iteration - 3645 -> loss: 0.0003311855536993196, self.slope: [1.04289021 1.04313922], self.intercept: 1.0037155199451633\n",
      "iteration - 3646 -> loss: 0.0003311642666495604, self.slope: [1.04290047 1.04314956], self.intercept: 1.003716437247637\n",
      "iteration - 3647 -> loss: 0.0003311429824273399, self.slope: [1.04291072 1.0431599 ], self.intercept: 1.0037173545022404\n",
      "iteration - 3648 -> loss: 0.00033112170103211173, self.slope: [1.04292097 1.04317023], self.intercept: 1.0037182717089796\n",
      "iteration - 3649 -> loss: 0.000331100422463278, self.slope: [1.04293122 1.04318057], self.intercept: 1.0037191888678592\n",
      "iteration - 3650 -> loss: 0.0003310791467202826, self.slope: [1.04294148 1.0431909 ], self.intercept: 1.0037201059788852\n",
      "iteration - 3651 -> loss: 0.00033105787380254784, self.slope: [1.04295173 1.04320124], self.intercept: 1.0037210230420626\n",
      "iteration - 3652 -> loss: 0.0003310366037095284, self.slope: [1.04296198 1.04321157], self.intercept: 1.0037219400573976\n",
      "iteration - 3653 -> loss: 0.0003310153364406275, self.slope: [1.04297222 1.04322191], self.intercept: 1.0037228570248955\n",
      "iteration - 3654 -> loss: 0.0003309940719952747, self.slope: [1.04298247 1.04323224], self.intercept: 1.0037237739445617\n",
      "iteration - 3655 -> loss: 0.00033097281037291755, self.slope: [1.04299272 1.04324257], self.intercept: 1.0037246908164008\n",
      "iteration - 3656 -> loss: 0.00033095155157297345, self.slope: [1.04300297 1.0432529 ], self.intercept: 1.0037256076404186\n",
      "iteration - 3657 -> loss: 0.00033093029559488874, self.slope: [1.04301321 1.04326323], self.intercept: 1.003726524416621\n",
      "iteration - 3658 -> loss: 0.0003309090424380759, self.slope: [1.04302346 1.04327356], self.intercept: 1.0037274411450143\n",
      "iteration - 3659 -> loss: 0.00033088779210194765, self.slope: [1.0430337  1.04328389], self.intercept: 1.0037283578256029\n",
      "iteration - 3660 -> loss: 0.0003308665445859728, self.slope: [1.04304395 1.04329422], self.intercept: 1.0037292744583917\n",
      "iteration - 3661 -> loss: 0.00033084529988959137, self.slope: [1.04305419 1.04330455], self.intercept: 1.0037301910433856\n",
      "iteration - 3662 -> loss: 0.0003308240580121855, self.slope: [1.04306443 1.04331487], self.intercept: 1.0037311075805924\n",
      "iteration - 3663 -> loss: 0.0003308028189532299, self.slope: [1.04307468 1.0433252 ], self.intercept: 1.0037320240700163\n",
      "iteration - 3664 -> loss: 0.00033078158271213754, self.slope: [1.04308492 1.04333553], self.intercept: 1.0037329405116622\n",
      "iteration - 3665 -> loss: 0.00033076034928832427, self.slope: [1.04309516 1.04334585], self.intercept: 1.003733856905537\n",
      "iteration - 3666 -> loss: 0.00033073911868125865, self.slope: [1.0431054  1.04335618], self.intercept: 1.0037347732516442\n",
      "iteration - 3667 -> loss: 0.00033071789089034816, self.slope: [1.04311564 1.0433665 ], self.intercept: 1.003735689549991\n",
      "iteration - 3668 -> loss: 0.0003306966659150239, self.slope: [1.04312588 1.04337682], self.intercept: 1.003736605800581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 3669 -> loss: 0.00033067544375475023, self.slope: [1.04313611 1.04338715], self.intercept: 1.0037375220034215\n",
      "iteration - 3670 -> loss: 0.0003306542244089145, self.slope: [1.04314635 1.04339747], self.intercept: 1.0037384381585162\n",
      "iteration - 3671 -> loss: 0.0003306330078769818, self.slope: [1.04315659 1.04340779], self.intercept: 1.003739354265873\n",
      "iteration - 3672 -> loss: 0.00033061179415837006, self.slope: [1.04316682 1.04341811], self.intercept: 1.0037402703254954\n",
      "iteration - 3673 -> loss: 0.00033059058325250924, self.slope: [1.04317706 1.04342843], self.intercept: 1.003741186337389\n",
      "iteration - 3674 -> loss: 0.0003305693751588343, self.slope: [1.04318729 1.04343875], self.intercept: 1.0037421023015602\n",
      "iteration - 3675 -> loss: 0.00033054816987678403, self.slope: [1.04319753 1.04344907], self.intercept: 1.0037430182180136\n",
      "iteration - 3676 -> loss: 0.0003305269674057965, self.slope: [1.04320776 1.04345938], self.intercept: 1.0037439340867542\n",
      "iteration - 3677 -> loss: 0.00033050576774531105, self.slope: [1.04321799 1.0434697 ], self.intercept: 1.0037448499077872\n",
      "iteration - 3678 -> loss: 0.0003304845708947342, self.slope: [1.04322823 1.04348002], self.intercept: 1.00374576568112\n",
      "iteration - 3679 -> loss: 0.0003304633768535165, self.slope: [1.04323846 1.04349033], self.intercept: 1.0037466814067575\n",
      "iteration - 3680 -> loss: 0.00033044218562109853, self.slope: [1.04324869 1.04350065], self.intercept: 1.0037475970847036\n",
      "iteration - 3681 -> loss: 0.00033042099719690713, self.slope: [1.04325892 1.04351096], self.intercept: 1.003748512714964\n",
      "iteration - 3682 -> loss: 0.00033039981158038167, self.slope: [1.04326915 1.04352127], self.intercept: 1.0037494282975452\n",
      "iteration - 3683 -> loss: 0.0003303786287709317, self.slope: [1.04327937 1.04353159], self.intercept: 1.0037503438324529\n",
      "iteration - 3684 -> loss: 0.0003303574487680283, self.slope: [1.0432896 1.0435419], self.intercept: 1.0037512593196916\n",
      "iteration - 3685 -> loss: 0.000330336271571091, self.slope: [1.04329983 1.04355221], self.intercept: 1.0037521747592668\n",
      "iteration - 3686 -> loss: 0.0003303150971795324, self.slope: [1.04331006 1.04356252], self.intercept: 1.0037530901511837\n",
      "iteration - 3687 -> loss: 0.0003302939255928271, self.slope: [1.04332028 1.04357283], self.intercept: 1.0037540054954497\n",
      "iteration - 3688 -> loss: 0.00033027275681039235, self.slope: [1.04333051 1.04358314], self.intercept: 1.0037549207920666\n",
      "iteration - 3689 -> loss: 0.00033025159083166435, self.slope: [1.04334073 1.04359345], self.intercept: 1.003755836041042\n",
      "iteration - 3690 -> loss: 0.00033023042765607753, self.slope: [1.04335095 1.04360376], self.intercept: 1.003756751242382\n",
      "iteration - 3691 -> loss: 0.00033020926728307017, self.slope: [1.04336118 1.04361407], self.intercept: 1.0037576663960908\n",
      "iteration - 3692 -> loss: 0.00033018810971206395, self.slope: [1.0433714  1.04362437], self.intercept: 1.0037585815021737\n",
      "iteration - 3693 -> loss: 0.00033016695494251657, self.slope: [1.04338162 1.04363468], self.intercept: 1.0037594965606371\n",
      "iteration - 3694 -> loss: 0.00033014580297385554, self.slope: [1.04339184 1.04364498], self.intercept: 1.0037604115714853\n",
      "iteration - 3695 -> loss: 0.0003301246538055228, self.slope: [1.04340206 1.04365529], self.intercept: 1.0037613265347245\n",
      "iteration - 3696 -> loss: 0.0003301035074369265, self.slope: [1.04341228 1.04366559], self.intercept: 1.0037622414503609\n",
      "iteration - 3697 -> loss: 0.00033008236386754123, self.slope: [1.0434225 1.0436759], self.intercept: 1.0037631563183975\n",
      "iteration - 3698 -> loss: 0.0003300612230967996, self.slope: [1.04343272 1.0436862 ], self.intercept: 1.0037640711388427\n",
      "iteration - 3699 -> loss: 0.00033004008512411016, self.slope: [1.04344294 1.0436965 ], self.intercept: 1.003764985911699\n",
      "iteration - 3700 -> loss: 0.00033001894994892715, self.slope: [1.04345315 1.0437068 ], self.intercept: 1.0037659006369741\n",
      "iteration - 3701 -> loss: 0.0003299978175706917, self.slope: [1.04346337 1.0437171 ], self.intercept: 1.0037668153146713\n",
      "iteration - 3702 -> loss: 0.0003299766879888251, self.slope: [1.04347358 1.0437274 ], self.intercept: 1.0037677299447982\n",
      "iteration - 3703 -> loss: 0.0003299555612027805, self.slope: [1.0434838 1.0437377], self.intercept: 1.0037686445273577\n",
      "iteration - 3704 -> loss: 0.00032993443721200536, self.slope: [1.04349401 1.043748  ], self.intercept: 1.003769559062358\n",
      "iteration - 3705 -> loss: 0.0003299133160159208, self.slope: [1.04350423 1.0437583 ], self.intercept: 1.003770473549803\n",
      "iteration - 3706 -> loss: 0.0003298921976139647, self.slope: [1.04351444 1.0437686 ], self.intercept: 1.0037713879896981\n",
      "iteration - 3707 -> loss: 0.00032987108200558513, self.slope: [1.04352465 1.04377889], self.intercept: 1.00377230238205\n",
      "iteration - 3708 -> loss: 0.0003298499691902059, self.slope: [1.04353486 1.04378919], self.intercept: 1.0037732167268605\n",
      "iteration - 3709 -> loss: 0.0003298288591672776, self.slope: [1.04354507 1.04379948], self.intercept: 1.0037741310241377\n",
      "iteration - 3710 -> loss: 0.0003298077519362315, self.slope: [1.04355528 1.04380978], self.intercept: 1.0037750452738887\n",
      "iteration - 3711 -> loss: 0.0003297866474965158, self.slope: [1.04356549 1.04382007], self.intercept: 1.0037759594761158\n",
      "iteration - 3712 -> loss: 0.0003297655458475626, self.slope: [1.0435757  1.04383037], self.intercept: 1.0037768736308246\n",
      "iteration - 3713 -> loss: 0.00032974444698880245, self.slope: [1.04358591 1.04384066], self.intercept: 1.0037777877380225\n",
      "iteration - 3714 -> loss: 0.00032972335091968846, self.slope: [1.04359612 1.04385095], self.intercept: 1.0037787017977142\n",
      "iteration - 3715 -> loss: 0.0003297022576396605, self.slope: [1.04360632 1.04386124], self.intercept: 1.003779615809904\n",
      "iteration - 3716 -> loss: 0.0003296811671481602, self.slope: [1.04361653 1.04387153], self.intercept: 1.003780529774598\n",
      "iteration - 3717 -> loss: 0.0003296600794446069, self.slope: [1.04362673 1.04388182], self.intercept: 1.003781443691803\n",
      "iteration - 3718 -> loss: 0.00032963899452845524, self.slope: [1.04363694 1.04389211], self.intercept: 1.0037823575615221\n",
      "iteration - 3719 -> loss: 0.0003296179123991479, self.slope: [1.04364714 1.0439024 ], self.intercept: 1.0037832713837622\n",
      "iteration - 3720 -> loss: 0.00032959683305612076, self.slope: [1.04365735 1.04391269], self.intercept: 1.003784185158528\n",
      "iteration - 3721 -> loss: 0.0003295757564988185, self.slope: [1.04366755 1.04392297], self.intercept: 1.0037850988858261\n",
      "iteration - 3722 -> loss: 0.0003295546827266738, self.slope: [1.04367775 1.04393326], self.intercept: 1.0037860125656592\n",
      "iteration - 3723 -> loss: 0.0003295336117391371, self.slope: [1.04368795 1.04394355], self.intercept: 1.0037869261980352\n",
      "iteration - 3724 -> loss: 0.0003295125435356352, self.slope: [1.04369815 1.04395383], self.intercept: 1.0037878397829572\n",
      "iteration - 3725 -> loss: 0.00032949147811562165, self.slope: [1.04370835 1.04396412], self.intercept: 1.0037887533204324\n",
      "iteration - 3726 -> loss: 0.0003294704154785322, self.slope: [1.04371855 1.0439744 ], self.intercept: 1.0037896668104653\n",
      "iteration - 3727 -> loss: 0.0003294493556238058, self.slope: [1.04372875 1.04398468], self.intercept: 1.0037905802530624\n",
      "iteration - 3728 -> loss: 0.0003294282985508934, self.slope: [1.04373895 1.04399497], self.intercept: 1.0037914936482268\n",
      "iteration - 3729 -> loss: 0.0003294072442592262, self.slope: [1.04374914 1.04400525], self.intercept: 1.0037924069959667\n",
      "iteration - 3730 -> loss: 0.0003293861927482416, self.slope: [1.04375934 1.04401553], self.intercept: 1.0037933202962857\n",
      "iteration - 3731 -> loss: 0.0003293651440173859, self.slope: [1.04376954 1.04402581], self.intercept: 1.0037942335491898\n",
      "iteration - 3732 -> loss: 0.0003293440980661152, self.slope: [1.04377973 1.04403609], self.intercept: 1.0037951467546844\n",
      "iteration - 3733 -> loss: 0.00032932305489386297, self.slope: [1.04378992 1.04404637], self.intercept: 1.003796059912774\n",
      "iteration - 3734 -> loss: 0.00032930201450006723, self.slope: [1.04380012 1.04405665], self.intercept: 1.003796973023466\n",
      "iteration - 3735 -> loss: 0.000329280976884182, self.slope: [1.04381031 1.04406692], self.intercept: 1.003797886086765\n",
      "iteration - 3736 -> loss: 0.0003292599420456188, self.slope: [1.0438205 1.0440772], self.intercept: 1.0037987991026742\n",
      "iteration - 3737 -> loss: 0.0003292389099838654, self.slope: [1.04383069 1.04408748], self.intercept: 1.0037997120712019\n",
      "iteration - 3738 -> loss: 0.00032921788069831807, self.slope: [1.04384089 1.04409775], self.intercept: 1.0038006249923523\n",
      "iteration - 3739 -> loss: 0.0003291968541884555, self.slope: [1.04385108 1.04410803], self.intercept: 1.0038015378661298\n",
      "iteration - 3740 -> loss: 0.000329175830453717, self.slope: [1.04386127 1.0441183 ], self.intercept: 1.0038024506925407\n",
      "iteration - 3741 -> loss: 0.00032915480949352935, self.slope: [1.04387145 1.04412858], self.intercept: 1.0038033634715906\n",
      "iteration - 3742 -> loss: 0.00032913379130733846, self.slope: [1.04388164 1.04413885], self.intercept: 1.003804276203285\n",
      "iteration - 3743 -> loss: 0.00032911277589459575, self.slope: [1.04389183 1.04414912], self.intercept: 1.0038051888876287\n",
      "iteration - 3744 -> loss: 0.0003290917632547436, self.slope: [1.04390202 1.04415939], self.intercept: 1.003806101524626\n",
      "iteration - 3745 -> loss: 0.00032907075338723773, self.slope: [1.0439122  1.04416966], self.intercept: 1.0038070141142854\n",
      "iteration - 3746 -> loss: 0.00032904974629149723, self.slope: [1.04392239 1.04417993], self.intercept: 1.0038079266566093\n",
      "iteration - 3747 -> loss: 0.00032902874196699585, self.slope: [1.04393257 1.0441902 ], self.intercept: 1.0038088391516045\n",
      "iteration - 3748 -> loss: 0.0003290077404131273, self.slope: [1.04394276 1.04420047], self.intercept: 1.003809751599277\n",
      "iteration - 3749 -> loss: 0.0003289867416293879, self.slope: [1.04395294 1.04421074], self.intercept: 1.0038106639996303\n",
      "iteration - 3750 -> loss: 0.00032896574561520724, self.slope: [1.04396312 1.04422101], self.intercept: 1.0038115763526696\n",
      "iteration - 3751 -> loss: 0.0003289447523700353, self.slope: [1.04397331 1.04423128], self.intercept: 1.0038124886584023\n",
      "iteration - 3752 -> loss: 0.0003289237618932906, self.slope: [1.04398349 1.04424154], self.intercept: 1.0038134009168327\n",
      "iteration - 3753 -> loss: 0.0003289027741844228, self.slope: [1.04399367 1.04425181], self.intercept: 1.0038143131279662\n",
      "iteration - 3754 -> loss: 0.0003288817892429236, self.slope: [1.04400385 1.04426207], self.intercept: 1.0038152252918073\n",
      "iteration - 3755 -> loss: 0.00032886080706818853, self.slope: [1.04401403 1.04427234], self.intercept: 1.003816137408363\n",
      "iteration - 3756 -> loss: 0.00032883982765970367, self.slope: [1.04402421 1.0442826 ], self.intercept: 1.003817049477637\n",
      "iteration - 3757 -> loss: 0.0003288188510168568, self.slope: [1.04403438 1.04429286], self.intercept: 1.0038179614996372\n",
      "iteration - 3758 -> loss: 0.00032879787713915843, self.slope: [1.04404456 1.04430313], self.intercept: 1.003818873474367\n",
      "iteration - 3759 -> loss: 0.00032877690602600056, self.slope: [1.04405474 1.04431339], self.intercept: 1.0038197854018311\n",
      "iteration - 3760 -> loss: 0.0003287559376768607, self.slope: [1.04406491 1.04432365], self.intercept: 1.0038206972820358\n",
      "iteration - 3761 -> loss: 0.0003287349720911731, self.slope: [1.04407509 1.04433391], self.intercept: 1.0038216091149874\n",
      "iteration - 3762 -> loss: 0.0003287140092684005, self.slope: [1.04408526 1.04434417], self.intercept: 1.0038225209006897\n",
      "iteration - 3763 -> loss: 0.0003286930492079619, self.slope: [1.04409544 1.04435443], self.intercept: 1.0038234326391486\n",
      "iteration - 3764 -> loss: 0.00032867209190934224, self.slope: [1.04410561 1.04436469], self.intercept: 1.0038243443303696\n",
      "iteration - 3765 -> loss: 0.00032865113737194434, self.slope: [1.04411578 1.04437494], self.intercept: 1.003825255974358\n",
      "iteration - 3766 -> loss: 0.0003286301855952492, self.slope: [1.04412596 1.0443852 ], self.intercept: 1.00382616757112\n",
      "iteration - 3767 -> loss: 0.0003286092365787013, self.slope: [1.04413613 1.04439546], self.intercept: 1.0038270791206587\n",
      "iteration - 3768 -> loss: 0.0003285882903217266, self.slope: [1.0441463  1.04440571], self.intercept: 1.0038279906229808\n",
      "iteration - 3769 -> loss: 0.00032856734682378035, self.slope: [1.04415647 1.04441597], self.intercept: 1.0038289020780922\n",
      "iteration - 3770 -> loss: 0.00032854640608432365, self.slope: [1.04416664 1.04442622], self.intercept: 1.0038298134859962\n",
      "iteration - 3771 -> loss: 0.0003285254681027868, self.slope: [1.04417681 1.04443647], self.intercept: 1.0038307248467002\n",
      "iteration - 3772 -> loss: 0.00032850453287863106, self.slope: [1.04418697 1.04444673], self.intercept: 1.003831636160209\n",
      "iteration - 3773 -> loss: 0.0003284836004113184, self.slope: [1.04419714 1.04445698], self.intercept: 1.0038325474265284\n",
      "iteration - 3774 -> loss: 0.0003284626707002502, self.slope: [1.04420731 1.04446723], self.intercept: 1.0038334586456625\n",
      "iteration - 3775 -> loss: 0.00032844174374491023, self.slope: [1.04421747 1.04447748], self.intercept: 1.003834369817617\n",
      "iteration - 3776 -> loss: 0.00032842081954473183, self.slope: [1.04422764 1.04448773], self.intercept: 1.0038352809423992\n",
      "iteration - 3777 -> loss: 0.00032839989809918427, self.slope: [1.0442378  1.04449798], self.intercept: 1.0038361920200107\n",
      "iteration - 3778 -> loss: 0.0003283789794076946, self.slope: [1.04424797 1.04450823], self.intercept: 1.0038371030504605\n",
      "iteration - 3779 -> loss: 0.00032835806346974064, self.slope: [1.04425813 1.04451848], self.intercept: 1.0038380140337515\n",
      "iteration - 3780 -> loss: 0.00032833715028472384, self.slope: [1.04426829 1.04452873], self.intercept: 1.0038389249698898\n",
      "iteration - 3781 -> loss: 0.0003283162398521432, self.slope: [1.04427845 1.04453897], self.intercept: 1.0038398358588805\n",
      "iteration - 3782 -> loss: 0.0003282953321714182, self.slope: [1.04428862 1.04454922], self.intercept: 1.0038407467007298\n",
      "iteration - 3783 -> loss: 0.00032827442724200754, self.slope: [1.04429878 1.04455947], self.intercept: 1.0038416574954432\n",
      "iteration - 3784 -> loss: 0.00032825352506335947, self.slope: [1.04430894 1.04456971], self.intercept: 1.0038425682430248\n",
      "iteration - 3785 -> loss: 0.00032823262563491684, self.slope: [1.04431909 1.04457995], self.intercept: 1.0038434789434805\n",
      "iteration - 3786 -> loss: 0.0003282117289561436, self.slope: [1.04432925 1.0445902 ], self.intercept: 1.0038443895968159\n",
      "iteration - 3787 -> loss: 0.0003281908350264886, self.slope: [1.04433941 1.04460044], self.intercept: 1.0038453002030368\n",
      "iteration - 3788 -> loss: 0.0003281699438453894, self.slope: [1.04434957 1.04461068], self.intercept: 1.0038462107621475\n",
      "iteration - 3789 -> loss: 0.00032814905541232156, self.slope: [1.04435972 1.04462092], self.intercept: 1.0038471212741522\n",
      "iteration - 3790 -> loss: 0.00032812816972668704, self.slope: [1.04436988 1.04463117], self.intercept: 1.0038480317390577\n",
      "iteration - 3791 -> loss: 0.0003281072867879988, self.slope: [1.04438004 1.04464141], self.intercept: 1.0038489421568682\n",
      "iteration - 3792 -> loss: 0.00032808640659564897, self.slope: [1.04439019 1.04465164], self.intercept: 1.0038498525275914\n",
      "iteration - 3793 -> loss: 0.0003280655291491337, self.slope: [1.04440034 1.04466188], self.intercept: 1.0038507628512332\n",
      "iteration - 3794 -> loss: 0.00032804465444789105, self.slope: [1.0444105  1.04467212], self.intercept: 1.0038516731277949\n",
      "iteration - 3795 -> loss: 0.00032802378249136287, self.slope: [1.04442065 1.04468236], self.intercept: 1.0038525833572833\n",
      "iteration - 3796 -> loss: 0.00032800291327899115, self.slope: [1.0444308 1.0446926], self.intercept: 1.0038534935397043\n",
      "iteration - 3797 -> loss: 0.00032798204681024935, self.slope: [1.04444095 1.04470283], self.intercept: 1.0038544036750643\n",
      "iteration - 3798 -> loss: 0.00032796118308460963, self.slope: [1.0444511  1.04471307], self.intercept: 1.0038553137633666\n",
      "iteration - 3799 -> loss: 0.00032794032210146386, self.slope: [1.04446125 1.0447233 ], self.intercept: 1.0038562238046178\n",
      "iteration - 3800 -> loss: 0.0003279194638603211, self.slope: [1.0444714  1.04473354], self.intercept: 1.0038571337988236\n",
      "iteration - 3801 -> loss: 0.0003278986083605778, self.slope: [1.04448155 1.04474377], self.intercept: 1.0038580437459879\n",
      "iteration - 3802 -> loss: 0.00032787775560175046, self.slope: [1.0444917 1.044754 ], self.intercept: 1.003858953646117\n",
      "iteration - 3803 -> loss: 0.00032785690558324675, self.slope: [1.04450184 1.04476424], self.intercept: 1.0038598634992155\n",
      "iteration - 3804 -> loss: 0.00032783605830453315, self.slope: [1.04451199 1.04477447], self.intercept: 1.0038607733052887\n",
      "iteration - 3805 -> loss: 0.00032781521376505223, self.slope: [1.04452214 1.0447847 ], self.intercept: 1.0038616830643419\n",
      "iteration - 3806 -> loss: 0.0003277943719642744, self.slope: [1.04453228 1.04479493], self.intercept: 1.003862592776382\n",
      "iteration - 3807 -> loss: 0.0003277735329016401, self.slope: [1.04454242 1.04480516], self.intercept: 1.0038635024414122\n",
      "iteration - 3808 -> loss: 0.000327752696576614, self.slope: [1.04455257 1.04481539], self.intercept: 1.00386441205944\n",
      "iteration - 3809 -> loss: 0.0003277318629886381, self.slope: [1.04456271 1.04482561], self.intercept: 1.0038653216304692\n",
      "iteration - 3810 -> loss: 0.0003277110321371639, self.slope: [1.04457285 1.04483584], self.intercept: 1.0038662311545052\n",
      "iteration - 3811 -> loss: 0.00032769020402166014, self.slope: [1.04458299 1.04484607], self.intercept: 1.0038671406315531\n",
      "iteration - 3812 -> loss: 0.00032766937864156027, self.slope: [1.04459314 1.04485629], self.intercept: 1.0038680500616184\n",
      "iteration - 3813 -> loss: 0.00032764855599634233, self.slope: [1.04460328 1.04486652], self.intercept: 1.0038689594447077\n",
      "iteration - 3814 -> loss: 0.0003276277360854441, self.slope: [1.04461342 1.04487675], self.intercept: 1.0038698687808225\n",
      "iteration - 3815 -> loss: 0.00032760691890831644, self.slope: [1.04462355 1.04488697], self.intercept: 1.0038707780699734\n",
      "iteration - 3816 -> loss: 0.0003275861044644323, self.slope: [1.04463369 1.04489719], self.intercept: 1.0038716873121618\n",
      "iteration - 3817 -> loss: 0.00032756529275322253, self.slope: [1.04464383 1.04490742], self.intercept: 1.0038725965073945\n",
      "iteration - 3818 -> loss: 0.00032754448377416686, self.slope: [1.04465397 1.04491764], self.intercept: 1.003873505655677\n",
      "iteration - 3819 -> loss: 0.00032752367752671147, self.slope: [1.0446641  1.04492786], self.intercept: 1.003874414757013\n",
      "iteration - 3820 -> loss: 0.00032750287401028545, self.slope: [1.04467424 1.04493808], self.intercept: 1.0038753238114093\n",
      "iteration - 3821 -> loss: 0.0003274820732243781, self.slope: [1.04468437 1.0449483 ], self.intercept: 1.0038762328188724\n",
      "iteration - 3822 -> loss: 0.0003274612751684435, self.slope: [1.04469451 1.04495852], self.intercept: 1.0038771417794057\n",
      "iteration - 3823 -> loss: 0.00032744047984190636, self.slope: [1.04470464 1.04496874], self.intercept: 1.0038780506930147\n",
      "iteration - 3824 -> loss: 0.0003274196872442625, self.slope: [1.04471477 1.04497896], self.intercept: 1.0038789595597044\n",
      "iteration - 3825 -> loss: 0.0003273988973749162, self.slope: [1.04472491 1.04498917], self.intercept: 1.0038798683794794\n",
      "iteration - 3826 -> loss: 0.00032737811023337643, self.slope: [1.04473504 1.04499939], self.intercept: 1.0038807771523477\n",
      "iteration - 3827 -> loss: 0.0003273573258190846, self.slope: [1.04474517 1.04500961], self.intercept: 1.0038816858783122\n",
      "iteration - 3828 -> loss: 0.0003273365441314753, self.slope: [1.0447553  1.04501982], self.intercept: 1.0038825945573782\n",
      "iteration - 3829 -> loss: 0.0003273157651700259, self.slope: [1.04476543 1.04503004], self.intercept: 1.003883503189552\n",
      "iteration - 3830 -> loss: 0.0003272949889341928, self.slope: [1.04477556 1.04504025], self.intercept: 1.0038844117748398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 3831 -> loss: 0.00032727421542341214, self.slope: [1.04478569 1.04505047], self.intercept: 1.0038853203132447\n",
      "iteration - 3832 -> loss: 0.00032725344463717105, self.slope: [1.04479581 1.04506068], self.intercept: 1.0038862288047736\n",
      "iteration - 3833 -> loss: 0.00032723267657489165, self.slope: [1.04480594 1.04507089], self.intercept: 1.0038871372494294\n",
      "iteration - 3834 -> loss: 0.0003272119112360396, self.slope: [1.04481607 1.0450811 ], self.intercept: 1.003888045647221\n",
      "iteration - 3835 -> loss: 0.00032719114862010256, self.slope: [1.04482619 1.04509131], self.intercept: 1.0038889539981515\n",
      "iteration - 3836 -> loss: 0.0003271703887265246, self.slope: [1.04483632 1.04510152], self.intercept: 1.003889862302226\n",
      "iteration - 3837 -> loss: 0.0003271496315547374, self.slope: [1.04484644 1.04511173], self.intercept: 1.0038907705594504\n",
      "iteration - 3838 -> loss: 0.00032712887710423125, self.slope: [1.04485656 1.04512194], self.intercept: 1.0038916787698298\n",
      "iteration - 3839 -> loss: 0.0003271081253744488, self.slope: [1.04486669 1.04513215], self.intercept: 1.0038925869333706\n",
      "iteration - 3840 -> loss: 0.00032708737636484076, self.slope: [1.04487681 1.04514236], self.intercept: 1.0038934950500773\n",
      "iteration - 3841 -> loss: 0.0003270666300748673, self.slope: [1.04488693 1.04515256], self.intercept: 1.0038944031199535\n",
      "iteration - 3842 -> loss: 0.0003270458865039978, self.slope: [1.04489705 1.04516277], self.intercept: 1.0038953111430062\n",
      "iteration - 3843 -> loss: 0.0003270251456516922, self.slope: [1.04490717 1.04517298], self.intercept: 1.0038962191192407\n",
      "iteration - 3844 -> loss: 0.0003270044075173944, self.slope: [1.04491729 1.04518318], self.intercept: 1.003897127048663\n",
      "iteration - 3845 -> loss: 0.00032698367210057353, self.slope: [1.04492741 1.04519338], self.intercept: 1.0038980349312756\n",
      "iteration - 3846 -> loss: 0.00032696293940068526, self.slope: [1.04493753 1.04520359], self.intercept: 1.0038989427670866\n",
      "iteration - 3847 -> loss: 0.00032694220941718324, self.slope: [1.04494765 1.04521379], self.intercept: 1.0038998505560996\n",
      "iteration - 3848 -> loss: 0.00032692148214955036, self.slope: [1.04495776 1.04522399], self.intercept: 1.0039007582983208\n",
      "iteration - 3849 -> loss: 0.00032690075759720283, self.slope: [1.04496788 1.04523419], self.intercept: 1.0039016659937547\n",
      "iteration - 3850 -> loss: 0.0003268800357596484, self.slope: [1.04497799 1.0452444 ], self.intercept: 1.0039025736424063\n",
      "iteration - 3851 -> loss: 0.00032685931663631573, self.slope: [1.04498811 1.0452546 ], self.intercept: 1.0039034812442815\n",
      "iteration - 3852 -> loss: 0.00032683860022665427, self.slope: [1.04499822 1.0452648 ], self.intercept: 1.0039043887993861\n",
      "iteration - 3853 -> loss: 0.0003268178865301653, self.slope: [1.04500834 1.04527499], self.intercept: 1.003905296307724\n",
      "iteration - 3854 -> loss: 0.00032679717554626473, self.slope: [1.04501845 1.04528519], self.intercept: 1.0039062037693027\n",
      "iteration - 3855 -> loss: 0.0003267764672744534, self.slope: [1.04502856 1.04529539], self.intercept: 1.0039071111841256\n",
      "iteration - 3856 -> loss: 0.00032675576171416155, self.slope: [1.04503867 1.04530559], self.intercept: 1.003908018552199\n",
      "iteration - 3857 -> loss: 0.0003267350588648576, self.slope: [1.04504878 1.04531578], self.intercept: 1.003908925873527\n",
      "iteration - 3858 -> loss: 0.00032671435872600444, self.slope: [1.04505889 1.04532598], self.intercept: 1.0039098331481164\n",
      "iteration - 3859 -> loss: 0.0003266936612970661, self.slope: [1.045069   1.04533617], self.intercept: 1.003910740375971\n",
      "iteration - 3860 -> loss: 0.00032667296657749173, self.slope: [1.04507911 1.04534637], self.intercept: 1.0039116475570968\n",
      "iteration - 3861 -> loss: 0.00032665227456675613, self.slope: [1.04508922 1.04535656], self.intercept: 1.0039125546914989\n",
      "iteration - 3862 -> loss: 0.0003266315852643162, self.slope: [1.04509933 1.04536675], self.intercept: 1.0039134617791823\n",
      "iteration - 3863 -> loss: 0.0003266108986696234, self.slope: [1.04510943 1.04537695], self.intercept: 1.0039143688201524\n",
      "iteration - 3864 -> loss: 0.0003265902147821398, self.slope: [1.04511954 1.04538714], self.intercept: 1.0039152758144139\n",
      "iteration - 3865 -> loss: 0.0003265695336013544, self.slope: [1.04512965 1.04539733], self.intercept: 1.0039161827619731\n",
      "iteration - 3866 -> loss: 0.00032654885512669105, self.slope: [1.04513975 1.04540752], self.intercept: 1.0039170896628349\n",
      "iteration - 3867 -> loss: 0.0003265281793576539, self.slope: [1.04514985 1.04541771], self.intercept: 1.0039179965170044\n",
      "iteration - 3868 -> loss: 0.000326507506293655, self.slope: [1.04515996 1.0454279 ], self.intercept: 1.0039189033244877\n",
      "iteration - 3869 -> loss: 0.00032648683593418853, self.slope: [1.04517006 1.04543809], self.intercept: 1.0039198100852889\n",
      "iteration - 3870 -> loss: 0.0003264661682786956, self.slope: [1.04518016 1.04544827], self.intercept: 1.0039207167994135\n",
      "iteration - 3871 -> loss: 0.00032644550332666536, self.slope: [1.04519026 1.04545846], self.intercept: 1.0039216234668658\n",
      "iteration - 3872 -> loss: 0.0003264248410775579, self.slope: [1.04520036 1.04546865], self.intercept: 1.003922530087653\n",
      "iteration - 3873 -> loss: 0.00032640418153080637, self.slope: [1.04521046 1.04547883], self.intercept: 1.0039234366617793\n",
      "iteration - 3874 -> loss: 0.0003263835246859096, self.slope: [1.04522056 1.04548902], self.intercept: 1.00392434318925\n",
      "iteration - 3875 -> loss: 0.0003263628705423068, self.slope: [1.04523066 1.0454992 ], self.intercept: 1.0039252496700708\n",
      "iteration - 3876 -> loss: 0.0003263422190994646, self.slope: [1.04524076 1.04550939], self.intercept: 1.0039261561042474\n",
      "iteration - 3877 -> loss: 0.0003263215703568529, self.slope: [1.04525086 1.04551957], self.intercept: 1.003927062491784\n",
      "iteration - 3878 -> loss: 0.0003263009243139347, self.slope: [1.04526095 1.04552975], self.intercept: 1.0039279688326865\n",
      "iteration - 3879 -> loss: 0.00032628028097017044, self.slope: [1.04527105 1.04553993], self.intercept: 1.003928875126959\n",
      "iteration - 3880 -> loss: 0.0003262596403250294, self.slope: [1.04528115 1.04555011], self.intercept: 1.003929781374607\n",
      "iteration - 3881 -> loss: 0.0003262390023779578, self.slope: [1.04529124 1.0455603 ], self.intercept: 1.0039306875756353\n",
      "iteration - 3882 -> loss: 0.0003262183671284351, self.slope: [1.04530134 1.04557047], self.intercept: 1.0039315937300501\n",
      "iteration - 3883 -> loss: 0.0003261977345759179, self.slope: [1.04531143 1.04558065], self.intercept: 1.0039324998378567\n",
      "iteration - 3884 -> loss: 0.00032617710471988937, self.slope: [1.04532152 1.04559083], self.intercept: 1.0039334058990599\n",
      "iteration - 3885 -> loss: 0.0003261564775597894, self.slope: [1.04533161 1.04560101], self.intercept: 1.0039343119136659\n",
      "iteration - 3886 -> loss: 0.0003261358530950971, self.slope: [1.0453417  1.04561119], self.intercept: 1.0039352178816798\n",
      "iteration - 3887 -> loss: 0.00032611523132526616, self.slope: [1.0453518  1.04562136], self.intercept: 1.0039361238031064\n",
      "iteration - 3888 -> loss: 0.0003260946122497816, self.slope: [1.04536189 1.04563154], self.intercept: 1.0039370296779497\n",
      "iteration - 3889 -> loss: 0.00032607399586807666, self.slope: [1.04537198 1.04564171], self.intercept: 1.0039379355062166\n",
      "iteration - 3890 -> loss: 0.00032605338217964555, self.slope: [1.04538206 1.04565189], self.intercept: 1.0039388412879116\n",
      "iteration - 3891 -> loss: 0.0003260327711839455, self.slope: [1.04539215 1.04566206], self.intercept: 1.003939747023039\n",
      "iteration - 3892 -> loss: 0.00032601216288043216, self.slope: [1.04540224 1.04567224], self.intercept: 1.003940652711608\n",
      "iteration - 3893 -> loss: 0.00032599155726857626, self.slope: [1.04541233 1.04568241], self.intercept: 1.0039415583536198\n",
      "iteration - 3894 -> loss: 0.00032597095434785413, self.slope: [1.04542241 1.04569258], self.intercept: 1.003942463949079\n",
      "iteration - 3895 -> loss: 0.0003259503541177081, self.slope: [1.0454325  1.04570275], self.intercept: 1.0039433694979953\n",
      "iteration - 3896 -> loss: 0.00032592975657763504, self.slope: [1.04544258 1.04571292], self.intercept: 1.0039442750003704\n",
      "iteration - 3897 -> loss: 0.0003259091617270844, self.slope: [1.04545267 1.04572309], self.intercept: 1.0039451804562107\n",
      "iteration - 3898 -> loss: 0.0003258885695655073, self.slope: [1.04546275 1.04573326], self.intercept: 1.0039460858655203\n",
      "iteration - 3899 -> loss: 0.00032586798009239296, self.slope: [1.04547283 1.04574343], self.intercept: 1.0039469912283054\n",
      "iteration - 3900 -> loss: 0.00032584739330719897, self.slope: [1.04548291 1.0457536 ], self.intercept: 1.0039478965445712\n",
      "iteration - 3901 -> loss: 0.0003258268092093938, self.slope: [1.045493   1.04576376], self.intercept: 1.0039488018143226\n",
      "iteration - 3902 -> loss: 0.00032580622779844687, self.slope: [1.04550308 1.04577393], self.intercept: 1.0039497070375654\n",
      "iteration - 3903 -> loss: 0.00032578564907382305, self.slope: [1.04551316 1.0457841 ], self.intercept: 1.003950612214304\n",
      "iteration - 3904 -> loss: 0.00032576507303499374, self.slope: [1.04552324 1.04579426], self.intercept: 1.0039515173445435\n",
      "iteration - 3905 -> loss: 0.00032574449968141657, self.slope: [1.04553332 1.04580443], self.intercept: 1.0039524224282903\n",
      "iteration - 3906 -> loss: 0.00032572392901255827, self.slope: [1.04554339 1.04581459], self.intercept: 1.0039533274655494\n",
      "iteration - 3907 -> loss: 0.0003257033610279028, self.slope: [1.04555347 1.04582475], self.intercept: 1.0039542324563255\n",
      "iteration - 3908 -> loss: 0.0003256827957268931, self.slope: [1.04556355 1.04583492], self.intercept: 1.0039551374006241\n",
      "iteration - 3909 -> loss: 0.0003256622331090029, self.slope: [1.04557362 1.04584508], self.intercept: 1.00395604229845\n",
      "iteration - 3910 -> loss: 0.0003256416731737313, self.slope: [1.0455837  1.04585524], self.intercept: 1.003956947149809\n",
      "iteration - 3911 -> loss: 0.0003256211159205238, self.slope: [1.04559377 1.0458654 ], self.intercept: 1.0039578519547054\n",
      "iteration - 3912 -> loss: 0.00032560056134883027, self.slope: [1.04560385 1.04587556], self.intercept: 1.003958756713145\n",
      "iteration - 3913 -> loss: 0.00032558000945813703, self.slope: [1.04561392 1.04588572], self.intercept: 1.0039596614251336\n",
      "iteration - 3914 -> loss: 0.00032555946024792273, self.slope: [1.04562399 1.04589588], self.intercept: 1.003960566090675\n",
      "iteration - 3915 -> loss: 0.00032553891371765053, self.slope: [1.04563407 1.04590604], self.intercept: 1.0039614707097742\n",
      "iteration - 3916 -> loss: 0.0003255183698667734, self.slope: [1.04564414 1.04591619], self.intercept: 1.003962375282437\n",
      "iteration - 3917 -> loss: 0.00032549782869477334, self.slope: [1.04565421 1.04592635], self.intercept: 1.00396327980867\n",
      "iteration - 3918 -> loss: 0.0003254772902011205, self.slope: [1.04566428 1.04593651], self.intercept: 1.003964184288477\n",
      "iteration - 3919 -> loss: 0.00032545675438528195, self.slope: [1.04567435 1.04594666], self.intercept: 1.0039650887218643\n",
      "iteration - 3920 -> loss: 0.0003254362212467177, self.slope: [1.04568442 1.04595682], self.intercept: 1.0039659931088374\n",
      "iteration - 3921 -> loss: 0.0003254156907849062, self.slope: [1.04569449 1.04596697], self.intercept: 1.0039668974494\n",
      "iteration - 3922 -> loss: 0.00032539516299931616, self.slope: [1.04570455 1.04597712], self.intercept: 1.0039678017435574\n",
      "iteration - 3923 -> loss: 0.00032537463788944316, self.slope: [1.04571462 1.04598728], self.intercept: 1.0039687059913147\n",
      "iteration - 3924 -> loss: 0.0003253541154547097, self.slope: [1.04572469 1.04599743], self.intercept: 1.003969610192678\n",
      "iteration - 3925 -> loss: 0.00032533359569460304, self.slope: [1.04573475 1.04600758], self.intercept: 1.0039705143476518\n",
      "iteration - 3926 -> loss: 0.0003253130786086023, self.slope: [1.04574482 1.04601773], self.intercept: 1.0039714184562418\n",
      "iteration - 3927 -> loss: 0.000325292564196174, self.slope: [1.04575488 1.04602788], self.intercept: 1.0039723225184538\n",
      "iteration - 3928 -> loss: 0.00032527205245679264, self.slope: [1.04576494 1.04603803], self.intercept: 1.0039732265342913\n",
      "iteration - 3929 -> loss: 0.00032525154338991236, self.slope: [1.04577501 1.04604818], self.intercept: 1.00397413050376\n",
      "iteration - 3930 -> loss: 0.0003252310369950437, self.slope: [1.04578507 1.04605833], self.intercept: 1.0039750344268668\n",
      "iteration - 3931 -> loss: 0.0003252105332715945, self.slope: [1.04579513 1.04606847], self.intercept: 1.0039759383036158\n",
      "iteration - 3932 -> loss: 0.0003251900322191001, self.slope: [1.04580519 1.04607862], self.intercept: 1.0039768421340103\n",
      "iteration - 3933 -> loss: 0.00032516953383699803, self.slope: [1.04581525 1.04608877], self.intercept: 1.0039777459180577\n",
      "iteration - 3934 -> loss: 0.0003251490381247568, self.slope: [1.04582531 1.04609891], self.intercept: 1.0039786496557628\n",
      "iteration - 3935 -> loss: 0.00032512854508185416, self.slope: [1.04583537 1.04610906], self.intercept: 1.003979553347131\n",
      "iteration - 3936 -> loss: 0.0003251080547077708, self.slope: [1.04584543 1.0461192 ], self.intercept: 1.0039804569921669\n",
      "iteration - 3937 -> loss: 0.00032508756700196984, self.slope: [1.04585549 1.04612935], self.intercept: 1.0039813605908754\n",
      "iteration - 3938 -> loss: 0.000325067081963928, self.slope: [1.04586554 1.04613949], self.intercept: 1.0039822641432623\n",
      "iteration - 3939 -> loss: 0.00032504659959310136, self.slope: [1.0458756  1.04614963], self.intercept: 1.0039831676493332\n",
      "iteration - 3940 -> loss: 0.0003250261198889899, self.slope: [1.04588566 1.04615977], self.intercept: 1.003984071109092\n",
      "iteration - 3941 -> loss: 0.0003250056428510433, self.slope: [1.04589571 1.04616991], self.intercept: 1.0039849745225455\n",
      "iteration - 3942 -> loss: 0.00032498516847873353, self.slope: [1.04590577 1.04618005], self.intercept: 1.0039858778896988\n",
      "iteration - 3943 -> loss: 0.0003249646967715526, self.slope: [1.04591582 1.04619019], self.intercept: 1.003986781210556\n",
      "iteration - 3944 -> loss: 0.0003249442277289502, self.slope: [1.04592587 1.04620033], self.intercept: 1.003987684485122\n",
      "iteration - 3945 -> loss: 0.00032492376135042646, self.slope: [1.04593592 1.04621047], self.intercept: 1.0039885877134027\n",
      "iteration - 3946 -> loss: 0.0003249032976354331, self.slope: [1.04594598 1.04622061], self.intercept: 1.0039894908954035\n",
      "iteration - 3947 -> loss: 0.0003248828365834433, self.slope: [1.04595603 1.04623074], self.intercept: 1.0039903940311286\n",
      "iteration - 3948 -> loss: 0.0003248623781939357, self.slope: [1.04596608 1.04624088], self.intercept: 1.0039912971205835\n",
      "iteration - 3949 -> loss: 0.0003248419224663876, self.slope: [1.04597613 1.04625102], self.intercept: 1.0039922001637755\n",
      "iteration - 3950 -> loss: 0.0003248214694002782, self.slope: [1.04598618 1.04626115], self.intercept: 1.0039931031607074\n",
      "iteration - 3951 -> loss: 0.0003248010189950679, self.slope: [1.04599622 1.04627129], self.intercept: 1.0039940061113841\n",
      "iteration - 3952 -> loss: 0.0003247805712502289, self.slope: [1.04600627 1.04628142], self.intercept: 1.0039949090158116\n",
      "iteration - 3953 -> loss: 0.0003247601261652378, self.slope: [1.04601632 1.04629155], self.intercept: 1.0039958118739958\n",
      "iteration - 3954 -> loss: 0.00032473968373957743, self.slope: [1.04602637 1.04630169], self.intercept: 1.0039967146859405\n",
      "iteration - 3955 -> loss: 0.0003247192439727145, self.slope: [1.04603641 1.04631182], self.intercept: 1.003997617451652\n",
      "iteration - 3956 -> loss: 0.0003246988068641318, self.slope: [1.04604646 1.04632195], self.intercept: 1.0039985201711352\n",
      "iteration - 3957 -> loss: 0.00032467837241328604, self.slope: [1.0460565  1.04633208], self.intercept: 1.003999422844395\n",
      "iteration - 3958 -> loss: 0.00032465794061967596, self.slope: [1.04606654 1.04634221], self.intercept: 1.0040003254714365\n",
      "iteration - 3959 -> loss: 0.00032463751148275883, self.slope: [1.04607659 1.04635234], self.intercept: 1.0040012280522663\n",
      "iteration - 3960 -> loss: 0.00032461708500199896, self.slope: [1.04608663 1.04636247], self.intercept: 1.0040021305868878\n",
      "iteration - 3961 -> loss: 0.00032459666117690166, self.slope: [1.04609667 1.04637259], self.intercept: 1.0040030330753067\n",
      "iteration - 3962 -> loss: 0.0003245762400069392, self.slope: [1.04610671 1.04638272], self.intercept: 1.0040039355175263\n",
      "iteration - 3963 -> loss: 0.0003245558214915789, self.slope: [1.04611675 1.04639285], self.intercept: 1.0040048379135555\n",
      "iteration - 3964 -> loss: 0.0003245354056302748, self.slope: [1.04612679 1.04640297], self.intercept: 1.0040057402633964\n",
      "iteration - 3965 -> loss: 0.00032451499242252386, self.slope: [1.04613683 1.0464131 ], self.intercept: 1.0040066425670566\n",
      "iteration - 3966 -> loss: 0.0003244945818677966, self.slope: [1.04614687 1.04642322], self.intercept: 1.0040075448245391\n",
      "iteration - 3967 -> loss: 0.00032447417396557735, self.slope: [1.04615691 1.04643335], self.intercept: 1.0040084470358503\n",
      "iteration - 3968 -> loss: 0.00032445376871533693, self.slope: [1.04616695 1.04644347], self.intercept: 1.0040093492009943\n",
      "iteration - 3969 -> loss: 0.00032443336611655206, self.slope: [1.04617698 1.04645359], self.intercept: 1.0040102513199771\n",
      "iteration - 3970 -> loss: 0.0003244129661686966, self.slope: [1.04618702 1.04646372], self.intercept: 1.0040111533928044\n",
      "iteration - 3971 -> loss: 0.0003243925688712351, self.slope: [1.04619705 1.04647384], self.intercept: 1.004012055419481\n",
      "iteration - 3972 -> loss: 0.00032437217422368714, self.slope: [1.04620709 1.04648396], self.intercept: 1.0040129574000107\n",
      "iteration - 3973 -> loss: 0.0003243517822254825, self.slope: [1.04621712 1.04649408], self.intercept: 1.0040138593344001\n",
      "iteration - 3974 -> loss: 0.00032433139287610445, self.slope: [1.04622715 1.0465042 ], self.intercept: 1.0040147612226533\n",
      "iteration - 3975 -> loss: 0.0003243110061750549, self.slope: [1.04623719 1.04651432], self.intercept: 1.004015663064777\n",
      "iteration - 3976 -> loss: 0.00032429062212179795, self.slope: [1.04624722 1.04652443], self.intercept: 1.0040165648607748\n",
      "iteration - 3977 -> loss: 0.00032427024071580936, self.slope: [1.04625725 1.04653455], self.intercept: 1.004017466610653\n",
      "iteration - 3978 -> loss: 0.00032424986195657283, self.slope: [1.04626728 1.04654467], self.intercept: 1.0040183683144164\n",
      "iteration - 3979 -> loss: 0.0003242294858435417, self.slope: [1.04627731 1.04655478], self.intercept: 1.0040192699720694\n",
      "iteration - 3980 -> loss: 0.000324209112376226, self.slope: [1.04628734 1.0465649 ], self.intercept: 1.0040201715836181\n",
      "iteration - 3981 -> loss: 0.00032418874155409406, self.slope: [1.04629737 1.04657501], self.intercept: 1.0040210731490673\n",
      "iteration - 3982 -> loss: 0.00032416837337661137, self.slope: [1.0463074  1.04658513], self.intercept: 1.004021974668423\n",
      "iteration - 3983 -> loss: 0.00032414800784327466, self.slope: [1.04631742 1.04659524], self.intercept: 1.0040228761416887\n",
      "iteration - 3984 -> loss: 0.00032412764495354213, self.slope: [1.04632745 1.04660535], self.intercept: 1.0040237775688707\n",
      "iteration - 3985 -> loss: 0.00032410728470691616, self.slope: [1.04633748 1.04661547], self.intercept: 1.0040246789499736\n",
      "iteration - 3986 -> loss: 0.0003240869271028452, self.slope: [1.0463475  1.04662558], self.intercept: 1.0040255802850022\n",
      "iteration - 3987 -> loss: 0.00032406657214083473, self.slope: [1.04635753 1.04663569], self.intercept: 1.0040264815739632\n",
      "iteration - 3988 -> loss: 0.00032404621982036886, self.slope: [1.04636755 1.0466458 ], self.intercept: 1.004027382816861\n",
      "iteration - 3989 -> loss: 0.0003240258701408773, self.slope: [1.04637757 1.04665591], self.intercept: 1.0040282840137005\n",
      "iteration - 3990 -> loss: 0.0003240055231019026, self.slope: [1.0463876  1.04666602], self.intercept: 1.0040291851644865\n",
      "iteration - 3991 -> loss: 0.00032398517870288273, self.slope: [1.04639762 1.04667613], self.intercept: 1.0040300862692249\n",
      "iteration - 3992 -> loss: 0.0003239648369433101, self.slope: [1.04640764 1.04668623], self.intercept: 1.0040309873279196\n",
      "iteration - 3993 -> loss: 0.00032394449782266243, self.slope: [1.04641766 1.04669634], self.intercept: 1.0040318883405759\n",
      "iteration - 3994 -> loss: 0.00032392416134042356, self.slope: [1.04642768 1.04670645], self.intercept: 1.004032789307199\n",
      "iteration - 3995 -> loss: 0.00032390382749607254, self.slope: [1.0464377  1.04671655], self.intercept: 1.0040336902277964\n",
      "iteration - 3996 -> loss: 0.0003238834962890811, self.slope: [1.04644772 1.04672666], self.intercept: 1.0040345911023711\n",
      "iteration - 3997 -> loss: 0.0003238631677189435, self.slope: [1.04645774 1.04673676], self.intercept: 1.004035491930928\n",
      "iteration - 3998 -> loss: 0.00032384284178512085, self.slope: [1.04646775 1.04674687], self.intercept: 1.004036392713473\n",
      "iteration - 3999 -> loss: 0.00032382251848711184, self.slope: [1.04647777 1.04675697], self.intercept: 1.0040372934500115\n",
      "iteration - 4000 -> loss: 0.0003238021978243795, self.slope: [1.04648779 1.04676707], self.intercept: 1.004038194140548\n",
      "iteration - 4001 -> loss: 0.0003237818797964101, self.slope: [1.0464978  1.04677717], self.intercept: 1.0040390947850881\n",
      "iteration - 4002 -> loss: 0.00032376156440271824, self.slope: [1.04650782 1.04678727], self.intercept: 1.0040399953836354\n",
      "iteration - 4003 -> loss: 0.00032374125164273687, self.slope: [1.04651783 1.04679737], self.intercept: 1.0040408959361973\n",
      "iteration - 4004 -> loss: 0.0003237209415159692, self.slope: [1.04652784 1.04680747], self.intercept: 1.004041796442778\n",
      "iteration - 4005 -> loss: 0.0003237006340218871, self.slope: [1.04653786 1.04681757], self.intercept: 1.0040426969033822\n",
      "iteration - 4006 -> loss: 0.00032368032915997826, self.slope: [1.04654787 1.04682767], self.intercept: 1.0040435973180157\n",
      "iteration - 4007 -> loss: 0.00032366002692972367, self.slope: [1.04655788 1.04683777], self.intercept: 1.0040444976866838\n",
      "iteration - 4008 -> loss: 0.000323639727330604, self.slope: [1.04656789 1.04684787], self.intercept: 1.0040453980093917\n",
      "iteration - 4009 -> loss: 0.0003236194303621103, self.slope: [1.0465779  1.04685796], self.intercept: 1.0040462982861422\n",
      "iteration - 4010 -> loss: 0.0003235991360237248, self.slope: [1.04658791 1.04686806], self.intercept: 1.0040471985169417\n",
      "iteration - 4011 -> loss: 0.0003235788443148945, self.slope: [1.04659792 1.04687815], self.intercept: 1.0040480987017957\n",
      "iteration - 4012 -> loss: 0.00032355855523514, self.slope: [1.04660793 1.04688825], self.intercept: 1.0040489988407097\n",
      "iteration - 4013 -> loss: 0.0003235382687839227, self.slope: [1.04661794 1.04689834], self.intercept: 1.004049898933688\n",
      "iteration - 4014 -> loss: 0.00032351798496075483, self.slope: [1.04662794 1.04690844], self.intercept: 1.0040507989807372\n",
      "iteration - 4015 -> loss: 0.000323497703765092, self.slope: [1.04663795 1.04691853], self.intercept: 1.0040516989818618\n",
      "iteration - 4016 -> loss: 0.0003234774251964138, self.slope: [1.04664796 1.04692862], self.intercept: 1.0040525989370659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 4017 -> loss: 0.0003234571492542208, self.slope: [1.04665796 1.04693871], self.intercept: 1.0040534988463552\n",
      "iteration - 4018 -> loss: 0.0003234368759379854, self.slope: [1.04666797 1.0469488 ], self.intercept: 1.0040543987097348\n",
      "iteration - 4019 -> loss: 0.00032341660524719197, self.slope: [1.04667797 1.04695889], self.intercept: 1.00405529852721\n",
      "iteration - 4020 -> loss: 0.00032339633718131227, self.slope: [1.04668797 1.04696898], self.intercept: 1.0040561982987863\n",
      "iteration - 4021 -> loss: 0.0003233760717398594, self.slope: [1.04669797 1.04697907], self.intercept: 1.004057098024468\n",
      "iteration - 4022 -> loss: 0.0003233558089222892, self.slope: [1.04670798 1.04698916], self.intercept: 1.004057997704261\n",
      "iteration - 4023 -> loss: 0.0003233355487281089, self.slope: [1.04671798 1.04699925], self.intercept: 1.00405889733817\n",
      "iteration - 4024 -> loss: 0.00032331529115677595, self.slope: [1.04672798 1.04700933], self.intercept: 1.0040597969261995\n",
      "iteration - 4025 -> loss: 0.000323295036207787, self.slope: [1.04673798 1.04701942], self.intercept: 1.0040606964683558\n",
      "iteration - 4026 -> loss: 0.00032327478388063734, self.slope: [1.04674798 1.04702951], self.intercept: 1.0040615959646433\n",
      "iteration - 4027 -> loss: 0.00032325453417479254, self.slope: [1.04675797 1.04703959], self.intercept: 1.0040624954150676\n",
      "iteration - 4028 -> loss: 0.0003232342870897567, self.slope: [1.04676797 1.04704968], self.intercept: 1.0040633948196318\n",
      "iteration - 4029 -> loss: 0.0003232140426249961, self.slope: [1.04677797 1.04705976], self.intercept: 1.0040642941783435\n",
      "iteration - 4030 -> loss: 0.0003231938007799999, self.slope: [1.04678797 1.04706984], self.intercept: 1.0040651934912082\n",
      "iteration - 4031 -> loss: 0.0003231735615542477, self.slope: [1.04679796 1.04707992], self.intercept: 1.0040660927582281\n",
      "iteration - 4032 -> loss: 0.0003231533249472414, self.slope: [1.04680796 1.04709001], self.intercept: 1.0040669919794094\n",
      "iteration - 4033 -> loss: 0.0003231330909584464, self.slope: [1.04681795 1.04710009], self.intercept: 1.0040678911547583\n",
      "iteration - 4034 -> loss: 0.00032311285958735477, self.slope: [1.04682795 1.04711017], self.intercept: 1.0040687902842795\n",
      "iteration - 4035 -> loss: 0.0003230926308334862, self.slope: [1.04683794 1.04712025], self.intercept: 1.004069689367979\n",
      "iteration - 4036 -> loss: 0.00032307240469626867, self.slope: [1.04684793 1.04713033], self.intercept: 1.0040705884058598\n",
      "iteration - 4037 -> loss: 0.00032305218117522174, self.slope: [1.04685792 1.0471404 ], self.intercept: 1.0040714873979286\n",
      "iteration - 4038 -> loss: 0.0003230319602698119, self.slope: [1.04686791 1.04715048], self.intercept: 1.0040723863441896\n",
      "iteration - 4039 -> loss: 0.0003230117419795488, self.slope: [1.04687791 1.04716056], self.intercept: 1.004073285244648\n",
      "iteration - 4040 -> loss: 0.00032299152630391474, self.slope: [1.0468879  1.04717064], self.intercept: 1.0040741840993097\n",
      "iteration - 4041 -> loss: 0.0003229713132423584, self.slope: [1.04689788 1.04718071], self.intercept: 1.0040750829081784\n",
      "iteration - 4042 -> loss: 0.00032295110279440177, self.slope: [1.04690787 1.04719079], self.intercept: 1.004075981671262\n",
      "iteration - 4043 -> loss: 0.000322930894959539, self.slope: [1.04691786 1.04720086], self.intercept: 1.0040768803885616\n",
      "iteration - 4044 -> loss: 0.00032291068973724246, self.slope: [1.04692785 1.04721094], self.intercept: 1.0040777790600857\n",
      "iteration - 4045 -> loss: 0.0003228904871270015, self.slope: [1.04693784 1.04722101], self.intercept: 1.0040786776858353\n",
      "iteration - 4046 -> loss: 0.0003228702871282849, self.slope: [1.04694782 1.04723108], self.intercept: 1.0040795762658201\n",
      "iteration - 4047 -> loss: 0.0003228500897406007, self.slope: [1.04695781 1.04724115], self.intercept: 1.0040804748000434\n",
      "iteration - 4048 -> loss: 0.0003228298949634318, self.slope: [1.04696779 1.04725122], self.intercept: 1.0040813732885094\n",
      "iteration - 4049 -> loss: 0.00032280970279625453, self.slope: [1.04697778 1.0472613 ], self.intercept: 1.0040822717312252\n",
      "iteration - 4050 -> loss: 0.00032278951323856415, self.slope: [1.04698776 1.04727137], self.intercept: 1.0040831701281938\n",
      "iteration - 4051 -> loss: 0.00032276932628986095, self.slope: [1.04699774 1.04728143], self.intercept: 1.0040840684794212\n",
      "iteration - 4052 -> loss: 0.0003227491419496069, self.slope: [1.04700772 1.0472915 ], self.intercept: 1.0040849667849123\n",
      "iteration - 4053 -> loss: 0.0003227289602173234, self.slope: [1.04701771 1.04730157], self.intercept: 1.0040858650446733\n",
      "iteration - 4054 -> loss: 0.00032270878109246566, self.slope: [1.04702769 1.04731164], self.intercept: 1.0040867632587085\n",
      "iteration - 4055 -> loss: 0.0003226886045745185, self.slope: [1.04703767 1.04732171], self.intercept: 1.0040876614270222\n",
      "iteration - 4056 -> loss: 0.0003226684306630094, self.slope: [1.04704765 1.04733177], self.intercept: 1.0040885595496205\n",
      "iteration - 4057 -> loss: 0.00032264825935739876, self.slope: [1.04705763 1.04734184], self.intercept: 1.0040894576265071\n",
      "iteration - 4058 -> loss: 0.00032262809065717555, self.slope: [1.0470676 1.0473519], self.intercept: 1.004090355657688\n",
      "iteration - 4059 -> loss: 0.000322607924561826, self.slope: [1.04707758 1.04736197], self.intercept: 1.0040912536431688\n",
      "iteration - 4060 -> loss: 0.0003225877610708508, self.slope: [1.04708756 1.04737203], self.intercept: 1.0040921515829544\n",
      "iteration - 4061 -> loss: 0.0003225676001837415, self.slope: [1.04709753 1.04738209], self.intercept: 1.0040930494770492\n",
      "iteration - 4062 -> loss: 0.00032254744189997626, self.slope: [1.04710751 1.04739216], self.intercept: 1.0040939473254578\n",
      "iteration - 4063 -> loss: 0.00032252728621903694, self.slope: [1.04711748 1.04740222], self.intercept: 1.004094845128187\n",
      "iteration - 4064 -> loss: 0.00032250713314041783, self.slope: [1.04712746 1.04741228], self.intercept: 1.0040957428852406\n",
      "iteration - 4065 -> loss: 0.0003224869826636321, self.slope: [1.04713743 1.04742234], self.intercept: 1.0040966405966238\n",
      "iteration - 4066 -> loss: 0.00032246683478815504, self.slope: [1.04714741 1.0474324 ], self.intercept: 1.0040975382623423\n",
      "iteration - 4067 -> loss: 0.00032244668951344785, self.slope: [1.04715738 1.04744246], self.intercept: 1.0040984358824017\n",
      "iteration - 4068 -> loss: 0.0003224265468390412, self.slope: [1.04716735 1.04745252], self.intercept: 1.0040993334568047\n",
      "iteration - 4069 -> loss: 0.0003224064067643727, self.slope: [1.04717732 1.04746257], self.intercept: 1.0041002309855591\n",
      "iteration - 4070 -> loss: 0.0003223862692889965, self.slope: [1.04718729 1.04747263], self.intercept: 1.0041011284686667\n",
      "iteration - 4071 -> loss: 0.0003223661344123763, self.slope: [1.04719726 1.04748269], self.intercept: 1.004102025906134\n",
      "iteration - 4072 -> loss: 0.0003223460021339947, self.slope: [1.04720723 1.04749274], self.intercept: 1.004102923297969\n",
      "iteration - 4073 -> loss: 0.0003223258724533474, self.slope: [1.0472172 1.0475028], self.intercept: 1.0041038206441733\n",
      "iteration - 4074 -> loss: 0.0003223057453699285, self.slope: [1.04722717 1.04751285], self.intercept: 1.0041047179447542\n",
      "iteration - 4075 -> loss: 0.00032228562088321025, self.slope: [1.04723713 1.04752291], self.intercept: 1.004105615199715\n",
      "iteration - 4076 -> loss: 0.0003222654989927111, self.slope: [1.0472471  1.04753296], self.intercept: 1.0041065124090611\n",
      "iteration - 4077 -> loss: 0.0003222453796979068, self.slope: [1.04725707 1.04754301], self.intercept: 1.0041074095727982\n",
      "iteration - 4078 -> loss: 0.0003222252629982846, self.slope: [1.04726703 1.04755306], self.intercept: 1.0041083066909313\n",
      "iteration - 4079 -> loss: 0.0003222051488933402, self.slope: [1.047277   1.04756312], self.intercept: 1.004109203763465\n",
      "iteration - 4080 -> loss: 0.0003221850373825843, self.slope: [1.04728696 1.04757317], self.intercept: 1.004110100790404\n",
      "iteration - 4081 -> loss: 0.0003221649284654755, self.slope: [1.04729692 1.04758322], self.intercept: 1.004110997771754\n",
      "iteration - 4082 -> loss: 0.00032214482214152295, self.slope: [1.04730689 1.04759327], self.intercept: 1.0041118947075218\n",
      "iteration - 4083 -> loss: 0.00032212471841020716, self.slope: [1.04731685 1.04760331], self.intercept: 1.00411279159771\n",
      "iteration - 4084 -> loss: 0.00032210461727104497, self.slope: [1.04732681 1.04761336], self.intercept: 1.0041136884423234\n",
      "iteration - 4085 -> loss: 0.0003220845187235086, self.slope: [1.04733677 1.04762341], self.intercept: 1.0041145852413678\n",
      "iteration - 4086 -> loss: 0.00032206442276709585, self.slope: [1.04734673 1.04763346], self.intercept: 1.0041154819948483\n",
      "iteration - 4087 -> loss: 0.0003220443294013019, self.slope: [1.04735669 1.0476435 ], self.intercept: 1.0041163787027703\n",
      "iteration - 4088 -> loss: 0.0003220242386256055, self.slope: [1.04736665 1.04765355], self.intercept: 1.0041172753651397\n",
      "iteration - 4089 -> loss: 0.0003220041504395047, self.slope: [1.04737661 1.04766359], self.intercept: 1.0041181719819599\n",
      "iteration - 4090 -> loss: 0.00032198406484250527, self.slope: [1.04738656 1.04767364], self.intercept: 1.0041190685532364\n",
      "iteration - 4091 -> loss: 0.0003219639818340775, self.slope: [1.04739652 1.04768368], self.intercept: 1.0041199650789745\n",
      "iteration - 4092 -> loss: 0.00032194390141374035, self.slope: [1.04740648 1.04769372], self.intercept: 1.0041208615591795\n",
      "iteration - 4093 -> loss: 0.00032192382358096975, self.slope: [1.04741643 1.04770377], self.intercept: 1.0041217579938544\n",
      "iteration - 4094 -> loss: 0.000321903748335272, self.slope: [1.04742639 1.04771381], self.intercept: 1.0041226543830073\n",
      "iteration - 4095 -> loss: 0.00032188367567610813, self.slope: [1.04743634 1.04772385], self.intercept: 1.004123550726642\n",
      "iteration - 4096 -> loss: 0.0003218636056030223, self.slope: [1.0474463  1.04773389], self.intercept: 1.0041244470247643\n",
      "iteration - 4097 -> loss: 0.00032184353811546835, self.slope: [1.04745625 1.04774393], self.intercept: 1.0041253432773762\n",
      "iteration - 4098 -> loss: 0.00032182347321295103, self.slope: [1.0474662  1.04775397], self.intercept: 1.0041262394844863\n",
      "iteration - 4099 -> loss: 0.00032180341089497555, self.slope: [1.04747615 1.04776401], self.intercept: 1.0041271356460977\n",
      "iteration - 4100 -> loss: 0.0003217833511610366, self.slope: [1.0474861  1.04777405], self.intercept: 1.0041280317622163\n",
      "iteration - 4101 -> loss: 0.0003217632940105906, self.slope: [1.04749605 1.04778408], self.intercept: 1.004128927832847\n",
      "iteration - 4102 -> loss: 0.0003217432394431794, self.slope: [1.047506   1.04779412], self.intercept: 1.004129823857994\n",
      "iteration - 4103 -> loss: 0.000321723187458261, self.slope: [1.04751595 1.04780415], self.intercept: 1.0041307198376637\n",
      "iteration - 4104 -> loss: 0.00032170313805536516, self.slope: [1.0475259  1.04781419], self.intercept: 1.0041316157718596\n",
      "iteration - 4105 -> loss: 0.00032168309123395156, self.slope: [1.04753585 1.04782422], self.intercept: 1.0041325116605884\n",
      "iteration - 4106 -> loss: 0.00032166304699355675, self.slope: [1.0475458  1.04783426], self.intercept: 1.0041334075038544\n",
      "iteration - 4107 -> loss: 0.00032164300533363705, self.slope: [1.04755574 1.04784429], self.intercept: 1.0041343033016628\n",
      "iteration - 4108 -> loss: 0.00032162296625369395, self.slope: [1.04756569 1.04785432], self.intercept: 1.0041351990540182\n",
      "iteration - 4109 -> loss: 0.0003216029297532258, self.slope: [1.04757563 1.04786436], self.intercept: 1.0041360947609261\n",
      "iteration - 4110 -> loss: 0.0003215828958317479, self.slope: [1.04758558 1.04787439], self.intercept: 1.004136990422392\n",
      "iteration - 4111 -> loss: 0.00032156286448873034, self.slope: [1.04759552 1.04788442], self.intercept: 1.0041378860384196\n",
      "iteration - 4112 -> loss: 0.0003215428357236851, self.slope: [1.04760547 1.04789445], self.intercept: 1.004138781609014\n",
      "iteration - 4113 -> loss: 0.0003215228095360988, self.slope: [1.04761541 1.04790448], self.intercept: 1.004139677134181\n",
      "iteration - 4114 -> loss: 0.00032150278592547226, self.slope: [1.04762535 1.04791451], self.intercept: 1.0041405726139252\n",
      "iteration - 4115 -> loss: 0.0003214827648912908, self.slope: [1.04763529 1.04792454], self.intercept: 1.0041414680482519\n",
      "iteration - 4116 -> loss: 0.0003214627464330645, self.slope: [1.04764523 1.04793456], self.intercept: 1.0041423634371665\n",
      "iteration - 4117 -> loss: 0.00032144273055028527, self.slope: [1.04765517 1.04794459], self.intercept: 1.004143258780674\n",
      "iteration - 4118 -> loss: 0.0003214227172424539, self.slope: [1.04766511 1.04795462], self.intercept: 1.0041441540787788\n",
      "iteration - 4119 -> loss: 0.00032140270650906293, self.slope: [1.04767505 1.04796464], self.intercept: 1.0041450493314859\n",
      "iteration - 4120 -> loss: 0.00032138269834959847, self.slope: [1.04768499 1.04797467], self.intercept: 1.0041459445388\n",
      "iteration - 4121 -> loss: 0.00032136269276356955, self.slope: [1.04769493 1.04798469], self.intercept: 1.0041468397007272\n",
      "iteration - 4122 -> loss: 0.00032134268975046254, self.slope: [1.04770486 1.04799472], self.intercept: 1.0041477348172732\n",
      "iteration - 4123 -> loss: 0.0003213226893097894, self.slope: [1.0477148  1.04800474], self.intercept: 1.004148629888441\n",
      "iteration - 4124 -> loss: 0.0003213026914410423, self.slope: [1.04772473 1.04801476], self.intercept: 1.0041495249142358\n",
      "iteration - 4125 -> loss: 0.00032128269614370696, self.slope: [1.04773467 1.04802478], self.intercept: 1.0041504198946654\n",
      "iteration - 4126 -> loss: 0.00032126270341730265, self.slope: [1.0477446 1.0480348], self.intercept: 1.004151314829731\n",
      "iteration - 4127 -> loss: 0.0003212427132613051, self.slope: [1.04775454 1.04804482], self.intercept: 1.0041522097194395\n",
      "iteration - 4128 -> loss: 0.0003212227256752244, self.slope: [1.04776447 1.04805484], self.intercept: 1.0041531045637953\n",
      "iteration - 4129 -> loss: 0.0003212027406585509, self.slope: [1.0477744  1.04806486], self.intercept: 1.0041539993628044\n",
      "iteration - 4130 -> loss: 0.00032118275821080067, self.slope: [1.04778433 1.04807488], self.intercept: 1.0041548941164713\n",
      "iteration - 4131 -> loss: 0.00032116277833144953, self.slope: [1.04779426 1.0480849 ], self.intercept: 1.0041557888248012\n",
      "iteration - 4132 -> loss: 0.00032114280102001015, self.slope: [1.04780419 1.04809492], self.intercept: 1.0041566834877995\n",
      "iteration - 4133 -> loss: 0.0003211228262759699, self.slope: [1.04781412 1.04810493], self.intercept: 1.00415757810547\n",
      "iteration - 4134 -> loss: 0.00032110285409884425, self.slope: [1.04782405 1.04811495], self.intercept: 1.0041584726778177\n",
      "iteration - 4135 -> loss: 0.00032108288448810097, self.slope: [1.04783398 1.04812497], self.intercept: 1.0041593672048492\n",
      "iteration - 4136 -> loss: 0.0003210629174432785, self.slope: [1.04784391 1.04813498], self.intercept: 1.004160261686569\n",
      "iteration - 4137 -> loss: 0.0003210429529638379, self.slope: [1.04785384 1.048145  ], self.intercept: 1.0041611561229815\n",
      "iteration - 4138 -> loss: 0.00032102299104930053, self.slope: [1.04786376 1.04815501], self.intercept: 1.0041620505140922\n",
      "iteration - 4139 -> loss: 0.0003210030316991733, self.slope: [1.04787369 1.04816502], self.intercept: 1.0041629448599054\n",
      "iteration - 4140 -> loss: 0.0003209830749129478, self.slope: [1.04788361 1.04817503], self.intercept: 1.0041638391604268\n",
      "iteration - 4141 -> loss: 0.00032096312069010695, self.slope: [1.04789354 1.04818505], self.intercept: 1.0041647334156618\n",
      "iteration - 4142 -> loss: 0.0003209431690301607, self.slope: [1.04790346 1.04819506], self.intercept: 1.0041656276256152\n",
      "iteration - 4143 -> loss: 0.0003209232199326178, self.slope: [1.04791339 1.04820507], self.intercept: 1.0041665217902904\n",
      "iteration - 4144 -> loss: 0.00032090327339696673, self.slope: [1.04792331 1.04821508], self.intercept: 1.0041674159096932\n",
      "iteration - 4145 -> loss: 0.0003208833294227121, self.slope: [1.04793323 1.04822509], self.intercept: 1.0041683099838294\n",
      "iteration - 4146 -> loss: 0.0003208633880093547, self.slope: [1.04794315 1.04823509], self.intercept: 1.004169204012703\n",
      "iteration - 4147 -> loss: 0.00032084344915638794, self.slope: [1.04795307 1.0482451 ], self.intercept: 1.0041700979963213\n",
      "iteration - 4148 -> loss: 0.0003208235128633374, self.slope: [1.04796299 1.04825511], self.intercept: 1.0041709919346862\n",
      "iteration - 4149 -> loss: 0.00032080357912966684, self.slope: [1.04797291 1.04826512], self.intercept: 1.0041718858278055\n",
      "iteration - 4150 -> loss: 0.0003207836479549117, self.slope: [1.04798283 1.04827512], self.intercept: 1.0041727796756814\n",
      "iteration - 4151 -> loss: 0.00032076371933853585, self.slope: [1.04799275 1.04828513], self.intercept: 1.0041736734783215\n",
      "iteration - 4152 -> loss: 0.0003207437932800629, self.slope: [1.04800267 1.04829513], self.intercept: 1.0041745672357285\n",
      "iteration - 4153 -> loss: 0.00032072386977899836, self.slope: [1.04801258 1.04830514], self.intercept: 1.0041754609479088\n",
      "iteration - 4154 -> loss: 0.0003207039488348337, self.slope: [1.0480225  1.04831514], self.intercept: 1.0041763546148685\n",
      "iteration - 4155 -> loss: 0.00032068403044707277, self.slope: [1.04803242 1.04832514], self.intercept: 1.0041772482366098\n",
      "iteration - 4156 -> loss: 0.0003206641146152078, self.slope: [1.04804233 1.04833514], self.intercept: 1.0041781418131392\n",
      "iteration - 4157 -> loss: 0.0003206442013387621, self.slope: [1.04805224 1.04834514], self.intercept: 1.0041790353444624\n",
      "iteration - 4158 -> loss: 0.0003206242906172239, self.slope: [1.04806216 1.04835515], self.intercept: 1.0041799288305842\n",
      "iteration - 4159 -> loss: 0.00032060438245008283, self.slope: [1.04807207 1.04836515], self.intercept: 1.0041808222715083\n",
      "iteration - 4160 -> loss: 0.00032058447683687376, self.slope: [1.04808198 1.04837515], self.intercept: 1.004181715667241\n",
      "iteration - 4161 -> loss: 0.00032056457377706743, self.slope: [1.0480919  1.04838514], self.intercept: 1.0041826090177854\n",
      "iteration - 4162 -> loss: 0.0003205446732701799, self.slope: [1.04810181 1.04839514], self.intercept: 1.0041835023231471\n",
      "iteration - 4163 -> loss: 0.0003205247753157093, self.slope: [1.04811172 1.04840514], self.intercept: 1.0041843955833332\n",
      "iteration - 4164 -> loss: 0.0003205048799131539, self.slope: [1.04812163 1.04841514], self.intercept: 1.004185288798348\n",
      "iteration - 4165 -> loss: 0.00032048498706203975, self.slope: [1.04813154 1.04842513], self.intercept: 1.004186181968195\n",
      "iteration - 4166 -> loss: 0.0003204650967618246, self.slope: [1.04814144 1.04843513], self.intercept: 1.004187075092879\n",
      "iteration - 4167 -> loss: 0.0003204452090120584, self.slope: [1.04815135 1.04844512], self.intercept: 1.0041879681724064\n",
      "iteration - 4168 -> loss: 0.00032042532381221207, self.slope: [1.04816126 1.04845512], self.intercept: 1.0041888612067815\n",
      "iteration - 4169 -> loss: 0.00032040544116181764, self.slope: [1.04817117 1.04846511], self.intercept: 1.0041897541960092\n",
      "iteration - 4170 -> loss: 0.00032038556106034094, self.slope: [1.04818107 1.04847511], self.intercept: 1.0041906471400952\n",
      "iteration - 4171 -> loss: 0.00032036568350732786, self.slope: [1.04819098 1.0484851 ], self.intercept: 1.0041915400390449\n",
      "iteration - 4172 -> loss: 0.00032034580850225536, self.slope: [1.04820088 1.04849509], self.intercept: 1.004192432892862\n",
      "iteration - 4173 -> loss: 0.00032032593604463004, self.slope: [1.04821079 1.04850508], self.intercept: 1.0041933257015514\n",
      "iteration - 4174 -> loss: 0.00032030606613395624, self.slope: [1.04822069 1.04851507], self.intercept: 1.0041942184651187\n",
      "iteration - 4175 -> loss: 0.0003202861987697377, self.slope: [1.04823059 1.04852506], self.intercept: 1.0041951111835679\n",
      "iteration - 4176 -> loss: 0.0003202663339514837, self.slope: [1.04824049 1.04853505], self.intercept: 1.0041960038569056\n",
      "iteration - 4177 -> loss: 0.0003202464716786807, self.slope: [1.0482504  1.04854504], self.intercept: 1.0041968964851364\n",
      "iteration - 4178 -> loss: 0.000320226611950873, self.slope: [1.0482603  1.04855503], self.intercept: 1.004197789068264\n",
      "iteration - 4179 -> loss: 0.00032020675476752123, self.slope: [1.0482702  1.04856501], self.intercept: 1.004198681606295\n",
      "iteration - 4180 -> loss: 0.00032018690012815406, self.slope: [1.0482801 1.048575 ], self.intercept: 1.004199574099233\n",
      "iteration - 4181 -> loss: 0.0003201670480322745, self.slope: [1.04828999 1.04858499], self.intercept: 1.0042004665470845\n",
      "iteration - 4182 -> loss: 0.0003201471984793744, self.slope: [1.04829989 1.04859497], self.intercept: 1.0042013589498529\n",
      "iteration - 4183 -> loss: 0.00032012735146896664, self.slope: [1.04830979 1.04860496], self.intercept: 1.004202251307543\n",
      "iteration - 4184 -> loss: 0.00032010750700055463, self.slope: [1.04831969 1.04861494], self.intercept: 1.0042031436201613\n",
      "iteration - 4185 -> loss: 0.0003200876650736658, self.slope: [1.04832958 1.04862493], self.intercept: 1.0042040358877116\n",
      "iteration - 4186 -> loss: 0.0003200678256877625, self.slope: [1.04833948 1.04863491], self.intercept: 1.0042049281102006\n",
      "iteration - 4187 -> loss: 0.00032004798884238553, self.slope: [1.04834937 1.04864489], self.intercept: 1.0042058202876323\n",
      "iteration - 4188 -> loss: 0.00032002815453702806, self.slope: [1.04835927 1.04865487], self.intercept: 1.004206712420011\n",
      "iteration - 4189 -> loss: 0.00032000832277119897, self.slope: [1.04836916 1.04866485], self.intercept: 1.0042076045073416\n",
      "iteration - 4190 -> loss: 0.00031998849354439464, self.slope: [1.04837906 1.04867483], self.intercept: 1.0042084965496292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 4191 -> loss: 0.000319968666856121, self.slope: [1.04838895 1.04868481], self.intercept: 1.0042093885468788\n",
      "iteration - 4192 -> loss: 0.0003199488427058973, self.slope: [1.04839884 1.04869479], self.intercept: 1.0042102804990976\n",
      "iteration - 4193 -> loss: 0.000319929021093238, self.slope: [1.04840873 1.04870477], self.intercept: 1.004211172406288\n",
      "iteration - 4194 -> loss: 0.0003199092020176178, self.slope: [1.04841862 1.04871475], self.intercept: 1.0042120642684544\n",
      "iteration - 4195 -> loss: 0.00031988938547856526, self.slope: [1.04842851 1.04872473], self.intercept: 1.0042129560856035\n",
      "iteration - 4196 -> loss: 0.0003198695714755689, self.slope: [1.0484384 1.0487347], self.intercept: 1.0042138478577405\n",
      "iteration - 4197 -> loss: 0.000319849760008168, self.slope: [1.04844829 1.04874468], self.intercept: 1.0042147395848695\n",
      "iteration - 4198 -> loss: 0.000319829951075843, self.slope: [1.04845818 1.04875466], self.intercept: 1.0042156312669954\n",
      "iteration - 4199 -> loss: 0.0003198101446781107, self.slope: [1.04846807 1.04876463], self.intercept: 1.0042165229041229\n",
      "iteration - 4200 -> loss: 0.00031979034081446777, self.slope: [1.04847795 1.0487746 ], self.intercept: 1.0042174144962583\n",
      "iteration - 4201 -> loss: 0.00031977053948442717, self.slope: [1.04848784 1.04878458], self.intercept: 1.0042183060434062\n",
      "iteration - 4202 -> loss: 0.00031975074068750346, self.slope: [1.04849772 1.04879455], self.intercept: 1.0042191975455703\n",
      "iteration - 4203 -> loss: 0.0003197309444231966, self.slope: [1.04850761 1.04880452], self.intercept: 1.0042200890027546\n",
      "iteration - 4204 -> loss: 0.0003197111506910237, self.slope: [1.04851749 1.04881449], self.intercept: 1.0042209804149675\n",
      "iteration - 4205 -> loss: 0.0003196913594904774, self.slope: [1.04852738 1.04882447], self.intercept: 1.0042218717822118\n",
      "iteration - 4206 -> loss: 0.0003196715708210784, self.slope: [1.04853726 1.04883444], self.intercept: 1.0042227631044924\n",
      "iteration - 4207 -> loss: 0.00031965178468233246, self.slope: [1.04854714 1.04884441], self.intercept: 1.004223654381816\n",
      "iteration - 4208 -> loss: 0.00031963200107373835, self.slope: [1.04855702 1.04885437], self.intercept: 1.0042245456141845\n",
      "iteration - 4209 -> loss: 0.00031961221999482226, self.slope: [1.0485669  1.04886434], self.intercept: 1.004225436801606\n",
      "iteration - 4210 -> loss: 0.000319592441445072, self.slope: [1.04857678 1.04887431], self.intercept: 1.004226327944084\n",
      "iteration - 4211 -> loss: 0.0003195726654239975, self.slope: [1.04858666 1.04888428], self.intercept: 1.0042272190416228\n",
      "iteration - 4212 -> loss: 0.000319552891931122, self.slope: [1.04859654 1.04889424], self.intercept: 1.004228110094228\n",
      "iteration - 4213 -> loss: 0.0003195331209659456, self.slope: [1.04860642 1.04890421], self.intercept: 1.0042290011019053\n",
      "iteration - 4214 -> loss: 0.0003195133525279829, self.slope: [1.0486163  1.04891418], self.intercept: 1.0042298920646586\n",
      "iteration - 4215 -> loss: 0.00031949358661675497, self.slope: [1.04862618 1.04892414], self.intercept: 1.0042307829824928\n",
      "iteration - 4216 -> loss: 0.0003194738232317396, self.slope: [1.04863605 1.0489341 ], self.intercept: 1.004231673855413\n",
      "iteration - 4217 -> loss: 0.00031945406237246184, self.slope: [1.04864593 1.04894407], self.intercept: 1.004232564683424\n",
      "iteration - 4218 -> loss: 0.0003194343040384221, self.slope: [1.0486558  1.04895403], self.intercept: 1.0042334554665324\n",
      "iteration - 4219 -> loss: 0.0003194145482291642, self.slope: [1.04866568 1.04896399], self.intercept: 1.0042343462047414\n",
      "iteration - 4220 -> loss: 0.00031939479494416857, self.slope: [1.04867555 1.04897395], self.intercept: 1.004235236898057\n",
      "iteration - 4221 -> loss: 0.0003193750441829222, self.slope: [1.04868543 1.04898391], self.intercept: 1.0042361275464822\n",
      "iteration - 4222 -> loss: 0.0003193552959450012, self.slope: [1.0486953  1.04899387], self.intercept: 1.0042370181500235\n",
      "iteration - 4223 -> loss: 0.000319335550229856, self.slope: [1.04870517 1.04900383], self.intercept: 1.0042379087086868\n",
      "iteration - 4224 -> loss: 0.00031931580703701293, self.slope: [1.04871504 1.04901379], self.intercept: 1.0042387992224746\n",
      "iteration - 4225 -> loss: 0.0003192960663660026, self.slope: [1.04872491 1.04902375], self.intercept: 1.0042396896913934\n",
      "iteration - 4226 -> loss: 0.00031927632821629546, self.slope: [1.04873478 1.04903371], self.intercept: 1.0042405801154477\n",
      "iteration - 4227 -> loss: 0.0003192565925874425, self.slope: [1.04874465 1.04904367], self.intercept: 1.004241470494642\n",
      "iteration - 4228 -> loss: 0.00031923685947893966, self.slope: [1.04875452 1.04905362], self.intercept: 1.0042423608289819\n",
      "iteration - 4229 -> loss: 0.0003192171288903098, self.slope: [1.04876439 1.04906358], self.intercept: 1.0042432511184727\n",
      "iteration - 4230 -> loss: 0.00031919740082103463, self.slope: [1.04877426 1.04907353], self.intercept: 1.0042441413631185\n",
      "iteration - 4231 -> loss: 0.00031917767527063853, self.slope: [1.04878412 1.04908349], self.intercept: 1.0042450315629243\n",
      "iteration - 4232 -> loss: 0.00031915795223864626, self.slope: [1.04879399 1.04909344], self.intercept: 1.0042459217178965\n",
      "iteration - 4233 -> loss: 0.0003191382317245436, self.slope: [1.04880386 1.0491034 ], self.intercept: 1.0042468118280388\n",
      "iteration - 4234 -> loss: 0.0003191185137278665, self.slope: [1.04881372 1.04911335], self.intercept: 1.0042477018933547\n",
      "iteration - 4235 -> loss: 0.00031909879824812214, self.slope: [1.04882359 1.0491233 ], self.intercept: 1.0042485919138517\n",
      "iteration - 4236 -> loss: 0.0003190790852848037, self.slope: [1.04883345 1.04913325], self.intercept: 1.0042494818895327\n",
      "iteration - 4237 -> loss: 0.00031905937483744565, self.slope: [1.04884331 1.0491432 ], self.intercept: 1.0042503718204034\n",
      "iteration - 4238 -> loss: 0.00031903966690555597, self.slope: [1.04885318 1.04915315], self.intercept: 1.0042512617064694\n",
      "iteration - 4239 -> loss: 0.00031901996148863136, self.slope: [1.04886304 1.0491631 ], self.intercept: 1.0042521515477347\n",
      "iteration - 4240 -> loss: 0.0003190002585862004, self.slope: [1.0488729  1.04917305], self.intercept: 1.0042530413442057\n",
      "iteration - 4241 -> loss: 0.000318980558197772, self.slope: [1.04888276 1.049183  ], self.intercept: 1.0042539310958862\n",
      "iteration - 4242 -> loss: 0.00031896086032285475, self.slope: [1.04889262 1.04919295], self.intercept: 1.0042548208027808\n",
      "iteration - 4243 -> loss: 0.0003189411649609613, self.slope: [1.04890248 1.04920289], self.intercept: 1.0042557104648946\n",
      "iteration - 4244 -> loss: 0.0003189214721116055, self.slope: [1.04891234 1.04921284], self.intercept: 1.0042566000822324\n",
      "iteration - 4245 -> loss: 0.0003189017817743116, self.slope: [1.0489222  1.04922279], self.intercept: 1.0042574896547998\n",
      "iteration - 4246 -> loss: 0.00031888209394855427, self.slope: [1.04893205 1.04923273], self.intercept: 1.004258379182602\n",
      "iteration - 4247 -> loss: 0.0003188624086338977, self.slope: [1.04894191 1.04924267], self.intercept: 1.0042592686656426\n",
      "iteration - 4248 -> loss: 0.0003188427258298221, self.slope: [1.04895177 1.04925262], self.intercept: 1.0042601581039272\n",
      "iteration - 4249 -> loss: 0.0003188230455358591, self.slope: [1.04896162 1.04926256], self.intercept: 1.0042610474974618\n",
      "iteration - 4250 -> loss: 0.00031880336775150545, self.slope: [1.04897148 1.0492725 ], self.intercept: 1.0042619368462493\n",
      "iteration - 4251 -> loss: 0.0003187836924762857, self.slope: [1.04898133 1.04928245], self.intercept: 1.0042628261502962\n",
      "iteration - 4252 -> loss: 0.0003187640197097186, self.slope: [1.04899119 1.04929239], self.intercept: 1.0042637154096066\n",
      "iteration - 4253 -> loss: 0.0003187443494512992, self.slope: [1.04900104 1.04930233], self.intercept: 1.004264604624186\n",
      "iteration - 4254 -> loss: 0.0003187246817005533, self.slope: [1.04901089 1.04931227], self.intercept: 1.004265493794038\n",
      "iteration - 4255 -> loss: 0.0003187050164569922, self.slope: [1.04902074 1.04932221], self.intercept: 1.0042663829191683\n",
      "iteration - 4256 -> loss: 0.0003186853537201373, self.slope: [1.04903059 1.04933215], self.intercept: 1.0042672719995818\n",
      "iteration - 4257 -> loss: 0.0003186656934895014, self.slope: [1.04904044 1.04934208], self.intercept: 1.0042681610352837\n",
      "iteration - 4258 -> loss: 0.0003186460357645906, self.slope: [1.04905029 1.04935202], self.intercept: 1.0042690500262788\n",
      "iteration - 4259 -> loss: 0.0003186263805449118, self.slope: [1.04906014 1.04936196], self.intercept: 1.0042699389725713\n",
      "iteration - 4260 -> loss: 0.0003186067278300201, self.slope: [1.04906999 1.0493719 ], self.intercept: 1.0042708278741668\n",
      "iteration - 4261 -> loss: 0.0003185870776193859, self.slope: [1.04907984 1.04938183], self.intercept: 1.0042717167310709\n",
      "iteration - 4262 -> loss: 0.00031856742991254525, self.slope: [1.04908969 1.04939177], self.intercept: 1.0042726055432873\n",
      "iteration - 4263 -> loss: 0.0003185477847090042, self.slope: [1.04909953 1.0494017 ], self.intercept: 1.0042734943108207\n",
      "iteration - 4264 -> loss: 0.0003185281420083034, self.slope: [1.04910938 1.04941163], self.intercept: 1.0042743830336782\n",
      "iteration - 4265 -> loss: 0.000318508501809908, self.slope: [1.04911922 1.04942157], self.intercept: 1.0042752717118617\n",
      "iteration - 4266 -> loss: 0.00031848886411337083, self.slope: [1.04912907 1.0494315 ], self.intercept: 1.0042761603453787\n",
      "iteration - 4267 -> loss: 0.00031846922891820903, self.slope: [1.04913891 1.04944143], self.intercept: 1.0042770489342323\n",
      "iteration - 4268 -> loss: 0.00031844959622392955, self.slope: [1.04914876 1.04945136], self.intercept: 1.004277937478429\n",
      "iteration - 4269 -> loss: 0.0003184299660300498, self.slope: [1.0491586  1.04946129], self.intercept: 1.0042788259779731\n",
      "iteration - 4270 -> loss: 0.00031841033833608423, self.slope: [1.04916844 1.04947122], self.intercept: 1.004279714432869\n",
      "iteration - 4271 -> loss: 0.0003183907131415315, self.slope: [1.04917828 1.04948115], self.intercept: 1.0042806028431208\n",
      "iteration - 4272 -> loss: 0.00031837109044595294, self.slope: [1.04918813 1.04949108], self.intercept: 1.0042814912087341\n",
      "iteration - 4273 -> loss: 0.0003183514702488139, self.slope: [1.04919797 1.04950101], self.intercept: 1.004282379529715\n",
      "iteration - 4274 -> loss: 0.00031833185254968193, self.slope: [1.04920781 1.04951094], self.intercept: 1.004283267806067\n",
      "iteration - 4275 -> loss: 0.0003183122373480226, self.slope: [1.04921764 1.04952086], self.intercept: 1.004284156037795\n",
      "iteration - 4276 -> loss: 0.0003182926246433847, self.slope: [1.04922748 1.04953079], self.intercept: 1.0042850442249045\n",
      "iteration - 4277 -> loss: 0.0003182730144352938, self.slope: [1.04923732 1.04954072], self.intercept: 1.0042859323674014\n",
      "iteration - 4278 -> loss: 0.00031825340672320834, self.slope: [1.04924716 1.04955064], self.intercept: 1.0042868204652882\n",
      "iteration - 4279 -> loss: 0.0003182338015067275, self.slope: [1.04925699 1.04956057], self.intercept: 1.004287708518572\n",
      "iteration - 4280 -> loss: 0.0003182141987853143, self.slope: [1.04926683 1.04957049], self.intercept: 1.0042885965272557\n",
      "iteration - 4281 -> loss: 0.00031819459855851465, self.slope: [1.04927667 1.04958041], self.intercept: 1.0042894844913453\n",
      "iteration - 4282 -> loss: 0.0003181750008258024, self.slope: [1.0492865  1.04959033], self.intercept: 1.0042903724108458\n",
      "iteration - 4283 -> loss: 0.00031815540558673984, self.slope: [1.04929633 1.04960026], self.intercept: 1.0042912602857634\n",
      "iteration - 4284 -> loss: 0.000318135812840839, self.slope: [1.04930617 1.04961018], self.intercept: 1.0042921481161007\n",
      "iteration - 4285 -> loss: 0.000318116222587599, self.slope: [1.049316  1.0496201], self.intercept: 1.0042930359018625\n",
      "iteration - 4286 -> loss: 0.0003180966348265517, self.slope: [1.04932583 1.04963002], self.intercept: 1.004293923643055\n",
      "iteration - 4287 -> loss: 0.00031807704955720496, self.slope: [1.04933566 1.04963994], self.intercept: 1.004294811339683\n",
      "iteration - 4288 -> loss: 0.00031805746677909303, self.slope: [1.0493455  1.04964986], self.intercept: 1.0042956989917502\n",
      "iteration - 4289 -> loss: 0.0003180378864917101, self.slope: [1.04935533 1.04965977], self.intercept: 1.0042965865992626\n",
      "iteration - 4290 -> loss: 0.00031801830869459543, self.slope: [1.04936515 1.04966969], self.intercept: 1.0042974741622246\n",
      "iteration - 4291 -> loss: 0.0003179987333872544, self.slope: [1.04937498 1.04967961], self.intercept: 1.004298361680641\n",
      "iteration - 4292 -> loss: 0.000317979160569232, self.slope: [1.04938481 1.04968952], self.intercept: 1.004299249154516\n",
      "iteration - 4293 -> loss: 0.0003179595902400195, self.slope: [1.04939464 1.04969944], self.intercept: 1.0043001365838562\n",
      "iteration - 4294 -> loss: 0.0003179400223991428, self.slope: [1.04940447 1.04970936], self.intercept: 1.004301023968667\n",
      "iteration - 4295 -> loss: 0.00031792045704611804, self.slope: [1.04941429 1.04971927], self.intercept: 1.004301911308952\n",
      "iteration - 4296 -> loss: 0.0003179008941804664, self.slope: [1.04942412 1.04972918], self.intercept: 1.0043027986047164\n",
      "iteration - 4297 -> loss: 0.00031788133380170974, self.slope: [1.04943394 1.0497391 ], self.intercept: 1.0043036858559635\n",
      "iteration - 4298 -> loss: 0.0003178617759093829, self.slope: [1.04944377 1.04974901], self.intercept: 1.0043045730626994\n",
      "iteration - 4299 -> loss: 0.00031784222050297995, self.slope: [1.04945359 1.04975892], self.intercept: 1.0043054602249302\n",
      "iteration - 4300 -> loss: 0.00031782266758203186, self.slope: [1.04946342 1.04976883], self.intercept: 1.004306347342659\n",
      "iteration - 4301 -> loss: 0.00031780311714606663, self.slope: [1.04947324 1.04977874], self.intercept: 1.0043072344158912\n",
      "iteration - 4302 -> loss: 0.00031778356919458185, self.slope: [1.04948306 1.04978865], self.intercept: 1.0043081214446308\n",
      "iteration - 4303 -> loss: 0.0003177640237271137, self.slope: [1.04949288 1.04979856], self.intercept: 1.0043090084288837\n",
      "iteration - 4304 -> loss: 0.0003177444807431992, self.slope: [1.0495027  1.04980847], self.intercept: 1.004309895368655\n",
      "iteration - 4305 -> loss: 0.0003177249402423117, self.slope: [1.04951252 1.04981838], self.intercept: 1.004310782263948\n",
      "iteration - 4306 -> loss: 0.0003177054022240164, self.slope: [1.04952234 1.04982829], self.intercept: 1.0043116691147709\n",
      "iteration - 4307 -> loss: 0.0003176858666878158, self.slope: [1.04953216 1.04983819], self.intercept: 1.0043125559211268\n",
      "iteration - 4308 -> loss: 0.00031766633363323365, self.slope: [1.04954198 1.0498481 ], self.intercept: 1.0043134426830185\n",
      "iteration - 4309 -> loss: 0.00031764680305978934, self.slope: [1.0495518 1.049858 ], self.intercept: 1.004314329400454\n",
      "iteration - 4310 -> loss: 0.0003176272749670034, self.slope: [1.04956161 1.04986791], self.intercept: 1.0043152160734357\n",
      "iteration - 4311 -> loss: 0.0003176077493543953, self.slope: [1.04957143 1.04987781], self.intercept: 1.0043161027019698\n",
      "iteration - 4312 -> loss: 0.00031758822622149, self.slope: [1.04958125 1.04988772], self.intercept: 1.0043169892860613\n",
      "iteration - 4313 -> loss: 0.00031756870556780655, self.slope: [1.04959106 1.04989762], self.intercept: 1.0043178758257156\n",
      "iteration - 4314 -> loss: 0.0003175491873928746, self.slope: [1.04960088 1.04990752], self.intercept: 1.0043187623209358\n",
      "iteration - 4315 -> loss: 0.00031752967169620776, self.slope: [1.04961069 1.04991742], self.intercept: 1.004319648771727\n",
      "iteration - 4316 -> loss: 0.00031751015847732703, self.slope: [1.0496205  1.04992733], self.intercept: 1.0043205351780962\n",
      "iteration - 4317 -> loss: 0.0003174906477357541, self.slope: [1.04963032 1.04993723], self.intercept: 1.0043214215400456\n",
      "iteration - 4318 -> loss: 0.0003174711394710207, self.slope: [1.04964013 1.04994713], self.intercept: 1.0043223078575816\n",
      "iteration - 4319 -> loss: 0.00031745163368263626, self.slope: [1.04964994 1.04995703], self.intercept: 1.0043231941307074\n",
      "iteration - 4320 -> loss: 0.00031743213037013096, self.slope: [1.04965975 1.04996692], self.intercept: 1.0043240803594302\n",
      "iteration - 4321 -> loss: 0.00031741262953301013, self.slope: [1.04966956 1.04997682], self.intercept: 1.0043249665437535\n",
      "iteration - 4322 -> loss: 0.00031739313117083034, self.slope: [1.04967937 1.04998672], self.intercept: 1.0043258526836822\n",
      "iteration - 4323 -> loss: 0.0003173736352830861, self.slope: [1.04968918 1.04999662], self.intercept: 1.0043267387792216\n",
      "iteration - 4324 -> loss: 0.00031735414186931404, self.slope: [1.04969899 1.05000651], self.intercept: 1.004327624830376\n",
      "iteration - 4325 -> loss: 0.0003173346509290405, self.slope: [1.04970879 1.05001641], self.intercept: 1.0043285108371505\n",
      "iteration - 4326 -> loss: 0.00031731516246175025, self.slope: [1.0497186 1.0500263], self.intercept: 1.004329396799551\n",
      "iteration - 4327 -> loss: 0.0003172956764670173, self.slope: [1.04972841 1.0500362 ], self.intercept: 1.0043302827175797\n",
      "iteration - 4328 -> loss: 0.0003172761929443428, self.slope: [1.04973821 1.05004609], self.intercept: 1.004331168591244\n",
      "iteration - 4329 -> loss: 0.0003172567118932447, self.slope: [1.04974802 1.05005598], self.intercept: 1.0043320544205476\n",
      "iteration - 4330 -> loss: 0.00031723723331325923, self.slope: [1.04975782 1.05006588], self.intercept: 1.0043329402054957\n",
      "iteration - 4331 -> loss: 0.00031721775720390327, self.slope: [1.04976763 1.05007577], self.intercept: 1.0043338259460926\n",
      "iteration - 4332 -> loss: 0.0003171982835647019, self.slope: [1.04977743 1.05008566], self.intercept: 1.004334711642345\n",
      "iteration - 4333 -> loss: 0.00031717881239518334, self.slope: [1.04978723 1.05009555], self.intercept: 1.0043355972942563\n",
      "iteration - 4334 -> loss: 0.0003171593436948528, self.slope: [1.04979703 1.05010544], self.intercept: 1.0043364829018302\n",
      "iteration - 4335 -> loss: 0.0003171398774632548, self.slope: [1.04980684 1.05011533], self.intercept: 1.004337368465074\n",
      "iteration - 4336 -> loss: 0.00031712041369990707, self.slope: [1.04981664 1.05012522], self.intercept: 1.0043382539839911\n",
      "iteration - 4337 -> loss: 0.00031710095240433043, self.slope: [1.04982644 1.05013511], self.intercept: 1.0043391394585874\n",
      "iteration - 4338 -> loss: 0.0003170814935760607, self.slope: [1.04983624 1.05014499], self.intercept: 1.0043400248888652\n",
      "iteration - 4339 -> loss: 0.00031706203721460857, self.slope: [1.04984604 1.05015488], self.intercept: 1.0043409102748315\n",
      "iteration - 4340 -> loss: 0.0003170425833195084, self.slope: [1.04985583 1.05016477], self.intercept: 1.0043417956164904\n",
      "iteration - 4341 -> loss: 0.00031702313189027164, self.slope: [1.04986563 1.05017465], self.intercept: 1.0043426809138463\n",
      "iteration - 4342 -> loss: 0.00031700368292644494, self.slope: [1.04987543 1.05018454], self.intercept: 1.004343566166906\n",
      "iteration - 4343 -> loss: 0.0003169842364275321, self.slope: [1.04988522 1.05019442], self.intercept: 1.0043444513756727\n",
      "iteration - 4344 -> loss: 0.00031696479239307665, self.slope: [1.04989502 1.05020431], self.intercept: 1.0043453365401533\n",
      "iteration - 4345 -> loss: 0.00031694535082259093, self.slope: [1.04990481 1.05021419], self.intercept: 1.0043462216603483\n",
      "iteration - 4346 -> loss: 0.0003169259117156094, self.slope: [1.04991461 1.05022407], self.intercept: 1.0043471067362675\n",
      "iteration - 4347 -> loss: 0.00031690647507165925, self.slope: [1.0499244  1.05023395], self.intercept: 1.0043479917679121\n",
      "iteration - 4348 -> loss: 0.00031688704089023745, self.slope: [1.0499342  1.05024384], self.intercept: 1.004348876755288\n",
      "iteration - 4349 -> loss: 0.0003168676091709084, self.slope: [1.04994399 1.05025372], self.intercept: 1.0043497616984007\n",
      "iteration - 4350 -> loss: 0.0003168481799131809, self.slope: [1.04995378 1.0502636 ], self.intercept: 1.0043506465972556\n",
      "iteration - 4351 -> loss: 0.0003168287531165807, self.slope: [1.04996357 1.05027348], self.intercept: 1.0043515314518545\n",
      "iteration - 4352 -> loss: 0.00031680932878064706, self.slope: [1.04997336 1.05028335], self.intercept: 1.004352416262206\n",
      "iteration - 4353 -> loss: 0.000316789906904874, self.slope: [1.04998315 1.05029323], self.intercept: 1.0043533010283132\n",
      "iteration - 4354 -> loss: 0.0003167704874888241, self.slope: [1.04999294 1.05030311], self.intercept: 1.0043541857501797\n",
      "iteration - 4355 -> loss: 0.00031675107053200677, self.slope: [1.05000273 1.05031299], self.intercept: 1.004355070427813\n",
      "iteration - 4356 -> loss: 0.0003167316560339441, self.slope: [1.05001252 1.05032286], self.intercept: 1.0043559550612156\n",
      "iteration - 4357 -> loss: 0.00031671224399417775, self.slope: [1.05002231 1.05033274], self.intercept: 1.0043568396503941\n",
      "iteration - 4358 -> loss: 0.0003166928344122173, self.slope: [1.05003209 1.05034261], self.intercept: 1.0043577241953532\n",
      "iteration - 4359 -> loss: 0.00031667342728760087, self.slope: [1.05004188 1.05035249], self.intercept: 1.004358608696096\n",
      "iteration - 4360 -> loss: 0.0003166540226198623, self.slope: [1.05005167 1.05036236], self.intercept: 1.004359493152627\n",
      "iteration - 4361 -> loss: 0.0003166346204085077, self.slope: [1.05006145 1.05037224], self.intercept: 1.0043603775649537\n",
      "iteration - 4362 -> loss: 0.0003166152206530796, self.slope: [1.05007123 1.05038211], self.intercept: 1.0043612619330797\n",
      "iteration - 4363 -> loss: 0.0003165958233531168, self.slope: [1.05008102 1.05039198], self.intercept: 1.0043621462570096\n",
      "iteration - 4364 -> loss: 0.0003165764285081293, self.slope: [1.0500908  1.05040185], self.intercept: 1.0043630305367477\n",
      "iteration - 4365 -> loss: 0.00031655703611763126, self.slope: [1.05010058 1.05041172], self.intercept: 1.0043639147722994\n",
      "iteration - 4366 -> loss: 0.0003165376461811883, self.slope: [1.05011037 1.05042159], self.intercept: 1.00436479896367\n",
      "iteration - 4367 -> loss: 0.0003165182586983059, self.slope: [1.05012015 1.05043146], self.intercept: 1.0043656831108638\n",
      "iteration - 4368 -> loss: 0.0003164988736685052, self.slope: [1.05012993 1.05044133], self.intercept: 1.004366567213886\n",
      "iteration - 4369 -> loss: 0.0003164794910913337, self.slope: [1.05013971 1.0504512 ], self.intercept: 1.0043674512727414\n",
      "iteration - 4370 -> loss: 0.0003164601109663094, self.slope: [1.05014949 1.05046107], self.intercept: 1.0043683352874342\n",
      "iteration - 4371 -> loss: 0.00031644073329295075, self.slope: [1.05015927 1.05047093], self.intercept: 1.0043692192579698\n",
      "iteration - 4372 -> loss: 0.0003164213580708185, self.slope: [1.05016904 1.0504808 ], self.intercept: 1.004370103184352\n",
      "iteration - 4373 -> loss: 0.00031640198529940945, self.slope: [1.05017882 1.05049067], self.intercept: 1.0043709870665867\n",
      "iteration - 4374 -> loss: 0.0003163826149782551, self.slope: [1.0501886  1.05050053], self.intercept: 1.0043718709046785\n",
      "iteration - 4375 -> loss: 0.0003163632471069054, self.slope: [1.05019838 1.0505104 ], self.intercept: 1.004372754698632\n",
      "iteration - 4376 -> loss: 0.0003163438816848604, self.slope: [1.05020815 1.05052026], self.intercept: 1.0043736384484536\n",
      "iteration - 4377 -> loss: 0.0003163245187116873, self.slope: [1.05021793 1.05053012], self.intercept: 1.004374522154146\n",
      "iteration - 4378 -> loss: 0.0003163051581868846, self.slope: [1.0502277  1.05053999], self.intercept: 1.0043754058157142\n",
      "iteration - 4379 -> loss: 0.0003162858001099896, self.slope: [1.05023747 1.05054985], self.intercept: 1.004376289433165\n",
      "iteration - 4380 -> loss: 0.00031626644448054124, self.slope: [1.05024725 1.05055971], self.intercept: 1.0043771730065\n",
      "iteration - 4381 -> loss: 0.0003162470912980603, self.slope: [1.05025702 1.05056957], self.intercept: 1.0043780565357259\n",
      "iteration - 4382 -> loss: 0.00031622774056207253, self.slope: [1.05026679 1.05057943], self.intercept: 1.0043789400208467\n",
      "iteration - 4383 -> loss: 0.0003162083922721157, self.slope: [1.05027656 1.05058929], self.intercept: 1.0043798234618686\n",
      "iteration - 4384 -> loss: 0.00031618904642771966, self.slope: [1.05028633 1.05059915], self.intercept: 1.0043807068587958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 4385 -> loss: 0.00031616970302839916, self.slope: [1.0502961  1.05060901], self.intercept: 1.0043815902116329\n",
      "iteration - 4386 -> loss: 0.0003161503620737179, self.slope: [1.05030587 1.05061886], self.intercept: 1.0043824735203835\n",
      "iteration - 4387 -> loss: 0.00031613102356318313, self.slope: [1.05031564 1.05062872], self.intercept: 1.0043833567850535\n",
      "iteration - 4388 -> loss: 0.0003161116874963167, self.slope: [1.05032541 1.05063858], self.intercept: 1.0043842400056493\n",
      "iteration - 4389 -> loss: 0.0003160923538726787, self.slope: [1.05033518 1.05064843], self.intercept: 1.0043851231821739\n",
      "iteration - 4390 -> loss: 0.0003160730226917736, self.slope: [1.05034494 1.05065829], self.intercept: 1.0043860063146322\n",
      "iteration - 4391 -> loss: 0.00031605369395313666, self.slope: [1.05035471 1.05066814], self.intercept: 1.0043868894030301\n",
      "iteration - 4392 -> loss: 0.00031603436765632794, self.slope: [1.05036448 1.050678  ], self.intercept: 1.00438777244737\n",
      "iteration - 4393 -> loss: 0.00031601504380083715, self.slope: [1.05037424 1.05068785], self.intercept: 1.0043886554476589\n",
      "iteration - 4394 -> loss: 0.0003159957223862128, self.slope: [1.05038401 1.0506977 ], self.intercept: 1.0043895384039\n",
      "iteration - 4395 -> loss: 0.00031597640341198766, self.slope: [1.05039377 1.05070756], self.intercept: 1.0043904213161006\n",
      "iteration - 4396 -> loss: 0.0003159570868776893, self.slope: [1.05040353 1.05071741], self.intercept: 1.0043913041842634\n",
      "iteration - 4397 -> loss: 0.0003159377727828578, self.slope: [1.0504133  1.05072726], self.intercept: 1.0043921870083938\n",
      "iteration - 4398 -> loss: 0.00031591846112702686, self.slope: [1.05042306 1.05073711], self.intercept: 1.004393069788496\n",
      "iteration - 4399 -> loss: 0.00031589915190970234, self.slope: [1.05043282 1.05074696], self.intercept: 1.0043939525245762\n",
      "iteration - 4400 -> loss: 0.00031587984513044916, self.slope: [1.05044258 1.05075681], self.intercept: 1.0043948352166372\n",
      "iteration - 4401 -> loss: 0.0003158605407887943, self.slope: [1.05045234 1.05076666], self.intercept: 1.0043957178646852\n",
      "iteration - 4402 -> loss: 0.00031584123888425816, self.slope: [1.0504621 1.0507765], self.intercept: 1.0043966004687248\n",
      "iteration - 4403 -> loss: 0.0003158219394163662, self.slope: [1.05047186 1.05078635], self.intercept: 1.0043974830287616\n",
      "iteration - 4404 -> loss: 0.0003158026423846533, self.slope: [1.05048162 1.0507962 ], self.intercept: 1.0043983655447994\n",
      "iteration - 4405 -> loss: 0.0003157833477886771, self.slope: [1.05049137 1.05080604], self.intercept: 1.0043992480168416\n",
      "iteration - 4406 -> loss: 0.00031576405562795077, self.slope: [1.05050113 1.05081589], self.intercept: 1.0044001304448957\n",
      "iteration - 4407 -> loss: 0.0003157447659020008, self.slope: [1.05051089 1.05082573], self.intercept: 1.0044010128289644\n",
      "iteration - 4408 -> loss: 0.000315725478610382, self.slope: [1.05052064 1.05083558], self.intercept: 1.0044018951690532\n",
      "iteration - 4409 -> loss: 0.00031570619375261277, self.slope: [1.0505304  1.05084542], self.intercept: 1.0044027774651665\n",
      "iteration - 4410 -> loss: 0.00031568691132822564, self.slope: [1.05054015 1.05085527], self.intercept: 1.0044036597173085\n",
      "iteration - 4411 -> loss: 0.00031566763133676173, self.slope: [1.05054991 1.05086511], self.intercept: 1.0044045419254866\n",
      "iteration - 4412 -> loss: 0.00031564835377773256, self.slope: [1.05055966 1.05087495], self.intercept: 1.004405424089705\n",
      "iteration - 4413 -> loss: 0.0003156290786507014, self.slope: [1.05056941 1.05088479], self.intercept: 1.0044063062099668\n",
      "iteration - 4414 -> loss: 0.000315609805955187, self.slope: [1.05057916 1.05089463], self.intercept: 1.004407188286279\n",
      "iteration - 4415 -> loss: 0.00031559053569073253, self.slope: [1.05058892 1.05090447], self.intercept: 1.004408070318643\n",
      "iteration - 4416 -> loss: 0.00031557126785686327, self.slope: [1.05059867 1.05091431], self.intercept: 1.0044089523070667\n",
      "iteration - 4417 -> loss: 0.00031555200245310096, self.slope: [1.05060842 1.05092415], self.intercept: 1.004409834251553\n",
      "iteration - 4418 -> loss: 0.00031553273947902395, self.slope: [1.05061817 1.05093399], self.intercept: 1.0044107161521085\n",
      "iteration - 4419 -> loss: 0.0003155134789341018, self.slope: [1.05062791 1.05094382], self.intercept: 1.0044115980087351\n",
      "iteration - 4420 -> loss: 0.00031549422081792247, self.slope: [1.05063766 1.05095366], self.intercept: 1.00441247982144\n",
      "iteration - 4421 -> loss: 0.0003154749651300057, self.slope: [1.05064741 1.0509635 ], self.intercept: 1.0044133615902266\n",
      "iteration - 4422 -> loss: 0.0003154557118698618, self.slope: [1.05065716 1.05097333], self.intercept: 1.0044142433151007\n",
      "iteration - 4423 -> loss: 0.00031543646103707483, self.slope: [1.0506669  1.05098317], self.intercept: 1.004415124996065\n",
      "iteration - 4424 -> loss: 0.00031541721263113174, self.slope: [1.05067665 1.050993  ], self.intercept: 1.0044160066331265\n",
      "iteration - 4425 -> loss: 0.0003153979666515963, self.slope: [1.0506864  1.05100284], self.intercept: 1.0044168882262907\n",
      "iteration - 4426 -> loss: 0.0003153787230979917, self.slope: [1.05069614 1.05101267], self.intercept: 1.0044177697755619\n",
      "iteration - 4427 -> loss: 0.00031535948196984834, self.slope: [1.05070588 1.0510225 ], self.intercept: 1.0044186512809432\n",
      "iteration - 4428 -> loss: 0.0003153402432667108, self.slope: [1.05071563 1.05103233], self.intercept: 1.0044195327424403\n",
      "iteration - 4429 -> loss: 0.0003153210069881289, self.slope: [1.05072537 1.05104216], self.intercept: 1.0044204141600583\n",
      "iteration - 4430 -> loss: 0.00031530177313361424, self.slope: [1.05073511 1.05105199], self.intercept: 1.0044212955338003\n",
      "iteration - 4431 -> loss: 0.0003152825417027184, self.slope: [1.05074485 1.05106182], self.intercept: 1.0044221768636732\n",
      "iteration - 4432 -> loss: 0.00031526331269494473, self.slope: [1.05075459 1.05107165], self.intercept: 1.00442305814968\n",
      "iteration - 4433 -> loss: 0.0003152440861098769, self.slope: [1.05076433 1.05108148], self.intercept: 1.0044239393918273\n",
      "iteration - 4434 -> loss: 0.00031522486194702245, self.slope: [1.05077407 1.05109131], self.intercept: 1.0044248205901194\n",
      "iteration - 4435 -> loss: 0.0003152056402059247, self.slope: [1.05078381 1.05110114], self.intercept: 1.0044257017445597\n",
      "iteration - 4436 -> loss: 0.00031518642088610485, self.slope: [1.05079355 1.05111097], self.intercept: 1.0044265828551544\n",
      "iteration - 4437 -> loss: 0.0003151672039871282, self.slope: [1.05080329 1.05112079], self.intercept: 1.0044274639219073\n",
      "iteration - 4438 -> loss: 0.0003151479895085238, self.slope: [1.05081303 1.05113062], self.intercept: 1.0044283449448248\n",
      "iteration - 4439 -> loss: 0.000315128777449806, self.slope: [1.05082276 1.05114044], self.intercept: 1.0044292259239096\n",
      "iteration - 4440 -> loss: 0.0003151095678105272, self.slope: [1.0508325  1.05115027], self.intercept: 1.0044301068591681\n",
      "iteration - 4441 -> loss: 0.00031509036059023803, self.slope: [1.05084223 1.05116009], self.intercept: 1.0044309877506037\n",
      "iteration - 4442 -> loss: 0.00031507115578845315, self.slope: [1.05085197 1.05116991], self.intercept: 1.0044318685982219\n",
      "iteration - 4443 -> loss: 0.0003150519534047227, self.slope: [1.0508617  1.05117974], self.intercept: 1.0044327494020264\n",
      "iteration - 4444 -> loss: 0.00031503275343856325, self.slope: [1.05087144 1.05118956], self.intercept: 1.0044336301620231\n",
      "iteration - 4445 -> loss: 0.00031501355588954815, self.slope: [1.05088117 1.05119938], self.intercept: 1.0044345108782171\n",
      "iteration - 4446 -> loss: 0.00031499436075719346, self.slope: [1.0508909 1.0512092], self.intercept: 1.0044353915506121\n",
      "iteration - 4447 -> loss: 0.00031497516804103774, self.slope: [1.05090063 1.05121902], self.intercept: 1.004436272179213\n",
      "iteration - 4448 -> loss: 0.00031495597774062507, self.slope: [1.05091036 1.05122884], self.intercept: 1.0044371527640263\n",
      "iteration - 4449 -> loss: 0.0003149367898554642, self.slope: [1.05092009 1.05123866], self.intercept: 1.0044380333050549\n",
      "iteration - 4450 -> loss: 0.0003149176043851376, self.slope: [1.05092982 1.05124848], self.intercept: 1.0044389138023029\n",
      "iteration - 4451 -> loss: 0.0003148984213291471, self.slope: [1.05093955 1.0512583 ], self.intercept: 1.0044397942557768\n",
      "iteration - 4452 -> loss: 0.00031487924068707086, self.slope: [1.05094928 1.05126811], self.intercept: 1.00444067466548\n",
      "iteration - 4453 -> loss: 0.00031486006245841304, self.slope: [1.05095901 1.05127793], self.intercept: 1.0044415550314185\n",
      "iteration - 4454 -> loss: 0.0003148408866427248, self.slope: [1.05096874 1.05128775], self.intercept: 1.0044424353535977\n",
      "iteration - 4455 -> loss: 0.0003148217132395352, self.slope: [1.05097846 1.05129756], self.intercept: 1.0044433156320205\n",
      "iteration - 4456 -> loss: 0.00031480254224838946, self.slope: [1.05098819 1.05130738], self.intercept: 1.0044441958666916\n",
      "iteration - 4457 -> loss: 0.00031478337366883086, self.slope: [1.05099791 1.05131719], self.intercept: 1.0044450760576173\n",
      "iteration - 4458 -> loss: 0.0003147642075004074, self.slope: [1.05100764 1.051327  ], self.intercept: 1.0044459562047996\n",
      "iteration - 4459 -> loss: 0.0003147450437426282, self.slope: [1.05101736 1.05133682], self.intercept: 1.0044468363082475\n",
      "iteration - 4460 -> loss: 0.00031472588239505385, self.slope: [1.05102709 1.05134663], self.intercept: 1.0044477163679615\n",
      "iteration - 4461 -> loss: 0.00031470672345722413, self.slope: [1.05103681 1.05135644], self.intercept: 1.0044485963839491\n",
      "iteration - 4462 -> loss: 0.00031468756692866993, self.slope: [1.05104653 1.05136625], self.intercept: 1.0044494763562142\n",
      "iteration - 4463 -> loss: 0.00031466841280893714, self.slope: [1.05105625 1.05137606], self.intercept: 1.0044503562847609\n",
      "iteration - 4464 -> loss: 0.00031464926109756036, self.slope: [1.05106597 1.05138587], self.intercept: 1.0044512361695959\n",
      "iteration - 4465 -> loss: 0.0003146301117940987, self.slope: [1.0510757  1.05139568], self.intercept: 1.004452116010723\n",
      "iteration - 4466 -> loss: 0.0003146109648980517, self.slope: [1.05108541 1.05140549], self.intercept: 1.004452995808146\n",
      "iteration - 4467 -> loss: 0.00031459182040900096, self.slope: [1.05109513 1.0514153 ], self.intercept: 1.0044538755618697\n",
      "iteration - 4468 -> loss: 0.0003145726783264695, self.slope: [1.05110485 1.0514251 ], self.intercept: 1.0044547552718985\n",
      "iteration - 4469 -> loss: 0.00031455353864998076, self.slope: [1.05111457 1.05143491], self.intercept: 1.004455634938239\n",
      "iteration - 4470 -> loss: 0.00031453440137909993, self.slope: [1.05112429 1.05144472], self.intercept: 1.004456514560895\n",
      "iteration - 4471 -> loss: 0.000314515266513371, self.slope: [1.051134   1.05145452], self.intercept: 1.00445739413987\n",
      "iteration - 4472 -> loss: 0.00031449613405231004, self.slope: [1.05114372 1.05146433], self.intercept: 1.0044582736751715\n",
      "iteration - 4473 -> loss: 0.0003144770039954694, self.slope: [1.05115344 1.05147413], self.intercept: 1.0044591531668026\n",
      "iteration - 4474 -> loss: 0.00031445787634239825, self.slope: [1.05116315 1.05148393], self.intercept: 1.0044600326147666\n",
      "iteration - 4475 -> loss: 0.00031443875109263714, self.slope: [1.05117287 1.05149374], self.intercept: 1.0044609120190693\n",
      "iteration - 4476 -> loss: 0.00031441962824570755, self.slope: [1.05118258 1.05150354], self.intercept: 1.0044617913797165\n",
      "iteration - 4477 -> loss: 0.0003144005078011717, self.slope: [1.05119229 1.05151334], self.intercept: 1.0044626706967124\n",
      "iteration - 4478 -> loss: 0.00031438138975855944, self.slope: [1.051202   1.05152314], self.intercept: 1.004463549970062\n",
      "iteration - 4479 -> loss: 0.0003143622741174252, self.slope: [1.05121172 1.05153294], self.intercept: 1.0044644291997686\n",
      "iteration - 4480 -> loss: 0.0003143431608772858, self.slope: [1.05122143 1.05154274], self.intercept: 1.0044653083858384\n",
      "iteration - 4481 -> loss: 0.00031432405003771236, self.slope: [1.05123114 1.05155254], self.intercept: 1.0044661875282748\n",
      "iteration - 4482 -> loss: 0.0003143049415982243, self.slope: [1.05124085 1.05156234], self.intercept: 1.0044670666270856\n",
      "iteration - 4483 -> loss: 0.0003142858355583646, self.slope: [1.05125056 1.05157214], self.intercept: 1.0044679456822712\n",
      "iteration - 4484 -> loss: 0.000314266731917703, self.slope: [1.05126027 1.05158194], self.intercept: 1.0044688246938394\n",
      "iteration - 4485 -> loss: 0.0003142476306757569, self.slope: [1.05126997 1.05159173], self.intercept: 1.0044697036617938\n",
      "iteration - 4486 -> loss: 0.0003142285318320699, self.slope: [1.05127968 1.05160153], self.intercept: 1.0044705825861378\n",
      "iteration - 4487 -> loss: 0.0003142094353861856, self.slope: [1.05128939 1.05161133], self.intercept: 1.0044714614668788\n",
      "iteration - 4488 -> loss: 0.0003141903413376379, self.slope: [1.0512991  1.05162112], self.intercept: 1.0044723403040208\n",
      "iteration - 4489 -> loss: 0.0003141712496859928, self.slope: [1.0513088  1.05163092], self.intercept: 1.0044732190975667\n",
      "iteration - 4490 -> loss: 0.0003141521604307911, self.slope: [1.05131851 1.05164071], self.intercept: 1.0044740978475235\n",
      "iteration - 4491 -> loss: 0.0003141330735715509, self.slope: [1.05132821 1.0516505 ], self.intercept: 1.0044749765538954\n",
      "iteration - 4492 -> loss: 0.00031411398910782644, self.slope: [1.05133791 1.0516603 ], self.intercept: 1.004475855216686\n",
      "iteration - 4493 -> loss: 0.00031409490703916644, self.slope: [1.05134762 1.05167009], self.intercept: 1.0044767338359002\n",
      "iteration - 4494 -> loss: 0.0003140758273651198, self.slope: [1.05135732 1.05167988], self.intercept: 1.0044776124115435\n",
      "iteration - 4495 -> loss: 0.00031405675008522365, self.slope: [1.05136702 1.05168967], self.intercept: 1.0044784909436206\n",
      "iteration - 4496 -> loss: 0.00031403767519901505, self.slope: [1.05137672 1.05169946], self.intercept: 1.0044793694321346\n",
      "iteration - 4497 -> loss: 0.00031401860270604236, self.slope: [1.05138642 1.05170925], self.intercept: 1.0044802478770933\n",
      "iteration - 4498 -> loss: 0.0003139995326058321, self.slope: [1.05139612 1.05171904], self.intercept: 1.0044811262784983\n",
      "iteration - 4499 -> loss: 0.0003139804648979672, self.slope: [1.05140582 1.05172883], self.intercept: 1.004482004636356\n",
      "iteration - 4500 -> loss: 0.00031396139958194823, self.slope: [1.05141552 1.05173861], self.intercept: 1.0044828829506711\n",
      "iteration - 4501 -> loss: 0.0003139423366573551, self.slope: [1.05142522 1.0517484 ], self.intercept: 1.0044837612214488\n",
      "iteration - 4502 -> loss: 0.00031392327612373295, self.slope: [1.05143492 1.05175819], self.intercept: 1.0044846394486928\n",
      "iteration - 4503 -> loss: 0.00031390421798057114, self.slope: [1.05144462 1.05176797], self.intercept: 1.0044855176324083\n",
      "iteration - 4504 -> loss: 0.00031388516222748575, self.slope: [1.05145431 1.05177776], self.intercept: 1.0044863957726\n",
      "iteration - 4505 -> loss: 0.0003138661088639763, self.slope: [1.05146401 1.05178754], self.intercept: 1.0044872738692718\n",
      "iteration - 4506 -> loss: 0.0003138470578895981, self.slope: [1.0514737  1.05179733], self.intercept: 1.0044881519224298\n",
      "iteration - 4507 -> loss: 0.00031382800930390107, self.slope: [1.0514834  1.05180711], self.intercept: 1.0044890299320768\n",
      "iteration - 4508 -> loss: 0.0003138089631064294, self.slope: [1.05149309 1.05181689], self.intercept: 1.0044899078982183\n",
      "iteration - 4509 -> loss: 0.00031378991929673154, self.slope: [1.05150279 1.05182668], self.intercept: 1.0044907858208592\n",
      "iteration - 4510 -> loss: 0.00031377087787432255, self.slope: [1.05151248 1.05183646], self.intercept: 1.0044916637000045\n",
      "iteration - 4511 -> loss: 0.000313751838838787, self.slope: [1.05152217 1.05184624], self.intercept: 1.0044925415356587\n",
      "iteration - 4512 -> loss: 0.0003137328021896704, self.slope: [1.05153186 1.05185602], self.intercept: 1.0044934193278274\n",
      "iteration - 4513 -> loss: 0.0003137137679264773, self.slope: [1.05154155 1.0518658 ], self.intercept: 1.004494297076513\n",
      "iteration - 4514 -> loss: 0.00031369473604877997, self.slope: [1.05155124 1.05187558], self.intercept: 1.0044951747817217\n",
      "iteration - 4515 -> loss: 0.00031367570655612266, self.slope: [1.05156093 1.05188536], self.intercept: 1.0044960524434592\n",
      "iteration - 4516 -> loss: 0.00031365667944805955, self.slope: [1.05157062 1.05189514], self.intercept: 1.0044969300617275\n",
      "iteration - 4517 -> loss: 0.00031363765472412693, self.slope: [1.05158031 1.05190491], self.intercept: 1.0044978076365352\n",
      "iteration - 4518 -> loss: 0.00031361863238388765, self.slope: [1.05159    1.05191469], self.intercept: 1.0044986851678832\n",
      "iteration - 4519 -> loss: 0.000313599612426842, self.slope: [1.05159969 1.05192447], self.intercept: 1.00449956265578\n",
      "iteration - 4520 -> loss: 0.0003135805948525871, self.slope: [1.05160937 1.05193424], self.intercept: 1.0045004401002264\n",
      "iteration - 4521 -> loss: 0.0003135615796606328, self.slope: [1.05161906 1.05194402], self.intercept: 1.0045013175012278\n",
      "iteration - 4522 -> loss: 0.00031354256685055737, self.slope: [1.05162874 1.05195379], self.intercept: 1.0045021948587904\n",
      "iteration - 4523 -> loss: 0.0003135235564218855, self.slope: [1.05163843 1.05196357], self.intercept: 1.0045030721729182\n",
      "iteration - 4524 -> loss: 0.0003135045483741624, self.slope: [1.05164811 1.05197334], self.intercept: 1.0045039494436168\n",
      "iteration - 4525 -> loss: 0.00031348554270695605, self.slope: [1.0516578  1.05198311], self.intercept: 1.0045048266708891\n",
      "iteration - 4526 -> loss: 0.00031346653941980454, self.slope: [1.05166748 1.05199288], self.intercept: 1.004505703854742\n",
      "iteration - 4527 -> loss: 0.00031344753851223205, self.slope: [1.05167716 1.05200265], self.intercept: 1.0045065809951779\n",
      "iteration - 4528 -> loss: 0.00031342853998380505, self.slope: [1.05168684 1.05201243], self.intercept: 1.0045074580922022\n",
      "iteration - 4529 -> loss: 0.0003134095438340806, self.slope: [1.05169652 1.0520222 ], self.intercept: 1.004508335145821\n",
      "iteration - 4530 -> loss: 0.0003133905500625842, self.slope: [1.0517062  1.05203197], self.intercept: 1.004509212156037\n",
      "iteration - 4531 -> loss: 0.0003133715586688879, self.slope: [1.05171588 1.05204173], self.intercept: 1.0045100891228558\n",
      "iteration - 4532 -> loss: 0.0003133525696525127, self.slope: [1.05172556 1.0520515 ], self.intercept: 1.0045109660462803\n",
      "iteration - 4533 -> loss: 0.0003133335830130223, self.slope: [1.05173524 1.05206127], self.intercept: 1.0045118429263193\n",
      "iteration - 4534 -> loss: 0.000313314598749983, self.slope: [1.05174492 1.05207104], self.intercept: 1.004512719762976\n",
      "iteration - 4535 -> loss: 0.00031329561686288526, self.slope: [1.0517546 1.0520808], self.intercept: 1.004513596556253\n",
      "iteration - 4536 -> loss: 0.000313276637351343, self.slope: [1.05176427 1.05209057], self.intercept: 1.0045144733061562\n",
      "iteration - 4537 -> loss: 0.00031325766021486005, self.slope: [1.05177395 1.05210033], self.intercept: 1.0045153500126902\n",
      "iteration - 4538 -> loss: 0.0003132386854530038, self.slope: [1.05178363 1.0521101 ], self.intercept: 1.0045162266758596\n",
      "iteration - 4539 -> loss: 0.0003132197130653148, self.slope: [1.0517933  1.05211986], self.intercept: 1.004517103295669\n",
      "iteration - 4540 -> loss: 0.00031320074305135127, self.slope: [1.05180298 1.05212963], self.intercept: 1.0045179798721235\n",
      "iteration - 4541 -> loss: 0.0003131817754106548, self.slope: [1.05181265 1.05213939], self.intercept: 1.004518856405228\n",
      "iteration - 4542 -> loss: 0.00031316281014277315, self.slope: [1.05182232 1.05214915], self.intercept: 1.0045197328949866\n",
      "iteration - 4543 -> loss: 0.0003131438472472615, self.slope: [1.051832   1.05215891], self.intercept: 1.0045206093414056\n",
      "iteration - 4544 -> loss: 0.000313124886723666, self.slope: [1.05184167 1.05216867], self.intercept: 1.0045214857444864\n",
      "iteration - 4545 -> loss: 0.000313105928571525, self.slope: [1.05185134 1.05217844], self.intercept: 1.0045223621042356\n",
      "iteration - 4546 -> loss: 0.00031308697279040787, self.slope: [1.05186101 1.0521882 ], self.intercept: 1.004523238420659\n",
      "iteration - 4547 -> loss: 0.0003130680193798496, self.slope: [1.05187068 1.05219795], self.intercept: 1.0045241146937585\n",
      "iteration - 4548 -> loss: 0.0003130490683394065, self.slope: [1.05188035 1.05220771], self.intercept: 1.0045249909235408\n",
      "iteration - 4549 -> loss: 0.00031303011966862354, self.slope: [1.05189002 1.05221747], self.intercept: 1.0045258671100092\n",
      "iteration - 4550 -> loss: 0.0003130111733670454, self.slope: [1.05189969 1.05222723], self.intercept: 1.0045267432531706\n",
      "iteration - 4551 -> loss: 0.00031299222943424873, self.slope: [1.05190935 1.05223699], self.intercept: 1.0045276193530286\n",
      "iteration - 4552 -> loss: 0.000312973287869749, self.slope: [1.05191902 1.05224674], self.intercept: 1.004528495409588\n",
      "iteration - 4553 -> loss: 0.0003129543486731122, self.slope: [1.05192869 1.0522565 ], self.intercept: 1.004529371422853\n",
      "iteration - 4554 -> loss: 0.0003129354118438844, self.slope: [1.05193835 1.05226625], self.intercept: 1.0045302473928273\n",
      "iteration - 4555 -> loss: 0.00031291647738162414, self.slope: [1.05194802 1.05227601], self.intercept: 1.0045311233195169\n",
      "iteration - 4556 -> loss: 0.00031289754528589063, self.slope: [1.05195768 1.05228576], self.intercept: 1.0045319992029276\n",
      "iteration - 4557 -> loss: 0.0003128786155561943, self.slope: [1.05196735 1.05229551], self.intercept: 1.0045328750430624\n",
      "iteration - 4558 -> loss: 0.0003128596881921287, self.slope: [1.05197701 1.05230527], self.intercept: 1.004533750839926\n",
      "iteration - 4559 -> loss: 0.0003128407631932176, self.slope: [1.05198667 1.05231502], self.intercept: 1.0045346265935227\n",
      "iteration - 4560 -> loss: 0.0003128218405590228, self.slope: [1.05199634 1.05232477], self.intercept: 1.0045355023038598\n",
      "iteration - 4561 -> loss: 0.0003128029202891006, self.slope: [1.052006   1.05233452], self.intercept: 1.0045363779709375\n",
      "iteration - 4562 -> loss: 0.0003127840023829959, self.slope: [1.05201566 1.05234427], self.intercept: 1.0045372535947634\n",
      "iteration - 4563 -> loss: 0.0003127650868402606, self.slope: [1.05202532 1.05235402], self.intercept: 1.0045381291753441\n",
      "iteration - 4564 -> loss: 0.0003127461736604357, self.slope: [1.05203498 1.05236377], self.intercept: 1.00453900471268\n",
      "iteration - 4565 -> loss: 0.00031272726284309473, self.slope: [1.05204464 1.05237352], self.intercept: 1.0045398802067769\n",
      "iteration - 4566 -> loss: 0.00031270835438776894, self.slope: [1.0520543  1.05238326], self.intercept: 1.0045407556576407\n",
      "iteration - 4567 -> loss: 0.0003126894482940151, self.slope: [1.05206395 1.05239301], self.intercept: 1.0045416310652757\n",
      "iteration - 4568 -> loss: 0.0003126705445613905, self.slope: [1.05207361 1.05240276], self.intercept: 1.0045425064296885\n",
      "iteration - 4569 -> loss: 0.0003126516431894465, self.slope: [1.05208327 1.0524125 ], self.intercept: 1.00454338175088\n",
      "iteration - 4570 -> loss: 0.0003126327441777259, self.slope: [1.05209292 1.05242225], self.intercept: 1.0045442570288574\n",
      "iteration - 4571 -> loss: 0.00031261384752579016, self.slope: [1.05210258 1.05243199], self.intercept: 1.0045451322636232\n",
      "iteration - 4572 -> loss: 0.0003125949532332073, self.slope: [1.05211224 1.05244174], self.intercept: 1.004546007455184\n",
      "iteration - 4573 -> loss: 0.0003125760612994922, self.slope: [1.05212189 1.05245148], self.intercept: 1.0045468826035429\n",
      "iteration - 4574 -> loss: 0.00031255717172422857, self.slope: [1.05213154 1.05246122], self.intercept: 1.004547757708706\n",
      "iteration - 4575 -> loss: 0.00031253828450695826, self.slope: [1.0521412  1.05247097], self.intercept: 1.0045486327706785\n",
      "iteration - 4576 -> loss: 0.00031251939964721634, self.slope: [1.05215085 1.05248071], self.intercept: 1.0045495077894637\n",
      "iteration - 4577 -> loss: 0.00031250051714458443, self.slope: [1.0521605  1.05249045], self.intercept: 1.004550382765067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 4578 -> loss: 0.0003124816369985976, self.slope: [1.05217015 1.05250019], self.intercept: 1.0045512576974904\n",
      "iteration - 4579 -> loss: 0.00031246275920882293, self.slope: [1.0521798  1.05250993], self.intercept: 1.0045521325867428\n",
      "iteration - 4580 -> loss: 0.0003124438837748036, self.slope: [1.05218945 1.05251967], self.intercept: 1.0045530074328264\n",
      "iteration - 4581 -> loss: 0.0003124250106960864, self.slope: [1.0521991  1.05252941], self.intercept: 1.0045538822357465\n",
      "iteration - 4582 -> loss: 0.0003124061399722424, self.slope: [1.05220875 1.05253915], self.intercept: 1.004554756995507\n",
      "iteration - 4583 -> loss: 0.00031238727160281035, self.slope: [1.0522184  1.05254888], self.intercept: 1.0045556317121123\n",
      "iteration - 4584 -> loss: 0.00031236840558735053, self.slope: [1.05222805 1.05255862], self.intercept: 1.0045565063855673\n",
      "iteration - 4585 -> loss: 0.0003123495419254118, self.slope: [1.05223769 1.05256836], self.intercept: 1.0045573810158774\n",
      "iteration - 4586 -> loss: 0.00031233068061654835, self.slope: [1.05224734 1.05257809], self.intercept: 1.0045582556030486\n",
      "iteration - 4587 -> loss: 0.0003123118216603174, self.slope: [1.05225699 1.05258783], self.intercept: 1.0045591301470829\n",
      "iteration - 4588 -> loss: 0.00031229296505627847, self.slope: [1.05226663 1.05259756], self.intercept: 1.0045600046479857\n",
      "iteration - 4589 -> loss: 0.00031227411080397995, self.slope: [1.05227628 1.0526073 ], self.intercept: 1.0045608791057627\n",
      "iteration - 4590 -> loss: 0.0003122552589029743, self.slope: [1.05228592 1.05261703], self.intercept: 1.0045617535204179\n",
      "iteration - 4591 -> loss: 0.00031223640935281225, self.slope: [1.05229556 1.05262676], self.intercept: 1.004562627891956\n",
      "iteration - 4592 -> loss: 0.0003122175621530628, self.slope: [1.05230521 1.05263649], self.intercept: 1.0045635022203796\n",
      "iteration - 4593 -> loss: 0.00031219871730328445, self.slope: [1.05231485 1.05264623], self.intercept: 1.0045643765056962\n",
      "iteration - 4594 -> loss: 0.0003121798748029895, self.slope: [1.05232449 1.05265596], self.intercept: 1.0045652507479086\n",
      "iteration - 4595 -> loss: 0.0003121610346517829, self.slope: [1.05233413 1.05266569], self.intercept: 1.0045661249470226\n",
      "iteration - 4596 -> loss: 0.00031214219684919185, self.slope: [1.05234377 1.05267542], self.intercept: 1.004566999103042\n",
      "iteration - 4597 -> loss: 0.0003121233613947876, self.slope: [1.05235341 1.05268515], self.intercept: 1.0045678732159722\n",
      "iteration - 4598 -> loss: 0.0003121045282881006, self.slope: [1.05236305 1.05269487], self.intercept: 1.0045687472858174\n",
      "iteration - 4599 -> loss: 0.0003120856975287116, self.slope: [1.05237269 1.0527046 ], self.intercept: 1.0045696213125832\n",
      "iteration - 4600 -> loss: 0.0003120668691161673, self.slope: [1.05238233 1.05271433], self.intercept: 1.0045704952962735\n",
      "iteration - 4601 -> loss: 0.00031204804305002453, self.slope: [1.05239196 1.05272406], self.intercept: 1.0045713692368927\n",
      "iteration - 4602 -> loss: 0.0003120292193298336, self.slope: [1.0524016  1.05273378], self.intercept: 1.0045722431344448\n",
      "iteration - 4603 -> loss: 0.0003120103979551415, self.slope: [1.05241124 1.05274351], self.intercept: 1.0045731169889363\n",
      "iteration - 4604 -> loss: 0.0003119915789255414, self.slope: [1.05242087 1.05275323], self.intercept: 1.0045739908003697\n",
      "iteration - 4605 -> loss: 0.00031197276224054405, self.slope: [1.05243051 1.05276296], self.intercept: 1.0045748645687502\n",
      "iteration - 4606 -> loss: 0.0003119539478997258, self.slope: [1.05244014 1.05277268], self.intercept: 1.004575738294084\n",
      "iteration - 4607 -> loss: 0.0003119351359026564, self.slope: [1.05244977 1.0527824 ], self.intercept: 1.0045766119763742\n",
      "iteration - 4608 -> loss: 0.0003119163262488816, self.slope: [1.05245941 1.05279212], self.intercept: 1.0045774856156262\n",
      "iteration - 4609 -> loss: 0.000311897518937931, self.slope: [1.05246904 1.05280185], self.intercept: 1.0045783592118436\n",
      "iteration - 4610 -> loss: 0.00031187871396940977, self.slope: [1.05247867 1.05281157], self.intercept: 1.0045792327650325\n",
      "iteration - 4611 -> loss: 0.0003118599113428341, self.slope: [1.0524883  1.05282129], self.intercept: 1.0045801062751964\n",
      "iteration - 4612 -> loss: 0.0003118411110577779, self.slope: [1.05249793 1.05283101], self.intercept: 1.0045809797423404\n",
      "iteration - 4613 -> loss: 0.0003118223131138047, self.slope: [1.05250756 1.05284073], self.intercept: 1.004581853166468\n",
      "iteration - 4614 -> loss: 0.0003118035175104434, self.slope: [1.05251719 1.05285045], self.intercept: 1.0045827265475853\n",
      "iteration - 4615 -> loss: 0.00031178472424729295, self.slope: [1.05252682 1.05286017], self.intercept: 1.0045835998856965\n",
      "iteration - 4616 -> loss: 0.00031176593332387785, self.slope: [1.05253645 1.05286988], self.intercept: 1.0045844731808071\n",
      "iteration - 4617 -> loss: 0.00031174714473976387, self.slope: [1.05254608 1.0528796 ], self.intercept: 1.0045853464329215\n",
      "iteration - 4618 -> loss: 0.000311728358494526, self.slope: [1.0525557  1.05288932], self.intercept: 1.004586219642042\n",
      "iteration - 4619 -> loss: 0.00031170957458769634, self.slope: [1.05256533 1.05289903], self.intercept: 1.0045870928081748\n",
      "iteration - 4620 -> loss: 0.0003116907930188373, self.slope: [1.05257496 1.05290875], self.intercept: 1.004587965931325\n",
      "iteration - 4621 -> loss: 0.00031167201378751733, self.slope: [1.05258458 1.05291846], self.intercept: 1.0045888390114963\n",
      "iteration - 4622 -> loss: 0.0003116532368932897, self.slope: [1.05259421 1.05292818], self.intercept: 1.0045897120486944\n",
      "iteration - 4623 -> loss: 0.00031163446233571407, self.slope: [1.05260383 1.05293789], self.intercept: 1.0045905850429233\n",
      "iteration - 4624 -> loss: 0.00031161569011435195, self.slope: [1.05261345 1.0529476 ], self.intercept: 1.004591457994188\n",
      "iteration - 4625 -> loss: 0.0003115969202287622, self.slope: [1.05262308 1.05295731], self.intercept: 1.0045923309024936\n",
      "iteration - 4626 -> loss: 0.00031157815267847166, self.slope: [1.0526327  1.05296703], self.intercept: 1.0045932037678433\n",
      "iteration - 4627 -> loss: 0.00031155938746307897, self.slope: [1.05264232 1.05297674], self.intercept: 1.0045940765902417\n",
      "iteration - 4628 -> loss: 0.00031154062458211423, self.slope: [1.05265194 1.05298645], self.intercept: 1.0045949493696944\n",
      "iteration - 4629 -> loss: 0.00031152186403516773, self.slope: [1.05266156 1.05299616], self.intercept: 1.004595822106205\n",
      "iteration - 4630 -> loss: 0.0003115031058217749, self.slope: [1.05267118 1.05300587], self.intercept: 1.004596694799779\n",
      "iteration - 4631 -> loss: 0.000311484349941498, self.slope: [1.0526808  1.05301558], self.intercept: 1.0045975674504197\n",
      "iteration - 4632 -> loss: 0.0003114655963939179, self.slope: [1.05269042 1.05302528], self.intercept: 1.0045984400581336\n",
      "iteration - 4633 -> loss: 0.0003114468451785453, self.slope: [1.05270004 1.05303499], self.intercept: 1.0045993126229233\n",
      "iteration - 4634 -> loss: 0.00031142809629497746, self.slope: [1.05270965 1.0530447 ], self.intercept: 1.0046001851447945\n",
      "iteration - 4635 -> loss: 0.0003114093497427646, self.slope: [1.05271927 1.0530544 ], self.intercept: 1.0046010576237534\n",
      "iteration - 4636 -> loss: 0.00031139060552146233, self.slope: [1.05272889 1.05306411], self.intercept: 1.004601930059803\n",
      "iteration - 4637 -> loss: 0.0003113718636306506, self.slope: [1.0527385  1.05307381], self.intercept: 1.0046028024529468\n",
      "iteration - 4638 -> loss: 0.0003113531240698609, self.slope: [1.05274812 1.05308352], self.intercept: 1.0046036748031915\n",
      "iteration - 4639 -> loss: 0.000311334386838663, self.slope: [1.05275773 1.05309322], self.intercept: 1.0046045471105416\n",
      "iteration - 4640 -> loss: 0.0003113156519366134, self.slope: [1.05276735 1.05310293], self.intercept: 1.0046054193750005\n",
      "iteration - 4641 -> loss: 0.0003112969193632814, self.slope: [1.05277696 1.05311263], self.intercept: 1.0046062915965726\n",
      "iteration - 4642 -> loss: 0.0003112781891182325, self.slope: [1.05278657 1.05312233], self.intercept: 1.0046071637752636\n",
      "iteration - 4643 -> loss: 0.0003112594612010099, self.slope: [1.05279618 1.05313203], self.intercept: 1.0046080359110758\n",
      "iteration - 4644 -> loss: 0.0003112407356111819, self.slope: [1.05280579 1.05314173], self.intercept: 1.004608908004016\n",
      "iteration - 4645 -> loss: 0.00031122201234831014, self.slope: [1.0528154  1.05315143], self.intercept: 1.0046097800540887\n",
      "iteration - 4646 -> loss: 0.00031120329141194386, self.slope: [1.05282501 1.05316113], self.intercept: 1.004610652061297\n",
      "iteration - 4647 -> loss: 0.00031118457280168, self.slope: [1.05283462 1.05317083], self.intercept: 1.0046115240256492\n",
      "iteration - 4648 -> loss: 0.0003111658565170204, self.slope: [1.05284423 1.05318053], self.intercept: 1.0046123959471474\n",
      "iteration - 4649 -> loss: 0.0003111471425575823, self.slope: [1.05285384 1.05319023], self.intercept: 1.0046132678257937\n",
      "iteration - 4650 -> loss: 0.0003111284309228895, self.slope: [1.05286345 1.05319993], self.intercept: 1.0046141396615968\n",
      "iteration - 4651 -> loss: 0.0003111097216125214, self.slope: [1.05287306 1.05320962], self.intercept: 1.0046150114545602\n",
      "iteration - 4652 -> loss: 0.00031109101462603573, self.slope: [1.05288266 1.05321932], self.intercept: 1.0046158832046872\n",
      "iteration - 4653 -> loss: 0.0003110723099629982, self.slope: [1.05289227 1.05322901], self.intercept: 1.0046167549119824\n",
      "iteration - 4654 -> loss: 0.00031105360762295547, self.slope: [1.05290187 1.05323871], self.intercept: 1.0046176265764515\n",
      "iteration - 4655 -> loss: 0.00031103490760548287, self.slope: [1.05291148 1.0532484 ], self.intercept: 1.0046184981980992\n",
      "iteration - 4656 -> loss: 0.00031101620991014754, self.slope: [1.05292108 1.0532581 ], self.intercept: 1.0046193697769286\n",
      "iteration - 4657 -> loss: 0.0003109975145364736, self.slope: [1.05293069 1.05326779], self.intercept: 1.0046202413129466\n",
      "iteration - 4658 -> loss: 0.0003109788214840824, self.slope: [1.05294029 1.05327748], self.intercept: 1.0046211128061568\n",
      "iteration - 4659 -> loss: 0.0003109601307524763, self.slope: [1.05294989 1.05328717], self.intercept: 1.0046219842565625\n",
      "iteration - 4660 -> loss: 0.0003109414423412621, self.slope: [1.05295949 1.05329686], self.intercept: 1.0046228556641683\n",
      "iteration - 4661 -> loss: 0.00031092275624998607, self.slope: [1.05296909 1.05330656], self.intercept: 1.0046237270289808\n",
      "iteration - 4662 -> loss: 0.0003109040724782043, self.slope: [1.05297869 1.05331625], self.intercept: 1.004624598351005\n",
      "iteration - 4663 -> loss: 0.000310885391025492, self.slope: [1.05298829 1.05332594], self.intercept: 1.0046254696302424\n",
      "iteration - 4664 -> loss: 0.00031086671189140393, self.slope: [1.05299789 1.05333562], self.intercept: 1.0046263408666993\n",
      "iteration - 4665 -> loss: 0.0003108480350754821, self.slope: [1.05300749 1.05334531], self.intercept: 1.0046272120603803\n",
      "iteration - 4666 -> loss: 0.0003108293605773359, self.slope: [1.05301709 1.053355  ], self.intercept: 1.0046280832112897\n",
      "iteration - 4667 -> loss: 0.0003108106883964918, self.slope: [1.05302669 1.05336469], self.intercept: 1.0046289543194318\n",
      "iteration - 4668 -> loss: 0.0003107920185325286, self.slope: [1.05303628 1.05337437], self.intercept: 1.0046298253848132\n",
      "iteration - 4669 -> loss: 0.00031077335098500075, self.slope: [1.05304588 1.05338406], self.intercept: 1.0046306964074359\n",
      "iteration - 4670 -> loss: 0.000310754685753481, self.slope: [1.05305548 1.05339374], self.intercept: 1.0046315673873052\n",
      "iteration - 4671 -> loss: 0.00031073602283752575, self.slope: [1.05306507 1.05340343], self.intercept: 1.0046324383244276\n",
      "iteration - 4672 -> loss: 0.0003107173622367039, self.slope: [1.05307467 1.05341311], self.intercept: 1.0046333092188051\n",
      "iteration - 4673 -> loss: 0.0003106987039505666, self.slope: [1.05308426 1.0534228 ], self.intercept: 1.0046341800704424\n",
      "iteration - 4674 -> loss: 0.00031068004797868415, self.slope: [1.05309385 1.05343248], self.intercept: 1.004635050879344\n",
      "iteration - 4675 -> loss: 0.0003106613943206374, self.slope: [1.05310345 1.05344216], self.intercept: 1.0046359216455176\n",
      "iteration - 4676 -> loss: 0.0003106427429759722, self.slope: [1.05311304 1.05345184], self.intercept: 1.004636792368965\n",
      "iteration - 4677 -> loss: 0.00031062409394424085, self.slope: [1.05312263 1.05346153], self.intercept: 1.0046376630496914\n",
      "iteration - 4678 -> loss: 0.00031060544722503883, self.slope: [1.05313222 1.05347121], self.intercept: 1.0046385336877015\n",
      "iteration - 4679 -> loss: 0.0003105868028178995, self.slope: [1.05314181 1.05348089], self.intercept: 1.0046394042829991\n",
      "iteration - 4680 -> loss: 0.00031056816072241866, self.slope: [1.0531514  1.05349057], self.intercept: 1.0046402748355898\n",
      "iteration - 4681 -> loss: 0.000310549520938127, self.slope: [1.05316099 1.05350024], self.intercept: 1.0046411453454773\n",
      "iteration - 4682 -> loss: 0.0003105308834646155, self.slope: [1.05317058 1.05350992], self.intercept: 1.0046420158126677\n",
      "iteration - 4683 -> loss: 0.0003105122483014367, self.slope: [1.05318016 1.0535196 ], self.intercept: 1.004642886237164\n",
      "iteration - 4684 -> loss: 0.0003104936154481644, self.slope: [1.05318975 1.05352928], self.intercept: 1.0046437566189699\n",
      "iteration - 4685 -> loss: 0.00031047498490435624, self.slope: [1.05319934 1.05353895], self.intercept: 1.0046446269580929\n",
      "iteration - 4686 -> loss: 0.0003104563566695688, self.slope: [1.05320892 1.05354863], self.intercept: 1.0046454972545367\n",
      "iteration - 4687 -> loss: 0.0003104377307433714, self.slope: [1.05321851 1.0535583 ], self.intercept: 1.0046463675083048\n",
      "iteration - 4688 -> loss: 0.00031041910712534975, self.slope: [1.0532281  1.05356798], self.intercept: 1.0046472377194018\n",
      "iteration - 4689 -> loss: 0.00031040048581505107, self.slope: [1.05323768 1.05357765], self.intercept: 1.0046481078878324\n",
      "iteration - 4690 -> loss: 0.0003103818668120351, self.slope: [1.05324726 1.05358733], self.intercept: 1.004648978013602\n",
      "iteration - 4691 -> loss: 0.0003103632501158778, self.slope: [1.05325685 1.053597  ], self.intercept: 1.0046498480967136\n",
      "iteration - 4692 -> loss: 0.00031034463572616203, self.slope: [1.05326643 1.05360667], self.intercept: 1.0046507181371727\n",
      "iteration - 4693 -> loss: 0.0003103260236424077, self.slope: [1.05327601 1.05361634], self.intercept: 1.004651588134985\n",
      "iteration - 4694 -> loss: 0.00031030741386421786, self.slope: [1.05328559 1.05362601], self.intercept: 1.0046524580901532\n",
      "iteration - 4695 -> loss: 0.00031028880639115083, self.slope: [1.05329517 1.05363568], self.intercept: 1.0046533280026824\n",
      "iteration - 4696 -> loss: 0.0003102702012227641, self.slope: [1.05330475 1.05364535], self.intercept: 1.0046541978725776\n",
      "iteration - 4697 -> loss: 0.0003102515983586293, self.slope: [1.05331433 1.05365502], self.intercept: 1.004655067699844\n",
      "iteration - 4698 -> loss: 0.00031023299779831475, self.slope: [1.05332391 1.05366469], self.intercept: 1.0046559374844843\n",
      "iteration - 4699 -> loss: 0.00031021439954139656, self.slope: [1.05333349 1.05367436], self.intercept: 1.0046568072265034\n",
      "iteration - 4700 -> loss: 0.00031019580358742044, self.slope: [1.05334307 1.05368403], self.intercept: 1.0046576769259064\n",
      "iteration - 4701 -> loss: 0.0003101772099359624, self.slope: [1.05335264 1.05369369], self.intercept: 1.004658546582699\n",
      "iteration - 4702 -> loss: 0.00031015861858659427, self.slope: [1.05336222 1.05370336], self.intercept: 1.0046594161968845\n",
      "iteration - 4703 -> loss: 0.0003101400295388726, self.slope: [1.0533718  1.05371303], self.intercept: 1.0046602857684674\n",
      "iteration - 4704 -> loss: 0.0003101214427923775, self.slope: [1.05338137 1.05372269], self.intercept: 1.0046611552974534\n",
      "iteration - 4705 -> loss: 0.000310102858346678, self.slope: [1.05339095 1.05373236], self.intercept: 1.0046620247838454\n",
      "iteration - 4706 -> loss: 0.00031008427620130724, self.slope: [1.05340052 1.05374202], self.intercept: 1.0046628942276488\n",
      "iteration - 4707 -> loss: 0.0003100656963558764, self.slope: [1.05341009 1.05375168], self.intercept: 1.0046637636288689\n",
      "iteration - 4708 -> loss: 0.00031004711880992125, self.slope: [1.05341967 1.05376135], self.intercept: 1.0046646329875089\n",
      "iteration - 4709 -> loss: 0.00031002854356302663, self.slope: [1.05342924 1.05377101], self.intercept: 1.0046655023035727\n",
      "iteration - 4710 -> loss: 0.00031000997061475435, self.slope: [1.05343881 1.05378067], self.intercept: 1.0046663715770667\n",
      "iteration - 4711 -> loss: 0.00030999139996468775, self.slope: [1.05344838 1.05379033], self.intercept: 1.0046672408079949\n",
      "iteration - 4712 -> loss: 0.0003099728316123651, self.slope: [1.05345795 1.05379999], self.intercept: 1.0046681099963615\n",
      "iteration - 4713 -> loss: 0.0003099542655573739, self.slope: [1.05346752 1.05380965], self.intercept: 1.0046689791421708\n",
      "iteration - 4714 -> loss: 0.00030993570179928, self.slope: [1.05347709 1.05381931], self.intercept: 1.0046698482454293\n",
      "iteration - 4715 -> loss: 0.0003099171403376423, self.slope: [1.05348666 1.05382897], self.intercept: 1.0046707173061393\n",
      "iteration - 4716 -> loss: 0.0003098985811720351, self.slope: [1.05349623 1.05383863], self.intercept: 1.0046715863243065\n",
      "iteration - 4717 -> loss: 0.0003098800243020199, self.slope: [1.0535058  1.05384828], self.intercept: 1.004672455299935\n",
      "iteration - 4718 -> loss: 0.00030986146972719885, self.slope: [1.05351536 1.05385794], self.intercept: 1.004673324233029\n",
      "iteration - 4719 -> loss: 0.00030984291744710186, self.slope: [1.05352493 1.0538676 ], self.intercept: 1.0046741931235932\n",
      "iteration - 4720 -> loss: 0.00030982436746131484, self.slope: [1.05353449 1.05387725], self.intercept: 1.0046750619716318\n",
      "iteration - 4721 -> loss: 0.0003098058197693877, self.slope: [1.05354406 1.05388691], self.intercept: 1.0046759307771516\n",
      "iteration - 4722 -> loss: 0.00030978727437091846, self.slope: [1.05355362 1.05389656], self.intercept: 1.0046767995401549\n",
      "iteration - 4723 -> loss: 0.00030976873126546033, self.slope: [1.05356319 1.05390622], self.intercept: 1.004677668260647\n",
      "iteration - 4724 -> loss: 0.00030975019045258997, self.slope: [1.05357275 1.05391587], self.intercept: 1.004678536938632\n",
      "iteration - 4725 -> loss: 0.00030973165193186564, self.slope: [1.05358231 1.05392552], self.intercept: 1.0046794055741153\n",
      "iteration - 4726 -> loss: 0.0003097131157028581, self.slope: [1.05359188 1.05393517], self.intercept: 1.0046802741671004\n",
      "iteration - 4727 -> loss: 0.0003096945817651309, self.slope: [1.05360144 1.05394482], self.intercept: 1.0046811427175915\n",
      "iteration - 4728 -> loss: 0.0003096760501182818, self.slope: [1.053611   1.05395448], self.intercept: 1.0046820112255948\n",
      "iteration - 4729 -> loss: 0.0003096575207618646, self.slope: [1.05362056 1.05396413], self.intercept: 1.0046828796911134\n",
      "iteration - 4730 -> loss: 0.00030963899369543317, self.slope: [1.05363012 1.05397378], self.intercept: 1.004683748114153\n",
      "iteration - 4731 -> loss: 0.00030962046891858054, self.slope: [1.05363968 1.05398342], self.intercept: 1.0046846164947185\n",
      "iteration - 4732 -> loss: 0.0003096019464308497, self.slope: [1.05364924 1.05399307], self.intercept: 1.0046854848328128\n",
      "iteration - 4733 -> loss: 0.00030958342623185173, self.slope: [1.05365879 1.05400272], self.intercept: 1.0046863531284402\n",
      "iteration - 4734 -> loss: 0.0003095649083211114, self.slope: [1.05366835 1.05401237], self.intercept: 1.004687221381606\n",
      "iteration - 4735 -> loss: 0.0003095463926982319, self.slope: [1.05367791 1.05402201], self.intercept: 1.0046880895923151\n",
      "iteration - 4736 -> loss: 0.00030952787936279794, self.slope: [1.05368746 1.05403166], self.intercept: 1.0046889577605707\n",
      "iteration - 4737 -> loss: 0.00030950936831431066, self.slope: [1.05369702 1.05404131], self.intercept: 1.004689825886379\n",
      "iteration - 4738 -> loss: 0.00030949085955241594, self.slope: [1.05370657 1.05405095], self.intercept: 1.004690693969745\n",
      "iteration - 4739 -> loss: 0.0003094723530766476, self.slope: [1.05371613 1.0540606 ], self.intercept: 1.0046915620106724\n",
      "iteration - 4740 -> loss: 0.00030945384888657064, self.slope: [1.05372568 1.05407024], self.intercept: 1.0046924300091644\n",
      "iteration - 4741 -> loss: 0.0003094353469817943, self.slope: [1.05373524 1.05407988], self.intercept: 1.0046932979652283\n",
      "iteration - 4742 -> loss: 0.00030941684736184255, self.slope: [1.05374479 1.05408953], self.intercept: 1.004694165878866\n",
      "iteration - 4743 -> loss: 0.0003093983500263114, self.slope: [1.05375434 1.05409917], self.intercept: 1.0046950337500817\n",
      "iteration - 4744 -> loss: 0.0003093798549747653, self.slope: [1.05376389 1.05410881], self.intercept: 1.0046959015788823\n",
      "iteration - 4745 -> loss: 0.0003093613622067894, self.slope: [1.05377344 1.05411845], self.intercept: 1.0046967693652704\n",
      "iteration - 4746 -> loss: 0.00030934287172193465, self.slope: [1.05378299 1.05412809], self.intercept: 1.0046976371092526\n",
      "iteration - 4747 -> loss: 0.00030932438351979473, self.slope: [1.05379254 1.05413773], self.intercept: 1.0046985048108317\n",
      "iteration - 4748 -> loss: 0.0003093058975999105, self.slope: [1.05380209 1.05414737], self.intercept: 1.0046993724700126\n",
      "iteration - 4749 -> loss: 0.00030928741396190154, self.slope: [1.05381164 1.05415701], self.intercept: 1.0047002400868008\n",
      "iteration - 4750 -> loss: 0.00030926893260528805, self.slope: [1.05382119 1.05416664], self.intercept: 1.0047011076611978\n",
      "iteration - 4751 -> loss: 0.0003092504535296733, self.slope: [1.05383073 1.05417628], self.intercept: 1.0047019751932111\n",
      "iteration - 4752 -> loss: 0.0003092319767346178, self.slope: [1.05384028 1.05418592], self.intercept: 1.004702842682846\n",
      "iteration - 4753 -> loss: 0.00030921350221969657, self.slope: [1.05384983 1.05419555], self.intercept: 1.0047037101301037\n",
      "iteration - 4754 -> loss: 0.0003091950299844858, self.slope: [1.05385937 1.05420519], self.intercept: 1.0047045775349903\n",
      "iteration - 4755 -> loss: 0.0003091765600285654, self.slope: [1.05386892 1.05421482], self.intercept: 1.004705444897511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 4756 -> loss: 0.000309158092351484, self.slope: [1.05387846 1.05422446], self.intercept: 1.0047063122176692\n",
      "iteration - 4757 -> loss: 0.00030913962695282114, self.slope: [1.05388801 1.05423409], self.intercept: 1.0047071794954703\n",
      "iteration - 4758 -> loss: 0.00030912116383217876, self.slope: [1.05389755 1.05424373], self.intercept: 1.0047080467309195\n",
      "iteration - 4759 -> loss: 0.00030910270298909604, self.slope: [1.05390709 1.05425336], self.intercept: 1.0047089139240204\n",
      "iteration - 4760 -> loss: 0.0003090842444231714, self.slope: [1.05391663 1.05426299], self.intercept: 1.0047097810747767\n",
      "iteration - 4761 -> loss: 0.0003090657881339482, self.slope: [1.05392617 1.05427262], self.intercept: 1.0047106481831931\n",
      "iteration - 4762 -> loss: 0.0003090473341210278, self.slope: [1.05393572 1.05428225], self.intercept: 1.0047115152492747\n",
      "iteration - 4763 -> loss: 0.00030902888238396514, self.slope: [1.05394526 1.05429188], self.intercept: 1.0047123822730277\n",
      "iteration - 4764 -> loss: 0.00030901043292232806, self.slope: [1.05395479 1.05430151], self.intercept: 1.0047132492544537\n",
      "iteration - 4765 -> loss: 0.0003089919857357265, self.slope: [1.05396433 1.05431114], self.intercept: 1.0047141161935569\n",
      "iteration - 4766 -> loss: 0.0003089735408236894, self.slope: [1.05397387 1.05432077], self.intercept: 1.0047149830903452\n",
      "iteration - 4767 -> loss: 0.0003089550981858272, self.slope: [1.05398341 1.0543304 ], self.intercept: 1.0047158499448192\n",
      "iteration - 4768 -> loss: 0.0003089366578216941, self.slope: [1.05399295 1.05434003], self.intercept: 1.0047167167569868\n",
      "iteration - 4769 -> loss: 0.00030891821973086484, self.slope: [1.05400248 1.05434965], self.intercept: 1.0047175835268507\n",
      "iteration - 4770 -> loss: 0.0003088997839129113, self.slope: [1.05401202 1.05435928], self.intercept: 1.0047184502544158\n",
      "iteration - 4771 -> loss: 0.0003088813503674231, self.slope: [1.05402155 1.0543689 ], self.intercept: 1.004719316939687\n",
      "iteration - 4772 -> loss: 0.0003088629190939613, self.slope: [1.05403109 1.05437853], self.intercept: 1.0047201835826676\n",
      "iteration - 4773 -> loss: 0.0003088444900921077, self.slope: [1.05404062 1.05438815], self.intercept: 1.004721050183364\n",
      "iteration - 4774 -> loss: 0.00030882606336142716, self.slope: [1.05405016 1.05439778], self.intercept: 1.0047219167417791\n",
      "iteration - 4775 -> loss: 0.0003088076389014953, self.slope: [1.05405969 1.0544074 ], self.intercept: 1.0047227832579169\n",
      "iteration - 4776 -> loss: 0.00030878921671191487, self.slope: [1.05406922 1.05441702], self.intercept: 1.0047236497317835\n",
      "iteration - 4777 -> loss: 0.0003087707967922117, self.slope: [1.05407875 1.05442664], self.intercept: 1.0047245161633824\n",
      "iteration - 4778 -> loss: 0.0003087523791419935, self.slope: [1.05408829 1.05443627], self.intercept: 1.004725382552719\n",
      "iteration - 4779 -> loss: 0.0003087339637608352, self.slope: [1.05409782 1.05444589], self.intercept: 1.0047262488997981\n",
      "iteration - 4780 -> loss: 0.00030871555064830293, self.slope: [1.05410735 1.05445551], self.intercept: 1.0047271152046227\n",
      "iteration - 4781 -> loss: 0.0003086971398039906, self.slope: [1.05411688 1.05446513], self.intercept: 1.0047279814671968\n",
      "iteration - 4782 -> loss: 0.0003086787312274314, self.slope: [1.0541264  1.05447474], self.intercept: 1.0047288476875276\n",
      "iteration - 4783 -> loss: 0.0003086603249182348, self.slope: [1.05413593 1.05448436], self.intercept: 1.0047297138656177\n",
      "iteration - 4784 -> loss: 0.0003086419208759711, self.slope: [1.05414546 1.05449398], self.intercept: 1.0047305800014725\n",
      "iteration - 4785 -> loss: 0.00030862351910019913, self.slope: [1.05415499 1.0545036 ], self.intercept: 1.0047314460950958\n",
      "iteration - 4786 -> loss: 0.00030860511959053603, self.slope: [1.05416451 1.05451321], self.intercept: 1.0047323121464926\n",
      "iteration - 4787 -> loss: 0.00030858672234651807, self.slope: [1.05417404 1.05452283], self.intercept: 1.0047331781556663\n",
      "iteration - 4788 -> loss: 0.0003085683273677233, self.slope: [1.05418356 1.05453245], self.intercept: 1.0047340441226211\n",
      "iteration - 4789 -> loss: 0.00030854993465375514, self.slope: [1.05419309 1.05454206], self.intercept: 1.0047349100473644\n",
      "iteration - 4790 -> loss: 0.000308531544204165, self.slope: [1.05420261 1.05455168], self.intercept: 1.0047357759298983\n",
      "iteration - 4791 -> loss: 0.0003085131560185418, self.slope: [1.05421214 1.05456129], self.intercept: 1.0047366417702281\n",
      "iteration - 4792 -> loss: 0.00030849477009646303, self.slope: [1.05422166 1.0545709 ], self.intercept: 1.004737507568358\n",
      "iteration - 4793 -> loss: 0.00030847638643748934, self.slope: [1.05423118 1.05458051], self.intercept: 1.004738373324292\n",
      "iteration - 4794 -> loss: 0.00030845800504121577, self.slope: [1.0542407  1.05459013], self.intercept: 1.004739239038035\n",
      "iteration - 4795 -> loss: 0.0003084396259071987, self.slope: [1.05425023 1.05459974], self.intercept: 1.004740104709593\n",
      "iteration - 4796 -> loss: 0.0003084212490350411, self.slope: [1.05425975 1.05460935], self.intercept: 1.0047409703389674\n",
      "iteration - 4797 -> loss: 0.00030840287442431306, self.slope: [1.05426927 1.05461896], self.intercept: 1.0047418359261644\n",
      "iteration - 4798 -> loss: 0.000308384502074577, self.slope: [1.05427879 1.05462857], self.intercept: 1.004742701471189\n",
      "iteration - 4799 -> loss: 0.0003083661319854197, self.slope: [1.0542883  1.05463818], self.intercept: 1.0047435669740463\n",
      "iteration - 4800 -> loss: 0.00030834776415640546, self.slope: [1.05429782 1.05464779], self.intercept: 1.0047444324347388\n",
      "iteration - 4801 -> loss: 0.00030832939858714043, self.slope: [1.05430734 1.05465739], self.intercept: 1.0047452978532718\n",
      "iteration - 4802 -> loss: 0.000308311035277183, self.slope: [1.05431686 1.054667  ], self.intercept: 1.0047461632296495\n",
      "iteration - 4803 -> loss: 0.00030829267422609596, self.slope: [1.05432637 1.05467661], self.intercept: 1.0047470285638769\n",
      "iteration - 4804 -> loss: 0.00030827431543349273, self.slope: [1.05433589 1.05468621], self.intercept: 1.0047478938559582\n",
      "iteration - 4805 -> loss: 0.00030825595889893075, self.slope: [1.0543454  1.05469582], self.intercept: 1.0047487591058981\n",
      "iteration - 4806 -> loss: 0.0003082376046219961, self.slope: [1.05435492 1.05470542], self.intercept: 1.004749624313701\n",
      "iteration - 4807 -> loss: 0.00030821925260225214, self.slope: [1.05436443 1.05471503], self.intercept: 1.0047504894793704\n",
      "iteration - 4808 -> loss: 0.0003082009028392866, self.slope: [1.05437395 1.05472463], self.intercept: 1.004751354602912\n",
      "iteration - 4809 -> loss: 0.00030818255533268294, self.slope: [1.05438346 1.05473424], self.intercept: 1.0047522196843306\n",
      "iteration - 4810 -> loss: 0.0003081642100820001, self.slope: [1.05439297 1.05474384], self.intercept: 1.0047530847236286\n",
      "iteration - 4811 -> loss: 0.00030814586708684407, self.slope: [1.05440248 1.05475344], self.intercept: 1.0047539497208129\n",
      "iteration - 4812 -> loss: 0.00030812752634676565, self.slope: [1.05441199 1.05476304], self.intercept: 1.0047548146758865\n",
      "iteration - 4813 -> loss: 0.0003081091878613842, self.slope: [1.0544215  1.05477264], self.intercept: 1.004755679588854\n",
      "iteration - 4814 -> loss: 0.00030809085163022404, self.slope: [1.05443101 1.05478224], self.intercept: 1.0047565444597206\n",
      "iteration - 4815 -> loss: 0.0003080725176528942, self.slope: [1.05444052 1.05479184], self.intercept: 1.0047574092884899\n",
      "iteration - 4816 -> loss: 0.00030805418592898455, self.slope: [1.05445003 1.05480144], self.intercept: 1.0047582740751668\n",
      "iteration - 4817 -> loss: 0.0003080358564580644, self.slope: [1.05445954 1.05481104], self.intercept: 1.004759138819756\n",
      "iteration - 4818 -> loss: 0.00030801752923970176, self.slope: [1.05446905 1.05482064], self.intercept: 1.004760003522262\n",
      "iteration - 4819 -> loss: 0.00030799920427347616, self.slope: [1.05447856 1.05483023], self.intercept: 1.0047608681826887\n",
      "iteration - 4820 -> loss: 0.0003079808815589862, self.slope: [1.05448806 1.05483983], self.intercept: 1.0047617328010405\n",
      "iteration - 4821 -> loss: 0.0003079625610958013, self.slope: [1.05449757 1.05484943], self.intercept: 1.0047625973773222\n",
      "iteration - 4822 -> loss: 0.0003079442428834931, self.slope: [1.05450707 1.05485902], self.intercept: 1.0047634619115389\n",
      "iteration - 4823 -> loss: 0.0003079259269216528, self.slope: [1.05451658 1.05486862], self.intercept: 1.0047643264036945\n",
      "iteration - 4824 -> loss: 0.0003079076132098382, self.slope: [1.05452608 1.05487821], self.intercept: 1.0047651908537931\n",
      "iteration - 4825 -> loss: 0.00030788930174767166, self.slope: [1.05453558 1.05488781], self.intercept: 1.0047660552618398\n",
      "iteration - 4826 -> loss: 0.0003078709925346985, self.slope: [1.05454509 1.0548974 ], self.intercept: 1.0047669196278397\n",
      "iteration - 4827 -> loss: 0.00030785268557051394, self.slope: [1.05455459 1.05490699], self.intercept: 1.004767783951796\n",
      "iteration - 4828 -> loss: 0.0003078343808546808, self.slope: [1.05456409 1.05491658], self.intercept: 1.0047686482337121\n",
      "iteration - 4829 -> loss: 0.000307816078386804, self.slope: [1.05457359 1.05492618], self.intercept: 1.0047695124735958\n",
      "iteration - 4830 -> loss: 0.00030779777816644123, self.slope: [1.05458309 1.05493577], self.intercept: 1.0047703766714489\n",
      "iteration - 4831 -> loss: 0.0003077794801931804, self.slope: [1.05459259 1.05494536], self.intercept: 1.004771240827277\n",
      "iteration - 4832 -> loss: 0.0003077611844666205, self.slope: [1.05460209 1.05495495], self.intercept: 1.0047721049410843\n",
      "iteration - 4833 -> loss: 0.00030774289098631414, self.slope: [1.05461159 1.05496454], self.intercept: 1.0047729690128746\n",
      "iteration - 4834 -> loss: 0.0003077245997518699, self.slope: [1.05462109 1.05497412], self.intercept: 1.0047738330426534\n",
      "iteration - 4835 -> loss: 0.00030770631076285266, self.slope: [1.05463059 1.05498371], self.intercept: 1.004774697030424\n",
      "iteration - 4836 -> loss: 0.0003076880240188281, self.slope: [1.05464008 1.0549933 ], self.intercept: 1.0047755609761926\n",
      "iteration - 4837 -> loss: 0.00030766973951941163, self.slope: [1.05464958 1.05500289], self.intercept: 1.0047764248799613\n",
      "iteration - 4838 -> loss: 0.0003076514572641555, self.slope: [1.05465908 1.05501247], self.intercept: 1.004777288741736\n",
      "iteration - 4839 -> loss: 0.00030763317725266337, self.slope: [1.05466857 1.05502206], self.intercept: 1.0047781525615225\n",
      "iteration - 4840 -> loss: 0.00030761489948450424, self.slope: [1.05467807 1.05503164], self.intercept: 1.004779016339322\n",
      "iteration - 4841 -> loss: 0.0003075966239592582, self.slope: [1.05468756 1.05504123], self.intercept: 1.0047798800751409\n",
      "iteration - 4842 -> loss: 0.0003075783506765287, self.slope: [1.05469705 1.05505081], self.intercept: 1.0047807437689829\n",
      "iteration - 4843 -> loss: 0.00030756007963585907, self.slope: [1.05470655 1.05506039], self.intercept: 1.0047816074208544\n",
      "iteration - 4844 -> loss: 0.00030754181083686834, self.slope: [1.05471604 1.05506998], self.intercept: 1.0047824710307576\n",
      "iteration - 4845 -> loss: 0.00030752354427909703, self.slope: [1.05472553 1.05507956], self.intercept: 1.004783334598698\n",
      "iteration - 4846 -> loss: 0.00030750527996217586, self.slope: [1.05473502 1.05508914], self.intercept: 1.0047841981246817\n",
      "iteration - 4847 -> loss: 0.0003074870178856571, self.slope: [1.05474451 1.05509872], self.intercept: 1.0047850616087093\n",
      "iteration - 4848 -> loss: 0.0003074687580491316, self.slope: [1.054754  1.0551083], self.intercept: 1.0047859250507876\n",
      "iteration - 4849 -> loss: 0.0003074505004521718, self.slope: [1.05476349 1.05511788], self.intercept: 1.0047867884509207\n",
      "iteration - 4850 -> loss: 0.0003074322450943818, self.slope: [1.05477298 1.05512746], self.intercept: 1.0047876518091132\n",
      "iteration - 4851 -> loss: 0.0003074139919753281, self.slope: [1.05478247 1.05513704], self.intercept: 1.0047885151253684\n",
      "iteration - 4852 -> loss: 0.0003073957410946067, self.slope: [1.05479195 1.05514662], self.intercept: 1.0047893783996928\n",
      "iteration - 4853 -> loss: 0.00030737749245177305, self.slope: [1.05480144 1.0551562 ], self.intercept: 1.0047902416320897\n",
      "iteration - 4854 -> loss: 0.0003073592460464293, self.slope: [1.05481093 1.05516577], self.intercept: 1.0047911048225633\n",
      "iteration - 4855 -> loss: 0.00030734100187816455, self.slope: [1.05482041 1.05517535], self.intercept: 1.0047919679711181\n",
      "iteration - 4856 -> loss: 0.00030732275994654716, self.slope: [1.0548299  1.05518492], self.intercept: 1.004792831077759\n",
      "iteration - 4857 -> loss: 0.0003073045202511811, self.slope: [1.05483938 1.0551945 ], self.intercept: 1.0047936941424913\n",
      "iteration - 4858 -> loss: 0.0003072862827916212, self.slope: [1.05484887 1.05520407], self.intercept: 1.004794557165318\n",
      "iteration - 4859 -> loss: 0.0003072680475674685, self.slope: [1.05485835 1.05521365], self.intercept: 1.0047954201462432\n",
      "iteration - 4860 -> loss: 0.0003072498145783079, self.slope: [1.05486783 1.05522322], self.intercept: 1.0047962830852726\n",
      "iteration - 4861 -> loss: 0.00030723158382373126, self.slope: [1.05487732 1.05523279], self.intercept: 1.0047971459824097\n",
      "iteration - 4862 -> loss: 0.00030721335530329923, self.slope: [1.0548868  1.05524237], self.intercept: 1.0047980088376598\n",
      "iteration - 4863 -> loss: 0.0003071951290166162, self.slope: [1.05489628 1.05525194], self.intercept: 1.004798871651026\n",
      "iteration - 4864 -> loss: 0.00030717690496323975, self.slope: [1.05490576 1.05526151], self.intercept: 1.0047997344225146\n",
      "iteration - 4865 -> loss: 0.0003071586831427848, self.slope: [1.05491524 1.05527108], self.intercept: 1.0048005971521279\n",
      "iteration - 4866 -> loss: 0.0003071404635548232, self.slope: [1.05492472 1.05528065], self.intercept: 1.0048014598398716\n",
      "iteration - 4867 -> loss: 0.0003071222461989315, self.slope: [1.0549342  1.05529022], self.intercept: 1.0048023224857505\n",
      "iteration - 4868 -> loss: 0.0003071040310747102, self.slope: [1.05494368 1.05529979], self.intercept: 1.004803185089769\n",
      "iteration - 4869 -> loss: 0.00030708581818171847, self.slope: [1.05495315 1.05530936], self.intercept: 1.0048040476519307\n",
      "iteration - 4870 -> loss: 0.00030706760751958656, self.slope: [1.05496263 1.05531892], self.intercept: 1.0048049101722403\n",
      "iteration - 4871 -> loss: 0.0003070493990878543, self.slope: [1.05497211 1.05532849], self.intercept: 1.004805772650703\n",
      "iteration - 4872 -> loss: 0.0003070311928861243, self.slope: [1.05498158 1.05533806], self.intercept: 1.0048066350873222\n",
      "iteration - 4873 -> loss: 0.00030701298891398017, self.slope: [1.05499106 1.05534762], self.intercept: 1.0048074974821029\n",
      "iteration - 4874 -> loss: 0.0003069947871709951, self.slope: [1.05500053 1.05535719], self.intercept: 1.004808359835048\n",
      "iteration - 4875 -> loss: 0.00030697658765678465, self.slope: [1.05501001 1.05536675], self.intercept: 1.0048092221461635\n",
      "iteration - 4876 -> loss: 0.0003069583903709036, self.slope: [1.05501948 1.05537632], self.intercept: 1.0048100844154544\n",
      "iteration - 4877 -> loss: 0.00030694019531296433, self.slope: [1.05502895 1.05538588], self.intercept: 1.0048109466429236\n",
      "iteration - 4878 -> loss: 0.0003069220024825159, self.slope: [1.05503842 1.05539544], self.intercept: 1.0048118088285767\n",
      "iteration - 4879 -> loss: 0.00030690381187916565, self.slope: [1.0550479 1.055405 ], self.intercept: 1.0048126709724174\n",
      "iteration - 4880 -> loss: 0.0003068856235025145, self.slope: [1.05505737 1.05541457], self.intercept: 1.0048135330744499\n",
      "iteration - 4881 -> loss: 0.0003068674373521242, self.slope: [1.05506684 1.05542413], self.intercept: 1.0048143951346797\n",
      "iteration - 4882 -> loss: 0.0003068492534275963, self.slope: [1.05507631 1.05543369], self.intercept: 1.0048152571531113\n",
      "iteration - 4883 -> loss: 0.0003068310717285107, self.slope: [1.05508578 1.05544325], self.intercept: 1.0048161191297484\n",
      "iteration - 4884 -> loss: 0.00030681289225444123, self.slope: [1.05509525 1.05545281], self.intercept: 1.0048169810645948\n",
      "iteration - 4885 -> loss: 0.00030679471500499536, self.slope: [1.05510471 1.05546237], self.intercept: 1.0048178429576553\n",
      "iteration - 4886 -> loss: 0.0003067765399797334, self.slope: [1.05511418 1.05547192], self.intercept: 1.004818704808934\n",
      "iteration - 4887 -> loss: 0.00030675836717827565, self.slope: [1.05512365 1.05548148], self.intercept: 1.0048195666184372\n",
      "iteration - 4888 -> loss: 0.0003067401966001864, self.slope: [1.05513312 1.05549104], self.intercept: 1.0048204283861681\n",
      "iteration - 4889 -> loss: 0.00030672202824505587, self.slope: [1.05514258 1.0555006 ], self.intercept: 1.0048212901121314\n",
      "iteration - 4890 -> loss: 0.00030670386211247176, self.slope: [1.05515205 1.05551015], self.intercept: 1.0048221517963305\n",
      "iteration - 4891 -> loss: 0.00030668569820202935, self.slope: [1.05516151 1.05551971], self.intercept: 1.0048230134387706\n",
      "iteration - 4892 -> loss: 0.00030666753651329895, self.slope: [1.05517098 1.05552926], self.intercept: 1.0048238750394562\n",
      "iteration - 4893 -> loss: 0.00030664937704587584, self.slope: [1.05518044 1.05553882], self.intercept: 1.0048247365983916\n",
      "iteration - 4894 -> loss: 0.00030663121979935393, self.slope: [1.0551899  1.05554837], self.intercept: 1.004825598115582\n",
      "iteration - 4895 -> loss: 0.0003066130647733062, self.slope: [1.05519936 1.05555792], self.intercept: 1.004826459591031\n",
      "iteration - 4896 -> loss: 0.0003065949119673228, self.slope: [1.05520883 1.05556747], self.intercept: 1.0048273210247425\n",
      "iteration - 4897 -> loss: 0.0003065767613810131, self.slope: [1.05521829 1.05557703], self.intercept: 1.0048281824167205\n",
      "iteration - 4898 -> loss: 0.00030655861301392805, self.slope: [1.05522775 1.05558658], self.intercept: 1.004829043766972\n",
      "iteration - 4899 -> loss: 0.0003065404668656951, self.slope: [1.05523721 1.05559613], self.intercept: 1.0048299050754987\n",
      "iteration - 4900 -> loss: 0.0003065223229358622, self.slope: [1.05524667 1.05560568], self.intercept: 1.004830766342306\n",
      "iteration - 4901 -> loss: 0.0003065041812240697, self.slope: [1.05525613 1.05561523], self.intercept: 1.0048316275673976\n",
      "iteration - 4902 -> loss: 0.00030648604172983846, self.slope: [1.05526558 1.05562478], self.intercept: 1.0048324887507794\n",
      "iteration - 4903 -> loss: 0.00030646790445281575, self.slope: [1.05527504 1.05563433], self.intercept: 1.0048333498924542\n",
      "iteration - 4904 -> loss: 0.00030644976939253913, self.slope: [1.0552845  1.05564387], self.intercept: 1.0048342109924273\n",
      "iteration - 4905 -> loss: 0.000306431636548651, self.slope: [1.05529396 1.05565342], self.intercept: 1.0048350720507047\n",
      "iteration - 4906 -> loss: 0.00030641350592068616, self.slope: [1.05530341 1.05566297], self.intercept: 1.004835933067288\n",
      "iteration - 4907 -> loss: 0.0003063953775082722, self.slope: [1.05531287 1.05567251], self.intercept: 1.0048367940421832\n",
      "iteration - 4908 -> loss: 0.0003063772513109684, self.slope: [1.05532232 1.05568206], self.intercept: 1.004837654975394\n",
      "iteration - 4909 -> loss: 0.000306359127328395, self.slope: [1.05533178 1.0556916 ], self.intercept: 1.0048385158669249\n",
      "iteration - 4910 -> loss: 0.00030634100556011933, self.slope: [1.05534123 1.05570115], self.intercept: 1.0048393767167814\n",
      "iteration - 4911 -> loss: 0.00030632288600574304, self.slope: [1.05535068 1.05571069], self.intercept: 1.0048402375249668\n",
      "iteration - 4912 -> loss: 0.0003063047686648498, self.slope: [1.05536014 1.05572024], self.intercept: 1.0048410982914857\n",
      "iteration - 4913 -> loss: 0.00030628665353701245, self.slope: [1.05536959 1.05572978], self.intercept: 1.0048419590163422\n",
      "iteration - 4914 -> loss: 0.00030626854062184525, self.slope: [1.05537904 1.05573932], self.intercept: 1.0048428196995405\n",
      "iteration - 4915 -> loss: 0.00030625042991893204, self.slope: [1.05538849 1.05574886], self.intercept: 1.0048436803410856\n",
      "iteration - 4916 -> loss: 0.00030623232142784547, self.slope: [1.05539794 1.0557584 ], self.intercept: 1.004844540940982\n",
      "iteration - 4917 -> loss: 0.0003062142151481871, self.slope: [1.05540739 1.05576794], self.intercept: 1.0048454014992332\n",
      "iteration - 4918 -> loss: 0.00030619611107956103, self.slope: [1.05541684 1.05577748], self.intercept: 1.004846262015845\n",
      "iteration - 4919 -> loss: 0.0003061780092215332, self.slope: [1.05542629 1.05578702], self.intercept: 1.0048471224908209\n",
      "iteration - 4920 -> loss: 0.0003061599095736969, self.slope: [1.05543573 1.05579656], self.intercept: 1.0048479829241652\n",
      "iteration - 4921 -> loss: 0.0003061418121356659, self.slope: [1.05544518 1.0558061 ], self.intercept: 1.0048488433158833\n",
      "iteration - 4922 -> loss: 0.00030612371690698223, self.slope: [1.05545463 1.05581564], self.intercept: 1.0048497036659787\n",
      "iteration - 4923 -> loss: 0.00030610562388729196, self.slope: [1.05546407 1.05582517], self.intercept: 1.0048505639744558\n",
      "iteration - 4924 -> loss: 0.000306087533076138, self.slope: [1.05547352 1.05583471], self.intercept: 1.0048514242413193\n",
      "iteration - 4925 -> loss: 0.00030606944447315654, self.slope: [1.05548296 1.05584424], self.intercept: 1.0048522844665733\n",
      "iteration - 4926 -> loss: 0.00030605135807790744, self.slope: [1.05549241 1.05585378], self.intercept: 1.0048531446502222\n",
      "iteration - 4927 -> loss: 0.00030603327388997, self.slope: [1.05550185 1.05586331], self.intercept: 1.0048540047922716\n",
      "iteration - 4928 -> loss: 0.00030601519190897187, self.slope: [1.0555113  1.05587285], self.intercept: 1.0048548648927234\n",
      "iteration - 4929 -> loss: 0.0003059971121344556, self.slope: [1.05552074 1.05588238], self.intercept: 1.0048557249515848\n",
      "iteration - 4930 -> loss: 0.00030597903456606784, self.slope: [1.05553018 1.05589191], self.intercept: 1.004856584968858\n",
      "iteration - 4931 -> loss: 0.00030596095920336965, self.slope: [1.05553962 1.05590145], self.intercept: 1.004857444944548\n",
      "iteration - 4932 -> loss: 0.00030594288604595386, self.slope: [1.05554906 1.05591098], self.intercept: 1.0048583048786595\n",
      "iteration - 4933 -> loss: 0.00030592481509340706, self.slope: [1.0555585  1.05592051], self.intercept: 1.0048591647711953\n",
      "iteration - 4934 -> loss: 0.0003059067463453349, self.slope: [1.05556794 1.05593004], self.intercept: 1.0048600246221613\n",
      "iteration - 4935 -> loss: 0.0003058886798012999, self.slope: [1.05557738 1.05593957], self.intercept: 1.0048608844315632\n",
      "iteration - 4936 -> loss: 0.0003058706154609298, self.slope: [1.05558682 1.0559491 ], self.intercept: 1.0048617441994039\n",
      "iteration - 4937 -> loss: 0.00030585255332379375, self.slope: [1.05559626 1.05595863], self.intercept: 1.004862603925688\n",
      "iteration - 4938 -> loss: 0.00030583449338949267, self.slope: [1.05560569 1.05596816], self.intercept: 1.0048634636104201\n",
      "iteration - 4939 -> loss: 0.0003058164356576203, self.slope: [1.05561513 1.05597768], self.intercept: 1.004864323253604\n",
      "iteration - 4940 -> loss: 0.0003057983801277593, self.slope: [1.05562457 1.05598721], self.intercept: 1.0048651828552448\n",
      "iteration - 4941 -> loss: 0.00030578032679950273, self.slope: [1.055634   1.05599674], self.intercept: 1.004866042415346\n",
      "iteration - 4942 -> loss: 0.00030576227567244424, self.slope: [1.05564344 1.05600626], self.intercept: 1.0048669019339123\n",
      "iteration - 4943 -> loss: 0.0003057442267461804, self.slope: [1.05565287 1.05601579], self.intercept: 1.0048677614109482\n",
      "iteration - 4944 -> loss: 0.0003057261800203084, self.slope: [1.05566231 1.05602531], self.intercept: 1.0048686208464586\n",
      "iteration - 4945 -> loss: 0.00030570813549441004, self.slope: [1.05567174 1.05603484], self.intercept: 1.004869480240447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 4946 -> loss: 0.0003056900931680629, self.slope: [1.05568117 1.05604436], self.intercept: 1.004870339592918\n",
      "iteration - 4947 -> loss: 0.0003056720530408943, self.slope: [1.0556906  1.05605388], self.intercept: 1.004871198903876\n",
      "iteration - 4948 -> loss: 0.0003056540151124725, self.slope: [1.05570004 1.05606341], self.intercept: 1.0048720581733264\n",
      "iteration - 4949 -> loss: 0.0003056359793824095, self.slope: [1.05570947 1.05607293], self.intercept: 1.0048729174012716\n",
      "iteration - 4950 -> loss: 0.00030561794585026025, self.slope: [1.0557189  1.05608245], self.intercept: 1.0048737765877171\n",
      "iteration - 4951 -> loss: 0.0003055999145156724, self.slope: [1.05572833 1.05609197], self.intercept: 1.004874635732668\n",
      "iteration - 4952 -> loss: 0.0003055818853781897, self.slope: [1.05573776 1.05610149], self.intercept: 1.0048754948361271\n",
      "iteration - 4953 -> loss: 0.0003055638584374411, self.slope: [1.05574718 1.05611101], self.intercept: 1.0048763538980992\n",
      "iteration - 4954 -> loss: 0.00030554583369300304, self.slope: [1.05575661 1.05612053], self.intercept: 1.0048772129185897\n",
      "iteration - 4955 -> loss: 0.00030552781114446956, self.slope: [1.05576604 1.05613005], self.intercept: 1.0048780718976018\n",
      "iteration - 4956 -> loss: 0.0003055097907914317, self.slope: [1.05577547 1.05613956], self.intercept: 1.0048789308351422\n",
      "iteration - 4957 -> loss: 0.0003054917726334793, self.slope: [1.05578489 1.05614908], self.intercept: 1.004879789731212\n",
      "iteration - 4958 -> loss: 0.0003054737566702275, self.slope: [1.05579432 1.0561586 ], self.intercept: 1.0048806485858168\n",
      "iteration - 4959 -> loss: 0.0003054557429012605, self.slope: [1.05580374 1.05616811], self.intercept: 1.0048815073989612\n",
      "iteration - 4960 -> loss: 0.00030543773132615527, self.slope: [1.05581317 1.05617763], self.intercept: 1.0048823661706503\n",
      "iteration - 4961 -> loss: 0.0003054197219445207, self.slope: [1.05582259 1.05618714], self.intercept: 1.0048832249008868\n",
      "iteration - 4962 -> loss: 0.00030540171475594504, self.slope: [1.05583202 1.05619666], self.intercept: 1.0048840835896766\n",
      "iteration - 4963 -> loss: 0.00030538370976003904, self.slope: [1.05584144 1.05620617], self.intercept: 1.004884942237024\n",
      "iteration - 4964 -> loss: 0.00030536570695636117, self.slope: [1.05585086 1.05621569], self.intercept: 1.0048858008429324\n",
      "iteration - 4965 -> loss: 0.00030534770634454696, self.slope: [1.05586028 1.0562252 ], self.intercept: 1.0048866594074057\n",
      "iteration - 4966 -> loss: 0.00030532970792417497, self.slope: [1.0558697  1.05623471], self.intercept: 1.0048875179304495\n",
      "iteration - 4967 -> loss: 0.0003053117116948359, self.slope: [1.05587912 1.05624422], self.intercept: 1.004888376412068\n",
      "iteration - 4968 -> loss: 0.00030529371765611964, self.slope: [1.05588854 1.05625373], self.intercept: 1.0048892348522658\n",
      "iteration - 4969 -> loss: 0.00030527572580763115, self.slope: [1.05589796 1.05626324], self.intercept: 1.0048900932510472\n",
      "iteration - 4970 -> loss: 0.0003052577361489603, self.slope: [1.05590738 1.05627275], self.intercept: 1.004890951608416\n",
      "iteration - 4971 -> loss: 0.0003052397486797049, self.slope: [1.0559168  1.05628226], self.intercept: 1.0048918099243755\n",
      "iteration - 4972 -> loss: 0.0003052217633994409, self.slope: [1.05592622 1.05629177], self.intercept: 1.0048926681989323\n",
      "iteration - 4973 -> loss: 0.0003052037803078104, self.slope: [1.05593563 1.05630128], self.intercept: 1.0048935264320893\n",
      "iteration - 4974 -> loss: 0.0003051857994043694, self.slope: [1.05594505 1.05631079], self.intercept: 1.0048943846238507\n",
      "iteration - 4975 -> loss: 0.00030516782068871996, self.slope: [1.05595447 1.05632029], self.intercept: 1.0048952427742217\n",
      "iteration - 4976 -> loss: 0.0003051498441604648, self.slope: [1.05596388 1.0563298 ], self.intercept: 1.0048961008832062\n",
      "iteration - 4977 -> loss: 0.00030513186981918493, self.slope: [1.0559733 1.0563393], self.intercept: 1.0048969589508108\n",
      "iteration - 4978 -> loss: 0.0003051138976644996, self.slope: [1.05598271 1.05634881], self.intercept: 1.0048978169770368\n",
      "iteration - 4979 -> loss: 0.0003050959276959821, self.slope: [1.05599212 1.05635831], self.intercept: 1.0048986749618902\n",
      "iteration - 4980 -> loss: 0.0003050779599132485, self.slope: [1.05600154 1.05636782], self.intercept: 1.0048995329053747\n",
      "iteration - 4981 -> loss: 0.00030505999431587263, self.slope: [1.05601095 1.05637732], self.intercept: 1.004900390807493\n",
      "iteration - 4982 -> loss: 0.0003050420309034732, self.slope: [1.05602036 1.05638682], self.intercept: 1.0049012486682514\n",
      "iteration - 4983 -> loss: 0.00030502406967564, self.slope: [1.05602977 1.05639633], self.intercept: 1.0049021064876547\n",
      "iteration - 4984 -> loss: 0.0003050061106319521, self.slope: [1.05603918 1.05640583], self.intercept: 1.0049029642657055\n",
      "iteration - 4985 -> loss: 0.0003049881537720275, self.slope: [1.05604859 1.05641533], self.intercept: 1.0049038220024107\n",
      "iteration - 4986 -> loss: 0.0003049701990954485, self.slope: [1.056058   1.05642483], self.intercept: 1.004904679697773\n",
      "iteration - 4987 -> loss: 0.0003049522466018087, self.slope: [1.05606741 1.05643433], self.intercept: 1.0049055373517954\n",
      "iteration - 4988 -> loss: 0.0003049342962907315, self.slope: [1.05607682 1.05644383], self.intercept: 1.0049063949644843\n",
      "iteration - 4989 -> loss: 0.00030491634816179705, self.slope: [1.05608623 1.05645333], self.intercept: 1.0049072525358431\n",
      "iteration - 4990 -> loss: 0.00030489840221459215, self.slope: [1.05609564 1.05646283], self.intercept: 1.0049081100658759\n",
      "iteration - 4991 -> loss: 0.000304880458448715, self.slope: [1.05610504 1.05647232], self.intercept: 1.0049089675545884\n",
      "iteration - 4992 -> loss: 0.00030486251686378206, self.slope: [1.05611445 1.05648182], self.intercept: 1.0049098250019837\n",
      "iteration - 4993 -> loss: 0.000304844577459367, self.slope: [1.05612385 1.05649132], self.intercept: 1.0049106824080678\n",
      "iteration - 4994 -> loss: 0.0003048266402350966, self.slope: [1.05613326 1.05650081], self.intercept: 1.0049115397728436\n",
      "iteration - 4995 -> loss: 0.0003048087051905387, self.slope: [1.05614266 1.05651031], self.intercept: 1.0049123970963159\n",
      "iteration - 4996 -> loss: 0.000304790772325305, self.slope: [1.05615207 1.0565198 ], self.intercept: 1.0049132543784884\n",
      "iteration - 4997 -> loss: 0.00030477284163898293, self.slope: [1.05616147 1.0565293 ], self.intercept: 1.004914111619366\n",
      "iteration - 4998 -> loss: 0.00030475491313119383, self.slope: [1.05617087 1.05653879], self.intercept: 1.0049149688189525\n",
      "iteration - 4999 -> loss: 0.0003047369868015146, self.slope: [1.05618027 1.05654829], self.intercept: 1.004915825977254\n",
      "iteration - 5000 -> loss: 0.00030471906264954105, self.slope: [1.05618968 1.05655778], self.intercept: 1.0049166830942726\n",
      "iteration - 5001 -> loss: 0.000304701140674879, self.slope: [1.05619908 1.05656727], self.intercept: 1.0049175401700137\n",
      "iteration - 5002 -> loss: 0.0003046832208771328, self.slope: [1.05620848 1.05657676], self.intercept: 1.004918397204481\n",
      "iteration - 5003 -> loss: 0.0003046653032558981, self.slope: [1.05621788 1.05658625], self.intercept: 1.00491925419768\n",
      "iteration - 5004 -> loss: 0.000304647387810751, self.slope: [1.05622728 1.05659574], self.intercept: 1.0049201111496138\n",
      "iteration - 5005 -> loss: 0.00030462947454132464, self.slope: [1.05623667 1.05660523], self.intercept: 1.0049209680602882\n",
      "iteration - 5006 -> loss: 0.0003046115634471873, self.slope: [1.05624607 1.05661472], self.intercept: 1.004921824929706\n",
      "iteration - 5007 -> loss: 0.0003045936545279743, self.slope: [1.05625547 1.05662421], self.intercept: 1.0049226817578742\n",
      "iteration - 5008 -> loss: 0.0003045757477832358, self.slope: [1.05626487 1.0566337 ], self.intercept: 1.0049235385447932\n",
      "iteration - 5009 -> loss: 0.0003045578432126101, self.slope: [1.05627426 1.05664319], self.intercept: 1.0049243952904696\n",
      "iteration - 5010 -> loss: 0.00030453994081566614, self.slope: [1.05628366 1.05665267], self.intercept: 1.004925251994906\n",
      "iteration - 5011 -> loss: 0.00030452204059204616, self.slope: [1.05629305 1.05666216], self.intercept: 1.0049261086581085\n",
      "iteration - 5012 -> loss: 0.00030450414254131256, self.slope: [1.05630245 1.05667164], self.intercept: 1.0049269652800816\n",
      "iteration - 5013 -> loss: 0.0003044862466630535, self.slope: [1.05631184 1.05668113], self.intercept: 1.0049278218608284\n",
      "iteration - 5014 -> loss: 0.0003044683529569121, self.slope: [1.05632124 1.05669061], self.intercept: 1.0049286784003548\n",
      "iteration - 5015 -> loss: 0.00030445046142244875, self.slope: [1.05633063 1.0567001 ], self.intercept: 1.004929534898664\n",
      "iteration - 5016 -> loss: 0.00030443257205928264, self.slope: [1.05634002 1.05670958], self.intercept: 1.0049303913557608\n",
      "iteration - 5017 -> loss: 0.00030441468486702364, self.slope: [1.05634941 1.05671906], self.intercept: 1.004931247771649\n",
      "iteration - 5018 -> loss: 0.0003043967998452355, self.slope: [1.0563588  1.05672855], self.intercept: 1.004932104146334\n",
      "iteration - 5019 -> loss: 0.00030437891699355493, self.slope: [1.05636819 1.05673803], self.intercept: 1.00493296047982\n",
      "iteration - 5020 -> loss: 0.00030436103631155647, self.slope: [1.05637758 1.05674751], self.intercept: 1.0049338167721094\n",
      "iteration - 5021 -> loss: 0.00030434315779885476, self.slope: [1.05638697 1.05675699], self.intercept: 1.0049346730232074\n",
      "iteration - 5022 -> loss: 0.00030432528145504784, self.slope: [1.05639636 1.05676647], self.intercept: 1.0049355292331181\n",
      "iteration - 5023 -> loss: 0.0003043074072797216, self.slope: [1.05640575 1.05677595], self.intercept: 1.0049363854018483\n",
      "iteration - 5024 -> loss: 0.0003042895352725191, self.slope: [1.05641514 1.05678543], self.intercept: 1.0049372415293998\n",
      "iteration - 5025 -> loss: 0.00030427166543297977, self.slope: [1.05642453 1.05679491], self.intercept: 1.0049380976157773\n",
      "iteration - 5026 -> loss: 0.0003042537977607413, self.slope: [1.05643391 1.05680438], self.intercept: 1.0049389536609856\n",
      "iteration - 5027 -> loss: 0.0003042359322553929, self.slope: [1.0564433  1.05681386], self.intercept: 1.0049398096650277\n",
      "iteration - 5028 -> loss: 0.00030421806891656016, self.slope: [1.05645268 1.05682334], self.intercept: 1.0049406656279096\n",
      "iteration - 5029 -> loss: 0.0003042002077438078, self.slope: [1.05646207 1.05683281], self.intercept: 1.004941521549636\n",
      "iteration - 5030 -> loss: 0.0003041823487367426, self.slope: [1.05647145 1.05684229], self.intercept: 1.0049423774302106\n",
      "iteration - 5031 -> loss: 0.000304164491894987, self.slope: [1.05648084 1.05685176], self.intercept: 1.0049432332696362\n",
      "iteration - 5032 -> loss: 0.00030414663721813463, self.slope: [1.05649022 1.05686124], self.intercept: 1.004944089067917\n",
      "iteration - 5033 -> loss: 0.0003041287847057797, self.slope: [1.0564996  1.05687071], self.intercept: 1.00494494482506\n",
      "iteration - 5034 -> loss: 0.00030411093435752057, self.slope: [1.05650898 1.05688019], self.intercept: 1.0049458005410683\n",
      "iteration - 5035 -> loss: 0.0003040930861729694, self.slope: [1.05651836 1.05688966], self.intercept: 1.0049466562159457\n",
      "iteration - 5036 -> loss: 0.00030407524015170864, self.slope: [1.05652774 1.05689913], self.intercept: 1.0049475118496964\n",
      "iteration - 5037 -> loss: 0.0003040573962933652, self.slope: [1.05653712 1.0569086 ], self.intercept: 1.0049483674423252\n",
      "iteration - 5038 -> loss: 0.0003040395545975337, self.slope: [1.0565465  1.05691807], self.intercept: 1.0049492229938368\n",
      "iteration - 5039 -> loss: 0.00030402171506379834, self.slope: [1.05655588 1.05692754], self.intercept: 1.0049500785042356\n",
      "iteration - 5040 -> loss: 0.0003040038776917844, self.slope: [1.05656526 1.05693701], self.intercept: 1.004950933973525\n",
      "iteration - 5041 -> loss: 0.00030398604248107596, self.slope: [1.05657464 1.05694648], self.intercept: 1.0049517894017093\n",
      "iteration - 5042 -> loss: 0.00030396820943130043, self.slope: [1.05658402 1.05695595], self.intercept: 1.0049526447887926\n",
      "iteration - 5043 -> loss: 0.0003039503785420385, self.slope: [1.05659339 1.05696542], self.intercept: 1.0049535001347811\n",
      "iteration - 5044 -> loss: 0.0003039325498128762, self.slope: [1.05660277 1.05697489], self.intercept: 1.0049543554396785\n",
      "iteration - 5045 -> loss: 0.00030391472324345787, self.slope: [1.05661215 1.05698435], self.intercept: 1.0049552107034878\n",
      "iteration - 5046 -> loss: 0.00030389689883334635, self.slope: [1.05662152 1.05699382], self.intercept: 1.0049560659262131\n",
      "iteration - 5047 -> loss: 0.00030387907658217686, self.slope: [1.05663089 1.05700328], self.intercept: 1.0049569211078608\n",
      "iteration - 5048 -> loss: 0.0003038612564895234, self.slope: [1.05664027 1.05701275], self.intercept: 1.004957776248433\n",
      "iteration - 5049 -> loss: 0.00030384343855501054, self.slope: [1.05664964 1.05702221], self.intercept: 1.004958631347935\n",
      "iteration - 5050 -> loss: 0.00030382562277822013, self.slope: [1.05665901 1.05703168], self.intercept: 1.0049594864063711\n",
      "iteration - 5051 -> loss: 0.00030380780915879304, self.slope: [1.05666839 1.05704114], self.intercept: 1.0049603414237462\n",
      "iteration - 5052 -> loss: 0.0003037899976962822, self.slope: [1.05667776 1.0570506 ], self.intercept: 1.0049611964000629\n",
      "iteration - 5053 -> loss: 0.0003037721883903248, self.slope: [1.05668713 1.05706007], self.intercept: 1.0049620513353268\n",
      "iteration - 5054 -> loss: 0.00030375438124051517, self.slope: [1.0566965  1.05706953], self.intercept: 1.0049629062295424\n",
      "iteration - 5055 -> loss: 0.0003037365762464684, self.slope: [1.05670587 1.05707899], self.intercept: 1.0049637610827131\n",
      "iteration - 5056 -> loss: 0.00030371877340776326, self.slope: [1.05671524 1.05708845], self.intercept: 1.004964615894844\n",
      "iteration - 5057 -> loss: 0.0003037009727240164, self.slope: [1.05672461 1.05709791], self.intercept: 1.0049654706659379\n",
      "iteration - 5058 -> loss: 0.0003036831741948295, self.slope: [1.05673398 1.05710737], self.intercept: 1.004966325396002\n",
      "iteration - 5059 -> loss: 0.00030366537781982144, self.slope: [1.05674334 1.05711683], self.intercept: 1.0049671800850386\n",
      "iteration - 5060 -> loss: 0.00030364758359857885, self.slope: [1.05675271 1.05712629], self.intercept: 1.004968034733051\n",
      "iteration - 5061 -> loss: 0.0003036297915306912, self.slope: [1.05676208 1.05713574], self.intercept: 1.0049688893400457\n",
      "iteration - 5062 -> loss: 0.0003036120016158073, self.slope: [1.05677144 1.0571452 ], self.intercept: 1.0049697439060246\n",
      "iteration - 5063 -> loss: 0.00030359421385348296, self.slope: [1.05678081 1.05715466], self.intercept: 1.004970598430995\n",
      "iteration - 5064 -> loss: 0.0003035764282433506, self.slope: [1.05679017 1.05716411], self.intercept: 1.0049714529149598\n",
      "iteration - 5065 -> loss: 0.0003035586447850192, self.slope: [1.05679954 1.05717357], self.intercept: 1.0049723073579233\n",
      "iteration - 5066 -> loss: 0.0003035408634780635, self.slope: [1.0568089  1.05718303], self.intercept: 1.0049731617598887\n",
      "iteration - 5067 -> loss: 0.0003035230843221245, self.slope: [1.05681826 1.05719248], self.intercept: 1.004974016120863\n",
      "iteration - 5068 -> loss: 0.0003035053073167773, self.slope: [1.05682763 1.05720193], self.intercept: 1.0049748704408485\n",
      "iteration - 5069 -> loss: 0.00030348753246165275, self.slope: [1.05683699 1.05721139], self.intercept: 1.004975724719848\n",
      "iteration - 5070 -> loss: 0.00030346975975633034, self.slope: [1.05684635 1.05722084], self.intercept: 1.0049765789578673\n",
      "iteration - 5071 -> loss: 0.0003034519892004199, self.slope: [1.05685571 1.05723029], self.intercept: 1.004977433154913\n",
      "iteration - 5072 -> loss: 0.0003034342207935472, self.slope: [1.05686507 1.05723974], self.intercept: 1.004978287310986\n",
      "iteration - 5073 -> loss: 0.00030341645453529155, self.slope: [1.05687443 1.05724919], self.intercept: 1.0049791414260938\n",
      "iteration - 5074 -> loss: 0.00030339869042526175, self.slope: [1.05688379 1.05725864], self.intercept: 1.0049799955002365\n",
      "iteration - 5075 -> loss: 0.00030338092846307466, self.slope: [1.05689315 1.05726809], self.intercept: 1.0049808495334205\n",
      "iteration - 5076 -> loss: 0.0003033631686483497, self.slope: [1.0569025  1.05727754], self.intercept: 1.0049817035256499\n",
      "iteration - 5077 -> loss: 0.0003033454109806588, self.slope: [1.05691186 1.05728699], self.intercept: 1.004982557476931\n",
      "iteration - 5078 -> loss: 0.00030332765545964467, self.slope: [1.05692122 1.05729644], self.intercept: 1.0049834113872655\n",
      "iteration - 5079 -> loss: 0.00030330990208486517, self.slope: [1.05693057 1.05730589], self.intercept: 1.0049842652566585\n",
      "iteration - 5080 -> loss: 0.00030329215085595824, self.slope: [1.05693993 1.05731533], self.intercept: 1.0049851190851136\n",
      "iteration - 5081 -> loss: 0.00030327440177252304, self.slope: [1.05694928 1.05732478], self.intercept: 1.0049859728726365\n",
      "iteration - 5082 -> loss: 0.0003032566548341719, self.slope: [1.05695864 1.05733423], self.intercept: 1.0049868266192297\n",
      "iteration - 5083 -> loss: 0.00030323891004050606, self.slope: [1.05696799 1.05734367], self.intercept: 1.0049876803249005\n",
      "iteration - 5084 -> loss: 0.00030322116739112803, self.slope: [1.05697735 1.05735312], self.intercept: 1.0049885339896516\n",
      "iteration - 5085 -> loss: 0.00030320342688565816, self.slope: [1.0569867  1.05736256], self.intercept: 1.0049893876134866\n",
      "iteration - 5086 -> loss: 0.0003031856885236761, self.slope: [1.05699605 1.057372  ], self.intercept: 1.00499024119641\n",
      "iteration - 5087 -> loss: 0.00030316795230481716, self.slope: [1.0570054  1.05738145], self.intercept: 1.0049910947384253\n",
      "iteration - 5088 -> loss: 0.00030315021822866086, self.slope: [1.05701475 1.05739089], self.intercept: 1.0049919482395375\n",
      "iteration - 5089 -> loss: 0.00030313248629485563, self.slope: [1.0570241  1.05740033], self.intercept: 1.0049928016997507\n",
      "iteration - 5090 -> loss: 0.00030311475650295153, self.slope: [1.05703345 1.05740977], self.intercept: 1.0049936551190706\n",
      "iteration - 5091 -> loss: 0.00030309702885258184, self.slope: [1.0570428  1.05741921], self.intercept: 1.0049945084975014\n",
      "iteration - 5092 -> loss: 0.00030307930334337504, self.slope: [1.05705215 1.05742865], self.intercept: 1.0049953618350445\n",
      "iteration - 5093 -> loss: 0.00030306157997490196, self.slope: [1.0570615  1.05743809], self.intercept: 1.0049962151317076\n",
      "iteration - 5094 -> loss: 0.00030304385874680405, self.slope: [1.05707085 1.05744753], self.intercept: 1.0049970683874925\n",
      "iteration - 5095 -> loss: 0.0003030261396586548, self.slope: [1.05708019 1.05745697], self.intercept: 1.0049979216024045\n",
      "iteration - 5096 -> loss: 0.00030300842271009366, self.slope: [1.05708954 1.05746641], self.intercept: 1.0049987747764462\n",
      "iteration - 5097 -> loss: 0.00030299070790069916, self.slope: [1.05709889 1.05747585], self.intercept: 1.0049996279096252\n",
      "iteration - 5098 -> loss: 0.0003029729952301049, self.slope: [1.05710823 1.05748528], self.intercept: 1.0050004810019433\n",
      "iteration - 5099 -> loss: 0.0003029552846979079, self.slope: [1.05711758 1.05749472], self.intercept: 1.005001334053405\n",
      "iteration - 5100 -> loss: 0.0003029375763036984, self.slope: [1.05712692 1.05750416], self.intercept: 1.005002187064015\n",
      "iteration - 5101 -> loss: 0.0003029198700471031, self.slope: [1.05713626 1.05751359], self.intercept: 1.0050030400337784\n",
      "iteration - 5102 -> loss: 0.00030290216592772227, self.slope: [1.05714561 1.05752303], self.intercept: 1.0050038929626988\n",
      "iteration - 5103 -> loss: 0.0003028844639451961, self.slope: [1.05715495 1.05753246], self.intercept: 1.0050047458507803\n",
      "iteration - 5104 -> loss: 0.0003028667640990715, self.slope: [1.05716429 1.05754189], self.intercept: 1.005005598698027\n",
      "iteration - 5105 -> loss: 0.0003028490663890109, self.slope: [1.05717363 1.05755133], self.intercept: 1.0050064515044443\n",
      "iteration - 5106 -> loss: 0.00030283137081460535, self.slope: [1.05718297 1.05756076], self.intercept: 1.0050073042700356\n",
      "iteration - 5107 -> loss: 0.0003028136773754395, self.slope: [1.05719231 1.05757019], self.intercept: 1.005008156994804\n",
      "iteration - 5108 -> loss: 0.0003027959860711518, self.slope: [1.05720165 1.05757962], self.intercept: 1.0050090096787552\n",
      "iteration - 5109 -> loss: 0.00030277829690134186, self.slope: [1.05721099 1.05758905], self.intercept: 1.0050098623218944\n",
      "iteration - 5110 -> loss: 0.00030276060986560806, self.slope: [1.05722033 1.05759848], self.intercept: 1.0050107149242251\n",
      "iteration - 5111 -> loss: 0.00030274292496357914, self.slope: [1.05722967 1.05760791], self.intercept: 1.0050115674857503\n",
      "iteration - 5112 -> loss: 0.0003027252421948602, self.slope: [1.05723901 1.05761734], self.intercept: 1.005012420006474\n",
      "iteration - 5113 -> loss: 0.0003027075615590452, self.slope: [1.05724834 1.05762677], self.intercept: 1.0050132724864012\n",
      "iteration - 5114 -> loss: 0.00030268988305575393, self.slope: [1.05725768 1.0576362 ], self.intercept: 1.0050141249255369\n",
      "iteration - 5115 -> loss: 0.0003026722066845841, self.slope: [1.05726702 1.05764562], self.intercept: 1.0050149773238855\n",
      "iteration - 5116 -> loss: 0.0003026545324451523, self.slope: [1.05727635 1.05765505], self.intercept: 1.0050158296814506\n",
      "iteration - 5117 -> loss: 0.0003026368603370777, self.slope: [1.05728568 1.05766448], self.intercept: 1.005016681998236\n",
      "iteration - 5118 -> loss: 0.00030261919035996077, self.slope: [1.05729502 1.0576739 ], self.intercept: 1.0050175342742464\n",
      "iteration - 5119 -> loss: 0.0003026015225134137, self.slope: [1.05730435 1.05768333], self.intercept: 1.0050183865094864\n",
      "iteration - 5120 -> loss: 0.00030258385679705777, self.slope: [1.05731368 1.05769275], self.intercept: 1.0050192387039598\n",
      "iteration - 5121 -> loss: 0.0003025661932104713, self.slope: [1.05732302 1.05770217], self.intercept: 1.0050200908576714\n",
      "iteration - 5122 -> loss: 0.0003025485317532963, self.slope: [1.05733235 1.0577116 ], self.intercept: 1.0050209429706236\n",
      "iteration - 5123 -> loss: 0.00030253087242510554, self.slope: [1.05734168 1.05772102], self.intercept: 1.0050217950428242\n",
      "iteration - 5124 -> loss: 0.0003025132152255476, self.slope: [1.05735101 1.05773044], self.intercept: 1.005022647074275\n",
      "iteration - 5125 -> loss: 0.0003024955601542186, self.slope: [1.05736034 1.05773986], self.intercept: 1.0050234990649796\n",
      "iteration - 5126 -> loss: 0.0003024779072107176, self.slope: [1.05736967 1.05774929], self.intercept: 1.0050243510149437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 5127 -> loss: 0.00030246025639467703, self.slope: [1.057379   1.05775871], self.intercept: 1.0050252029241717\n",
      "iteration - 5128 -> loss: 0.00030244260770568703, self.slope: [1.05738833 1.05776813], self.intercept: 1.0050260547926684\n",
      "iteration - 5129 -> loss: 0.0003024249611433711, self.slope: [1.05739765 1.05777754], self.intercept: 1.0050269066204358\n",
      "iteration - 5130 -> loss: 0.0003024073167073228, self.slope: [1.05740698 1.05778696], self.intercept: 1.0050277584074803\n",
      "iteration - 5131 -> loss: 0.00030238967439717875, self.slope: [1.05741631 1.05779638], self.intercept: 1.0050286101538042\n",
      "iteration - 5132 -> loss: 0.00030237203421253756, self.slope: [1.05742563 1.0578058 ], self.intercept: 1.0050294618594113\n",
      "iteration - 5133 -> loss: 0.0003023543961529966, self.slope: [1.05743496 1.05781522], self.intercept: 1.0050303135243088\n",
      "iteration - 5134 -> loss: 0.00030233676021819406, self.slope: [1.05744428 1.05782463], self.intercept: 1.0050311651484998\n",
      "iteration - 5135 -> loss: 0.0003023191264077146, self.slope: [1.05745361 1.05783405], self.intercept: 1.0050320167319868\n",
      "iteration - 5136 -> loss: 0.00030230149472118496, self.slope: [1.05746293 1.05784346], self.intercept: 1.0050328682747751\n",
      "iteration - 5137 -> loss: 0.0003022838651581979, self.slope: [1.05747226 1.05785288], self.intercept: 1.0050337197768704\n",
      "iteration - 5138 -> loss: 0.00030226623771840874, self.slope: [1.05748158 1.05786229], self.intercept: 1.0050345712382758\n",
      "iteration - 5139 -> loss: 0.00030224861240137676, self.slope: [1.0574909  1.05787171], self.intercept: 1.005035422658995\n",
      "iteration - 5140 -> loss: 0.00030223098920674333, self.slope: [1.05750022 1.05788112], self.intercept: 1.0050362740390342\n",
      "iteration - 5141 -> loss: 0.00030221336813410866, self.slope: [1.05750954 1.05789053], self.intercept: 1.0050371253783952\n",
      "iteration - 5142 -> loss: 0.0003021957491830916, self.slope: [1.05751886 1.05789994], self.intercept: 1.0050379766770827\n",
      "iteration - 5143 -> loss: 0.0003021781323532961, self.slope: [1.05752818 1.05790936], self.intercept: 1.0050388279351012\n",
      "iteration - 5144 -> loss: 0.0003021605176443354, self.slope: [1.0575375  1.05791877], self.intercept: 1.0050396791524556\n",
      "iteration - 5145 -> loss: 0.00030214290505584487, self.slope: [1.05754682 1.05792818], self.intercept: 1.0050405303291499\n",
      "iteration - 5146 -> loss: 0.00030212529458740236, self.slope: [1.05755614 1.05793759], self.intercept: 1.0050413814651875\n",
      "iteration - 5147 -> loss: 0.00030210768623864173, self.slope: [1.05756546 1.057947  ], self.intercept: 1.0050422325605748\n",
      "iteration - 5148 -> loss: 0.00030209008000916344, self.slope: [1.05757477 1.0579564 ], self.intercept: 1.0050430836153132\n",
      "iteration - 5149 -> loss: 0.00030207247589858764, self.slope: [1.05758409 1.05796581], self.intercept: 1.005043934629408\n",
      "iteration - 5150 -> loss: 0.0003020548739065191, self.slope: [1.0575934  1.05797522], self.intercept: 1.0050447856028637\n",
      "iteration - 5151 -> loss: 0.00030203727403258667, self.slope: [1.05760272 1.05798463], self.intercept: 1.0050456365356848\n",
      "iteration - 5152 -> loss: 0.00030201967627638103, self.slope: [1.05761203 1.05799403], self.intercept: 1.0050464874278748\n",
      "iteration - 5153 -> loss: 0.00030200208063752525, self.slope: [1.05762135 1.05800344], self.intercept: 1.0050473382794394\n",
      "iteration - 5154 -> loss: 0.00030198448711564495, self.slope: [1.05763066 1.05801284], self.intercept: 1.0050481890903822\n",
      "iteration - 5155 -> loss: 0.000301966895710332, self.slope: [1.05763998 1.05802225], self.intercept: 1.0050490398607066\n",
      "iteration - 5156 -> loss: 0.00030194930642119954, self.slope: [1.05764929 1.05803165], self.intercept: 1.005049890590418\n",
      "iteration - 5157 -> loss: 0.00030193171924789455, self.slope: [1.0576586  1.05804106], self.intercept: 1.0050507412795195\n",
      "iteration - 5158 -> loss: 0.0003019141341899773, self.slope: [1.05766791 1.05805046], self.intercept: 1.005051591928016\n",
      "iteration - 5159 -> loss: 0.0003018965512470956, self.slope: [1.05767722 1.05805986], self.intercept: 1.005052442535911\n",
      "iteration - 5160 -> loss: 0.00030187897041886993, self.slope: [1.05768653 1.05806926], self.intercept: 1.0050532931032095\n",
      "iteration - 5161 -> loss: 0.00030186139170489156, self.slope: [1.05769584 1.05807867], self.intercept: 1.005054143629915\n",
      "iteration - 5162 -> loss: 0.0003018438151047835, self.slope: [1.05770515 1.05808807], self.intercept: 1.0050549941160318\n",
      "iteration - 5163 -> loss: 0.00030182624061816227, self.slope: [1.05771446 1.05809747], self.intercept: 1.0050558445615645\n",
      "iteration - 5164 -> loss: 0.0003018086682446452, self.slope: [1.05772377 1.05810687], self.intercept: 1.005056694966517\n",
      "iteration - 5165 -> loss: 0.00030179109798383094, self.slope: [1.05773307 1.05811627], self.intercept: 1.005057545330895\n",
      "iteration - 5166 -> loss: 0.00030177352983533476, self.slope: [1.05774238 1.05812566], self.intercept: 1.0050583956547015\n",
      "iteration - 5167 -> loss: 0.0003017559637987958, self.slope: [1.05775169 1.05813506], self.intercept: 1.00505924593794\n",
      "iteration - 5168 -> loss: 0.0003017383998737955, self.slope: [1.05776099 1.05814446], self.intercept: 1.0050600961806162\n",
      "iteration - 5169 -> loss: 0.0003017208380599708, self.slope: [1.0577703  1.05815386], self.intercept: 1.0050609463827336\n",
      "iteration - 5170 -> loss: 0.000301703278356934, self.slope: [1.0577796  1.05816325], self.intercept: 1.0050617965442963\n",
      "iteration - 5171 -> loss: 0.0003016857207642842, self.slope: [1.05778891 1.05817265], self.intercept: 1.0050626466653074\n",
      "iteration - 5172 -> loss: 0.0003016681652816494, self.slope: [1.05779821 1.05818204], self.intercept: 1.0050634967457746\n",
      "iteration - 5173 -> loss: 0.00030165061190864326, self.slope: [1.05780751 1.05819144], self.intercept: 1.0050643467856983\n",
      "iteration - 5174 -> loss: 0.00030163306064487344, self.slope: [1.05781681 1.05820083], self.intercept: 1.0050651967850845\n",
      "iteration - 5175 -> loss: 0.00030161551148997405, self.slope: [1.05782612 1.05821023], self.intercept: 1.005066046743938\n",
      "iteration - 5176 -> loss: 0.0003015979644435379, self.slope: [1.05783542 1.05821962], self.intercept: 1.005066896662262\n",
      "iteration - 5177 -> loss: 0.000301580419505178, self.slope: [1.05784472 1.05822901], self.intercept: 1.0050677465400613\n",
      "iteration - 5178 -> loss: 0.00030156287667453663, self.slope: [1.05785402 1.0582384 ], self.intercept: 1.0050685963773383\n",
      "iteration - 5179 -> loss: 0.00030154533595119293, self.slope: [1.05786332 1.05824779], self.intercept: 1.0050694461741008\n",
      "iteration - 5180 -> loss: 0.0003015277973347901, self.slope: [1.05787262 1.05825718], self.intercept: 1.005070295930351\n",
      "iteration - 5181 -> loss: 0.0003015102608249432, self.slope: [1.05788191 1.05826657], self.intercept: 1.0050711456460932\n",
      "iteration - 5182 -> loss: 0.00030149272642124796, self.slope: [1.05789121 1.05827596], self.intercept: 1.0050719953213305\n",
      "iteration - 5183 -> loss: 0.0003014751941233376, self.slope: [1.05790051 1.05828535], self.intercept: 1.0050728449560684\n",
      "iteration - 5184 -> loss: 0.00030145766393082263, self.slope: [1.0579098  1.05829474], self.intercept: 1.0050736945503105\n",
      "iteration - 5185 -> loss: 0.00030144013584331336, self.slope: [1.0579191  1.05830413], self.intercept: 1.0050745441040612\n",
      "iteration - 5186 -> loss: 0.00030142260986042537, self.slope: [1.0579284  1.05831352], self.intercept: 1.005075393617324\n",
      "iteration - 5187 -> loss: 0.0003014050859818019, self.slope: [1.05793769 1.0583229 ], self.intercept: 1.0050762430901041\n",
      "iteration - 5188 -> loss: 0.00030138756420700937, self.slope: [1.05794699 1.05833229], self.intercept: 1.0050770925224068\n",
      "iteration - 5189 -> loss: 0.00030137004453570647, self.slope: [1.05795628 1.05834168], self.intercept: 1.0050779419142328\n",
      "iteration - 5190 -> loss: 0.00030135252696748995, self.slope: [1.05796557 1.05835106], self.intercept: 1.0050787912655892\n",
      "iteration - 5191 -> loss: 0.00030133501150199257, self.slope: [1.05797487 1.05836045], self.intercept: 1.0050796405764801\n",
      "iteration - 5192 -> loss: 0.00030131749813882007, self.slope: [1.05798416 1.05836983], self.intercept: 1.0050804898469097\n",
      "iteration - 5193 -> loss: 0.0003012999868775769, self.slope: [1.05799345 1.05837921], self.intercept: 1.005081339076882\n",
      "iteration - 5194 -> loss: 0.0003012824777178803, self.slope: [1.05800274 1.0583886 ], self.intercept: 1.0050821882663996\n",
      "iteration - 5195 -> loss: 0.0003012649706593812, self.slope: [1.05801203 1.05839798], self.intercept: 1.005083037415469\n",
      "iteration - 5196 -> loss: 0.0003012474657016553, self.slope: [1.05802132 1.05840736], self.intercept: 1.005083886524093\n",
      "iteration - 5197 -> loss: 0.00030122996284434334, self.slope: [1.05803061 1.05841674], self.intercept: 1.005084735592276\n",
      "iteration - 5198 -> loss: 0.00030121246208705615, self.slope: [1.0580399  1.05842612], self.intercept: 1.005085584620022\n",
      "iteration - 5199 -> loss: 0.00030119496342941325, self.slope: [1.05804919 1.0584355 ], self.intercept: 1.0050864336073357\n",
      "iteration - 5200 -> loss: 0.00030117746687102336, self.slope: [1.05805847 1.05844488], self.intercept: 1.0050872825542212\n",
      "iteration - 5201 -> loss: 0.0003011599724115337, self.slope: [1.05806776 1.05845426], self.intercept: 1.005088131460682\n",
      "iteration - 5202 -> loss: 0.00030114248005049405, self.slope: [1.05807705 1.05846364], self.intercept: 1.0050889803267242\n",
      "iteration - 5203 -> loss: 0.00030112498978760837, self.slope: [1.05808633 1.05847302], self.intercept: 1.0050898291523496\n",
      "iteration - 5204 -> loss: 0.00030110750162242573, self.slope: [1.05809562 1.05848239], self.intercept: 1.005090677937564\n",
      "iteration - 5205 -> loss: 0.00030109001555460633, self.slope: [1.0581049  1.05849177], self.intercept: 1.005091526682372\n",
      "iteration - 5206 -> loss: 0.00030107253158374436, self.slope: [1.05811419 1.05850115], self.intercept: 1.0050923753867758\n",
      "iteration - 5207 -> loss: 0.00030105504970946175, self.slope: [1.05812347 1.05851052], self.intercept: 1.0050932240507808\n",
      "iteration - 5208 -> loss: 0.00030103756993138516, self.slope: [1.05813275 1.0585199 ], self.intercept: 1.0050940726743915\n",
      "iteration - 5209 -> loss: 0.0003010200922491293, self.slope: [1.05814204 1.05852927], self.intercept: 1.005094921257612\n",
      "iteration - 5210 -> loss: 0.0003010026166623098, self.slope: [1.05815132 1.05853865], self.intercept: 1.0050957698004452\n",
      "iteration - 5211 -> loss: 0.00030098514317053823, self.slope: [1.0581606  1.05854802], self.intercept: 1.0050966183028982\n",
      "iteration - 5212 -> loss: 0.00030096767177345915, self.slope: [1.05816988 1.05855739], self.intercept: 1.0050974667649721\n",
      "iteration - 5213 -> loss: 0.00030095020247065463, self.slope: [1.05817916 1.05856676], self.intercept: 1.0050983151866735\n",
      "iteration - 5214 -> loss: 0.0003009327352617578, self.slope: [1.05818844 1.05857614], self.intercept: 1.0050991635680049\n",
      "iteration - 5215 -> loss: 0.0003009152701464106, self.slope: [1.05819772 1.05858551], self.intercept: 1.0051000119089706\n",
      "iteration - 5216 -> loss: 0.000300897807124189, self.slope: [1.058207   1.05859488], self.intercept: 1.0051008602095757\n",
      "iteration - 5217 -> loss: 0.0003008803461947353, self.slope: [1.05821628 1.05860425], self.intercept: 1.0051017084698233\n",
      "iteration - 5218 -> loss: 0.00030086288735767653, self.slope: [1.05822555 1.05861362], self.intercept: 1.0051025566897172\n",
      "iteration - 5219 -> loss: 0.00030084543061262753, self.slope: [1.05823483 1.05862299], self.intercept: 1.0051034048692629\n",
      "iteration - 5220 -> loss: 0.000300827975959189, self.slope: [1.05824411 1.05863235], self.intercept: 1.0051042530084662\n",
      "iteration - 5221 -> loss: 0.00030081052339701284, self.slope: [1.05825338 1.05864172], self.intercept: 1.0051051011073278\n",
      "iteration - 5222 -> loss: 0.00030079307292568274, self.slope: [1.05826266 1.05865109], self.intercept: 1.005105949165854\n",
      "iteration - 5223 -> loss: 0.0003007756245448329, self.slope: [1.05827193 1.05866046], self.intercept: 1.005106797184049\n",
      "iteration - 5224 -> loss: 0.000300758178254097, self.slope: [1.05828121 1.05866982], self.intercept: 1.0051076451619152\n",
      "iteration - 5225 -> loss: 0.00030074073405308315, self.slope: [1.05829048 1.05867919], self.intercept: 1.0051084930994583\n",
      "iteration - 5226 -> loss: 0.00030072329194140467, self.slope: [1.05829975 1.05868855], self.intercept: 1.0051093409966825\n",
      "iteration - 5227 -> loss: 0.0003007058519186701, self.slope: [1.05830903 1.05869792], self.intercept: 1.0051101888535918\n",
      "iteration - 5228 -> loss: 0.0003006884139845481, self.slope: [1.0583183  1.05870728], self.intercept: 1.0051110366701885\n",
      "iteration - 5229 -> loss: 0.00030067097813859763, self.slope: [1.05832757 1.05871664], self.intercept: 1.0051118844464788\n",
      "iteration - 5230 -> loss: 0.000300653544380484, self.slope: [1.05833684 1.05872601], self.intercept: 1.0051127321824684\n",
      "iteration - 5231 -> loss: 0.00030063611270980233, self.slope: [1.05834611 1.05873537], self.intercept: 1.0051135798781592\n",
      "iteration - 5232 -> loss: 0.00030061868312618756, self.slope: [1.05835538 1.05874473], self.intercept: 1.0051144275335557\n",
      "iteration - 5233 -> loss: 0.0003006012556292366, self.slope: [1.05836465 1.05875409], self.intercept: 1.0051152751486616\n",
      "iteration - 5234 -> loss: 0.00030058383021861634, self.slope: [1.05837392 1.05876345], self.intercept: 1.0051161227234813\n",
      "iteration - 5235 -> loss: 0.0003005664068938882, self.slope: [1.05838318 1.05877281], self.intercept: 1.0051169702580192\n",
      "iteration - 5236 -> loss: 0.0003005489856547298, self.slope: [1.05839245 1.05878217], self.intercept: 1.0051178177522795\n",
      "iteration - 5237 -> loss: 0.0003005315665007207, self.slope: [1.05840172 1.05879153], self.intercept: 1.0051186652062667\n",
      "iteration - 5238 -> loss: 0.00030051414943149126, self.slope: [1.05841099 1.05880089], self.intercept: 1.005119512619985\n",
      "iteration - 5239 -> loss: 0.0003004967344466799, self.slope: [1.05842025 1.05881025], self.intercept: 1.005120359993439\n",
      "iteration - 5240 -> loss: 0.00030047932154588837, self.slope: [1.05842952 1.0588196 ], self.intercept: 1.0051212073266325\n",
      "iteration - 5241 -> loss: 0.0003004619107287471, self.slope: [1.05843878 1.05882896], self.intercept: 1.0051220546195683\n",
      "iteration - 5242 -> loss: 0.0003004445019948626, self.slope: [1.05844804 1.05883832], self.intercept: 1.005122901872252\n",
      "iteration - 5243 -> loss: 0.0003004270953438831, self.slope: [1.05845731 1.05884767], self.intercept: 1.0051237490846874\n",
      "iteration - 5244 -> loss: 0.0003004096907753944, self.slope: [1.05846657 1.05885703], self.intercept: 1.0051245962568789\n",
      "iteration - 5245 -> loss: 0.00030039228828904885, self.slope: [1.05847583 1.05886638], self.intercept: 1.0051254433888304\n",
      "iteration - 5246 -> loss: 0.0003003748878844665, self.slope: [1.0584851  1.05887574], self.intercept: 1.0051262904805458\n",
      "iteration - 5247 -> loss: 0.0003003574895612512, self.slope: [1.05849436 1.05888509], self.intercept: 1.00512713753203\n",
      "iteration - 5248 -> loss: 0.0003003400933190143, self.slope: [1.05850362 1.05889444], self.intercept: 1.005127984543286\n",
      "iteration - 5249 -> loss: 0.0003003226991574139, self.slope: [1.05851288 1.05890379], self.intercept: 1.0051288315143185\n",
      "iteration - 5250 -> loss: 0.00030030530707605757, self.slope: [1.05852214 1.05891315], self.intercept: 1.0051296784451336\n",
      "iteration - 5251 -> loss: 0.00030028791707456, self.slope: [1.0585314 1.0589225], self.intercept: 1.0051305253357339\n",
      "iteration - 5252 -> loss: 0.0003002705291525612, self.slope: [1.05854065 1.05893185], self.intercept: 1.0051313721861213\n",
      "iteration - 5253 -> loss: 0.00030025314330966015, self.slope: [1.05854991 1.0589412 ], self.intercept: 1.005132218996303\n",
      "iteration - 5254 -> loss: 0.00030023575954548216, self.slope: [1.05855917 1.05895055], self.intercept: 1.0051330657662834\n",
      "iteration - 5255 -> loss: 0.0003002183778596566, self.slope: [1.05856843 1.0589599 ], self.intercept: 1.0051339124960643\n",
      "iteration - 5256 -> loss: 0.0003002009982518055, self.slope: [1.05857768 1.05896924], self.intercept: 1.0051347591856503\n",
      "iteration - 5257 -> loss: 0.0003001836207215505, self.slope: [1.05858694 1.05897859], self.intercept: 1.0051356058350476\n",
      "iteration - 5258 -> loss: 0.0003001662452685125, self.slope: [1.05859619 1.05898794], self.intercept: 1.0051364524442599\n",
      "iteration - 5259 -> loss: 0.0003001488718923267, self.slope: [1.05860545 1.05899729], self.intercept: 1.005137299013289\n",
      "iteration - 5260 -> loss: 0.000300131500592603, self.slope: [1.0586147  1.05900663], self.intercept: 1.0051381455421413\n",
      "iteration - 5261 -> loss: 0.00030011413136896386, self.slope: [1.05862395 1.05901598], self.intercept: 1.005138992030821\n",
      "iteration - 5262 -> loss: 0.0003000967642210286, self.slope: [1.05863321 1.05902532], self.intercept: 1.0051398384793313\n",
      "iteration - 5263 -> loss: 0.0003000793991484394, self.slope: [1.05864246 1.05903467], self.intercept: 1.0051406848876767\n",
      "iteration - 5264 -> loss: 0.0003000620361508045, self.slope: [1.05865171 1.05904401], self.intercept: 1.0051415312558614\n",
      "iteration - 5265 -> loss: 0.00030004467522773745, self.slope: [1.05866096 1.05905335], self.intercept: 1.0051423775838892\n",
      "iteration - 5266 -> loss: 0.0003000273163788797, self.slope: [1.05867021 1.0590627 ], self.intercept: 1.0051432238717646\n",
      "iteration - 5267 -> loss: 0.0003000099596038531, self.slope: [1.05867946 1.05907204], self.intercept: 1.005144070119492\n",
      "iteration - 5268 -> loss: 0.00029999260490228105, self.slope: [1.05868871 1.05908138], self.intercept: 1.0051449163270738\n",
      "iteration - 5269 -> loss: 0.00029997525227377523, self.slope: [1.05869796 1.05909072], self.intercept: 1.0051457624945164\n",
      "iteration - 5270 -> loss: 0.0002999579017179739, self.slope: [1.05870721 1.05910006], self.intercept: 1.0051466086218235\n",
      "iteration - 5271 -> loss: 0.00029994055323448975, self.slope: [1.05871646 1.0591094 ], self.intercept: 1.0051474547089978\n",
      "iteration - 5272 -> loss: 0.0002999232068229582, self.slope: [1.05872571 1.05911874], self.intercept: 1.005148300756045\n",
      "iteration - 5273 -> loss: 0.0002999058624829918, self.slope: [1.05873495 1.05912808], self.intercept: 1.0051491467629698\n",
      "iteration - 5274 -> loss: 0.0002998885202142111, self.slope: [1.0587442  1.05913742], self.intercept: 1.0051499927297758\n",
      "iteration - 5275 -> loss: 0.0002998711800162661, self.slope: [1.05875344 1.05914676], self.intercept: 1.005150838656466\n",
      "iteration - 5276 -> loss: 0.00029985384188875456, self.slope: [1.05876269 1.05915609], self.intercept: 1.0051516845430446\n",
      "iteration - 5277 -> loss: 0.0002998365058313017, self.slope: [1.05877193 1.05916543], self.intercept: 1.0051525303895172\n",
      "iteration - 5278 -> loss: 0.000299819171843555, self.slope: [1.05878118 1.05917477], self.intercept: 1.0051533761958862\n",
      "iteration - 5279 -> loss: 0.00029980183992510303, self.slope: [1.05879042 1.0591841 ], self.intercept: 1.005154221962157\n",
      "iteration - 5280 -> loss: 0.00029978451007562333, self.slope: [1.05879966 1.05919344], self.intercept: 1.0051550676883338\n",
      "iteration - 5281 -> loss: 0.0002997671822946874, self.slope: [1.05880891 1.05920277], self.intercept: 1.00515591337442\n",
      "iteration - 5282 -> loss: 0.0002997498565819532, self.slope: [1.05881815 1.05921211], self.intercept: 1.0051567590204202\n",
      "iteration - 5283 -> loss: 0.0002997325329370224, self.slope: [1.05882739 1.05922144], self.intercept: 1.0051576046263384\n",
      "iteration - 5284 -> loss: 0.0002997152113595404, self.slope: [1.05883663 1.05923077], self.intercept: 1.005158450192178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 5285 -> loss: 0.0002996978918491108, self.slope: [1.05884587 1.0592401 ], self.intercept: 1.0051592957179432\n",
      "iteration - 5286 -> loss: 0.00029968057440537757, self.slope: [1.05885511 1.05924944], self.intercept: 1.0051601412036395\n",
      "iteration - 5287 -> loss: 0.00029966325902797266, self.slope: [1.05886435 1.05925877], self.intercept: 1.0051609866492712\n",
      "iteration - 5288 -> loss: 0.00029964594571648784, self.slope: [1.05887359 1.0592681 ], self.intercept: 1.005161832054842\n",
      "iteration - 5289 -> loss: 0.00029962863447058086, self.slope: [1.05888282 1.05927743], self.intercept: 1.0051626774203557\n",
      "iteration - 5290 -> loss: 0.000299611325289863, self.slope: [1.05889206 1.05928676], self.intercept: 1.0051635227458176\n",
      "iteration - 5291 -> loss: 0.00029959401817396844, self.slope: [1.0589013  1.05929609], self.intercept: 1.005164368031229\n",
      "iteration - 5292 -> loss: 0.0002995767131225111, self.slope: [1.05891053 1.05930542], self.intercept: 1.0051652132765971\n",
      "iteration - 5293 -> loss: 0.00029955941013511925, self.slope: [1.05891977 1.05931474], self.intercept: 1.0051660584819233\n",
      "iteration - 5294 -> loss: 0.0002995421092114356, self.slope: [1.058929   1.05932407], self.intercept: 1.0051669036472133\n",
      "iteration - 5295 -> loss: 0.00029952481035106345, self.slope: [1.05893824 1.0593334 ], self.intercept: 1.0051677487724706\n",
      "iteration - 5296 -> loss: 0.00029950751355364434, self.slope: [1.05894747 1.05934272], self.intercept: 1.0051685938577004\n",
      "iteration - 5297 -> loss: 0.00029949021881879383, self.slope: [1.05895671 1.05935205], self.intercept: 1.0051694389029056\n",
      "iteration - 5298 -> loss: 0.0002994729261461536, self.slope: [1.05896594 1.05936137], self.intercept: 1.0051702839080914\n",
      "iteration - 5299 -> loss: 0.0002994556355353258, self.slope: [1.05897517 1.0593707 ], self.intercept: 1.0051711288732605\n",
      "iteration - 5300 -> loss: 0.00029943834698594954, self.slope: [1.0589844  1.05938002], self.intercept: 1.0051719737984177\n",
      "iteration - 5301 -> loss: 0.0002994210604976678, self.slope: [1.05899363 1.05938935], self.intercept: 1.0051728186835682\n",
      "iteration - 5302 -> loss: 0.0002994037760700791, self.slope: [1.05900286 1.05939867], self.intercept: 1.005173663528715\n",
      "iteration - 5303 -> loss: 0.0002993864937028363, self.slope: [1.05901209 1.05940799], self.intercept: 1.0051745083338632\n",
      "iteration - 5304 -> loss: 0.0002993692133955395, self.slope: [1.05902132 1.05941731], self.intercept: 1.0051753530990162\n",
      "iteration - 5305 -> loss: 0.0002993519351478333, self.slope: [1.05903055 1.05942663], self.intercept: 1.0051761978241793\n",
      "iteration - 5306 -> loss: 0.00029933465895934147, self.slope: [1.05903978 1.05943595], self.intercept: 1.005177042509355\n",
      "iteration - 5307 -> loss: 0.00029931738482969416, self.slope: [1.05904901 1.05944528], self.intercept: 1.0051778871545474\n",
      "iteration - 5308 -> loss: 0.00029930011275850925, self.slope: [1.05905824 1.05945459], self.intercept: 1.0051787317597614\n",
      "iteration - 5309 -> loss: 0.00029928284274542504, self.slope: [1.05906746 1.05946391], self.intercept: 1.0051795763250018\n",
      "iteration - 5310 -> loss: 0.0002992655747900714, self.slope: [1.05907669 1.05947323], self.intercept: 1.0051804208502713\n",
      "iteration - 5311 -> loss: 0.0002992483088920457, self.slope: [1.05908591 1.05948255], self.intercept: 1.0051812653355745\n",
      "iteration - 5312 -> loss: 0.00029923104505101355, self.slope: [1.05909514 1.05949187], self.intercept: 1.0051821097809157\n",
      "iteration - 5313 -> loss: 0.0002992137832665829, self.slope: [1.05910436 1.05950118], self.intercept: 1.0051829541862995\n",
      "iteration - 5314 -> loss: 0.0002991965235383795, self.slope: [1.05911359 1.0595105 ], self.intercept: 1.0051837985517293\n",
      "iteration - 5315 -> loss: 0.0002991792658660393, self.slope: [1.05912281 1.05951982], self.intercept: 1.0051846428772087\n",
      "iteration - 5316 -> loss: 0.0002991620102491871, self.slope: [1.05913203 1.05952913], self.intercept: 1.0051854871627428\n",
      "iteration - 5317 -> loss: 0.00029914475668745715, self.slope: [1.05914126 1.05953845], self.intercept: 1.0051863314083358\n",
      "iteration - 5318 -> loss: 0.0002991275051804658, self.slope: [1.05915048 1.05954776], self.intercept: 1.0051871756139916\n",
      "iteration - 5319 -> loss: 0.0002991102557278427, self.slope: [1.0591597  1.05955707], self.intercept: 1.005188019779714\n",
      "iteration - 5320 -> loss: 0.00029909300832924534, self.slope: [1.05916892 1.05956639], self.intercept: 1.0051888639055073\n",
      "iteration - 5321 -> loss: 0.0002990757629842649, self.slope: [1.05917814 1.0595757 ], self.intercept: 1.005189707991375\n",
      "iteration - 5322 -> loss: 0.00029905851969253797, self.slope: [1.05918736 1.05958501], self.intercept: 1.0051905520373223\n",
      "iteration - 5323 -> loss: 0.00029904127845370096, self.slope: [1.05919658 1.05959432], self.intercept: 1.0051913960433538\n",
      "iteration - 5324 -> loss: 0.00029902403926738015, self.slope: [1.0592058  1.05960363], self.intercept: 1.0051922400094722\n",
      "iteration - 5325 -> loss: 0.0002990068021331873, self.slope: [1.05921501 1.05961294], self.intercept: 1.0051930839356824\n",
      "iteration - 5326 -> loss: 0.00029898956705078154, self.slope: [1.05922423 1.05962225], self.intercept: 1.0051939278219875\n",
      "iteration - 5327 -> loss: 0.0002989723340197897, self.slope: [1.05923345 1.05963156], self.intercept: 1.0051947716683918\n",
      "iteration - 5328 -> loss: 0.00029895510303981317, self.slope: [1.05924266 1.05964087], self.intercept: 1.0051956154749009\n",
      "iteration - 5329 -> loss: 0.0002989378741104996, self.slope: [1.05925188 1.05965018], self.intercept: 1.0051964592415186\n",
      "iteration - 5330 -> loss: 0.0002989206472314831, self.slope: [1.05926109 1.05965949], self.intercept: 1.0051973029682477\n",
      "iteration - 5331 -> loss: 0.0002989034224023772, self.slope: [1.05927031 1.05966879], self.intercept: 1.005198146655094\n",
      "iteration - 5332 -> loss: 0.0002988861996228041, self.slope: [1.05927952 1.0596781 ], self.intercept: 1.0051989903020604\n",
      "iteration - 5333 -> loss: 0.0002988689788924377, self.slope: [1.05928874 1.05968741], self.intercept: 1.005199833909151\n",
      "iteration - 5334 -> loss: 0.0002988517602108679, self.slope: [1.05929795 1.05969671], self.intercept: 1.0052006774763695\n",
      "iteration - 5335 -> loss: 0.0002988345435777218, self.slope: [1.05930716 1.05970602], self.intercept: 1.0052015210037217\n",
      "iteration - 5336 -> loss: 0.0002988173289926587, self.slope: [1.05931637 1.05971532], self.intercept: 1.0052023644912107\n",
      "iteration - 5337 -> loss: 0.00029880011645528384, self.slope: [1.05932558 1.05972462], self.intercept: 1.0052032079388404\n",
      "iteration - 5338 -> loss: 0.0002987829059652305, self.slope: [1.0593348  1.05973393], self.intercept: 1.0052040513466143\n",
      "iteration - 5339 -> loss: 0.00029876569752213986, self.slope: [1.05934401 1.05974323], self.intercept: 1.0052048947145376\n",
      "iteration - 5340 -> loss: 0.0002987484911256428, self.slope: [1.05935322 1.05975253], self.intercept: 1.0052057380426136\n",
      "iteration - 5341 -> loss: 0.0002987312867753652, self.slope: [1.05936242 1.05976183], self.intercept: 1.0052065813308468\n",
      "iteration - 5342 -> loss: 0.0002987140844709121, self.slope: [1.05937163 1.05977113], self.intercept: 1.005207424579241\n",
      "iteration - 5343 -> loss: 0.00029869688421194253, self.slope: [1.05938084 1.05978043], self.intercept: 1.0052082677878018\n",
      "iteration - 5344 -> loss: 0.00029867968599809247, self.slope: [1.05939005 1.05978973], self.intercept: 1.005209110956532\n",
      "iteration - 5345 -> loss: 0.00029866248982896737, self.slope: [1.05939925 1.05979903], self.intercept: 1.0052099540854358\n",
      "iteration - 5346 -> loss: 0.0002986452957042153, self.slope: [1.05940846 1.05980833], self.intercept: 1.005210797174517\n",
      "iteration - 5347 -> loss: 0.0002986281036234711, self.slope: [1.05941767 1.05981763], self.intercept: 1.00521164022378\n",
      "iteration - 5348 -> loss: 0.00029861091358635293, self.slope: [1.05942687 1.05982693], self.intercept: 1.0052124832332305\n",
      "iteration - 5349 -> loss: 0.00029859372559248973, self.slope: [1.05943608 1.05983622], self.intercept: 1.0052133262028695\n",
      "iteration - 5350 -> loss: 0.00029857653964151734, self.slope: [1.05944528 1.05984552], self.intercept: 1.0052141691327046\n",
      "iteration - 5351 -> loss: 0.00029855935573306963, self.slope: [1.05945448 1.05985482], self.intercept: 1.0052150120227366\n",
      "iteration - 5352 -> loss: 0.00029854217386678176, self.slope: [1.05946369 1.05986411], self.intercept: 1.0052158548729702\n",
      "iteration - 5353 -> loss: 0.00029852499404228023, self.slope: [1.05947289 1.05987341], self.intercept: 1.0052166976834116\n",
      "iteration - 5354 -> loss: 0.00029850781625918274, self.slope: [1.05948209 1.0598827 ], self.intercept: 1.0052175404540633\n",
      "iteration - 5355 -> loss: 0.00029849064051714637, self.slope: [1.05949129 1.05989199], self.intercept: 1.0052183831849308\n",
      "iteration - 5356 -> loss: 0.00029847346681577885, self.slope: [1.05950049 1.05990129], self.intercept: 1.0052192258760164\n",
      "iteration - 5357 -> loss: 0.0002984562951547339, self.slope: [1.05950969 1.05991058], self.intercept: 1.0052200685273247\n",
      "iteration - 5358 -> loss: 0.00029843912553362885, self.slope: [1.05951889 1.05991987], self.intercept: 1.0052209111388615\n",
      "iteration - 5359 -> loss: 0.00029842195795209454, self.slope: [1.05952809 1.05992916], self.intercept: 1.0052217537106287\n",
      "iteration - 5360 -> loss: 0.0002984047924097638, self.slope: [1.05953729 1.05993846], self.intercept: 1.0052225962426318\n",
      "iteration - 5361 -> loss: 0.0002983876289062843, self.slope: [1.05954649 1.05994775], self.intercept: 1.005223438734873\n",
      "iteration - 5362 -> loss: 0.00029837046744127, self.slope: [1.05955568 1.05995704], self.intercept: 1.005224281187358\n",
      "iteration - 5363 -> loss: 0.00029835330801435535, self.slope: [1.05956488 1.05996633], self.intercept: 1.0052251236000904\n",
      "iteration - 5364 -> loss: 0.00029833615062517516, self.slope: [1.05957408 1.05997561], self.intercept: 1.005225965973075\n",
      "iteration - 5365 -> loss: 0.0002983189952733786, self.slope: [1.05958327 1.0599849 ], self.intercept: 1.005226808306314\n",
      "iteration - 5366 -> loss: 0.00029830184195856835, self.slope: [1.05959247 1.05999419], self.intercept: 1.0052276505998126\n",
      "iteration - 5367 -> loss: 0.0002982846906803797, self.slope: [1.05960166 1.06000348], self.intercept: 1.0052284928535753\n",
      "iteration - 5368 -> loss: 0.0002982675414384657, self.slope: [1.05961086 1.06001276], self.intercept: 1.0052293350676067\n",
      "iteration - 5369 -> loss: 0.00029825039423246396, self.slope: [1.05962005 1.06002205], self.intercept: 1.0052301772419097\n",
      "iteration - 5370 -> loss: 0.0002982332490619749, self.slope: [1.05962924 1.06003134], self.intercept: 1.0052310193764893\n",
      "iteration - 5371 -> loss: 0.00029821610592664877, self.slope: [1.05963844 1.06004062], self.intercept: 1.0052318614713482\n",
      "iteration - 5372 -> loss: 0.0002981989648261359, self.slope: [1.05964763 1.06004991], self.intercept: 1.0052327035264912\n",
      "iteration - 5373 -> loss: 0.00029818182576001983, self.slope: [1.05965682 1.06005919], self.intercept: 1.0052335455419232\n",
      "iteration - 5374 -> loss: 0.000298164688728001, self.slope: [1.05966601 1.06006847], self.intercept: 1.005234387517647\n",
      "iteration - 5375 -> loss: 0.00029814755372966376, self.slope: [1.0596752  1.06007776], self.intercept: 1.0052352294536682\n",
      "iteration - 5376 -> loss: 0.00029813042076464857, self.slope: [1.05968439 1.06008704], self.intercept: 1.00523607134999\n",
      "iteration - 5377 -> loss: 0.00029811328983260125, self.slope: [1.05969358 1.06009632], self.intercept: 1.0052369132066175\n",
      "iteration - 5378 -> loss: 0.00029809616093316325, self.slope: [1.05970277 1.0601056 ], self.intercept: 1.0052377550235527\n",
      "iteration - 5379 -> loss: 0.00029807903406593907, self.slope: [1.05971196 1.06011488], self.intercept: 1.0052385968008013\n",
      "iteration - 5380 -> loss: 0.0002980619092305925, self.slope: [1.05972114 1.06012416], self.intercept: 1.0052394385383663\n",
      "iteration - 5381 -> loss: 0.000298044786426716, self.slope: [1.05973033 1.06013344], self.intercept: 1.0052402802362523\n",
      "iteration - 5382 -> loss: 0.0002980276656539797, self.slope: [1.05973952 1.06014272], self.intercept: 1.0052411218944644\n",
      "iteration - 5383 -> loss: 0.00029801054691201825, self.slope: [1.0597487 1.060152 ], self.intercept: 1.005241963513005\n",
      "iteration - 5384 -> loss: 0.0002979934302004568, self.slope: [1.05975789 1.06016128], self.intercept: 1.0052428050918787\n",
      "iteration - 5385 -> loss: 0.00029797631551891984, self.slope: [1.05976707 1.06017055], self.intercept: 1.0052436466310897\n",
      "iteration - 5386 -> loss: 0.00029795920286706157, self.slope: [1.05977626 1.06017983], self.intercept: 1.0052444881306408\n",
      "iteration - 5387 -> loss: 0.000297942092244492, self.slope: [1.05978544 1.06018911], self.intercept: 1.00524532959054\n",
      "iteration - 5388 -> loss: 0.0002979249836508608, self.slope: [1.05979462 1.06019838], self.intercept: 1.0052461710107872\n",
      "iteration - 5389 -> loss: 0.00029790787708580056, self.slope: [1.05980381 1.06020766], self.intercept: 1.0052470123913873\n",
      "iteration - 5390 -> loss: 0.0002978907725489583, self.slope: [1.05981299 1.06021693], self.intercept: 1.005247853732346\n",
      "iteration - 5391 -> loss: 0.0002978736700399388, self.slope: [1.05982217 1.06022621], self.intercept: 1.0052486950336654\n",
      "iteration - 5392 -> loss: 0.00029785656955839355, self.slope: [1.05983135 1.06023548], self.intercept: 1.0052495362953515\n",
      "iteration - 5393 -> loss: 0.0002978394711039633, self.slope: [1.05984053 1.06024475], self.intercept: 1.0052503775174084\n",
      "iteration - 5394 -> loss: 0.0002978223746762869, self.slope: [1.05984971 1.06025402], self.intercept: 1.0052512186998384\n",
      "iteration - 5395 -> loss: 0.00029780528027496854, self.slope: [1.05985889 1.0602633 ], self.intercept: 1.0052520598426464\n",
      "iteration - 5396 -> loss: 0.000297788187899672, self.slope: [1.05986807 1.06027257], self.intercept: 1.0052529009458366\n",
      "iteration - 5397 -> loss: 0.00029777109755002427, self.slope: [1.05987725 1.06028184], self.intercept: 1.0052537420094139\n",
      "iteration - 5398 -> loss: 0.00029775400922565654, self.slope: [1.05988642 1.06029111], self.intercept: 1.005254583033381\n",
      "iteration - 5399 -> loss: 0.00029773692292621266, self.slope: [1.0598956  1.06030038], self.intercept: 1.0052554240177423\n",
      "iteration - 5400 -> loss: 0.0002977198386513338, self.slope: [1.05990478 1.06030965], self.intercept: 1.0052562649625019\n",
      "iteration - 5401 -> loss: 0.00029770275640062476, self.slope: [1.05991395 1.06031892], self.intercept: 1.0052571058676638\n",
      "iteration - 5402 -> loss: 0.0002976856761737535, self.slope: [1.05992313 1.06032818], self.intercept: 1.005257946733233\n",
      "iteration - 5403 -> loss: 0.0002976685979703481, self.slope: [1.0599323  1.06033745], self.intercept: 1.005258787559212\n",
      "iteration - 5404 -> loss: 0.00029765152179003237, self.slope: [1.05994148 1.06034672], self.intercept: 1.0052596283456057\n",
      "iteration - 5405 -> loss: 0.0002976344476324564, self.slope: [1.05995065 1.06035599], self.intercept: 1.0052604690924183\n",
      "iteration - 5406 -> loss: 0.00029761737549724676, self.slope: [1.05995982 1.06036525], self.intercept: 1.005261309799654\n",
      "iteration - 5407 -> loss: 0.00029760030538404674, self.slope: [1.059969   1.06037452], self.intercept: 1.0052621504673165\n",
      "iteration - 5408 -> loss: 0.0002975832372924806, self.slope: [1.05997817 1.06038378], self.intercept: 1.0052629910954094\n",
      "iteration - 5409 -> loss: 0.00029756617122219856, self.slope: [1.05998734 1.06039305], self.intercept: 1.005263831683938\n",
      "iteration - 5410 -> loss: 0.0002975491071728299, self.slope: [1.05999651 1.06040231], self.intercept: 1.005264672232906\n",
      "iteration - 5411 -> loss: 0.00029753204514400587, self.slope: [1.06000568 1.06041157], self.intercept: 1.0052655127423165\n",
      "iteration - 5412 -> loss: 0.0002975149851353625, self.slope: [1.06001485 1.06042084], self.intercept: 1.0052663532121746\n",
      "iteration - 5413 -> loss: 0.0002974979271465456, self.slope: [1.06002402 1.0604301 ], self.intercept: 1.005267193642484\n",
      "iteration - 5414 -> loss: 0.000297480871177201, self.slope: [1.06003319 1.06043936], self.intercept: 1.0052680340332487\n",
      "iteration - 5415 -> loss: 0.0002974638172269496, self.slope: [1.06004236 1.06044862], self.intercept: 1.0052688743844727\n",
      "iteration - 5416 -> loss: 0.00029744676529543123, self.slope: [1.06005153 1.06045788], self.intercept: 1.00526971469616\n",
      "iteration - 5417 -> loss: 0.0002974297153822794, self.slope: [1.06006069 1.06046714], self.intercept: 1.0052705549683143\n",
      "iteration - 5418 -> loss: 0.0002974126674871472, self.slope: [1.06006986 1.0604764 ], self.intercept: 1.0052713952009396\n",
      "iteration - 5419 -> loss: 0.0002973956216096544, self.slope: [1.06007903 1.06048566], self.intercept: 1.005272235394041\n",
      "iteration - 5420 -> loss: 0.0002973785777494352, self.slope: [1.06008819 1.06049492], self.intercept: 1.0052730755476225\n",
      "iteration - 5421 -> loss: 0.00029736153590612926, self.slope: [1.06009736 1.06050417], self.intercept: 1.0052739156616877\n",
      "iteration - 5422 -> loss: 0.00029734449607940537, self.slope: [1.06010652 1.06051343], self.intercept: 1.0052747557362407\n",
      "iteration - 5423 -> loss: 0.0002973274582688452, self.slope: [1.06011568 1.06052269], self.intercept: 1.0052755957712847\n",
      "iteration - 5424 -> loss: 0.0002973104224741478, self.slope: [1.06012485 1.06053194], self.intercept: 1.005276435766826\n",
      "iteration - 5425 -> loss: 0.00029729338869490093, self.slope: [1.06013401 1.0605412 ], self.intercept: 1.0052772757228667\n",
      "iteration - 5426 -> loss: 0.00029727635693076757, self.slope: [1.06014317 1.06055046], self.intercept: 1.005278115639412\n",
      "iteration - 5427 -> loss: 0.0002972593271813643, self.slope: [1.06015233 1.06055971], self.intercept: 1.0052789555164656\n",
      "iteration - 5428 -> loss: 0.00029724229944636617, self.slope: [1.0601615  1.06056896], self.intercept: 1.005279795354031\n",
      "iteration - 5429 -> loss: 0.00029722527372536976, self.slope: [1.06017066 1.06057822], self.intercept: 1.005280635152112\n",
      "iteration - 5430 -> loss: 0.0002972082500180345, self.slope: [1.06017982 1.06058747], self.intercept: 1.0052814749107124\n",
      "iteration - 5431 -> loss: 0.00029719122832401376, self.slope: [1.06018898 1.06059672], self.intercept: 1.0052823146298384\n",
      "iteration - 5432 -> loss: 0.00029717420864291375, self.slope: [1.06019813 1.06060597], self.intercept: 1.0052831543094916\n",
      "iteration - 5433 -> loss: 0.0002971571909743887, self.slope: [1.06020729 1.06061523], self.intercept: 1.0052839939496772\n",
      "iteration - 5434 -> loss: 0.0002971401753180849, self.slope: [1.06021645 1.06062448], self.intercept: 1.0052848335503994\n",
      "iteration - 5435 -> loss: 0.0002971231616736034, self.slope: [1.06022561 1.06063373], self.intercept: 1.005285673111662\n",
      "iteration - 5436 -> loss: 0.0002971061500406315, self.slope: [1.06023476 1.06064298], self.intercept: 1.0052865126334682\n",
      "iteration - 5437 -> loss: 0.0002970891404187924, self.slope: [1.06024392 1.06065222], self.intercept: 1.0052873521158237\n",
      "iteration - 5438 -> loss: 0.0002970721328077125, self.slope: [1.06025308 1.06066147], self.intercept: 1.0052881915587317\n",
      "iteration - 5439 -> loss: 0.0002970551272070467, self.slope: [1.06026223 1.06067072], self.intercept: 1.0052890309621965\n",
      "iteration - 5440 -> loss: 0.0002970381236164052, self.slope: [1.06027139 1.06067997], self.intercept: 1.0052898703262205\n",
      "iteration - 5441 -> loss: 0.00029702112203546205, self.slope: [1.06028054 1.06068922], self.intercept: 1.0052907096508097\n",
      "iteration - 5442 -> loss: 0.00029700412246383786, self.slope: [1.06028969 1.06069846], self.intercept: 1.0052915489359684\n",
      "iteration - 5443 -> loss: 0.0002969871249011693, self.slope: [1.06029885 1.06070771], self.intercept: 1.0052923881816995\n",
      "iteration - 5444 -> loss: 0.0002969701293471113, self.slope: [1.060308   1.06071695], self.intercept: 1.005293227388008\n",
      "iteration - 5445 -> loss: 0.00029695313580129873, self.slope: [1.06031715 1.0607262 ], self.intercept: 1.005294066554897\n",
      "iteration - 5446 -> loss: 0.00029693614426334154, self.slope: [1.0603263  1.06073544], self.intercept: 1.0052949056823712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 5447 -> loss: 0.00029691915473292014, self.slope: [1.06033545 1.06074469], self.intercept: 1.0052957447704343\n",
      "iteration - 5448 -> loss: 0.0002969021672096605, self.slope: [1.0603446  1.06075393], self.intercept: 1.00529658381909\n",
      "iteration - 5449 -> loss: 0.00029688518169319585, self.slope: [1.06035375 1.06076317], self.intercept: 1.0052974228283424\n",
      "iteration - 5450 -> loss: 0.00029686819818316366, self.slope: [1.0603629  1.06077241], self.intercept: 1.005298261798196\n",
      "iteration - 5451 -> loss: 0.0002968512166791973, self.slope: [1.06037205 1.06078165], self.intercept: 1.005299100728653\n",
      "iteration - 5452 -> loss: 0.0002968342371809746, self.slope: [1.0603812 1.0607909], self.intercept: 1.0052999396197215\n",
      "iteration - 5453 -> loss: 0.0002968172596881061, self.slope: [1.06039035 1.06080014], self.intercept: 1.0053007784714023\n",
      "iteration - 5454 -> loss: 0.00029680028420022873, self.slope: [1.06039949 1.06080938], self.intercept: 1.0053016172837006\n",
      "iteration - 5455 -> loss: 0.0002967833107169906, self.slope: [1.06040864 1.06081861], self.intercept: 1.00530245605662\n",
      "iteration - 5456 -> loss: 0.0002967663392380287, self.slope: [1.06041779 1.06082785], self.intercept: 1.0053032947901637\n",
      "iteration - 5457 -> loss: 0.0002967493697629908, self.slope: [1.06042693 1.06083709], self.intercept: 1.0053041334843373\n",
      "iteration - 5458 -> loss: 0.00029673240229151647, self.slope: [1.06043608 1.06084633], self.intercept: 1.0053049721391436\n",
      "iteration - 5459 -> loss: 0.00029671543682323646, self.slope: [1.06044522 1.06085557], self.intercept: 1.005305810754588\n",
      "iteration - 5460 -> loss: 0.0002966984733578039, self.slope: [1.06045436 1.0608648 ], self.intercept: 1.0053066493306742\n",
      "iteration - 5461 -> loss: 0.0002966815118948358, self.slope: [1.06046351 1.06087404], self.intercept: 1.0053074878674046\n",
      "iteration - 5462 -> loss: 0.0002966645524340098, self.slope: [1.06047265 1.06088327], self.intercept: 1.0053083263647853\n",
      "iteration - 5463 -> loss: 0.0002966475949749462, self.slope: [1.06048179 1.06089251], self.intercept: 1.0053091648228178\n",
      "iteration - 5464 -> loss: 0.00029663063951728124, self.slope: [1.06049093 1.06090174], self.intercept: 1.0053100032415092\n",
      "iteration - 5465 -> loss: 0.00029661368606064833, self.slope: [1.06050007 1.06091098], self.intercept: 1.0053108416208607\n",
      "iteration - 5466 -> loss: 0.00029659673460471727, self.slope: [1.06050921 1.06092021], self.intercept: 1.0053116799608774\n",
      "iteration - 5467 -> loss: 0.0002965797851491124, self.slope: [1.06051835 1.06092944], self.intercept: 1.0053125182615643\n",
      "iteration - 5468 -> loss: 0.00029656283769349383, self.slope: [1.06052749 1.06093868], self.intercept: 1.0053133565229255\n",
      "iteration - 5469 -> loss: 0.0002965458922374607, self.slope: [1.06053663 1.06094791], self.intercept: 1.005314194744963\n",
      "iteration - 5470 -> loss: 0.0002965289487806963, self.slope: [1.06054577 1.06095714], self.intercept: 1.0053150329276832\n",
      "iteration - 5471 -> loss: 0.00029651200732282466, self.slope: [1.06055491 1.06096637], self.intercept: 1.0053158710710886\n",
      "iteration - 5472 -> loss: 0.0002964950678634781, self.slope: [1.06056404 1.0609756 ], self.intercept: 1.0053167091751838\n",
      "iteration - 5473 -> loss: 0.0002964781304023172, self.slope: [1.06057318 1.06098483], self.intercept: 1.0053175472399727\n",
      "iteration - 5474 -> loss: 0.00029646119493896843, self.slope: [1.06058232 1.06099406], self.intercept: 1.005318385265459\n",
      "iteration - 5475 -> loss: 0.00029644426147308015, self.slope: [1.06059145 1.06100329], self.intercept: 1.0053192232516472\n",
      "iteration - 5476 -> loss: 0.0002964273300042971, self.slope: [1.06060059 1.06101251], self.intercept: 1.0053200611985404\n",
      "iteration - 5477 -> loss: 0.00029641040053227596, self.slope: [1.06060972 1.06102174], self.intercept: 1.005320899106143\n",
      "iteration - 5478 -> loss: 0.0002963934730566275, self.slope: [1.06061886 1.06103097], self.intercept: 1.00532173697446\n",
      "iteration - 5479 -> loss: 0.0002963765475770283, self.slope: [1.06062799 1.0610402 ], self.intercept: 1.005322574803496\n",
      "iteration - 5480 -> loss: 0.0002963596240930764, self.slope: [1.06063712 1.06104942], self.intercept: 1.0053234125932522\n",
      "iteration - 5481 -> loss: 0.0002963427026044434, self.slope: [1.06064625 1.06105865], self.intercept: 1.0053242503437343\n",
      "iteration - 5482 -> loss: 0.00029632578311077973, self.slope: [1.06065539 1.06106787], self.intercept: 1.005325088054946\n",
      "iteration - 5483 -> loss: 0.0002963088656117031, self.slope: [1.06066452 1.0610771 ], self.intercept: 1.0053259257268927\n",
      "iteration - 5484 -> loss: 0.0002962919501068839, self.slope: [1.06067365 1.06108632], self.intercept: 1.005326763359576\n",
      "iteration - 5485 -> loss: 0.000296275036595948, self.slope: [1.06068278 1.06109554], self.intercept: 1.0053276009530019\n",
      "iteration - 5486 -> loss: 0.00029625812507852933, self.slope: [1.06069191 1.06110476], self.intercept: 1.0053284385071737\n",
      "iteration - 5487 -> loss: 0.0002962412155542921, self.slope: [1.06070104 1.06111399], self.intercept: 1.0053292760220953\n",
      "iteration - 5488 -> loss: 0.00029622430802286924, self.slope: [1.06071016 1.06112321], self.intercept: 1.0053301134977701\n",
      "iteration - 5489 -> loss: 0.0002962074024838941, self.slope: [1.06071929 1.06113243], self.intercept: 1.0053309509342019\n",
      "iteration - 5490 -> loss: 0.0002961904989370392, self.slope: [1.06072842 1.06114165], self.intercept: 1.0053317883313966\n",
      "iteration - 5491 -> loss: 0.0002961735973819118, self.slope: [1.06073755 1.06115087], self.intercept: 1.0053326256893584\n",
      "iteration - 5492 -> loss: 0.00029615669781818404, self.slope: [1.06074667 1.06116009], self.intercept: 1.0053334630080883\n",
      "iteration - 5493 -> loss: 0.0002961398002454855, self.slope: [1.0607558  1.06116931], self.intercept: 1.0053343002875934\n",
      "iteration - 5494 -> loss: 0.00029612290466346047, self.slope: [1.06076492 1.06117853], self.intercept: 1.0053351375278767\n",
      "iteration - 5495 -> loss: 0.00029610601107174733, self.slope: [1.06077405 1.06118774], self.intercept: 1.005335974728941\n",
      "iteration - 5496 -> loss: 0.0002960891194700064, self.slope: [1.06078317 1.06119696], self.intercept: 1.0053368118907917\n",
      "iteration - 5497 -> loss: 0.0002960722298578611, self.slope: [1.0607923  1.06120618], self.intercept: 1.0053376490134331\n",
      "iteration - 5498 -> loss: 0.00029605534223497846, self.slope: [1.06080142 1.06121539], self.intercept: 1.005338486096868\n",
      "iteration - 5499 -> loss: 0.0002960384566009977, self.slope: [1.06081054 1.06122461], self.intercept: 1.0053393231410999\n",
      "iteration - 5500 -> loss: 0.0002960215729555324, self.slope: [1.06081966 1.06123382], self.intercept: 1.005340160146134\n",
      "iteration - 5501 -> loss: 0.0002960046912982574, self.slope: [1.06082879 1.06124304], self.intercept: 1.0053409971119731\n",
      "iteration - 5502 -> loss: 0.000295987811628815, self.slope: [1.06083791 1.06125225], self.intercept: 1.0053418340386242\n",
      "iteration - 5503 -> loss: 0.0002959709339468426, self.slope: [1.06084703 1.06126147], self.intercept: 1.0053426709260886\n",
      "iteration - 5504 -> loss: 0.0002959540582519978, self.slope: [1.06085615 1.06127068], self.intercept: 1.0053435077743698\n",
      "iteration - 5505 -> loss: 0.00029593718454388665, self.slope: [1.06086527 1.06127989], self.intercept: 1.0053443445834742\n",
      "iteration - 5506 -> loss: 0.0002959203128222093, self.slope: [1.06087438 1.0612891 ], self.intercept: 1.0053451813534044\n",
      "iteration - 5507 -> loss: 0.00029590344308657083, self.slope: [1.0608835  1.06129831], self.intercept: 1.005346018084165\n",
      "iteration - 5508 -> loss: 0.000295886575336608, self.slope: [1.06089262 1.06130752], self.intercept: 1.0053468547757602\n",
      "iteration - 5509 -> loss: 0.0002958697095720056, self.slope: [1.06090174 1.06131673], self.intercept: 1.0053476914281931\n",
      "iteration - 5510 -> loss: 0.0002958528457923836, self.slope: [1.06091085 1.06132594], self.intercept: 1.0053485280414682\n",
      "iteration - 5511 -> loss: 0.0002958359839973859, self.slope: [1.06091997 1.06133515], self.intercept: 1.005349364615589\n",
      "iteration - 5512 -> loss: 0.0002958191241866719, self.slope: [1.06092908 1.06134436], self.intercept: 1.0053502011505602\n",
      "iteration - 5513 -> loss: 0.0002958022663598671, self.slope: [1.0609382  1.06135357], self.intercept: 1.005351037646384\n",
      "iteration - 5514 -> loss: 0.0002957854105166244, self.slope: [1.06094731 1.06136278], self.intercept: 1.0053518741030665\n",
      "iteration - 5515 -> loss: 0.00029576855665662034, self.slope: [1.06095643 1.06137198], self.intercept: 1.0053527105206106\n",
      "iteration - 5516 -> loss: 0.0002957517047794366, self.slope: [1.06096554 1.06138119], self.intercept: 1.0053535468990205\n",
      "iteration - 5517 -> loss: 0.0002957348548847799, self.slope: [1.06097465 1.0613904 ], self.intercept: 1.0053543832383007\n",
      "iteration - 5518 -> loss: 0.00029571800697225864, self.slope: [1.06098377 1.0613996 ], self.intercept: 1.0053552195384545\n",
      "iteration - 5519 -> loss: 0.0002957011610415351, self.slope: [1.06099288 1.06140881], self.intercept: 1.0053560557994872\n",
      "iteration - 5520 -> loss: 0.0002956843170922475, self.slope: [1.06100199 1.06141801], self.intercept: 1.0053568920214015\n",
      "iteration - 5521 -> loss: 0.0002956674751240471, self.slope: [1.0610111  1.06142721], self.intercept: 1.0053577282042017\n",
      "iteration - 5522 -> loss: 0.0002956506351365698, self.slope: [1.06102021 1.06143642], self.intercept: 1.0053585643478913\n",
      "iteration - 5523 -> loss: 0.00029563379712947257, self.slope: [1.06102932 1.06144562], self.intercept: 1.0053594004524748\n",
      "iteration - 5524 -> loss: 0.0002956169611024115, self.slope: [1.06103843 1.06145482], self.intercept: 1.0053602365179573\n",
      "iteration - 5525 -> loss: 0.00029560012705499785, self.slope: [1.06104754 1.06146402], self.intercept: 1.00536107254434\n",
      "iteration - 5526 -> loss: 0.0002955832949869149, self.slope: [1.06105664 1.06147322], self.intercept: 1.0053619085316288\n",
      "iteration - 5527 -> loss: 0.0002955664648977846, self.slope: [1.06106575 1.06148242], self.intercept: 1.0053627444798283\n",
      "iteration - 5528 -> loss: 0.00029554963678726705, self.slope: [1.06107486 1.06149162], self.intercept: 1.005363580388942\n",
      "iteration - 5529 -> loss: 0.000295532810655009, self.slope: [1.06108396 1.06150082], self.intercept: 1.0053644162589723\n",
      "iteration - 5530 -> loss: 0.00029551598650064104, self.slope: [1.06109307 1.06151002], self.intercept: 1.0053652520899248\n",
      "iteration - 5531 -> loss: 0.00029549916432383564, self.slope: [1.06110217 1.06151922], self.intercept: 1.0053660878818031\n",
      "iteration - 5532 -> loss: 0.00029548234412422094, self.slope: [1.06111128 1.06152842], self.intercept: 1.005366923634612\n",
      "iteration - 5533 -> loss: 0.0002954655259014479, self.slope: [1.06112038 1.06153762], self.intercept: 1.0053677593483545\n",
      "iteration - 5534 -> loss: 0.0002954487096551608, self.slope: [1.06112949 1.06154681], self.intercept: 1.0053685950230342\n",
      "iteration - 5535 -> loss: 0.00029543189538500624, self.slope: [1.06113859 1.06155601], self.intercept: 1.0053694306586562\n",
      "iteration - 5536 -> loss: 0.00029541508309063457, self.slope: [1.06114769 1.06156521], self.intercept: 1.0053702662552229\n",
      "iteration - 5537 -> loss: 0.00029539827277169607, self.slope: [1.06115679 1.0615744 ], self.intercept: 1.0053711018127398\n",
      "iteration - 5538 -> loss: 0.0002953814644278412, self.slope: [1.0611659  1.06158359], self.intercept: 1.0053719373312093\n",
      "iteration - 5539 -> loss: 0.0002953646580587101, self.slope: [1.061175   1.06159279], self.intercept: 1.0053727728106372\n",
      "iteration - 5540 -> loss: 0.00029534785366395637, self.slope: [1.0611841  1.06160198], self.intercept: 1.0053736082510263\n",
      "iteration - 5541 -> loss: 0.00029533105124321163, self.slope: [1.0611932  1.06161118], self.intercept: 1.0053744436523815\n",
      "iteration - 5542 -> loss: 0.0002953142507961372, self.slope: [1.0612023  1.06162037], self.intercept: 1.0053752790147052\n",
      "iteration - 5543 -> loss: 0.0002952974523223935, self.slope: [1.06121139 1.06162956], self.intercept: 1.0053761143380036\n",
      "iteration - 5544 -> loss: 0.00029528065582159606, self.slope: [1.06122049 1.06163875], self.intercept: 1.0053769496222782\n",
      "iteration - 5545 -> loss: 0.0002952638612934253, self.slope: [1.06122959 1.06164794], self.intercept: 1.005377784867535\n",
      "iteration - 5546 -> loss: 0.0002952470687375119, self.slope: [1.06123869 1.06165713], self.intercept: 1.0053786200737773\n",
      "iteration - 5547 -> loss: 0.00029523027815349335, self.slope: [1.06124778 1.06166632], self.intercept: 1.0053794552410107\n",
      "iteration - 5548 -> loss: 0.0002952134895410426, self.slope: [1.06125688 1.06167551], self.intercept: 1.0053802903692364\n",
      "iteration - 5549 -> loss: 0.00029519670289978765, self.slope: [1.06126598 1.0616847 ], self.intercept: 1.0053811254584588\n",
      "iteration - 5550 -> loss: 0.0002951799182293888, self.slope: [1.06127507 1.06169389], self.intercept: 1.0053819605086833\n",
      "iteration - 5551 -> loss: 0.00029516313552949624, self.slope: [1.06128416 1.06170308], self.intercept: 1.005382795519913\n",
      "iteration - 5552 -> loss: 0.0002951463547997415, self.slope: [1.06129326 1.06171226], self.intercept: 1.005383630492152\n",
      "iteration - 5553 -> loss: 0.0002951295760397882, self.slope: [1.06130235 1.06172145], self.intercept: 1.005384465425405\n",
      "iteration - 5554 -> loss: 0.0002951127992492922, self.slope: [1.06131144 1.06173064], self.intercept: 1.0053853003196744\n",
      "iteration - 5555 -> loss: 0.00029509602442788057, self.slope: [1.06132054 1.06173982], self.intercept: 1.0053861351749644\n",
      "iteration - 5556 -> loss: 0.0002950792515752168, self.slope: [1.06132963 1.06174901], self.intercept: 1.0053869699912807\n",
      "iteration - 5557 -> loss: 0.0002950624806909669, self.slope: [1.06133872 1.06175819], self.intercept: 1.0053878047686253\n",
      "iteration - 5558 -> loss: 0.00029504571177472647, self.slope: [1.06134781 1.06176737], self.intercept: 1.0053886395070035\n",
      "iteration - 5559 -> loss: 0.00029502894482618487, self.slope: [1.0613569  1.06177656], self.intercept: 1.0053894742064193\n",
      "iteration - 5560 -> loss: 0.0002950121798449959, self.slope: [1.06136599 1.06178574], self.intercept: 1.0053903088668756\n",
      "iteration - 5561 -> loss: 0.0002949954168307985, self.slope: [1.06137508 1.06179492], self.intercept: 1.0053911434883773\n",
      "iteration - 5562 -> loss: 0.00029497865578324877, self.slope: [1.06138417 1.0618041 ], self.intercept: 1.0053919780709275\n",
      "iteration - 5563 -> loss: 0.0002949618967019523, self.slope: [1.06139325 1.06181329], self.intercept: 1.005392812614531\n",
      "iteration - 5564 -> loss: 0.0002949451395866162, self.slope: [1.06140234 1.06182247], self.intercept: 1.0053936471191915\n",
      "iteration - 5565 -> loss: 0.0002949283844368765, self.slope: [1.06141143 1.06183165], self.intercept: 1.005394481584912\n",
      "iteration - 5566 -> loss: 0.00029491163125237114, self.slope: [1.06142052 1.06184083], self.intercept: 1.0053953160116968\n",
      "iteration - 5567 -> loss: 0.00029489488003273806, self.slope: [1.0614296 1.06185  ], self.intercept: 1.0053961503995512\n",
      "iteration - 5568 -> loss: 0.0002948781307776657, self.slope: [1.06143869 1.06185918], self.intercept: 1.0053969847484783\n",
      "iteration - 5569 -> loss: 0.0002948613834867706, self.slope: [1.06144777 1.06186836], self.intercept: 1.0053978190584811\n",
      "iteration - 5570 -> loss: 0.00029484463815970926, self.slope: [1.06145686 1.06187754], self.intercept: 1.0053986533295662\n",
      "iteration - 5571 -> loss: 0.00029482789479613454, self.slope: [1.06146594 1.06188672], self.intercept: 1.0053994875617347\n",
      "iteration - 5572 -> loss: 0.0002948111533957005, self.slope: [1.06147502 1.06189589], self.intercept: 1.0054003217549927\n",
      "iteration - 5573 -> loss: 0.00029479441395806316, self.slope: [1.0614841  1.06190507], self.intercept: 1.0054011559093434\n",
      "iteration - 5574 -> loss: 0.0002947776764828614, self.slope: [1.06149319 1.06191424], self.intercept: 1.0054019900247908\n",
      "iteration - 5575 -> loss: 0.0002947609409697258, self.slope: [1.06150227 1.06192342], self.intercept: 1.0054028241013375\n",
      "iteration - 5576 -> loss: 0.0002947442074183476, self.slope: [1.06151135 1.06193259], self.intercept: 1.0054036581389887\n",
      "iteration - 5577 -> loss: 0.00029472747582836597, self.slope: [1.06152043 1.06194177], self.intercept: 1.0054044921377485\n",
      "iteration - 5578 -> loss: 0.00029471074619942154, self.slope: [1.06152951 1.06195094], self.intercept: 1.0054053260976206\n",
      "iteration - 5579 -> loss: 0.0002946940185311619, self.slope: [1.06153859 1.06196011], self.intercept: 1.0054061600186097\n",
      "iteration - 5580 -> loss: 0.0002946772928232501, self.slope: [1.06154767 1.06196928], self.intercept: 1.0054069939007186\n",
      "iteration - 5581 -> loss: 0.0002946605690753415, self.slope: [1.06155675 1.06197846], self.intercept: 1.0054078277439524\n",
      "iteration - 5582 -> loss: 0.0002946438472870468, self.slope: [1.06156582 1.06198763], self.intercept: 1.0054086615483133\n",
      "iteration - 5583 -> loss: 0.0002946271274580675, self.slope: [1.0615749 1.0619968], self.intercept: 1.0054094953138073\n",
      "iteration - 5584 -> loss: 0.0002946104095880314, self.slope: [1.06158398 1.06200597], self.intercept: 1.0054103290404361\n",
      "iteration - 5585 -> loss: 0.00029459369367660666, self.slope: [1.06159305 1.06201514], self.intercept: 1.005411162728204\n",
      "iteration - 5586 -> loss: 0.0002945769797234091, self.slope: [1.06160213 1.06202431], self.intercept: 1.0054119963771173\n",
      "iteration - 5587 -> loss: 0.00029456026772814464, self.slope: [1.0616112  1.06203347], self.intercept: 1.0054128299871778\n",
      "iteration - 5588 -> loss: 0.000294543557690417, self.slope: [1.06162028 1.06204264], self.intercept: 1.0054136635583908\n",
      "iteration - 5589 -> loss: 0.00029452684960988335, self.slope: [1.06162935 1.06205181], self.intercept: 1.00541449709076\n",
      "iteration - 5590 -> loss: 0.00029451014348620463, self.slope: [1.06163842 1.06206098], self.intercept: 1.0054153305842888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 5591 -> loss: 0.0002944934393190404, self.slope: [1.0616475  1.06207014], self.intercept: 1.0054161640389814\n",
      "iteration - 5592 -> loss: 0.0002944767371080411, self.slope: [1.06165657 1.06207931], self.intercept: 1.0054169974548424\n",
      "iteration - 5593 -> loss: 0.0002944600368528508, self.slope: [1.06166564 1.06208847], self.intercept: 1.005417830831874\n",
      "iteration - 5594 -> loss: 0.0002944433385531063, self.slope: [1.06167471 1.06209764], self.intercept: 1.0054186641700804\n",
      "iteration - 5595 -> loss: 0.0002944266422085051, self.slope: [1.06168378 1.0621068 ], self.intercept: 1.0054194974694664\n",
      "iteration - 5596 -> loss: 0.0002944099478186487, self.slope: [1.06169285 1.06211596], self.intercept: 1.0054203307300362\n",
      "iteration - 5597 -> loss: 0.0002943932553832332, self.slope: [1.06170192 1.06212513], self.intercept: 1.0054211639517927\n",
      "iteration - 5598 -> loss: 0.00029437656490187197, self.slope: [1.06171099 1.06213429], self.intercept: 1.0054219971347418\n",
      "iteration - 5599 -> loss: 0.000294359876374241, self.slope: [1.06172006 1.06214345], self.intercept: 1.0054228302788861\n",
      "iteration - 5600 -> loss: 0.0002943431897999918, self.slope: [1.06172913 1.06215261], self.intercept: 1.0054236633842297\n",
      "iteration - 5601 -> loss: 0.00029432650517877005, self.slope: [1.0617382  1.06216177], self.intercept: 1.0054244964507755\n",
      "iteration - 5602 -> loss: 0.0002943098225102252, self.slope: [1.06174726 1.06217094], self.intercept: 1.005425329478528\n",
      "iteration - 5603 -> loss: 0.00029429314179402747, self.slope: [1.06175633 1.0621801 ], self.intercept: 1.0054261624674925\n",
      "iteration - 5604 -> loss: 0.0002942764630298205, self.slope: [1.0617654  1.06218925], self.intercept: 1.00542699541767\n",
      "iteration - 5605 -> loss: 0.00029425978621724783, self.slope: [1.06177446 1.06219841], self.intercept: 1.0054278283290679\n",
      "iteration - 5606 -> loss: 0.00029424311135595334, self.slope: [1.06178353 1.06220757], self.intercept: 1.0054286612016887\n",
      "iteration - 5607 -> loss: 0.00029422643844562375, self.slope: [1.06179259 1.06221673], self.intercept: 1.0054294940355357\n",
      "iteration - 5608 -> loss: 0.000294209767485893, self.slope: [1.06180165 1.06222589], self.intercept: 1.005430326830613\n",
      "iteration - 5609 -> loss: 0.00029419309847641793, self.slope: [1.06181072 1.06223504], self.intercept: 1.005431159586926\n",
      "iteration - 5610 -> loss: 0.00029417643141686214, self.slope: [1.06181978 1.0622442 ], self.intercept: 1.0054319923044788\n",
      "iteration - 5611 -> loss: 0.00029415976630684263, self.slope: [1.06182884 1.06225335], self.intercept: 1.0054328249832727\n",
      "iteration - 5612 -> loss: 0.00029414310314604863, self.slope: [1.0618379  1.06226251], self.intercept: 1.0054336576233127\n",
      "iteration - 5613 -> loss: 0.0002941264419341208, self.slope: [1.06184697 1.06227166], self.intercept: 1.0054344902246033\n",
      "iteration - 5614 -> loss: 0.0002941097826707224, self.slope: [1.06185603 1.06228082], self.intercept: 1.0054353227871473\n",
      "iteration - 5615 -> loss: 0.0002940931253555003, self.slope: [1.06186509 1.06228997], self.intercept: 1.0054361553109508\n",
      "iteration - 5616 -> loss: 0.0002940764699880806, self.slope: [1.06187415 1.06229912], self.intercept: 1.0054369877960156\n",
      "iteration - 5617 -> loss: 0.0002940598165681627, self.slope: [1.0618832  1.06230828], self.intercept: 1.005437820242346\n",
      "iteration - 5618 -> loss: 0.0002940431650953986, self.slope: [1.06189226 1.06231743], self.intercept: 1.0054386526499475\n",
      "iteration - 5619 -> loss: 0.00029402651556940045, self.slope: [1.06190132 1.06232658], self.intercept: 1.005439485018823\n",
      "iteration - 5620 -> loss: 0.0002940098679898525, self.slope: [1.06191038 1.06233573], self.intercept: 1.0054403173489772\n",
      "iteration - 5621 -> loss: 0.00029399322235641625, self.slope: [1.06191943 1.06234488], self.intercept: 1.005441149640411\n",
      "iteration - 5622 -> loss: 0.000293976578668721, self.slope: [1.06192849 1.06235403], self.intercept: 1.0054419818931306\n",
      "iteration - 5623 -> loss: 0.0002939599369264548, self.slope: [1.06193755 1.06236318], self.intercept: 1.0054428141071412\n",
      "iteration - 5624 -> loss: 0.0002939432971292383, self.slope: [1.0619466  1.06237233], self.intercept: 1.0054436462824448\n",
      "iteration - 5625 -> loss: 0.0002939266592767312, self.slope: [1.06195566 1.06238148], self.intercept: 1.0054444784190464\n",
      "iteration - 5626 -> loss: 0.00029391002336860993, self.slope: [1.06196471 1.06239063], self.intercept: 1.0054453105169485\n",
      "iteration - 5627 -> loss: 0.0002938933894045012, self.slope: [1.06197376 1.06239977], self.intercept: 1.0054461425761567\n",
      "iteration - 5628 -> loss: 0.0002938767573840954, self.slope: [1.06198282 1.06240892], self.intercept: 1.0054469745966739\n",
      "iteration - 5629 -> loss: 0.0002938601273070086, self.slope: [1.06199187 1.06241807], self.intercept: 1.0054478065785046\n",
      "iteration - 5630 -> loss: 0.0002938434991729295, self.slope: [1.06200092 1.06242721], self.intercept: 1.0054486385216526\n",
      "iteration - 5631 -> loss: 0.0002938268729814756, self.slope: [1.06200997 1.06243636], self.intercept: 1.0054494704261214\n",
      "iteration - 5632 -> loss: 0.0002938102487323326, self.slope: [1.06201902 1.0624455 ], self.intercept: 1.0054503022919152\n",
      "iteration - 5633 -> loss: 0.00029379362642515517, self.slope: [1.06202807 1.06245464], self.intercept: 1.0054511341190377\n",
      "iteration - 5634 -> loss: 0.00029377700605959055, self.slope: [1.06203712 1.06246379], self.intercept: 1.0054519659074934\n",
      "iteration - 5635 -> loss: 0.00029376038763529675, self.slope: [1.06204617 1.06247293], self.intercept: 1.0054527976572862\n",
      "iteration - 5636 -> loss: 0.00029374377115191507, self.slope: [1.06205522 1.06248207], self.intercept: 1.0054536293684195\n",
      "iteration - 5637 -> loss: 0.00029372715660912365, self.slope: [1.06206427 1.06249121], self.intercept: 1.0054544610408962\n",
      "iteration - 5638 -> loss: 0.000293710544006554, self.slope: [1.06207332 1.06250036], self.intercept: 1.0054552926747224\n",
      "iteration - 5639 -> loss: 0.00029369393334388095, self.slope: [1.06208237 1.0625095 ], self.intercept: 1.0054561242699003\n",
      "iteration - 5640 -> loss: 0.0002936773246207638, self.slope: [1.06209141 1.06251864], self.intercept: 1.0054569558264348\n",
      "iteration - 5641 -> loss: 0.00029366071783684796, self.slope: [1.06210046 1.06252778], self.intercept: 1.0054577873443296\n",
      "iteration - 5642 -> loss: 0.0002936441129917786, self.slope: [1.0621095  1.06253692], self.intercept: 1.005458618823589\n",
      "iteration - 5643 -> loss: 0.00029362751008523726, self.slope: [1.06211855 1.06254605], self.intercept: 1.005459450264215\n",
      "iteration - 5644 -> loss: 0.00029361090911685946, self.slope: [1.06212759 1.06255519], self.intercept: 1.0054602816662144\n",
      "iteration - 5645 -> loss: 0.00029359431008631697, self.slope: [1.06213664 1.06256433], self.intercept: 1.0054611130295885\n",
      "iteration - 5646 -> loss: 0.0002935777129932476, self.slope: [1.06214568 1.06257347], self.intercept: 1.0054619443543416\n",
      "iteration - 5647 -> loss: 0.0002935611178373162, self.slope: [1.06215472 1.0625826 ], self.intercept: 1.00546277564048\n",
      "iteration - 5648 -> loss: 0.0002935445246181969, self.slope: [1.06216377 1.06259174], self.intercept: 1.005463606888006\n",
      "iteration - 5649 -> loss: 0.00029352793333551155, self.slope: [1.06217281 1.06260087], self.intercept: 1.0054644380969233\n",
      "iteration - 5650 -> loss: 0.00029351134398894756, self.slope: [1.06218185 1.06261001], self.intercept: 1.0054652692672363\n",
      "iteration - 5651 -> loss: 0.0002934947565781451, self.slope: [1.06219089 1.06261914], self.intercept: 1.0054661003989482\n",
      "iteration - 5652 -> loss: 0.00029347817110276565, self.slope: [1.06219993 1.06262828], self.intercept: 1.0054669314920646\n",
      "iteration - 5653 -> loss: 0.00029346158756247764, self.slope: [1.06220897 1.06263741], self.intercept: 1.0054677625465867\n",
      "iteration - 5654 -> loss: 0.00029344500595691176, self.slope: [1.06221801 1.06264654], self.intercept: 1.00546859356252\n",
      "iteration - 5655 -> loss: 0.0002934284262857534, self.slope: [1.06222705 1.06265568], self.intercept: 1.0054694245398696\n",
      "iteration - 5656 -> loss: 0.0002934118485486218, self.slope: [1.06223609 1.06266481], self.intercept: 1.0054702554786366\n",
      "iteration - 5657 -> loss: 0.000293395272745217, self.slope: [1.06224512 1.06267394], self.intercept: 1.0054710863788263\n",
      "iteration - 5658 -> loss: 0.0002933786988751926, self.slope: [1.06225416 1.06268307], self.intercept: 1.0054719172404436\n",
      "iteration - 5659 -> loss: 0.0002933621269381649, self.slope: [1.0622632 1.0626922], self.intercept: 1.0054727480634909\n",
      "iteration - 5660 -> loss: 0.00029334555693382716, self.slope: [1.06227223 1.06270133], self.intercept: 1.0054735788479723\n",
      "iteration - 5661 -> loss: 0.00029332898886182216, self.slope: [1.06228127 1.06271046], self.intercept: 1.0054744095938917\n",
      "iteration - 5662 -> loss: 0.00029331242272182033, self.slope: [1.0622903  1.06271959], self.intercept: 1.005475240301254\n",
      "iteration - 5663 -> loss: 0.00029329585851347066, self.slope: [1.06229934 1.06272872], self.intercept: 1.0054760709700632\n",
      "iteration - 5664 -> loss: 0.0002932792962364379, self.slope: [1.06230837 1.06273784], self.intercept: 1.0054769016003222\n",
      "iteration - 5665 -> loss: 0.0002932627358903605, self.slope: [1.06231741 1.06274697], self.intercept: 1.0054777321920358\n",
      "iteration - 5666 -> loss: 0.0002932461774749303, self.slope: [1.06232644 1.0627561 ], self.intercept: 1.0054785627452072\n",
      "iteration - 5667 -> loss: 0.00029322962098977067, self.slope: [1.06233547 1.06276522], self.intercept: 1.0054793932598405\n",
      "iteration - 5668 -> loss: 0.0002932130664345464, self.slope: [1.0623445  1.06277435], self.intercept: 1.005480223735939\n",
      "iteration - 5669 -> loss: 0.0002931965138089503, self.slope: [1.06235353 1.06278347], self.intercept: 1.0054810541735073\n",
      "iteration - 5670 -> loss: 0.0002931799631125922, self.slope: [1.06236256 1.0627926 ], self.intercept: 1.0054818845725506\n",
      "iteration - 5671 -> loss: 0.00029316341434516596, self.slope: [1.06237159 1.06280172], self.intercept: 1.0054827149330703\n",
      "iteration - 5672 -> loss: 0.00029314686750630116, self.slope: [1.06238062 1.06281084], self.intercept: 1.0054835452550703\n",
      "iteration - 5673 -> loss: 0.0002931303225956857, self.slope: [1.06238965 1.06281997], self.intercept: 1.0054843755385576\n",
      "iteration - 5674 -> loss: 0.00029311377961296176, self.slope: [1.06239868 1.06282909], self.intercept: 1.005485205783533\n",
      "iteration - 5675 -> loss: 0.0002930972385577759, self.slope: [1.06240771 1.06283821], self.intercept: 1.005486035990001\n",
      "iteration - 5676 -> loss: 0.00029308069942981916, self.slope: [1.06241674 1.06284733], self.intercept: 1.0054868661579652\n",
      "iteration - 5677 -> loss: 0.0002930641622287293, self.slope: [1.06242576 1.06285645], self.intercept: 1.0054876962874306\n",
      "iteration - 5678 -> loss: 0.0002930476269541444, self.slope: [1.06243479 1.06286557], self.intercept: 1.0054885263784008\n",
      "iteration - 5679 -> loss: 0.0002930310936057771, self.slope: [1.06244382 1.06287469], self.intercept: 1.0054893564308784\n",
      "iteration - 5680 -> loss: 0.0002930145621832569, self.slope: [1.06245284 1.06288381], self.intercept: 1.0054901864448698\n",
      "iteration - 5681 -> loss: 0.00029299803268623354, self.slope: [1.06246187 1.06289293], self.intercept: 1.0054910164203772\n",
      "iteration - 5682 -> loss: 0.00029298150511437003, self.slope: [1.06247089 1.06290205], self.intercept: 1.0054918463574058\n",
      "iteration - 5683 -> loss: 0.0002929649794673411, self.slope: [1.06247992 1.06291117], self.intercept: 1.0054926762559573\n",
      "iteration - 5684 -> loss: 0.00029294845574479576, self.slope: [1.06248894 1.06292028], self.intercept: 1.0054935061160375\n",
      "iteration - 5685 -> loss: 0.00029293193394639794, self.slope: [1.06249796 1.0629294 ], self.intercept: 1.0054943359376496\n",
      "iteration - 5686 -> loss: 0.00029291541407179024, self.slope: [1.06250698 1.06293852], self.intercept: 1.005495165720797\n",
      "iteration - 5687 -> loss: 0.0002928988961206546, self.slope: [1.062516   1.06294763], self.intercept: 1.0054959954654845\n",
      "iteration - 5688 -> loss: 0.00029288238009264893, self.slope: [1.06252503 1.06295675], self.intercept: 1.005496825171716\n",
      "iteration - 5689 -> loss: 0.00029286586598740853, self.slope: [1.06253405 1.06296586], self.intercept: 1.0054976548394952\n",
      "iteration - 5690 -> loss: 0.0002928493538046094, self.slope: [1.06254307 1.06297497], self.intercept: 1.005498484468826\n",
      "iteration - 5691 -> loss: 0.0002928328435439376, self.slope: [1.06255209 1.06298409], self.intercept: 1.00549931405971\n",
      "iteration - 5692 -> loss: 0.0002928163352050044, self.slope: [1.06256111 1.0629932 ], self.intercept: 1.0055001436121536\n",
      "iteration - 5693 -> loss: 0.0002927998287875281, self.slope: [1.06257012 1.06300231], self.intercept: 1.0055009731261606\n",
      "iteration - 5694 -> loss: 0.00029278332429110674, self.slope: [1.06257914 1.06301142], self.intercept: 1.0055018026017346\n",
      "iteration - 5695 -> loss: 0.00029276682171541833, self.slope: [1.06258816 1.06302054], self.intercept: 1.0055026320388791\n",
      "iteration - 5696 -> loss: 0.00029275032106015534, self.slope: [1.06259718 1.06302965], self.intercept: 1.0055034614375986\n",
      "iteration - 5697 -> loss: 0.00029273382232495286, self.slope: [1.06260619 1.06303876], self.intercept: 1.0055042907978966\n",
      "iteration - 5698 -> loss: 0.0002927173255094602, self.slope: [1.06261521 1.06304787], self.intercept: 1.0055051201197776\n",
      "iteration - 5699 -> loss: 0.0002927008306133647, self.slope: [1.06262422 1.06305697], self.intercept: 1.0055059494032441\n",
      "iteration - 5700 -> loss: 0.00029268433763632014, self.slope: [1.06263324 1.06306608], self.intercept: 1.0055067786483005\n",
      "iteration - 5701 -> loss: 0.00029266784657796483, self.slope: [1.06264225 1.06307519], self.intercept: 1.0055076078549516\n",
      "iteration - 5702 -> loss: 0.0002926513574380038, self.slope: [1.06265127 1.0630843 ], self.intercept: 1.0055084370232006\n",
      "iteration - 5703 -> loss: 0.0002926348702160552, self.slope: [1.06266028 1.06309341], self.intercept: 1.0055092661530527\n",
      "iteration - 5704 -> loss: 0.00029261838491179837, self.slope: [1.06266929 1.06310251], self.intercept: 1.005510095244509\n",
      "iteration - 5705 -> loss: 0.00029260190152488895, self.slope: [1.0626783  1.06311162], self.intercept: 1.0055109242975744\n",
      "iteration - 5706 -> loss: 0.00029258542005500076, self.slope: [1.06268732 1.06312072], self.intercept: 1.0055117533122544\n",
      "iteration - 5707 -> loss: 0.0002925689405017855, self.slope: [1.06269633 1.06312983], self.intercept: 1.0055125822885504\n",
      "iteration - 5708 -> loss: 0.00029255246286489427, self.slope: [1.06270534 1.06313893], self.intercept: 1.0055134112264679\n",
      "iteration - 5709 -> loss: 0.00029253598714400615, self.slope: [1.06271435 1.06314804], self.intercept: 1.0055142401260098\n",
      "iteration - 5710 -> loss: 0.00029251951333878975, self.slope: [1.06272336 1.06315714], self.intercept: 1.0055150689871821\n",
      "iteration - 5711 -> loss: 0.00029250304144885184, self.slope: [1.06273237 1.06316624], self.intercept: 1.0055158978099852\n",
      "iteration - 5712 -> loss: 0.00029248657147393946, self.slope: [1.06274137 1.06317534], self.intercept: 1.005516726594426\n",
      "iteration - 5713 -> loss: 0.00029247010341364654, self.slope: [1.06275038 1.06318445], self.intercept: 1.0055175553405085\n",
      "iteration - 5714 -> loss: 0.00029245363726765843, self.slope: [1.06275939 1.06319355], self.intercept: 1.005518384048235\n",
      "iteration - 5715 -> loss: 0.0002924371730356457, self.slope: [1.0627684  1.06320265], self.intercept: 1.0055192127176094\n",
      "iteration - 5716 -> loss: 0.00029242071071726336, self.slope: [1.0627774  1.06321175], self.intercept: 1.0055200413486354\n",
      "iteration - 5717 -> loss: 0.0002924042503121626, self.slope: [1.06278641 1.06322085], self.intercept: 1.0055208699413172\n",
      "iteration - 5718 -> loss: 0.00029238779182001946, self.slope: [1.06279541 1.06322995], self.intercept: 1.0055216984956599\n",
      "iteration - 5719 -> loss: 0.00029237133524049436, self.slope: [1.06280442 1.06323905], self.intercept: 1.0055225270116648\n",
      "iteration - 5720 -> loss: 0.0002923548805732296, self.slope: [1.06281342 1.06324814], self.intercept: 1.0055233554893388\n",
      "iteration - 5721 -> loss: 0.0002923384278179227, self.slope: [1.06282243 1.06325724], self.intercept: 1.0055241839286846\n",
      "iteration - 5722 -> loss: 0.00029232197697421557, self.slope: [1.06283143 1.06326634], self.intercept: 1.005525012329704\n",
      "iteration - 5723 -> loss: 0.00029230552804176453, self.slope: [1.06284043 1.06327544], self.intercept: 1.0055258406924041\n",
      "iteration - 5724 -> loss: 0.00029228908102025755, self.slope: [1.06284943 1.06328453], self.intercept: 1.0055266690167868\n",
      "iteration - 5725 -> loss: 0.00029227263590932286, self.slope: [1.06285844 1.06329363], self.intercept: 1.0055274973028572\n",
      "iteration - 5726 -> loss: 0.0002922561927086398, self.slope: [1.06286744 1.06330272], self.intercept: 1.0055283255506187\n",
      "iteration - 5727 -> loss: 0.00029223975141789516, self.slope: [1.06287644 1.06331182], self.intercept: 1.0055291537600743\n",
      "iteration - 5728 -> loss: 0.0002922233120366905, self.slope: [1.06288544 1.06332091], self.intercept: 1.0055299819312284\n",
      "iteration - 5729 -> loss: 0.0002922068745647681, self.slope: [1.06289444 1.06333   ], self.intercept: 1.0055308100640856\n",
      "iteration - 5730 -> loss: 0.00029219043900172886, self.slope: [1.06290344 1.0633391 ], self.intercept: 1.0055316381586474\n",
      "iteration - 5731 -> loss: 0.00029217400534726606, self.slope: [1.06291243 1.06334819], self.intercept: 1.0055324662149214\n",
      "iteration - 5732 -> loss: 0.0002921575736010236, self.slope: [1.06292143 1.06335728], self.intercept: 1.005533294232908\n",
      "iteration - 5733 -> loss: 0.0002921411437626772, self.slope: [1.06293043 1.06336637], self.intercept: 1.005534122212613\n",
      "iteration - 5734 -> loss: 0.00029212471583191067, self.slope: [1.06293943 1.06337546], self.intercept: 1.0055349501540405\n",
      "iteration - 5735 -> loss: 0.00029210828980834867, self.slope: [1.06294842 1.06338455], self.intercept: 1.0055357780571927\n",
      "iteration - 5736 -> loss: 0.00029209186569166843, self.slope: [1.06295742 1.06339364], self.intercept: 1.0055366059220745\n",
      "iteration - 5737 -> loss: 0.0002920754434815501, self.slope: [1.06296641 1.06340273], self.intercept: 1.0055374337486898\n",
      "iteration - 5738 -> loss: 0.00029205902317763294, self.slope: [1.06297541 1.06341182], self.intercept: 1.0055382615370425\n",
      "iteration - 5739 -> loss: 0.00029204260477959403, self.slope: [1.0629844  1.06342091], self.intercept: 1.005539089287136\n",
      "iteration - 5740 -> loss: 0.0002920261882870962, self.slope: [1.0629934 1.06343  ], self.intercept: 1.0055399169989756\n",
      "iteration - 5741 -> loss: 0.00029200977369980824, self.slope: [1.06300239 1.06343908], self.intercept: 1.0055407446725624\n",
      "iteration - 5742 -> loss: 0.000291993361017384, self.slope: [1.06301138 1.06344817], self.intercept: 1.0055415723079013\n",
      "iteration - 5743 -> loss: 0.0002919769502394983, self.slope: [1.06302037 1.06345725], self.intercept: 1.0055423999049968\n",
      "iteration - 5744 -> loss: 0.0002919605413658005, self.slope: [1.06302937 1.06346634], self.intercept: 1.0055432274638527\n",
      "iteration - 5745 -> loss: 0.00029194413439597176, self.slope: [1.06303836 1.06347543], self.intercept: 1.005544054984473\n",
      "iteration - 5746 -> loss: 0.0002919277293296528, self.slope: [1.06304735 1.06348451], self.intercept: 1.0055448824668598\n",
      "iteration - 5747 -> loss: 0.00029191132616655026, self.slope: [1.06305634 1.06349359], self.intercept: 1.0055457099110194\n",
      "iteration - 5748 -> loss: 0.00029189492490628926, self.slope: [1.06306533 1.06350268], self.intercept: 1.005546537316955\n",
      "iteration - 5749 -> loss: 0.0002918785255485368, self.slope: [1.06307432 1.06351176], self.intercept: 1.0055473646846715\n",
      "iteration - 5750 -> loss: 0.00029186212809297735, self.slope: [1.0630833  1.06352084], self.intercept: 1.0055481920141693\n",
      "iteration - 5751 -> loss: 0.00029184573253927495, self.slope: [1.06309229 1.06352992], self.intercept: 1.0055490193054548\n",
      "iteration - 5752 -> loss: 0.00029182933888707884, self.slope: [1.06310128 1.06353901], self.intercept: 1.0055498465585313\n",
      "iteration - 5753 -> loss: 0.00029181294713606334, self.slope: [1.06311027 1.06354809], self.intercept: 1.0055506737734032\n",
      "iteration - 5754 -> loss: 0.000291796557285886, self.slope: [1.06311925 1.06355717], self.intercept: 1.005551500950074\n",
      "iteration - 5755 -> loss: 0.00029178016933620923, self.slope: [1.06312824 1.06356625], self.intercept: 1.0055523280885463\n",
      "iteration - 5756 -> loss: 0.0002917637832867212, self.slope: [1.06313722 1.06357533], self.intercept: 1.005553155188828\n",
      "iteration - 5757 -> loss: 0.0002917473991370778, self.slope: [1.06314621 1.0635844 ], self.intercept: 1.0055539822509183\n",
      "iteration - 5758 -> loss: 0.00029173101688692804, self.slope: [1.06315519 1.06359348], self.intercept: 1.005554809274823\n",
      "iteration - 5759 -> loss: 0.00029171463653594466, self.slope: [1.06316418 1.06360256], self.intercept: 1.0055556362605447\n",
      "iteration - 5760 -> loss: 0.00029169825808381296, self.slope: [1.06317316 1.06361164], self.intercept: 1.0055564632080887\n",
      "iteration - 5761 -> loss: 0.00029168188153017363, self.slope: [1.06318214 1.06362071], self.intercept: 1.0055572901174583\n",
      "iteration - 5762 -> loss: 0.0002916655068746972, self.slope: [1.06319112 1.06362979], self.intercept: 1.005558116988657\n",
      "iteration - 5763 -> loss: 0.00029164913411705985, self.slope: [1.06320011 1.06363886], self.intercept: 1.0055589438216899\n",
      "iteration - 5764 -> loss: 0.00029163276325692083, self.slope: [1.06320909 1.06364794], self.intercept: 1.0055597706165589\n",
      "iteration - 5765 -> loss: 0.0002916163942939391, self.slope: [1.06321807 1.06365701], self.intercept: 1.0055605973732702\n",
      "iteration - 5766 -> loss: 0.0002916000272277931, self.slope: [1.06322705 1.06366609], self.intercept: 1.0055614240918271\n",
      "iteration - 5767 -> loss: 0.00029158366205813297, self.slope: [1.06323603 1.06367516], self.intercept: 1.0055622507722322\n",
      "iteration - 5768 -> loss: 0.00029156729878465024, self.slope: [1.06324501 1.06368423], self.intercept: 1.0055630774144897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 5769 -> loss: 0.0002915509374069853, self.slope: [1.06325398 1.06369331], self.intercept: 1.0055639040186033\n",
      "iteration - 5770 -> loss: 0.0002915345779248139, self.slope: [1.06326296 1.06370238], self.intercept: 1.005564730584578\n",
      "iteration - 5771 -> loss: 0.00029151822033781223, self.slope: [1.06327194 1.06371145], self.intercept: 1.0055655571124174\n",
      "iteration - 5772 -> loss: 0.0002915018646456316, self.slope: [1.06328092 1.06372052], self.intercept: 1.0055663836021234\n",
      "iteration - 5773 -> loss: 0.0002914855108479513, self.slope: [1.06328989 1.06372959], self.intercept: 1.0055672100537008\n",
      "iteration - 5774 -> loss: 0.0002914691589444316, self.slope: [1.06329887 1.06373866], self.intercept: 1.0055680364671529\n",
      "iteration - 5775 -> loss: 0.00029145280893473407, self.slope: [1.06330784 1.06374773], self.intercept: 1.0055688628424844\n",
      "iteration - 5776 -> loss: 0.00029143646081853454, self.slope: [1.06331682 1.0637568 ], self.intercept: 1.0055696891797008\n",
      "iteration - 5777 -> loss: 0.0002914201145954979, self.slope: [1.06332579 1.06376587], self.intercept: 1.0055705154788044\n",
      "iteration - 5778 -> loss: 0.00029140377026527883, self.slope: [1.06333477 1.06377494], self.intercept: 1.0055713417397985\n",
      "iteration - 5779 -> loss: 0.00029138742782757013, self.slope: [1.06334374 1.063784  ], self.intercept: 1.0055721679626868\n",
      "iteration - 5780 -> loss: 0.00029137108728201426, self.slope: [1.06335271 1.06379307], self.intercept: 1.0055729941474738\n",
      "iteration - 5781 -> loss: 0.00029135474862830064, self.slope: [1.06336168 1.06380214], self.intercept: 1.005573820294163\n",
      "iteration - 5782 -> loss: 0.0002913384118660557, self.slope: [1.06337066 1.0638112 ], self.intercept: 1.0055746464027588\n",
      "iteration - 5783 -> loss: 0.0002913220769950016, self.slope: [1.06337963 1.06382027], self.intercept: 1.0055754724732646\n",
      "iteration - 5784 -> loss: 0.0002913057440147538, self.slope: [1.0633886  1.06382933], self.intercept: 1.005576298505684\n",
      "iteration - 5785 -> loss: 0.0002912894129250353, self.slope: [1.06339757 1.0638384 ], self.intercept: 1.0055771245000216\n",
      "iteration - 5786 -> loss: 0.00029127308372546286, self.slope: [1.06340654 1.06384746], self.intercept: 1.0055779504562805\n",
      "iteration - 5787 -> loss: 0.0002912567564157245, self.slope: [1.06341551 1.06385652], self.intercept: 1.0055787763744652\n",
      "iteration - 5788 -> loss: 0.00029124043099549955, self.slope: [1.06342447 1.06386558], self.intercept: 1.0055796022545782\n",
      "iteration - 5789 -> loss: 0.00029122410746443864, self.slope: [1.06343344 1.06387465], self.intercept: 1.0055804280966247\n",
      "iteration - 5790 -> loss: 0.00029120778582219766, self.slope: [1.06344241 1.06388371], self.intercept: 1.0055812539006088\n",
      "iteration - 5791 -> loss: 0.0002911914660684809, self.slope: [1.06345138 1.06389277], self.intercept: 1.0055820796665327\n",
      "iteration - 5792 -> loss: 0.00029117514820294147, self.slope: [1.06346034 1.06390183], self.intercept: 1.0055829053944016\n",
      "iteration - 5793 -> loss: 0.0002911588322252463, self.slope: [1.06346931 1.06391089], self.intercept: 1.0055837310842184\n",
      "iteration - 5794 -> loss: 0.00029114251813504457, self.slope: [1.06347827 1.06391995], self.intercept: 1.0055845567359882\n",
      "iteration - 5795 -> loss: 0.0002911262059320197, self.slope: [1.06348724 1.06392901], self.intercept: 1.0055853823497132\n",
      "iteration - 5796 -> loss: 0.0002911098956158527, self.slope: [1.0634962  1.06393807], self.intercept: 1.0055862079253985\n",
      "iteration - 5797 -> loss: 0.00029109358718619764, self.slope: [1.06350517 1.06394712], self.intercept: 1.005587033463047\n",
      "iteration - 5798 -> loss: 0.000291077280642719, self.slope: [1.06351413 1.06395618], self.intercept: 1.0055878589626641\n",
      "iteration - 5799 -> loss: 0.0002910609759850909, self.slope: [1.06352309 1.06396524], self.intercept: 1.005588684424251\n",
      "iteration - 5800 -> loss: 0.0002910446732129917, self.slope: [1.06353205 1.06397429], self.intercept: 1.0055895098478138\n",
      "iteration - 5801 -> loss: 0.0002910283723260742, self.slope: [1.06354102 1.06398335], self.intercept: 1.005590335233354\n",
      "iteration - 5802 -> loss: 0.0002910120733240231, self.slope: [1.06354998 1.0639924 ], self.intercept: 1.0055911605808776\n",
      "iteration - 5803 -> loss: 0.000290995776206491, self.slope: [1.06355894 1.06400146], self.intercept: 1.0055919858903881\n",
      "iteration - 5804 -> loss: 0.0002909794809731481, self.slope: [1.0635679  1.06401051], self.intercept: 1.0055928111618884\n",
      "iteration - 5805 -> loss: 0.00029096318762369364, self.slope: [1.06357686 1.06401957], self.intercept: 1.0055936363953843\n",
      "iteration - 5806 -> loss: 0.0002909468961577549, self.slope: [1.06358582 1.06402862], self.intercept: 1.005594461590878\n",
      "iteration - 5807 -> loss: 0.00029093060657501895, self.slope: [1.06359477 1.06403767], self.intercept: 1.0055952867483715\n",
      "iteration - 5808 -> loss: 0.00029091431887516453, self.slope: [1.06360373 1.06404673], self.intercept: 1.0055961118678707\n",
      "iteration - 5809 -> loss: 0.00029089803305784806, self.slope: [1.06361269 1.06405578], self.intercept: 1.0055969369493811\n",
      "iteration - 5810 -> loss: 0.00029088174912272863, self.slope: [1.06362165 1.06406483], self.intercept: 1.0055977619929044\n",
      "iteration - 5811 -> loss: 0.0002908654670695123, self.slope: [1.0636306  1.06407388], self.intercept: 1.0055985869984454\n",
      "iteration - 5812 -> loss: 0.0002908491868978459, self.slope: [1.06363956 1.06408293], self.intercept: 1.0055994119660074\n",
      "iteration - 5813 -> loss: 0.00029083290860738316, self.slope: [1.06364852 1.06409198], self.intercept: 1.0056002368955932\n",
      "iteration - 5814 -> loss: 0.00029081663219781233, self.slope: [1.06365747 1.06410103], self.intercept: 1.005601061787207\n",
      "iteration - 5815 -> loss: 0.00029080035766881375, self.slope: [1.06366642 1.06411008], self.intercept: 1.0056018866408536\n",
      "iteration - 5816 -> loss: 0.0002907840850200267, self.slope: [1.06367538 1.06411912], self.intercept: 1.0056027114565371\n",
      "iteration - 5817 -> loss: 0.000290767814251149, self.slope: [1.06368433 1.06412817], self.intercept: 1.00560353623426\n",
      "iteration - 5818 -> loss: 0.0002907515453618405, self.slope: [1.06369328 1.06413722], self.intercept: 1.0056043609740257\n",
      "iteration - 5819 -> loss: 0.0002907352783517723, self.slope: [1.06370224 1.06414626], self.intercept: 1.0056051856758383\n",
      "iteration - 5820 -> loss: 0.0002907190132206026, self.slope: [1.06371119 1.06415531], self.intercept: 1.0056060103397035\n",
      "iteration - 5821 -> loss: 0.0002907027499680385, self.slope: [1.06372014 1.06416436], self.intercept: 1.005606834965625\n",
      "iteration - 5822 -> loss: 0.0002906864885936948, self.slope: [1.06372909 1.0641734 ], self.intercept: 1.0056076595536048\n",
      "iteration - 5823 -> loss: 0.0002906702290972984, self.slope: [1.06373804 1.06418245], self.intercept: 1.005608484103648\n",
      "iteration - 5824 -> loss: 0.0002906539714784654, self.slope: [1.06374699 1.06419149], self.intercept: 1.005609308615758\n",
      "iteration - 5825 -> loss: 0.000290637715736906, self.slope: [1.06375594 1.06420053], self.intercept: 1.005610133089937\n",
      "iteration - 5826 -> loss: 0.0002906214618722918, self.slope: [1.06376489 1.06420957], self.intercept: 1.0056109575261918\n",
      "iteration - 5827 -> loss: 0.00029060520988427325, self.slope: [1.06377384 1.06421862], self.intercept: 1.0056117819245245\n",
      "iteration - 5828 -> loss: 0.0002905889597725273, self.slope: [1.06378278 1.06422766], self.intercept: 1.0056126062849386\n",
      "iteration - 5829 -> loss: 0.00029057271153672213, self.slope: [1.06379173 1.0642367 ], self.intercept: 1.0056134306074371\n",
      "iteration - 5830 -> loss: 0.0002905564651765268, self.slope: [1.06380068 1.06424574], self.intercept: 1.0056142548920237\n",
      "iteration - 5831 -> loss: 0.00029054022069163277, self.slope: [1.06380962 1.06425478], self.intercept: 1.0056150791387048\n",
      "iteration - 5832 -> loss: 0.0002905239780816876, self.slope: [1.06381857 1.06426382], self.intercept: 1.0056159033474836\n",
      "iteration - 5833 -> loss: 0.00029050773734638107, self.slope: [1.06382751 1.06427286], self.intercept: 1.0056167275183634\n",
      "iteration - 5834 -> loss: 0.00029049149848536397, self.slope: [1.06383646 1.0642819 ], self.intercept: 1.005617551651348\n",
      "iteration - 5835 -> loss: 0.0002904752614983275, self.slope: [1.0638454  1.06429094], self.intercept: 1.0056183757464394\n",
      "iteration - 5836 -> loss: 0.0002904590263849321, self.slope: [1.06385434 1.06429997], self.intercept: 1.0056191998036441\n",
      "iteration - 5837 -> loss: 0.00029044279314485505, self.slope: [1.06386329 1.06430901], self.intercept: 1.0056200238229647\n",
      "iteration - 5838 -> loss: 0.00029042656177777533, self.slope: [1.06387223 1.06431805], self.intercept: 1.0056208478044055\n",
      "iteration - 5839 -> loss: 0.0002904103322833368, self.slope: [1.06388117 1.06432708], self.intercept: 1.0056216717479693\n",
      "iteration - 5840 -> loss: 0.0002903941046612286, self.slope: [1.06389011 1.06433612], self.intercept: 1.0056224956536606\n",
      "iteration - 5841 -> loss: 0.0002903778789111344, self.slope: [1.06389905 1.06434515], self.intercept: 1.0056233195214836\n",
      "iteration - 5842 -> loss: 0.0002903616550326948, self.slope: [1.06390799 1.06435419], self.intercept: 1.005624143351441\n",
      "iteration - 5843 -> loss: 0.00029034543302561207, self.slope: [1.06391693 1.06436322], self.intercept: 1.0056249671435376\n",
      "iteration - 5844 -> loss: 0.0002903292128895568, self.slope: [1.06392587 1.06437226], self.intercept: 1.0056257908977784\n",
      "iteration - 5845 -> loss: 0.0002903129946241841, self.slope: [1.06393481 1.06438129], self.intercept: 1.005626614614164\n",
      "iteration - 5846 -> loss: 0.00029029677822917154, self.slope: [1.06394375 1.06439032], self.intercept: 1.0056274382927\n",
      "iteration - 5847 -> loss: 0.000290280563704183, self.slope: [1.06395269 1.06439935], self.intercept: 1.0056282619333887\n",
      "iteration - 5848 -> loss: 0.00029026435104891816, self.slope: [1.06396162 1.06440839], self.intercept: 1.005629085536236\n",
      "iteration - 5849 -> loss: 0.00029024814026302787, self.slope: [1.06397056 1.06441742], self.intercept: 1.0056299091012444\n",
      "iteration - 5850 -> loss: 0.00029023193134619527, self.slope: [1.0639795  1.06442645], self.intercept: 1.0056307326284188\n",
      "iteration - 5851 -> loss: 0.00029021572429807483, self.slope: [1.06398843 1.06443548], self.intercept: 1.0056315561177622\n",
      "iteration - 5852 -> loss: 0.0002901995191183571, self.slope: [1.06399737 1.06444451], self.intercept: 1.0056323795692783\n",
      "iteration - 5853 -> loss: 0.0002901833158067213, self.slope: [1.0640063  1.06445353], self.intercept: 1.0056332029829704\n",
      "iteration - 5854 -> loss: 0.00029016711436281113, self.slope: [1.06401524 1.06446256], self.intercept: 1.0056340263588444\n",
      "iteration - 5855 -> loss: 0.00029015091478631476, self.slope: [1.06402417 1.06447159], self.intercept: 1.0056348496969014\n",
      "iteration - 5856 -> loss: 0.0002901347170769181, self.slope: [1.0640331  1.06448062], self.intercept: 1.0056356729971463\n",
      "iteration - 5857 -> loss: 0.00029011852123427933, self.slope: [1.06404204 1.06448964], self.intercept: 1.0056364962595836\n",
      "iteration - 5858 -> loss: 0.00029010232725808536, self.slope: [1.06405097 1.06449867], self.intercept: 1.0056373194842168\n",
      "iteration - 5859 -> loss: 0.0002900861351479836, self.slope: [1.0640599 1.0645077], self.intercept: 1.0056381426710488\n",
      "iteration - 5860 -> loss: 0.00029006994490366503, self.slope: [1.06406883 1.06451672], self.intercept: 1.0056389658200848\n",
      "iteration - 5861 -> loss: 0.00029005375652480805, self.slope: [1.06407776 1.06452575], self.intercept: 1.0056397889313273\n",
      "iteration - 5862 -> loss: 0.00029003757001108335, self.slope: [1.06408669 1.06453477], self.intercept: 1.0056406120047792\n",
      "iteration - 5863 -> loss: 0.00029002138536214975, self.slope: [1.06409562 1.06454379], self.intercept: 1.005641435040448\n",
      "iteration - 5864 -> loss: 0.00029000520257770534, self.slope: [1.06410455 1.06455282], self.intercept: 1.005642258038334\n",
      "iteration - 5865 -> loss: 0.0002899890216573787, self.slope: [1.06411348 1.06456184], self.intercept: 1.0056430809984418\n",
      "iteration - 5866 -> loss: 0.0002899728426009034, self.slope: [1.0641224  1.06457086], self.intercept: 1.0056439039207774\n",
      "iteration - 5867 -> loss: 0.0002899566654079296, self.slope: [1.06413133 1.06457988], self.intercept: 1.0056447268053412\n",
      "iteration - 5868 -> loss: 0.00028994049007810573, self.slope: [1.06414026 1.0645889 ], self.intercept: 1.0056455496521388\n",
      "iteration - 5869 -> loss: 0.00028992431661114875, self.slope: [1.06414918 1.06459793], self.intercept: 1.0056463724611733\n",
      "iteration - 5870 -> loss: 0.0002899081450066999, self.slope: [1.06415811 1.06460695], self.intercept: 1.0056471952324486\n",
      "iteration - 5871 -> loss: 0.0002898919752644423, self.slope: [1.06416704 1.06461597], self.intercept: 1.0056480179659688\n",
      "iteration - 5872 -> loss: 0.0002898758073840527, self.slope: [1.06417596 1.06462498], self.intercept: 1.0056488406617377\n",
      "iteration - 5873 -> loss: 0.0002898596413651968, self.slope: [1.06418488 1.064634  ], self.intercept: 1.0056496633197578\n",
      "iteration - 5874 -> loss: 0.000289843477207562, self.slope: [1.06419381 1.06464302], self.intercept: 1.005650485940035\n",
      "iteration - 5875 -> loss: 0.00028982731491081866, self.slope: [1.06420273 1.06465204], self.intercept: 1.0056513085225722\n",
      "iteration - 5876 -> loss: 0.00028981115447464353, self.slope: [1.06421165 1.06466106], self.intercept: 1.005652131067373\n",
      "iteration - 5877 -> loss: 0.0002897949958987028, self.slope: [1.06422058 1.06467007], self.intercept: 1.0056529535744416\n",
      "iteration - 5878 -> loss: 0.0002897788391826812, self.slope: [1.0642295  1.06467909], self.intercept: 1.0056537760437805\n",
      "iteration - 5879 -> loss: 0.0002897626843262472, self.slope: [1.06423842 1.0646881 ], self.intercept: 1.0056545984753942\n",
      "iteration - 5880 -> loss: 0.0002897465313290728, self.slope: [1.06424734 1.06469712], self.intercept: 1.0056554208692874\n",
      "iteration - 5881 -> loss: 0.0002897303801908399, self.slope: [1.06425626 1.06470613], self.intercept: 1.0056562432254634\n",
      "iteration - 5882 -> loss: 0.0002897142309112212, self.slope: [1.06426518 1.06471515], self.intercept: 1.0056570655439254\n",
      "iteration - 5883 -> loss: 0.00028969808348988034, self.slope: [1.0642741  1.06472416], self.intercept: 1.0056578878246778\n",
      "iteration - 5884 -> loss: 0.00028968193792651957, self.slope: [1.06428302 1.06473317], self.intercept: 1.0056587100677234\n",
      "iteration - 5885 -> loss: 0.0002896657942207897, self.slope: [1.06429193 1.06474218], self.intercept: 1.0056595322730673\n",
      "iteration - 5886 -> loss: 0.000289649652372362, self.slope: [1.06430085 1.0647512 ], self.intercept: 1.0056603544407121\n",
      "iteration - 5887 -> loss: 0.0002896335123809449, self.slope: [1.06430977 1.06476021], self.intercept: 1.0056611765706625\n",
      "iteration - 5888 -> loss: 0.00028961737424618714, self.slope: [1.06431868 1.06476922], self.intercept: 1.0056619986629205\n",
      "iteration - 5889 -> loss: 0.0002896012379677707, self.slope: [1.0643276  1.06477823], self.intercept: 1.0056628207174916\n",
      "iteration - 5890 -> loss: 0.0002895851035453634, self.slope: [1.06433652 1.06478724], self.intercept: 1.0056636427343786\n",
      "iteration - 5891 -> loss: 0.0002895689709786593, self.slope: [1.06434543 1.06479625], self.intercept: 1.0056644647135864\n",
      "iteration - 5892 -> loss: 0.0002895528402673043, self.slope: [1.06435434 1.06480526], self.intercept: 1.0056652866551181\n",
      "iteration - 5893 -> loss: 0.0002895367114109953, self.slope: [1.06436326 1.06481426], self.intercept: 1.0056661085589782\n",
      "iteration - 5894 -> loss: 0.0002895205844094237, self.slope: [1.06437217 1.06482327], self.intercept: 1.0056669304251695\n",
      "iteration - 5895 -> loss: 0.00028950445926223246, self.slope: [1.06438108 1.06483228], self.intercept: 1.0056677522536952\n",
      "iteration - 5896 -> loss: 0.00028948833596912043, self.slope: [1.06439    1.06484129], self.intercept: 1.00566857404456\n",
      "iteration - 5897 -> loss: 0.00028947221452975245, self.slope: [1.06439891 1.06485029], self.intercept: 1.0056693957977676\n",
      "iteration - 5898 -> loss: 0.0002894560949438094, self.slope: [1.06440782 1.0648593 ], self.intercept: 1.005670217513322\n",
      "iteration - 5899 -> loss: 0.00028943997721096135, self.slope: [1.06441673 1.0648683 ], self.intercept: 1.0056710391912262\n",
      "iteration - 5900 -> loss: 0.00028942386133088424, self.slope: [1.06442564 1.06487731], self.intercept: 1.0056718608314852\n",
      "iteration - 5901 -> loss: 0.000289407747303283, self.slope: [1.06443455 1.06488631], self.intercept: 1.0056726824341022\n",
      "iteration - 5902 -> loss: 0.000289391635127789, self.slope: [1.06444346 1.06489532], self.intercept: 1.0056735039990807\n",
      "iteration - 5903 -> loss: 0.0002893755248041135, self.slope: [1.06445237 1.06490432], self.intercept: 1.005674325526424\n",
      "iteration - 5904 -> loss: 0.0002893594163319119, self.slope: [1.06446128 1.06491332], self.intercept: 1.0056751470161367\n",
      "iteration - 5905 -> loss: 0.00028934330971087653, self.slope: [1.06447018 1.06492232], self.intercept: 1.0056759684682226\n",
      "iteration - 5906 -> loss: 0.00028932720494066316, self.slope: [1.06447909 1.06493132], self.intercept: 1.0056767898826848\n",
      "iteration - 5907 -> loss: 0.00028931110202098145, self.slope: [1.064488   1.06494033], self.intercept: 1.0056776112595276\n",
      "iteration - 5908 -> loss: 0.0002892950009514881, self.slope: [1.0644969  1.06494933], self.intercept: 1.0056784325987542\n",
      "iteration - 5909 -> loss: 0.0002892789017318447, self.slope: [1.06450581 1.06495833], self.intercept: 1.005679253900368\n",
      "iteration - 5910 -> loss: 0.0002892628043617508, self.slope: [1.06451471 1.06496733], self.intercept: 1.0056800751643742\n",
      "iteration - 5911 -> loss: 0.00028924670884087727, self.slope: [1.06452362 1.06497632], self.intercept: 1.0056808963907762\n",
      "iteration - 5912 -> loss: 0.00028923061516890537, self.slope: [1.06453252 1.06498532], self.intercept: 1.0056817175795767\n",
      "iteration - 5913 -> loss: 0.00028921452334551475, self.slope: [1.06454143 1.06499432], self.intercept: 1.0056825387307804\n",
      "iteration - 5914 -> loss: 0.00028919843337036613, self.slope: [1.06455033 1.06500332], self.intercept: 1.0056833598443906\n",
      "iteration - 5915 -> loss: 0.0002891823452431653, self.slope: [1.06455923 1.06501232], self.intercept: 1.005684180920411\n",
      "iteration - 5916 -> loss: 0.0002891662589635463, self.slope: [1.06456813 1.06502131], self.intercept: 1.0056850019588461\n",
      "iteration - 5917 -> loss: 0.00028915017453123593, self.slope: [1.06457703 1.06503031], self.intercept: 1.0056858229596985\n",
      "iteration - 5918 -> loss: 0.0002891340919458766, self.slope: [1.06458593 1.0650393 ], self.intercept: 1.0056866439229732\n",
      "iteration - 5919 -> loss: 0.0002891180112071692, self.slope: [1.06459484 1.0650483 ], self.intercept: 1.0056874648486733\n",
      "iteration - 5920 -> loss: 0.0002891019323147672, self.slope: [1.06460373 1.06505729], self.intercept: 1.0056882857368032\n",
      "iteration - 5921 -> loss: 0.0002890858552683842, self.slope: [1.06461263 1.06506629], self.intercept: 1.005689106587365\n",
      "iteration - 5922 -> loss: 0.000289069780067655, self.slope: [1.06462153 1.06507528], self.intercept: 1.005689927400364\n",
      "iteration - 5923 -> loss: 0.0002890537067122925, self.slope: [1.06463043 1.06508427], self.intercept: 1.005690748175803\n",
      "iteration - 5924 -> loss: 0.00028903763520195475, self.slope: [1.06463933 1.06509326], self.intercept: 1.0056915689136867\n",
      "iteration - 5925 -> loss: 0.0002890215655363345, self.slope: [1.06464823 1.06510226], self.intercept: 1.0056923896140173\n",
      "iteration - 5926 -> loss: 0.0002890054977150874, self.slope: [1.06465712 1.06511125], self.intercept: 1.0056932102768001\n",
      "iteration - 5927 -> loss: 0.00028898943173792175, self.slope: [1.06466602 1.06512024], self.intercept: 1.0056940309020386\n",
      "iteration - 5928 -> loss: 0.00028897336760449246, self.slope: [1.06467492 1.06512923], self.intercept: 1.0056948514897364\n",
      "iteration - 5929 -> loss: 0.000288957305314493, self.slope: [1.06468381 1.06513822], self.intercept: 1.005695672039897\n",
      "iteration - 5930 -> loss: 0.000288941244867591, self.slope: [1.0646927  1.06514721], self.intercept: 1.0056964925525222\n",
      "iteration - 5931 -> loss: 0.0002889251862634618, self.slope: [1.0647016 1.0651562], self.intercept: 1.005697313027618\n",
      "iteration - 5932 -> loss: 0.00028890912950181266, self.slope: [1.06471049 1.06516518], self.intercept: 1.0056981334651887\n",
      "iteration - 5933 -> loss: 0.0002888930745822851, self.slope: [1.06471939 1.06517417], self.intercept: 1.0056989538652388\n",
      "iteration - 5934 -> loss: 0.0002888770215045698, self.slope: [1.06472828 1.06518316], self.intercept: 1.0056997742277693\n",
      "iteration - 5935 -> loss: 0.0002888609702683556, self.slope: [1.06473717 1.06519215], self.intercept: 1.0057005945527855\n",
      "iteration - 5936 -> loss: 0.0002888449208733307, self.slope: [1.06474606 1.06520113], self.intercept: 1.00570141484029\n",
      "iteration - 5937 -> loss: 0.00028882887331914376, self.slope: [1.06475495 1.06521012], self.intercept: 1.0057022350902889\n",
      "iteration - 5938 -> loss: 0.00028881282760549027, self.slope: [1.06476384 1.0652191 ], self.intercept: 1.0057030553027837\n",
      "iteration - 5939 -> loss: 0.00028879678373207275, self.slope: [1.06477273 1.06522809], self.intercept: 1.0057038754777778\n",
      "iteration - 5940 -> loss: 0.0002887807416985231, self.slope: [1.06478162 1.06523707], self.intercept: 1.0057046956152764\n",
      "iteration - 5941 -> loss: 0.00028876470150456375, self.slope: [1.06479051 1.06524606], self.intercept: 1.0057055157152832\n",
      "iteration - 5942 -> loss: 0.00028874866314984083, self.slope: [1.0647994  1.06525504], self.intercept: 1.0057063357778018\n",
      "iteration - 5943 -> loss: 0.00028873262663405523, self.slope: [1.06480829 1.06526402], self.intercept: 1.005707155802834\n",
      "iteration - 5944 -> loss: 0.00028871659195687827, self.slope: [1.06481718 1.065273  ], self.intercept: 1.0057079757903864\n",
      "iteration - 5945 -> loss: 0.0002887005591179929, self.slope: [1.06482606 1.06528198], self.intercept: 1.0057087957404613\n",
      "iteration - 5946 -> loss: 0.0002886845281170755, self.slope: [1.06483495 1.06529097], self.intercept: 1.0057096156530634\n",
      "iteration - 5947 -> loss: 0.00028866849895380737, self.slope: [1.06484384 1.06529995], self.intercept: 1.0057104355281963\n",
      "iteration - 5948 -> loss: 0.00028865247162787236, self.slope: [1.06485272 1.06530893], self.intercept: 1.0057112553658603\n",
      "iteration - 5949 -> loss: 0.0002886364461389499, self.slope: [1.06486161 1.06531791], self.intercept: 1.005712075166064\n",
      "iteration - 5950 -> loss: 0.0002886204224867099, self.slope: [1.06487049 1.06532688], self.intercept: 1.005712894928808\n",
      "iteration - 5951 -> loss: 0.0002886044006708512, self.slope: [1.06487937 1.06533586], self.intercept: 1.0057137146540966\n",
      "iteration - 5952 -> loss: 0.00028858838069103685, self.slope: [1.06488826 1.06534484], self.intercept: 1.0057145343419347\n",
      "iteration - 5953 -> loss: 0.0002885723625469565, self.slope: [1.06489714 1.06535382], self.intercept: 1.005715353992325\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 5954 -> loss: 0.0002885563462382827, self.slope: [1.06490602 1.0653628 ], self.intercept: 1.0057161736052722\n",
      "iteration - 5955 -> loss: 0.00028854033176469503, self.slope: [1.0649149  1.06537177], self.intercept: 1.0057169931807795\n",
      "iteration - 5956 -> loss: 0.0002885243191259012, self.slope: [1.06492379 1.06538075], self.intercept: 1.0057178127188497\n",
      "iteration - 5957 -> loss: 0.0002885083083215362, self.slope: [1.06493267 1.06538972], self.intercept: 1.0057186322194884\n",
      "iteration - 5958 -> loss: 0.0002884922993513173, self.slope: [1.06494155 1.0653987 ], self.intercept: 1.0057194516826973\n",
      "iteration - 5959 -> loss: 0.0002884762922149157, self.slope: [1.06495043 1.06540767], self.intercept: 1.005720271108482\n",
      "iteration - 5960 -> loss: 0.0002884602869120087, self.slope: [1.06495931 1.06541665], self.intercept: 1.0057210904968437\n",
      "iteration - 5961 -> loss: 0.0002884442834422667, self.slope: [1.06496819 1.06542562], self.intercept: 1.0057219098477885\n",
      "iteration - 5962 -> loss: 0.0002884282818053921, self.slope: [1.06497706 1.06543459], self.intercept: 1.0057227291613202\n",
      "iteration - 5963 -> loss: 0.00028841228200104886, self.slope: [1.06498594 1.06544357], self.intercept: 1.005723548437442\n",
      "iteration - 5964 -> loss: 0.000288396284028934, self.slope: [1.06499482 1.06545254], self.intercept: 1.0057243676761558\n",
      "iteration - 5965 -> loss: 0.00028838028788872347, self.slope: [1.06500369 1.06546151], self.intercept: 1.0057251868774677\n",
      "iteration - 5966 -> loss: 0.0002883642935800829, self.slope: [1.06501257 1.06547048], self.intercept: 1.0057260060413806\n",
      "iteration - 5967 -> loss: 0.0002883483011027265, self.slope: [1.06502145 1.06547945], self.intercept: 1.0057268251678988\n",
      "iteration - 5968 -> loss: 0.0002883323104562868, self.slope: [1.06503032 1.06548842], self.intercept: 1.0057276442570253\n",
      "iteration - 5969 -> loss: 0.00028831632164049294, self.slope: [1.0650392  1.06549739], self.intercept: 1.005728463308763\n",
      "iteration - 5970 -> loss: 0.0002883003346550021, self.slope: [1.06504807 1.06550636], self.intercept: 1.0057292823231163\n",
      "iteration - 5971 -> loss: 0.00028828434949950565, self.slope: [1.06505694 1.06551533], self.intercept: 1.0057301013000908\n",
      "iteration - 5972 -> loss: 0.0002882683661736819, self.slope: [1.06506582 1.06552429], self.intercept: 1.0057309202396867\n",
      "iteration - 5973 -> loss: 0.00028825238467719344, self.slope: [1.06507469 1.06553326], self.intercept: 1.0057317391419107\n",
      "iteration - 5974 -> loss: 0.0002882364050097617, self.slope: [1.06508356 1.06554223], self.intercept: 1.005732558006765\n",
      "iteration - 5975 -> loss: 0.00028822042717103834, self.slope: [1.06509243 1.06555119], self.intercept: 1.005733376834255\n",
      "iteration - 5976 -> loss: 0.0002882044511607227, self.slope: [1.0651013  1.06556016], self.intercept: 1.0057341956243824\n",
      "iteration - 5977 -> loss: 0.0002881884769784782, self.slope: [1.06511018 1.06556912], self.intercept: 1.0057350143771515\n",
      "iteration - 5978 -> loss: 0.00028817250462401657, self.slope: [1.06511905 1.06557809], self.intercept: 1.0057358330925668\n",
      "iteration - 5979 -> loss: 0.0002881565340969771, self.slope: [1.06512791 1.06558705], self.intercept: 1.0057366517706305\n",
      "iteration - 5980 -> loss: 0.0002881405653970758, self.slope: [1.06513678 1.06559602], self.intercept: 1.005737470411349\n",
      "iteration - 5981 -> loss: 0.0002881245985239875, self.slope: [1.06514565 1.06560498], self.intercept: 1.0057382890147237\n",
      "iteration - 5982 -> loss: 0.00028810863347739036, self.slope: [1.06515452 1.06561394], self.intercept: 1.0057391075807594\n",
      "iteration - 5983 -> loss: 0.0002880926702569556, self.slope: [1.06516339 1.06562291], self.intercept: 1.0057399261094577\n",
      "iteration - 5984 -> loss: 0.0002880767088624073, self.slope: [1.06517225 1.06563187], self.intercept: 1.0057407446008242\n",
      "iteration - 5985 -> loss: 0.0002880607492933892, self.slope: [1.06518112 1.06564083], self.intercept: 1.0057415630548632\n",
      "iteration - 5986 -> loss: 0.00028804479154956943, self.slope: [1.06518999 1.06564979], self.intercept: 1.0057423814715765\n",
      "iteration - 5987 -> loss: 0.000288028835630704, self.slope: [1.06519885 1.06565875], self.intercept: 1.00574319985097\n",
      "iteration - 5988 -> loss: 0.00028801288153640646, self.slope: [1.06520772 1.06566771], self.intercept: 1.0057440181930444\n",
      "iteration - 5989 -> loss: 0.00028799692926637517, self.slope: [1.06521658 1.06567667], self.intercept: 1.0057448364978065\n",
      "iteration - 5990 -> loss: 0.0002879809788202981, self.slope: [1.06522545 1.06568563], self.intercept: 1.0057456547652588\n",
      "iteration - 5991 -> loss: 0.000287965030197867, self.slope: [1.06523431 1.06569458], self.intercept: 1.0057464729954042\n",
      "iteration - 5992 -> loss: 0.0002879490833987566, self.slope: [1.06524317 1.06570354], self.intercept: 1.0057472911882475\n",
      "iteration - 5993 -> loss: 0.000287933138422663, self.slope: [1.06525203 1.0657125 ], self.intercept: 1.0057481093437923\n",
      "iteration - 5994 -> loss: 0.00028791719526924083, self.slope: [1.0652609  1.06572146], self.intercept: 1.0057489274620421\n",
      "iteration - 5995 -> loss: 0.0002879012539382052, self.slope: [1.06526976 1.06573041], self.intercept: 1.0057497455430005\n",
      "iteration - 5996 -> loss: 0.00028788531442922293, self.slope: [1.06527862 1.06573937], self.intercept: 1.005750563586672\n",
      "iteration - 5997 -> loss: 0.000287869376741978, self.slope: [1.06528748 1.06574832], self.intercept: 1.0057513815930583\n",
      "iteration - 5998 -> loss: 0.000287853440876156, self.slope: [1.06529634 1.06575728], self.intercept: 1.0057521995621643\n",
      "iteration - 5999 -> loss: 0.00028783750683144773, self.slope: [1.0653052  1.06576623], self.intercept: 1.0057530174939948\n",
      "iteration - 6000 -> loss: 0.0002878215746075201, self.slope: [1.06531406 1.06577518], self.intercept: 1.0057538353885513\n",
      "iteration - 6001 -> loss: 0.00028780564420408133, self.slope: [1.06532291 1.06578414], self.intercept: 1.0057546532458408\n",
      "iteration - 6002 -> loss: 0.00028778971562078734, self.slope: [1.06533177 1.06579309], self.intercept: 1.0057554710658636\n",
      "iteration - 6003 -> loss: 0.0002877737888573432, self.slope: [1.06534063 1.06580204], self.intercept: 1.0057562888486262\n",
      "iteration - 6004 -> loss: 0.00028775786391342087, self.slope: [1.06534949 1.06581099], self.intercept: 1.0057571065941298\n",
      "iteration - 6005 -> loss: 0.0002877419407887239, self.slope: [1.06535834 1.06581994], self.intercept: 1.0057579243023793\n",
      "iteration - 6006 -> loss: 0.00028772601948290544, self.slope: [1.0653672 1.0658289], self.intercept: 1.005758741973378\n",
      "iteration - 6007 -> loss: 0.0002877100999956837, self.slope: [1.06537605 1.06583785], self.intercept: 1.0057595596071287\n",
      "iteration - 6008 -> loss: 0.00028769418232670827, self.slope: [1.06538491 1.06584679], self.intercept: 1.0057603772036368\n",
      "iteration - 6009 -> loss: 0.000287678266475696, self.slope: [1.06539376 1.06585574], self.intercept: 1.0057611947629057\n",
      "iteration - 6010 -> loss: 0.00028766235244231746, self.slope: [1.06540262 1.06586469], self.intercept: 1.0057620122849398\n",
      "iteration - 6011 -> loss: 0.00028764644022625174, self.slope: [1.06541147 1.06587364], self.intercept: 1.0057628297697407\n",
      "iteration - 6012 -> loss: 0.0002876305298271904, self.slope: [1.06542032 1.06588259], self.intercept: 1.0057636472173137\n",
      "iteration - 6013 -> loss: 0.000287614621244814, self.slope: [1.06542917 1.06589153], self.intercept: 1.005764464627661\n",
      "iteration - 6014 -> loss: 0.00028759871447882514, self.slope: [1.06543803 1.06590048], self.intercept: 1.0057652820007885\n",
      "iteration - 6015 -> loss: 0.0002875828095288784, self.slope: [1.06544688 1.06590943], self.intercept: 1.0057660993366986\n",
      "iteration - 6016 -> loss: 0.0002875669063946723, self.slope: [1.06545573 1.06591837], self.intercept: 1.005766916635394\n",
      "iteration - 6017 -> loss: 0.0002875510050759051, self.slope: [1.06546458 1.06592732], self.intercept: 1.00576773389688\n",
      "iteration - 6018 -> loss: 0.0002875351055722391, self.slope: [1.06547343 1.06593626], self.intercept: 1.0057685511211594\n",
      "iteration - 6019 -> loss: 0.0002875192078833825, self.slope: [1.06548228 1.06594521], self.intercept: 1.0057693683082354\n",
      "iteration - 6020 -> loss: 0.000287503312008995, self.slope: [1.06549112 1.06595415], self.intercept: 1.0057701854581147\n",
      "iteration - 6021 -> loss: 0.00028748741794879553, self.slope: [1.06549997 1.06596309], self.intercept: 1.0057710025707984\n",
      "iteration - 6022 -> loss: 0.0002874715257024414, self.slope: [1.06550882 1.06597203], self.intercept: 1.0057718196462904\n",
      "iteration - 6023 -> loss: 0.0002874556352696218, self.slope: [1.06551767 1.06598098], self.intercept: 1.0057726366845938\n",
      "iteration - 6024 -> loss: 0.0002874397466500269, self.slope: [1.06552651 1.06598992], self.intercept: 1.0057734536857141\n",
      "iteration - 6025 -> loss: 0.00028742385984335535, self.slope: [1.06553536 1.06599886], self.intercept: 1.0057742706496546\n",
      "iteration - 6026 -> loss: 0.0002874079748492673, self.slope: [1.06554421 1.0660078 ], self.intercept: 1.0057750875764175\n",
      "iteration - 6027 -> loss: 0.00028739209166746537, self.slope: [1.06555305 1.06601674], self.intercept: 1.0057759044660073\n",
      "iteration - 6028 -> loss: 0.0002873762102976368, self.slope: [1.0655619  1.06602568], self.intercept: 1.0057767213184277\n",
      "iteration - 6029 -> loss: 0.00028736033073946057, self.slope: [1.06557074 1.06603462], self.intercept: 1.0057775381336833\n",
      "iteration - 6030 -> loss: 0.00028734445299261643, self.slope: [1.06557958 1.06604356], self.intercept: 1.0057783549117756\n",
      "iteration - 6031 -> loss: 0.0002873285770568143, self.slope: [1.06558843 1.06605249], self.intercept: 1.0057791716527107\n",
      "iteration - 6032 -> loss: 0.00028731270293170955, self.slope: [1.06559727 1.06606143], self.intercept: 1.0057799883564904\n",
      "iteration - 6033 -> loss: 0.0002872968306170023, self.slope: [1.06560611 1.06607037], self.intercept: 1.0057808050231198\n",
      "iteration - 6034 -> loss: 0.0002872809601124018, self.slope: [1.06561495 1.0660793 ], self.intercept: 1.0057816216526023\n",
      "iteration - 6035 -> loss: 0.00028726509141755856, self.slope: [1.06562379 1.06608824], self.intercept: 1.005782438244941\n",
      "iteration - 6036 -> loss: 0.0002872492245321663, self.slope: [1.06563263 1.06609717], self.intercept: 1.0057832548001393\n",
      "iteration - 6037 -> loss: 0.00028723335945592896, self.slope: [1.06564147 1.06610611], self.intercept: 1.0057840713182022\n",
      "iteration - 6038 -> loss: 0.0002872174961885243, self.slope: [1.06565031 1.06611504], self.intercept: 1.005784887799132\n",
      "iteration - 6039 -> loss: 0.00028720163472963344, self.slope: [1.06565915 1.06612398], self.intercept: 1.005785704242932\n",
      "iteration - 6040 -> loss: 0.0002871857750789515, self.slope: [1.06566799 1.06613291], self.intercept: 1.0057865206496073\n",
      "iteration - 6041 -> loss: 0.00028716991723616385, self.slope: [1.06567683 1.06614184], self.intercept: 1.0057873370191612\n",
      "iteration - 6042 -> loss: 0.000287154061200941, self.slope: [1.06568566 1.06615078], self.intercept: 1.0057881533515982\n",
      "iteration - 6043 -> loss: 0.0002871382069729977, self.slope: [1.0656945  1.06615971], self.intercept: 1.005788969646921\n",
      "iteration - 6044 -> loss: 0.0002871223545520039, self.slope: [1.06570334 1.06616864], self.intercept: 1.0057897859051335\n",
      "iteration - 6045 -> loss: 0.0002871065039376385, self.slope: [1.06571217 1.06617757], self.intercept: 1.0057906021262393\n",
      "iteration - 6046 -> loss: 0.0002870906551296138, self.slope: [1.06572101 1.0661865 ], self.intercept: 1.0057914183102414\n",
      "iteration - 6047 -> loss: 0.0002870748081275934, self.slope: [1.06572984 1.06619543], self.intercept: 1.005792234457145\n",
      "iteration - 6048 -> loss: 0.00028705896293126795, self.slope: [1.06573868 1.06620436], self.intercept: 1.005793050566952\n",
      "iteration - 6049 -> loss: 0.0002870431195403691, self.slope: [1.06574751 1.06621329], self.intercept: 1.0057938666396677\n",
      "iteration - 6050 -> loss: 0.0002870272779545169, self.slope: [1.06575635 1.06622222], self.intercept: 1.0057946826752948\n",
      "iteration - 6051 -> loss: 0.0002870114381734353, self.slope: [1.06576518 1.06623114], self.intercept: 1.005795498673837\n",
      "iteration - 6052 -> loss: 0.0002869956001967948, self.slope: [1.06577401 1.06624007], self.intercept: 1.0057963146352984\n",
      "iteration - 6053 -> loss: 0.0002869797640242913, self.slope: [1.06578284 1.066249  ], self.intercept: 1.0057971305596818\n",
      "iteration - 6054 -> loss: 0.0002869639296556362, self.slope: [1.06579167 1.06625792], self.intercept: 1.0057979464469915\n",
      "iteration - 6055 -> loss: 0.0002869480970904933, self.slope: [1.0658005  1.06626685], self.intercept: 1.0057987622972313\n",
      "iteration - 6056 -> loss: 0.00028693226632853653, self.slope: [1.06580933 1.06627577], self.intercept: 1.0057995781104054\n",
      "iteration - 6057 -> loss: 0.00028691643736948857, self.slope: [1.06581816 1.0662847 ], self.intercept: 1.005800393886517\n",
      "iteration - 6058 -> loss: 0.0002869006102130104, self.slope: [1.06582699 1.06629362], self.intercept: 1.0058012096255697\n",
      "iteration - 6059 -> loss: 0.00028688478485878533, self.slope: [1.06583582 1.06630255], self.intercept: 1.0058020253275677\n",
      "iteration - 6060 -> loss: 0.0002868689613065346, self.slope: [1.06584465 1.06631147], self.intercept: 1.0058028409925128\n",
      "iteration - 6061 -> loss: 0.00028685313955592763, self.slope: [1.06585348 1.06632039], self.intercept: 1.0058036566204107\n",
      "iteration - 6062 -> loss: 0.0002868373196066466, self.slope: [1.06586231 1.06632932], self.intercept: 1.0058044722112627\n",
      "iteration - 6063 -> loss: 0.0002868215014583838, self.slope: [1.06587113 1.06633824], self.intercept: 1.005805287765074\n",
      "iteration - 6064 -> loss: 0.0002868056851108436, self.slope: [1.06587996 1.06634716], self.intercept: 1.005806103281849\n",
      "iteration - 6065 -> loss: 0.0002867898705636785, self.slope: [1.06588878 1.06635608], self.intercept: 1.0058069187615912\n",
      "iteration - 6066 -> loss: 0.0002867740578166141, self.slope: [1.06589761 1.066365  ], self.intercept: 1.0058077342043055\n",
      "iteration - 6067 -> loss: 0.0002867582468693166, self.slope: [1.06590643 1.06637392], self.intercept: 1.0058085496099924\n",
      "iteration - 6068 -> loss: 0.0002867424377214879, self.slope: [1.06591526 1.06638284], self.intercept: 1.0058093649786561\n",
      "iteration - 6069 -> loss: 0.00028672663037282426, self.slope: [1.06592408 1.06639176], self.intercept: 1.0058101803103017\n",
      "iteration - 6070 -> loss: 0.00028671082482298245, self.slope: [1.0659329  1.06640067], self.intercept: 1.0058109956049326\n",
      "iteration - 6071 -> loss: 0.0002866950210716653, self.slope: [1.06594173 1.06640959], self.intercept: 1.005811810862552\n",
      "iteration - 6072 -> loss: 0.00028667921911859173, self.slope: [1.06595055 1.06641851], self.intercept: 1.0058126260831644\n",
      "iteration - 6073 -> loss: 0.0002866634189634194, self.slope: [1.06595937 1.06642743], self.intercept: 1.0058134412667727\n",
      "iteration - 6074 -> loss: 0.00028664762060584927, self.slope: [1.06596819 1.06643634], self.intercept: 1.0058142564133805\n",
      "iteration - 6075 -> loss: 0.0002866318240455599, self.slope: [1.06597701 1.06644526], self.intercept: 1.0058150715229905\n",
      "iteration - 6076 -> loss: 0.00028661602928225274, self.slope: [1.06598583 1.06645417], self.intercept: 1.0058158865956073\n",
      "iteration - 6077 -> loss: 0.00028660023631560166, self.slope: [1.06599465 1.06646309], self.intercept: 1.0058167016312354\n",
      "iteration - 6078 -> loss: 0.00028658444514530684, self.slope: [1.06600347 1.066472  ], self.intercept: 1.0058175166298777\n",
      "iteration - 6079 -> loss: 0.0002865686557710768, self.slope: [1.06601229 1.06648092], self.intercept: 1.0058183315915386\n",
      "iteration - 6080 -> loss: 0.0002865528681925526, self.slope: [1.06602111 1.06648983], self.intercept: 1.0058191465162214\n",
      "iteration - 6081 -> loss: 0.00028653708240947086, self.slope: [1.06602993 1.06649874], self.intercept: 1.0058199614039294\n",
      "iteration - 6082 -> loss: 0.00028652129842151024, self.slope: [1.06603874 1.06650765], self.intercept: 1.005820776254666\n",
      "iteration - 6083 -> loss: 0.0002865055162283383, self.slope: [1.06604756 1.06651656], self.intercept: 1.0058215910684354\n",
      "iteration - 6084 -> loss: 0.0002864897358296707, self.slope: [1.06605638 1.06652548], self.intercept: 1.0058224058452403\n",
      "iteration - 6085 -> loss: 0.0002864739572251726, self.slope: [1.06606519 1.06653439], self.intercept: 1.005823220585085\n",
      "iteration - 6086 -> loss: 0.0002864581804145608, self.slope: [1.06607401 1.0665433 ], self.intercept: 1.0058240352879748\n",
      "iteration - 6087 -> loss: 0.00028644240539750705, self.slope: [1.06608282 1.06655221], self.intercept: 1.0058248499539109\n",
      "iteration - 6088 -> loss: 0.00028642663217372634, self.slope: [1.06609164 1.06656112], self.intercept: 1.0058256645828982\n",
      "iteration - 6089 -> loss: 0.00028641086074287304, self.slope: [1.06610045 1.06657002], self.intercept: 1.0058264791749405\n",
      "iteration - 6090 -> loss: 0.0002863950911046568, self.slope: [1.06610926 1.06657893], self.intercept: 1.0058272937300403\n",
      "iteration - 6091 -> loss: 0.0002863793232587727, self.slope: [1.06611807 1.06658784], self.intercept: 1.0058281082482017\n",
      "iteration - 6092 -> loss: 0.0002863635572048989, self.slope: [1.06612689 1.06659675], self.intercept: 1.0058289227294277\n",
      "iteration - 6093 -> loss: 0.00028634779294273616, self.slope: [1.0661357  1.06660565], self.intercept: 1.005829737173724\n",
      "iteration - 6094 -> loss: 0.000286332030471966, self.slope: [1.06614451 1.06661456], self.intercept: 1.0058305515810924\n",
      "iteration - 6095 -> loss: 0.000286316269792296, self.slope: [1.06615332 1.06662346], self.intercept: 1.0058313659515372\n",
      "iteration - 6096 -> loss: 0.00028630051090339096, self.slope: [1.06616213 1.06663237], self.intercept: 1.005832180285062\n",
      "iteration - 6097 -> loss: 0.0002862847538049773, self.slope: [1.06617094 1.06664127], self.intercept: 1.0058329945816704\n",
      "iteration - 6098 -> loss: 0.00028626899849670383, self.slope: [1.06617975 1.06665018], self.intercept: 1.0058338088413659\n",
      "iteration - 6099 -> loss: 0.000286253244978287, self.slope: [1.06618856 1.06665908], self.intercept: 1.0058346230641524\n",
      "iteration - 6100 -> loss: 0.0002862374932494371, self.slope: [1.06619736 1.06666798], self.intercept: 1.005835437250035\n",
      "iteration - 6101 -> loss: 0.0002862217433097865, self.slope: [1.06620617 1.06667689], self.intercept: 1.0058362513990147\n",
      "iteration - 6102 -> loss: 0.00028620599515908045, self.slope: [1.06621498 1.06668579], self.intercept: 1.0058370655110973\n",
      "iteration - 6103 -> loss: 0.0002861902487969822, self.slope: [1.06622379 1.06669469], self.intercept: 1.0058378795862857\n",
      "iteration - 6104 -> loss: 0.00028617450422319194, self.slope: [1.06623259 1.06670359], self.intercept: 1.005838693624584\n",
      "iteration - 6105 -> loss: 0.00028615876143741166, self.slope: [1.0662414  1.06671249], self.intercept: 1.005839507625993\n",
      "iteration - 6106 -> loss: 0.00028614302043931825, self.slope: [1.0662502  1.06672139], self.intercept: 1.0058403215905196\n",
      "iteration - 6107 -> loss: 0.00028612728122859603, self.slope: [1.06625901 1.06673029], self.intercept: 1.005841135518166\n",
      "iteration - 6108 -> loss: 0.0002861115438049653, self.slope: [1.06626781 1.06673919], self.intercept: 1.005841949408937\n",
      "iteration - 6109 -> loss: 0.00028609580816808973, self.slope: [1.06627661 1.06674809], self.intercept: 1.0058427632628346\n",
      "iteration - 6110 -> loss: 0.0002860800743176831, self.slope: [1.06628542 1.06675699], self.intercept: 1.0058435770798635\n",
      "iteration - 6111 -> loss: 0.0002860643422534313, self.slope: [1.06629422 1.06676589], self.intercept: 1.0058443908600274\n",
      "iteration - 6112 -> loss: 0.0002860486119750126, self.slope: [1.06630302 1.06677478], self.intercept: 1.0058452046033288\n",
      "iteration - 6113 -> loss: 0.00028603288348211426, self.slope: [1.06631182 1.06678368], self.intercept: 1.0058460183097713\n",
      "iteration - 6114 -> loss: 0.000286017156774464, self.slope: [1.06632062 1.06679258], self.intercept: 1.0058468319793605\n",
      "iteration - 6115 -> loss: 0.00028600143185173637, self.slope: [1.06632942 1.06680147], self.intercept: 1.0058476456120982\n",
      "iteration - 6116 -> loss: 0.0002859857087135911, self.slope: [1.06633822 1.06681037], self.intercept: 1.0058484592079897\n",
      "iteration - 6117 -> loss: 0.00028596998735977344, self.slope: [1.06634702 1.06681926], self.intercept: 1.005849272767037\n",
      "iteration - 6118 -> loss: 0.000285954267789936, self.slope: [1.06635582 1.06682815], self.intercept: 1.0058500862892457\n",
      "iteration - 6119 -> loss: 0.0002859385500038057, self.slope: [1.06636462 1.06683705], self.intercept: 1.005850899774618\n",
      "iteration - 6120 -> loss: 0.00028592283400103195, self.slope: [1.06637342 1.06684594], self.intercept: 1.005851713223158\n",
      "iteration - 6121 -> loss: 0.00028590711978133623, self.slope: [1.06638222 1.06685483], self.intercept: 1.005852526634869\n",
      "iteration - 6122 -> loss: 0.0002858914073444181, self.slope: [1.06639101 1.06686373], self.intercept: 1.0058533400097547\n",
      "iteration - 6123 -> loss: 0.00028587569668994667, self.slope: [1.06639981 1.06687262], self.intercept: 1.0058541533478194\n",
      "iteration - 6124 -> loss: 0.0002858599878176414, self.slope: [1.0664086  1.06688151], self.intercept: 1.0058549666490653\n",
      "iteration - 6125 -> loss: 0.0002858442807271559, self.slope: [1.0664174 1.0668904], self.intercept: 1.0058557799134968\n",
      "iteration - 6126 -> loss: 0.00028582857541822616, self.slope: [1.06642619 1.06689929], self.intercept: 1.0058565931411165\n",
      "iteration - 6127 -> loss: 0.0002858128718905317, self.slope: [1.06643499 1.06690818], self.intercept: 1.0058574063319305\n",
      "iteration - 6128 -> loss: 0.00028579717014374817, self.slope: [1.06644378 1.06691707], self.intercept: 1.0058582194859422\n",
      "iteration - 6129 -> loss: 0.000285781470177573, self.slope: [1.06645258 1.06692596], self.intercept: 1.0058590326031533\n",
      "iteration - 6130 -> loss: 0.00028576577199172884, self.slope: [1.06646137 1.06693484], self.intercept: 1.005859845683568\n",
      "iteration - 6131 -> loss: 0.0002857500755858782, self.slope: [1.06647016 1.06694373], self.intercept: 1.0058606587271892\n",
      "iteration - 6132 -> loss: 0.0002857343809597149, self.slope: [1.06647895 1.06695262], self.intercept: 1.0058614717340224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 6133 -> loss: 0.000285718688112958, self.slope: [1.06648774 1.0669615 ], self.intercept: 1.00586228470407\n",
      "iteration - 6134 -> loss: 0.00028570299704526637, self.slope: [1.06649654 1.06697039], self.intercept: 1.0058630976373364\n",
      "iteration - 6135 -> loss: 0.00028568730775635075, self.slope: [1.06650533 1.06697928], self.intercept: 1.0058639105338254\n",
      "iteration - 6136 -> loss: 0.0002856716202459144, self.slope: [1.06651412 1.06698816], self.intercept: 1.0058647233935383\n",
      "iteration - 6137 -> loss: 0.0002856559345136497, self.slope: [1.06652291 1.06699705], self.intercept: 1.0058655362164808\n",
      "iteration - 6138 -> loss: 0.00028564025055924174, self.slope: [1.06653169 1.06700593], self.intercept: 1.0058663490026571\n",
      "iteration - 6139 -> loss: 0.00028562456838237047, self.slope: [1.06654048 1.06701481], self.intercept: 1.0058671617520687\n",
      "iteration - 6140 -> loss: 0.000285608887982768, self.slope: [1.06654927 1.0670237 ], self.intercept: 1.0058679744647212\n",
      "iteration - 6141 -> loss: 0.00028559320936007696, self.slope: [1.06655806 1.06703258], self.intercept: 1.0058687871406173\n",
      "iteration - 6142 -> loss: 0.00028557753251403853, self.slope: [1.06656684 1.06704146], self.intercept: 1.0058695997797606\n",
      "iteration - 6143 -> loss: 0.00028556185744432766, self.slope: [1.06657563 1.06705034], self.intercept: 1.0058704123821542\n",
      "iteration - 6144 -> loss: 0.0002855461841506261, self.slope: [1.06658442 1.06705922], self.intercept: 1.0058712249478035\n",
      "iteration - 6145 -> loss: 0.00028553051263265853, self.slope: [1.0665932 1.0670681], self.intercept: 1.0058720374767107\n",
      "iteration - 6146 -> loss: 0.00028551484289009225, self.slope: [1.06660199 1.06707698], self.intercept: 1.005872849968879\n",
      "iteration - 6147 -> loss: 0.00028549917492262444, self.slope: [1.06661077 1.06708586], self.intercept: 1.0058736624243128\n",
      "iteration - 6148 -> loss: 0.00028548350872996837, self.slope: [1.06661955 1.06709474], self.intercept: 1.005874474843015\n",
      "iteration - 6149 -> loss: 0.0002854678443118028, self.slope: [1.06662834 1.06710362], self.intercept: 1.0058752872249905\n",
      "iteration - 6150 -> loss: 0.0002854521816678388, self.slope: [1.06663712 1.0671125 ], self.intercept: 1.0058760995702425\n",
      "iteration - 6151 -> loss: 0.00028543652079773623, self.slope: [1.0666459  1.06712138], self.intercept: 1.0058769118787732\n",
      "iteration - 6152 -> loss: 0.0002854208617012286, self.slope: [1.06665469 1.06713025], self.intercept: 1.005877724150589\n",
      "iteration - 6153 -> loss: 0.0002854052043779874, self.slope: [1.06666347 1.06713913], self.intercept: 1.005878536385691\n",
      "iteration - 6154 -> loss: 0.00028538954882770755, self.slope: [1.06667225 1.06714801], self.intercept: 1.005879348584084\n",
      "iteration - 6155 -> loss: 0.0002853738950501028, self.slope: [1.06668103 1.06715688], self.intercept: 1.0058801607457701\n",
      "iteration - 6156 -> loss: 0.0002853582430448524, self.slope: [1.06668981 1.06716576], self.intercept: 1.005880972870755\n",
      "iteration - 6157 -> loss: 0.00028534259281166484, self.slope: [1.06669859 1.06717463], self.intercept: 1.0058817849590425\n",
      "iteration - 6158 -> loss: 0.0002853269443502016, self.slope: [1.06670737 1.06718351], self.intercept: 1.005882597010635\n",
      "iteration - 6159 -> loss: 0.000285311297660215, self.slope: [1.06671614 1.06719238], self.intercept: 1.0058834090255364\n",
      "iteration - 6160 -> loss: 0.0002852956527413438, self.slope: [1.06672492 1.06720125], self.intercept: 1.0058842210037497\n",
      "iteration - 6161 -> loss: 0.00028528000959332804, self.slope: [1.0667337  1.06721012], self.intercept: 1.0058850329452793\n",
      "iteration - 6162 -> loss: 0.0002852643682158213, self.slope: [1.06674248 1.067219  ], self.intercept: 1.005885844850128\n",
      "iteration - 6163 -> loss: 0.0002852487286085457, self.slope: [1.06675125 1.06722787], self.intercept: 1.0058866567183\n",
      "iteration - 6164 -> loss: 0.0002852330907712038, self.slope: [1.06676003 1.06723674], self.intercept: 1.0058874685497994\n",
      "iteration - 6165 -> loss: 0.0002852174547034691, self.slope: [1.0667688  1.06724561], self.intercept: 1.0058882803446294\n",
      "iteration - 6166 -> loss: 0.0002852018204050541, self.slope: [1.06677758 1.06725448], self.intercept: 1.005889092102793\n",
      "iteration - 6167 -> loss: 0.0002851861878756443, self.slope: [1.06678635 1.06726335], self.intercept: 1.0058899038242957\n",
      "iteration - 6168 -> loss: 0.0002851705571149351, self.slope: [1.06679513 1.06727222], self.intercept: 1.0058907155091394\n",
      "iteration - 6169 -> loss: 0.0002851549281226374, self.slope: [1.0668039  1.06728109], self.intercept: 1.005891527157327\n",
      "iteration - 6170 -> loss: 0.00028513930089842473, self.slope: [1.06681267 1.06728996], self.intercept: 1.005892338768864\n",
      "iteration - 6171 -> loss: 0.00028512367544199544, self.slope: [1.06682144 1.06729882], self.intercept: 1.0058931503437525\n",
      "iteration - 6172 -> loss: 0.00028510805175308745, self.slope: [1.06683022 1.06730769], self.intercept: 1.005893961881996\n",
      "iteration - 6173 -> loss: 0.0002850924298313338, self.slope: [1.06683899 1.06731656], self.intercept: 1.0058947733836\n",
      "iteration - 6174 -> loss: 0.0002850768096764955, self.slope: [1.06684776 1.06732542], self.intercept: 1.0058955848485667\n",
      "iteration - 6175 -> loss: 0.0002850611912882128, self.slope: [1.06685653 1.06733429], self.intercept: 1.0058963962768996\n",
      "iteration - 6176 -> loss: 0.0002850455746662075, self.slope: [1.0668653  1.06734315], self.intercept: 1.0058972076686024\n",
      "iteration - 6177 -> loss: 0.0002850299598101637, self.slope: [1.06687407 1.06735202], self.intercept: 1.0058980190236793\n",
      "iteration - 6178 -> loss: 0.0002850143467198021, self.slope: [1.06688284 1.06736088], self.intercept: 1.0058988303421348\n",
      "iteration - 6179 -> loss: 0.0002849987353948005, self.slope: [1.0668916  1.06736975], self.intercept: 1.0058996416239703\n",
      "iteration - 6180 -> loss: 0.00028498312583486173, self.slope: [1.06690037 1.06737861], self.intercept: 1.0059004528691915\n",
      "iteration - 6181 -> loss: 0.0002849675180396861, self.slope: [1.06690914 1.06738747], self.intercept: 1.0059012640778\n",
      "iteration - 6182 -> loss: 0.00028495191200896214, self.slope: [1.06691791 1.06739633], self.intercept: 1.0059020752498\n",
      "iteration - 6183 -> loss: 0.0002849363077423888, self.slope: [1.06692667 1.0674052 ], self.intercept: 1.005902886385195\n",
      "iteration - 6184 -> loss: 0.00028492070523965707, self.slope: [1.06693544 1.06741406], self.intercept: 1.0059036974839906\n",
      "iteration - 6185 -> loss: 0.0002849051045004836, self.slope: [1.0669442  1.06742292], self.intercept: 1.0059045085461873\n",
      "iteration - 6186 -> loss: 0.000284889505524541, self.slope: [1.06695297 1.06743178], self.intercept: 1.005905319571791\n",
      "iteration - 6187 -> loss: 0.0002848739083115601, self.slope: [1.06696173 1.06744064], self.intercept: 1.005906130560804\n",
      "iteration - 6188 -> loss: 0.0002848583128611977, self.slope: [1.0669705 1.0674495], self.intercept: 1.005906941513231\n",
      "iteration - 6189 -> loss: 0.000284842719173183, self.slope: [1.06697926 1.06745835], self.intercept: 1.0059077524290752\n",
      "iteration - 6190 -> loss: 0.0002848271272471982, self.slope: [1.06698802 1.06746721], self.intercept: 1.0059085633083396\n",
      "iteration - 6191 -> loss: 0.0002848115370829433, self.slope: [1.06699678 1.06747607], self.intercept: 1.005909374151028\n",
      "iteration - 6192 -> loss: 0.00028479594868011647, self.slope: [1.06700555 1.06748493], self.intercept: 1.0059101849571437\n",
      "iteration - 6193 -> loss: 0.0002847803620384049, self.slope: [1.06701431 1.06749378], self.intercept: 1.0059109957266923\n",
      "iteration - 6194 -> loss: 0.00028476477715751576, self.slope: [1.06702307 1.06750264], self.intercept: 1.0059118064596742\n",
      "iteration - 6195 -> loss: 0.00028474919403717597, self.slope: [1.06703183 1.0675115 ], self.intercept: 1.0059126171560961\n",
      "iteration - 6196 -> loss: 0.0002847336126770296, self.slope: [1.06704059 1.06752035], self.intercept: 1.0059134278159587\n",
      "iteration - 6197 -> loss: 0.00028471803307680035, self.slope: [1.06704935 1.06752921], self.intercept: 1.0059142384392683\n",
      "iteration - 6198 -> loss: 0.0002847024552361963, self.slope: [1.06705811 1.06753806], self.intercept: 1.0059150490260262\n",
      "iteration - 6199 -> loss: 0.00028468687915491036, self.slope: [1.06706687 1.06754691], self.intercept: 1.005915859576238\n",
      "iteration - 6200 -> loss: 0.0002846713048326182, self.slope: [1.06707562 1.06755577], self.intercept: 1.005916670089906\n",
      "iteration - 6201 -> loss: 0.00028465573226905364, self.slope: [1.06708438 1.06756462], self.intercept: 1.0059174805670337\n",
      "iteration - 6202 -> loss: 0.00028464016146387646, self.slope: [1.06709314 1.06757347], self.intercept: 1.0059182910076252\n",
      "iteration - 6203 -> loss: 0.0002846245924168155, self.slope: [1.06710189 1.06758232], self.intercept: 1.0059191014116844\n",
      "iteration - 6204 -> loss: 0.0002846090251275662, self.slope: [1.06711065 1.06759117], self.intercept: 1.0059199117792157\n",
      "iteration - 6205 -> loss: 0.00028459345959581397, self.slope: [1.0671194  1.06760002], self.intercept: 1.0059207221102195\n",
      "iteration - 6206 -> loss: 0.0002845778958212738, self.slope: [1.06712816 1.06760887], self.intercept: 1.0059215324047015\n",
      "iteration - 6207 -> loss: 0.0002845623338036209, self.slope: [1.06713691 1.06761772], self.intercept: 1.0059223426626664\n",
      "iteration - 6208 -> loss: 0.0002845467735425723, self.slope: [1.06714567 1.06762657], self.intercept: 1.0059231528841157\n",
      "iteration - 6209 -> loss: 0.0002845312150378181, self.slope: [1.06715442 1.06763542], self.intercept: 1.0059239630690533\n",
      "iteration - 6210 -> loss: 0.0002845156582890536, self.slope: [1.06716317 1.06764427], self.intercept: 1.0059247732174839\n",
      "iteration - 6211 -> loss: 0.00028450010329600443, self.slope: [1.06717193 1.06765312], self.intercept: 1.0059255833294105\n",
      "iteration - 6212 -> loss: 0.0002844845500583395, self.slope: [1.06718068 1.06766197], self.intercept: 1.0059263934048366\n",
      "iteration - 6213 -> loss: 0.0002844689985757585, self.slope: [1.06718943 1.06767081], self.intercept: 1.0059272034437652\n",
      "iteration - 6214 -> loss: 0.00028445344884797696, self.slope: [1.06719818 1.06767966], self.intercept: 1.0059280134462019\n",
      "iteration - 6215 -> loss: 0.00028443790087469907, self.slope: [1.06720693 1.0676885 ], self.intercept: 1.0059288234121484\n",
      "iteration - 6216 -> loss: 0.00028442235465559243, self.slope: [1.06721568 1.06769735], self.intercept: 1.0059296333416086\n",
      "iteration - 6217 -> loss: 0.0002844068101904008, self.slope: [1.06722443 1.06770619], self.intercept: 1.0059304432345852\n",
      "iteration - 6218 -> loss: 0.0002843912674787856, self.slope: [1.06723318 1.06771504], self.intercept: 1.0059312530910842\n",
      "iteration - 6219 -> loss: 0.00028437572652046056, self.slope: [1.06724193 1.06772388], self.intercept: 1.0059320629111081\n",
      "iteration - 6220 -> loss: 0.00028436018731511984, self.slope: [1.06725067 1.06773273], self.intercept: 1.0059328726946606\n",
      "iteration - 6221 -> loss: 0.00028434464986247125, self.slope: [1.06725942 1.06774157], self.intercept: 1.0059336824417437\n",
      "iteration - 6222 -> loss: 0.0002843291141622132, self.slope: [1.06726817 1.06775041], self.intercept: 1.005934492152362\n",
      "iteration - 6223 -> loss: 0.00028431358021404273, self.slope: [1.06727691 1.06775925], self.intercept: 1.00593530182652\n",
      "iteration - 6224 -> loss: 0.0002842980480176515, self.slope: [1.06728566 1.06776809], self.intercept: 1.00593611146422\n",
      "iteration - 6225 -> loss: 0.00028428251757275767, self.slope: [1.06729441 1.06777693], self.intercept: 1.0059369210654663\n",
      "iteration - 6226 -> loss: 0.0002842669888790529, self.slope: [1.06730315 1.06778577], self.intercept: 1.0059377306302628\n",
      "iteration - 6227 -> loss: 0.00028425146193622317, self.slope: [1.06731189 1.06779461], self.intercept: 1.0059385401586125\n",
      "iteration - 6228 -> loss: 0.0002842359367440001, self.slope: [1.06732064 1.06780345], self.intercept: 1.005939349650518\n",
      "iteration - 6229 -> loss: 0.00028422041330205134, self.slope: [1.06732938 1.06781229], self.intercept: 1.0059401591059847\n",
      "iteration - 6230 -> loss: 0.00028420489161009715, self.slope: [1.06733812 1.06782113], self.intercept: 1.0059409685250167\n",
      "iteration - 6231 -> loss: 0.0002841893716678365, self.slope: [1.06734687 1.06782997], self.intercept: 1.0059417779076139\n",
      "iteration - 6232 -> loss: 0.0002841738534749484, self.slope: [1.06735561 1.06783881], self.intercept: 1.0059425872537826\n",
      "iteration - 6233 -> loss: 0.00028415833703115826, self.slope: [1.06736435 1.06784764], self.intercept: 1.0059433965635267\n",
      "iteration - 6234 -> loss: 0.000284142822336164, self.slope: [1.06737309 1.06785648], self.intercept: 1.005944205836849\n",
      "iteration - 6235 -> loss: 0.0002841273093896393, self.slope: [1.06738183 1.06786531], self.intercept: 1.005945015073753\n",
      "iteration - 6236 -> loss: 0.0002841117981913306, self.slope: [1.06739057 1.06787415], self.intercept: 1.0059458242742427\n",
      "iteration - 6237 -> loss: 0.00028409628874089877, self.slope: [1.06739931 1.06788299], self.intercept: 1.0059466334383214\n",
      "iteration - 6238 -> loss: 0.0002840807810380783, self.slope: [1.06740805 1.06789182], self.intercept: 1.005947442565992\n",
      "iteration - 6239 -> loss: 0.00028406527508252627, self.slope: [1.06741679 1.06790065], self.intercept: 1.0059482516572593\n",
      "iteration - 6240 -> loss: 0.000284049770873986, self.slope: [1.06742553 1.06790949], self.intercept: 1.0059490607121275\n",
      "iteration - 6241 -> loss: 0.00028403426841213617, self.slope: [1.06743426 1.06791832], self.intercept: 1.005949869730598\n",
      "iteration - 6242 -> loss: 0.00028401876769669563, self.slope: [1.067443   1.06792715], self.intercept: 1.005950678712676\n",
      "iteration - 6243 -> loss: 0.0002840032687273276, self.slope: [1.06745174 1.06793598], self.intercept: 1.0059514876583633\n",
      "iteration - 6244 -> loss: 0.0002839877715037588, self.slope: [1.06746047 1.06794482], self.intercept: 1.005952296567665\n",
      "iteration - 6245 -> loss: 0.00028397227602570556, self.slope: [1.06746921 1.06795365], self.intercept: 1.005953105440584\n",
      "iteration - 6246 -> loss: 0.00028395678229284826, self.slope: [1.06747794 1.06796248], self.intercept: 1.0059539142771243\n",
      "iteration - 6247 -> loss: 0.0002839412903049059, self.slope: [1.06748668 1.06797131], self.intercept: 1.00595472307729\n",
      "iteration - 6248 -> loss: 0.00028392580006156493, self.slope: [1.06749541 1.06798014], self.intercept: 1.0059555318410853\n",
      "iteration - 6249 -> loss: 0.0002839103115624988, self.slope: [1.06750414 1.06798896], self.intercept: 1.0059563405685104\n",
      "iteration - 6250 -> loss: 0.0002838948248074738, self.slope: [1.06751288 1.06799779], self.intercept: 1.0059571492595702\n",
      "iteration - 6251 -> loss: 0.00028387933979614577, self.slope: [1.06752161 1.06800662], self.intercept: 1.0059579579142692\n",
      "iteration - 6252 -> loss: 0.0002838638565282232, self.slope: [1.06753034 1.06801545], self.intercept: 1.005958766532612\n",
      "iteration - 6253 -> loss: 0.0002838483750034273, self.slope: [1.06753907 1.06802428], self.intercept: 1.0059595751145987\n",
      "iteration - 6254 -> loss: 0.00028383289522143634, self.slope: [1.0675478 1.0680331], self.intercept: 1.0059603836602362\n",
      "iteration - 6255 -> loss: 0.00028381741718195224, self.slope: [1.06755653 1.06804193], self.intercept: 1.0059611921695273\n",
      "iteration - 6256 -> loss: 0.00028380194088470633, self.slope: [1.06756526 1.06805075], self.intercept: 1.005962000642474\n",
      "iteration - 6257 -> loss: 0.00028378646632937004, self.slope: [1.06757399 1.06805958], self.intercept: 1.0059628090790826\n",
      "iteration - 6258 -> loss: 0.00028377099351566283, self.slope: [1.06758272 1.0680684 ], self.intercept: 1.0059636174793543\n",
      "iteration - 6259 -> loss: 0.0002837555224432621, self.slope: [1.06759145 1.06807723], self.intercept: 1.0059644258432927\n",
      "iteration - 6260 -> loss: 0.00028374005311192023, self.slope: [1.06760018 1.06808605], self.intercept: 1.005965234170903\n",
      "iteration - 6261 -> loss: 0.00028372458552128435, self.slope: [1.06760891 1.06809487], self.intercept: 1.0059660424621886\n",
      "iteration - 6262 -> loss: 0.000283709119671086, self.slope: [1.06761763 1.0681037 ], self.intercept: 1.0059668507171518\n",
      "iteration - 6263 -> loss: 0.00028369365556102924, self.slope: [1.06762636 1.06811252], self.intercept: 1.0059676589357969\n",
      "iteration - 6264 -> loss: 0.0002836781931907987, self.slope: [1.06763509 1.06812134], self.intercept: 1.0059684671181268\n",
      "iteration - 6265 -> loss: 0.00028366273256011284, self.slope: [1.06764381 1.06813016], self.intercept: 1.0059692752641463\n",
      "iteration - 6266 -> loss: 0.00028364727366865625, self.slope: [1.06765254 1.06813898], self.intercept: 1.0059700833738576\n",
      "iteration - 6267 -> loss: 0.0002836318165161643, self.slope: [1.06766126 1.0681478 ], self.intercept: 1.0059708914472651\n",
      "iteration - 6268 -> loss: 0.000283616361102317, self.slope: [1.06766998 1.06815662], self.intercept: 1.0059716994843726\n",
      "iteration - 6269 -> loss: 0.0002836009074268183, self.slope: [1.06767871 1.06816544], self.intercept: 1.0059725074851829\n",
      "iteration - 6270 -> loss: 0.00028358545548936323, self.slope: [1.06768743 1.06817426], self.intercept: 1.005973315449699\n",
      "iteration - 6271 -> loss: 0.00028357000528967774, self.slope: [1.06769615 1.06818308], self.intercept: 1.0059741233779242\n",
      "iteration - 6272 -> loss: 0.0002835545568274376, self.slope: [1.06770487 1.06819189], self.intercept: 1.0059749312698636\n",
      "iteration - 6273 -> loss: 0.00028353911010238145, self.slope: [1.0677136  1.06820071], self.intercept: 1.005975739125521\n",
      "iteration - 6274 -> loss: 0.00028352366511418935, self.slope: [1.06772232 1.06820953], self.intercept: 1.0059765469448991\n",
      "iteration - 6275 -> loss: 0.0002835082218625522, self.slope: [1.06773104 1.06821834], self.intercept: 1.005977354728001\n",
      "iteration - 6276 -> loss: 0.00028349278034719787, self.slope: [1.06773976 1.06822716], self.intercept: 1.005978162474831\n",
      "iteration - 6277 -> loss: 0.00028347734056782136, self.slope: [1.06774848 1.06823597], self.intercept: 1.005978970185392\n",
      "iteration - 6278 -> loss: 0.00028346190252412, self.slope: [1.0677572  1.06824479], self.intercept: 1.005979777859689\n",
      "iteration - 6279 -> loss: 0.0002834464662158076, self.slope: [1.06776592 1.0682536 ], self.intercept: 1.0059805854977242\n",
      "iteration - 6280 -> loss: 0.00028343103164258065, self.slope: [1.06777463 1.06826242], self.intercept: 1.0059813930995012\n",
      "iteration - 6281 -> loss: 0.00028341559880414486, self.slope: [1.06778335 1.06827123], self.intercept: 1.005982200665024\n",
      "iteration - 6282 -> loss: 0.0002834001677002014, self.slope: [1.06779207 1.06828004], self.intercept: 1.0059830081942964\n",
      "iteration - 6283 -> loss: 0.00028338473833044406, self.slope: [1.06780078 1.06828885], self.intercept: 1.005983815687321\n",
      "iteration - 6284 -> loss: 0.0002833693106946101, self.slope: [1.0678095  1.06829767], self.intercept: 1.005984623144102\n",
      "iteration - 6285 -> loss: 0.0002833538847923711, self.slope: [1.06781822 1.06830648], self.intercept: 1.0059854305646425\n",
      "iteration - 6286 -> loss: 0.0002833384606234497, self.slope: [1.06782693 1.06831529], self.intercept: 1.0059862379489464\n",
      "iteration - 6287 -> loss: 0.0002833230381875361, self.slope: [1.06783565 1.0683241 ], self.intercept: 1.0059870452970165\n",
      "iteration - 6288 -> loss: 0.0002833076174843468, self.slope: [1.06784436 1.06833291], self.intercept: 1.0059878526088566\n",
      "iteration - 6289 -> loss: 0.00028329219851357974, self.slope: [1.06785307 1.06834172], self.intercept: 1.0059886598844714\n",
      "iteration - 6290 -> loss: 0.0002832767812749478, self.slope: [1.06786179 1.06835053], self.intercept: 1.0059894671238645\n",
      "iteration - 6291 -> loss: 0.0002832613657681401, self.slope: [1.0678705  1.06835933], self.intercept: 1.0059902743270384\n",
      "iteration - 6292 -> loss: 0.00028324595199286497, self.slope: [1.06787921 1.06836814], self.intercept: 1.0059910814939963\n",
      "iteration - 6293 -> loss: 0.00028323053994883866, self.slope: [1.06788792 1.06837695], self.intercept: 1.0059918886247419\n",
      "iteration - 6294 -> loss: 0.0002832151296357591, self.slope: [1.06789663 1.06838576], self.intercept: 1.0059926957192797\n",
      "iteration - 6295 -> loss: 0.0002831997210533136, self.slope: [1.06790534 1.06839456], self.intercept: 1.0059935027776132\n",
      "iteration - 6296 -> loss: 0.0002831843142012335, self.slope: [1.06791405 1.06840337], self.intercept: 1.0059943097997455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 6297 -> loss: 0.0002831689090792217, self.slope: [1.06792276 1.06841217], self.intercept: 1.0059951167856795\n",
      "iteration - 6298 -> loss: 0.00028315350568697864, self.slope: [1.06793147 1.06842098], self.intercept: 1.005995923735419\n",
      "iteration - 6299 -> loss: 0.0002831381040241838, self.slope: [1.06794018 1.06842978], self.intercept: 1.005996730648969\n",
      "iteration - 6300 -> loss: 0.0002831227040905738, self.slope: [1.06794889 1.06843859], self.intercept: 1.0059975375263315\n",
      "iteration - 6301 -> loss: 0.0002831073058858465, self.slope: [1.0679576  1.06844739], self.intercept: 1.0059983443675098\n",
      "iteration - 6302 -> loss: 0.00028309190940969855, self.slope: [1.0679663  1.06845619], self.intercept: 1.0059991511725075\n",
      "iteration - 6303 -> loss: 0.00028307651466185285, self.slope: [1.06797501 1.06846499], self.intercept: 1.0059999579413297\n",
      "iteration - 6304 -> loss: 0.000283061121642003, self.slope: [1.06798372 1.0684738 ], self.intercept: 1.0060007646739788\n",
      "iteration - 6305 -> loss: 0.0002830457303498386, self.slope: [1.06799242 1.0684826 ], self.intercept: 1.0060015713704586\n",
      "iteration - 6306 -> loss: 0.00028303034078508644, self.slope: [1.06800113 1.0684914 ], self.intercept: 1.0060023780307732\n",
      "iteration - 6307 -> loss: 0.00028301495294744524, self.slope: [1.06800983 1.0685002 ], self.intercept: 1.0060031846549249\n",
      "iteration - 6308 -> loss: 0.0002829995668366285, self.slope: [1.06801854 1.068509  ], self.intercept: 1.006003991242917\n",
      "iteration - 6309 -> loss: 0.00028298418245233206, self.slope: [1.06802724 1.0685178 ], self.intercept: 1.0060047977947542\n",
      "iteration - 6310 -> loss: 0.0002829687997942547, self.slope: [1.06803594 1.0685266 ], self.intercept: 1.0060056043104408\n",
      "iteration - 6311 -> loss: 0.00028295341886211303, self.slope: [1.06804465 1.0685354 ], self.intercept: 1.0060064107899793\n",
      "iteration - 6312 -> loss: 0.00028293803965563126, self.slope: [1.06805335 1.06854419], self.intercept: 1.006007217233373\n",
      "iteration - 6313 -> loss: 0.000282922662174465, self.slope: [1.06806205 1.06855299], self.intercept: 1.0060080236406255\n",
      "iteration - 6314 -> loss: 0.0002829072864183806, self.slope: [1.06807075 1.06856179], self.intercept: 1.0060088300117396\n",
      "iteration - 6315 -> loss: 0.0002828919123870316, self.slope: [1.06807945 1.06857059], self.intercept: 1.0060096363467197\n",
      "iteration - 6316 -> loss: 0.0002828765400801534, self.slope: [1.06808815 1.06857938], self.intercept: 1.0060104426455696\n",
      "iteration - 6317 -> loss: 0.00028286116949744264, self.slope: [1.06809685 1.06858818], self.intercept: 1.0060112489082913\n",
      "iteration - 6318 -> loss: 0.00028284580063861557, self.slope: [1.06810555 1.06859697], self.intercept: 1.00601205513489\n",
      "iteration - 6319 -> loss: 0.00028283043350337374, self.slope: [1.06811425 1.06860577], self.intercept: 1.0060128613253696\n",
      "iteration - 6320 -> loss: 0.00028281506809141847, self.slope: [1.06812295 1.06861456], self.intercept: 1.0060136674797318\n",
      "iteration - 6321 -> loss: 0.00028279970440245523, self.slope: [1.06813165 1.06862335], self.intercept: 1.0060144735979804\n",
      "iteration - 6322 -> loss: 0.00028278434243619833, self.slope: [1.06814034 1.06863215], self.intercept: 1.0060152796801205\n",
      "iteration - 6323 -> loss: 0.0002827689821923432, self.slope: [1.06814904 1.06864094], self.intercept: 1.0060160857261562\n",
      "iteration - 6324 -> loss: 0.0002827536236706079, self.slope: [1.06815774 1.06864973], self.intercept: 1.0060168917360872\n",
      "iteration - 6325 -> loss: 0.0002827382668706783, self.slope: [1.06816643 1.06865852], self.intercept: 1.006017697709921\n",
      "iteration - 6326 -> loss: 0.0002827229117923047, self.slope: [1.06817513 1.06866731], self.intercept: 1.006018503647659\n",
      "iteration - 6327 -> loss: 0.000282707558435164, self.slope: [1.06818382 1.0686761 ], self.intercept: 1.006019309549304\n",
      "iteration - 6328 -> loss: 0.0002826922067989568, self.slope: [1.06819252 1.06868489], self.intercept: 1.006020115414862\n",
      "iteration - 6329 -> loss: 0.0002826768568833951, self.slope: [1.06820121 1.06869368], self.intercept: 1.0060209212443347\n",
      "iteration - 6330 -> loss: 0.0002826615086881872, self.slope: [1.06820991 1.06870247], self.intercept: 1.0060217270377265\n",
      "iteration - 6331 -> loss: 0.00028264616221306005, self.slope: [1.0682186  1.06871126], self.intercept: 1.0060225327950403\n",
      "iteration - 6332 -> loss: 0.00028263081745769346, self.slope: [1.06822729 1.06872005], self.intercept: 1.0060233385162805\n",
      "iteration - 6333 -> loss: 0.00028261547442179395, self.slope: [1.06823598 1.06872884], self.intercept: 1.0060241442014497\n",
      "iteration - 6334 -> loss: 0.0002826001331050945, self.slope: [1.06824467 1.06873763], self.intercept: 1.0060249498505507\n",
      "iteration - 6335 -> loss: 0.0002825847935072801, self.slope: [1.06825336 1.06874641], self.intercept: 1.0060257554635896\n",
      "iteration - 6336 -> loss: 0.0002825694556280736, self.slope: [1.06826206 1.0687552 ], self.intercept: 1.0060265610405683\n",
      "iteration - 6337 -> loss: 0.0002825541194671571, self.slope: [1.06827075 1.06876398], self.intercept: 1.0060273665814898\n",
      "iteration - 6338 -> loss: 0.00028253878502427387, self.slope: [1.06827943 1.06877277], self.intercept: 1.0060281720863586\n",
      "iteration - 6339 -> loss: 0.00028252345229911533, self.slope: [1.06828812 1.06878155], self.intercept: 1.0060289775551772\n",
      "iteration - 6340 -> loss: 0.0002825081212913663, self.slope: [1.06829681 1.06879034], self.intercept: 1.006029782987949\n",
      "iteration - 6341 -> loss: 0.0002824927920007706, self.slope: [1.0683055  1.06879912], self.intercept: 1.0060305883846798\n",
      "iteration - 6342 -> loss: 0.0002824774644270155, self.slope: [1.06831419 1.0688079 ], self.intercept: 1.0060313937453704\n",
      "iteration - 6343 -> loss: 0.00028246213856982785, self.slope: [1.06832287 1.06881669], self.intercept: 1.0060321990700267\n",
      "iteration - 6344 -> loss: 0.0002824468144288764, self.slope: [1.06833156 1.06882547], self.intercept: 1.0060330043586498\n",
      "iteration - 6345 -> loss: 0.00028243149200391453, self.slope: [1.06834025 1.06883425], self.intercept: 1.0060338096112453\n",
      "iteration - 6346 -> loss: 0.0002824161712946194, self.slope: [1.06834893 1.06884303], self.intercept: 1.0060346148278148\n",
      "iteration - 6347 -> loss: 0.0002824008523007263, self.slope: [1.06835762 1.06885181], self.intercept: 1.0060354200083645\n",
      "iteration - 6348 -> loss: 0.00028238553502190977, self.slope: [1.0683663  1.06886059], self.intercept: 1.006036225152896\n",
      "iteration - 6349 -> loss: 0.00028237021945791153, self.slope: [1.06837499 1.06886937], self.intercept: 1.0060370302614137\n",
      "iteration - 6350 -> loss: 0.0002823549056084164, self.slope: [1.06838367 1.06887815], self.intercept: 1.006037835333921\n",
      "iteration - 6351 -> loss: 0.0002823395934731463, self.slope: [1.06839235 1.06888693], self.intercept: 1.0060386403704196\n",
      "iteration - 6352 -> loss: 0.00028232428305178576, self.slope: [1.06840104 1.06889571], self.intercept: 1.0060394453709132\n",
      "iteration - 6353 -> loss: 0.0002823089743440798, self.slope: [1.06840972 1.06890449], self.intercept: 1.0060402503354062\n",
      "iteration - 6354 -> loss: 0.00028229366734972694, self.slope: [1.0684184  1.06891327], self.intercept: 1.0060410552639043\n",
      "iteration - 6355 -> loss: 0.00028227836206839963, self.slope: [1.06842708 1.06892204], self.intercept: 1.0060418601564074\n",
      "iteration - 6356 -> loss: 0.00028226305849985035, self.slope: [1.06843576 1.06893082], self.intercept: 1.0060426650129222\n",
      "iteration - 6357 -> loss: 0.0002822477566437733, self.slope: [1.06844444 1.0689396 ], self.intercept: 1.0060434698334504\n",
      "iteration - 6358 -> loss: 0.00028223245649988227, self.slope: [1.06845312 1.06894837], self.intercept: 1.0060442746179952\n",
      "iteration - 6359 -> loss: 0.0002822171580678673, self.slope: [1.0684618  1.06895715], self.intercept: 1.0060450793665618\n",
      "iteration - 6360 -> loss: 0.0002822018613474629, self.slope: [1.06847048 1.06896592], self.intercept: 1.0060458840791513\n",
      "iteration - 6361 -> loss: 0.0002821865663383601, self.slope: [1.06847916 1.06897469], self.intercept: 1.00604668875577\n",
      "iteration - 6362 -> loss: 0.000282171273040264, self.slope: [1.06848783 1.06898347], self.intercept: 1.0060474933964172\n",
      "iteration - 6363 -> loss: 0.0002821559814529141, self.slope: [1.06849651 1.06899224], self.intercept: 1.0060482980010994\n",
      "iteration - 6364 -> loss: 0.00028214069157597856, self.slope: [1.06850519 1.06900101], self.intercept: 1.006049102569821\n",
      "iteration - 6365 -> loss: 0.00028212540340921536, self.slope: [1.06851386 1.06900979], self.intercept: 1.0060499071025846\n",
      "iteration - 6366 -> loss: 0.0002821101169522897, self.slope: [1.06852254 1.06901856], self.intercept: 1.0060507115993933\n",
      "iteration - 6367 -> loss: 0.0002820948322049201, self.slope: [1.06853122 1.06902733], self.intercept: 1.006051516060251\n",
      "iteration - 6368 -> loss: 0.0002820795491668353, self.slope: [1.06853989 1.0690361 ], self.intercept: 1.0060523204851604\n",
      "iteration - 6369 -> loss: 0.0002820642678377219, self.slope: [1.06854856 1.06904487], self.intercept: 1.006053124874126\n",
      "iteration - 6370 -> loss: 0.00028204898821730987, self.slope: [1.06855724 1.06905364], self.intercept: 1.00605392922715\n",
      "iteration - 6371 -> loss: 0.0002820337103052968, self.slope: [1.06856591 1.06906241], self.intercept: 1.0060547335442362\n",
      "iteration - 6372 -> loss: 0.0002820184341013908, self.slope: [1.06857458 1.06907118], self.intercept: 1.0060555378253893\n",
      "iteration - 6373 -> loss: 0.00028200315960529894, self.slope: [1.06858326 1.06907994], self.intercept: 1.0060563420706115\n",
      "iteration - 6374 -> loss: 0.0002819878868167695, self.slope: [1.06859193 1.06908871], self.intercept: 1.0060571462799075\n",
      "iteration - 6375 -> loss: 0.00028197261573546415, self.slope: [1.0686006  1.06909748], self.intercept: 1.0060579504532798\n",
      "iteration - 6376 -> loss: 0.00028195734636111665, self.slope: [1.06860927 1.06910625], self.intercept: 1.0060587545907316\n",
      "iteration - 6377 -> loss: 0.0002819420786934164, self.slope: [1.06861794 1.06911501], self.intercept: 1.0060595586922678\n",
      "iteration - 6378 -> loss: 0.0002819268127320949, self.slope: [1.06862661 1.06912378], self.intercept: 1.0060603627578917\n",
      "iteration - 6379 -> loss: 0.00028191154847685934, self.slope: [1.06863528 1.06913254], self.intercept: 1.0060611667876063\n",
      "iteration - 6380 -> loss: 0.0002818962859274081, self.slope: [1.06864395 1.06914131], self.intercept: 1.0060619707814142\n",
      "iteration - 6381 -> loss: 0.0002818810250834694, self.slope: [1.06865262 1.06915007], self.intercept: 1.0060627747393196\n",
      "iteration - 6382 -> loss: 0.0002818657659447512, self.slope: [1.06866128 1.06915884], self.intercept: 1.0060635786613272\n",
      "iteration - 6383 -> loss: 0.0002818505085109601, self.slope: [1.06866995 1.0691676 ], self.intercept: 1.0060643825474405\n",
      "iteration - 6384 -> loss: 0.000281835252781784, self.slope: [1.06867862 1.06917636], self.intercept: 1.0060651863976593\n",
      "iteration - 6385 -> loss: 0.0002818199987569642, self.slope: [1.06868729 1.06918512], self.intercept: 1.00606599021199\n",
      "iteration - 6386 -> loss: 0.00028180474643618963, self.slope: [1.06869595 1.06919389], self.intercept: 1.006066793990436\n",
      "iteration - 6387 -> loss: 0.00028178949581920585, self.slope: [1.06870462 1.06920265], self.intercept: 1.0060675977330027\n",
      "iteration - 6388 -> loss: 0.0002817742469056611, self.slope: [1.06871328 1.06921141], self.intercept: 1.0060684014396895\n",
      "iteration - 6389 -> loss: 0.0002817589996953318, self.slope: [1.06872195 1.06922017], self.intercept: 1.006069205110502\n",
      "iteration - 6390 -> loss: 0.00028174375418789924, self.slope: [1.06873061 1.06922893], self.intercept: 1.006070008745442\n",
      "iteration - 6391 -> loss: 0.0002817285103830819, self.slope: [1.06873927 1.06923769], self.intercept: 1.0060708123445155\n",
      "iteration - 6392 -> loss: 0.00028171326828059664, self.slope: [1.06874794 1.06924645], self.intercept: 1.0060716159077259\n",
      "iteration - 6393 -> loss: 0.0002816980278801252, self.slope: [1.0687566  1.06925521], self.intercept: 1.0060724194350763\n",
      "iteration - 6394 -> loss: 0.000281682789181407, self.slope: [1.06876526 1.06926396], self.intercept: 1.0060732229265692\n",
      "iteration - 6395 -> loss: 0.00028166755218413147, self.slope: [1.06877392 1.06927272], self.intercept: 1.0060740263822079\n",
      "iteration - 6396 -> loss: 0.00028165231688803547, self.slope: [1.06878258 1.06928148], self.intercept: 1.0060748298019984\n",
      "iteration - 6397 -> loss: 0.00028163708329281974, self.slope: [1.06879124 1.06929023], self.intercept: 1.0060756331859402\n",
      "iteration - 6398 -> loss: 0.00028162185139820256, self.slope: [1.0687999  1.06929899], self.intercept: 1.0060764365340402\n",
      "iteration - 6399 -> loss: 0.0002816066212038763, self.slope: [1.06880856 1.06930775], self.intercept: 1.006077239846301\n",
      "iteration - 6400 -> loss: 0.00028159139270955756, self.slope: [1.06881722 1.0693165 ], self.intercept: 1.0060780431227245\n",
      "iteration - 6401 -> loss: 0.00028157616591497096, self.slope: [1.06882588 1.06932526], self.intercept: 1.0060788463633166\n",
      "iteration - 6402 -> loss: 0.0002815609408198226, self.slope: [1.06883454 1.06933401], self.intercept: 1.006079649568079\n",
      "iteration - 6403 -> loss: 0.0002815457174238282, self.slope: [1.0688432  1.06934276], self.intercept: 1.0060804527370169\n",
      "iteration - 6404 -> loss: 0.00028153049572668745, self.slope: [1.06885185 1.06935152], self.intercept: 1.0060812558701318\n",
      "iteration - 6405 -> loss: 0.00028151527572813187, self.slope: [1.06886051 1.06936027], self.intercept: 1.0060820589674273\n",
      "iteration - 6406 -> loss: 0.0002815000574278432, self.slope: [1.06886917 1.06936902], self.intercept: 1.0060828620289084\n",
      "iteration - 6407 -> loss: 0.00028148484082555743, self.slope: [1.06887782 1.06937777], self.intercept: 1.0060836650545784\n",
      "iteration - 6408 -> loss: 0.0002814696259209893, self.slope: [1.06888648 1.06938652], self.intercept: 1.006084468044441\n",
      "iteration - 6409 -> loss: 0.00028145441271383706, self.slope: [1.06889513 1.06939528], self.intercept: 1.0060852709984969\n",
      "iteration - 6410 -> loss: 0.0002814392012038227, self.slope: [1.06890379 1.06940403], self.intercept: 1.006086073916751\n",
      "iteration - 6411 -> loss: 0.0002814239913906476, self.slope: [1.06891244 1.06941278], self.intercept: 1.0060868767992084\n",
      "iteration - 6412 -> loss: 0.0002814087832740431, self.slope: [1.06892109 1.06942152], self.intercept: 1.006087679645871\n",
      "iteration - 6413 -> loss: 0.00028139357685370446, self.slope: [1.06892975 1.06943027], self.intercept: 1.006088482456744\n",
      "iteration - 6414 -> loss: 0.0002813783721293343, self.slope: [1.0689384  1.06943902], self.intercept: 1.0060892852318297\n",
      "iteration - 6415 -> loss: 0.00028136316910068985, self.slope: [1.06894705 1.06944777], self.intercept: 1.0060900879711303\n",
      "iteration - 6416 -> loss: 0.0002813479677674289, self.slope: [1.0689557  1.06945652], self.intercept: 1.0060908906746509\n",
      "iteration - 6417 -> loss: 0.00028133276812931604, self.slope: [1.06896435 1.06946526], self.intercept: 1.0060916933423951\n",
      "iteration - 6418 -> loss: 0.00028131757018603104, self.slope: [1.068973   1.06947401], self.intercept: 1.0060924959743653\n",
      "iteration - 6419 -> loss: 0.0002813023739372749, self.slope: [1.06898165 1.06948276], self.intercept: 1.0060932985705657\n",
      "iteration - 6420 -> loss: 0.0002812871793827838, self.slope: [1.0689903 1.0694915], self.intercept: 1.0060941011309992\n",
      "iteration - 6421 -> loss: 0.00028127198652228203, self.slope: [1.06899895 1.06950025], self.intercept: 1.0060949036556701\n",
      "iteration - 6422 -> loss: 0.0002812567953554647, self.slope: [1.0690076  1.06950899], self.intercept: 1.006095706144581\n",
      "iteration - 6423 -> loss: 0.0002812416058820351, self.slope: [1.06901625 1.06951773], self.intercept: 1.006096508597736\n",
      "iteration - 6424 -> loss: 0.0002812264181017262, self.slope: [1.0690249  1.06952648], self.intercept: 1.0060973110151379\n",
      "iteration - 6425 -> loss: 0.0002812112320142423, self.slope: [1.06903354 1.06953522], self.intercept: 1.0060981133967914\n",
      "iteration - 6426 -> loss: 0.0002811960476193094, self.slope: [1.06904219 1.06954396], self.intercept: 1.0060989157427007\n",
      "iteration - 6427 -> loss: 0.0002811808649166215, self.slope: [1.06905083 1.0695527 ], self.intercept: 1.0060997180528661\n",
      "iteration - 6428 -> loss: 0.00028116568390589887, self.slope: [1.06905948 1.06956145], self.intercept: 1.006100520327293\n",
      "iteration - 6429 -> loss: 0.0002811505045868707, self.slope: [1.06906813 1.06957019], self.intercept: 1.006101322565984\n",
      "iteration - 6430 -> loss: 0.00028113532695921124, self.slope: [1.06907677 1.06957893], self.intercept: 1.0061021247689441\n",
      "iteration - 6431 -> loss: 0.00028112015102268084, self.slope: [1.06908541 1.06958767], self.intercept: 1.0061029269361765\n",
      "iteration - 6432 -> loss: 0.0002811049767769632, self.slope: [1.06909406 1.06959641], self.intercept: 1.0061037290676842\n",
      "iteration - 6433 -> loss: 0.00028108980422179104, self.slope: [1.0691027  1.06960515], self.intercept: 1.00610453116347\n",
      "iteration - 6434 -> loss: 0.00028107463335685803, self.slope: [1.06911134 1.06961389], self.intercept: 1.006105333223537\n",
      "iteration - 6435 -> loss: 0.0002810594641818873, self.slope: [1.06911998 1.06962262], self.intercept: 1.006106135247891\n",
      "iteration - 6436 -> loss: 0.00028104429669661025, self.slope: [1.06912863 1.06963136], self.intercept: 1.0061069372365332\n",
      "iteration - 6437 -> loss: 0.0002810291309007083, self.slope: [1.06913727 1.0696401 ], self.intercept: 1.0061077391894693\n",
      "iteration - 6438 -> loss: 0.0002810139667939268, self.slope: [1.06914591 1.06964883], self.intercept: 1.006108541106699\n",
      "iteration - 6439 -> loss: 0.0002809988043759525, self.slope: [1.06915455 1.06965757], self.intercept: 1.0061093429882293\n",
      "iteration - 6440 -> loss: 0.00028098364364651294, self.slope: [1.06916319 1.06966631], self.intercept: 1.0061101448340624\n",
      "iteration - 6441 -> loss: 0.0002809684846053248, self.slope: [1.06917183 1.06967504], self.intercept: 1.0061109466442015\n",
      "iteration - 6442 -> loss: 0.0002809533272520979, self.slope: [1.06918047 1.06968378], self.intercept: 1.0061117484186508\n",
      "iteration - 6443 -> loss: 0.0002809381715865435, self.slope: [1.0691891  1.06969251], self.intercept: 1.006112550157413\n",
      "iteration - 6444 -> loss: 0.0002809230176083903, self.slope: [1.06919774 1.06970124], self.intercept: 1.0061133518604926\n",
      "iteration - 6445 -> loss: 0.0002809078653173439, self.slope: [1.06920638 1.06970998], self.intercept: 1.0061141535278917\n",
      "iteration - 6446 -> loss: 0.0002808927147131216, self.slope: [1.06921502 1.06971871], self.intercept: 1.006114955159614\n",
      "iteration - 6447 -> loss: 0.0002808775657954218, self.slope: [1.06922365 1.06972744], self.intercept: 1.0061157567556647\n",
      "iteration - 6448 -> loss: 0.0002808624185639871, self.slope: [1.06923229 1.06973617], self.intercept: 1.0061165583160443\n",
      "iteration - 6449 -> loss: 0.0002808472730185047, self.slope: [1.06924092 1.06974491], self.intercept: 1.0061173598407585\n",
      "iteration - 6450 -> loss: 0.00028083212915870756, self.slope: [1.06924956 1.06975364], self.intercept: 1.0061181613298111\n",
      "iteration - 6451 -> loss: 0.00028081698698431977, self.slope: [1.06925819 1.06976237], self.intercept: 1.0061189627832032\n",
      "iteration - 6452 -> loss: 0.00028080184649502957, self.slope: [1.06926683 1.0697711 ], self.intercept: 1.00611976420094\n",
      "iteration - 6453 -> loss: 0.0002807867076905713, self.slope: [1.06927546 1.06977983], self.intercept: 1.006120565583025\n",
      "iteration - 6454 -> loss: 0.00028077157057063986, self.slope: [1.06928409 1.06978856], self.intercept: 1.006121366929461\n",
      "iteration - 6455 -> loss: 0.00028075643513497607, self.slope: [1.06929272 1.06979728], self.intercept: 1.0061221682402521\n",
      "iteration - 6456 -> loss: 0.0002807413013832913, self.slope: [1.06930136 1.06980601], self.intercept: 1.0061229695154001\n",
      "iteration - 6457 -> loss: 0.0002807261693152872, self.slope: [1.06930999 1.06981474], self.intercept: 1.0061237707549109\n",
      "iteration - 6458 -> loss: 0.00028071103893068556, self.slope: [1.06931862 1.06982347], self.intercept: 1.0061245719587866\n",
      "iteration - 6459 -> loss: 0.00028069591022919754, self.slope: [1.06932725 1.06983219], self.intercept: 1.006125373127031\n",
      "iteration - 6460 -> loss: 0.0002806807832105464, self.slope: [1.06933588 1.06984092], self.intercept: 1.0061261742596486\n",
      "iteration - 6461 -> loss: 0.000280665657874429, self.slope: [1.06934451 1.06984964], self.intercept: 1.0061269753566404\n",
      "iteration - 6462 -> loss: 0.00028065053422060896, self.slope: [1.06935314 1.06985837], self.intercept: 1.0061277764180123\n",
      "iteration - 6463 -> loss: 0.000280635412248744, self.slope: [1.06936177 1.06986709], self.intercept: 1.006128577443765\n",
      "iteration - 6464 -> loss: 0.00028062029195860435, self.slope: [1.06937039 1.06987582], self.intercept: 1.006129378433904\n",
      "iteration - 6465 -> loss: 0.00028060517334985353, self.slope: [1.06937902 1.06988454], self.intercept: 1.006130179388433\n",
      "iteration - 6466 -> loss: 0.0002805900564222368, self.slope: [1.06938765 1.06989327], self.intercept: 1.0061309803073548\n",
      "iteration - 6467 -> loss: 0.00028057494117545145, self.slope: [1.06939627 1.06990199], self.intercept: 1.0061317811906727\n",
      "iteration - 6468 -> loss: 0.00028055982760924085, self.slope: [1.0694049  1.06991071], self.intercept: 1.006132582038388\n",
      "iteration - 6469 -> loss: 0.0002805447157233082, self.slope: [1.06941353 1.06991943], self.intercept: 1.0061333828505075\n",
      "iteration - 6470 -> loss: 0.00028052960551735816, self.slope: [1.06942215 1.06992815], self.intercept: 1.0061341836270339\n",
      "iteration - 6471 -> loss: 0.0002805144969911334, self.slope: [1.06943078 1.06993687], self.intercept: 1.0061349843679703\n",
      "iteration - 6472 -> loss: 0.00028049939014432047, self.slope: [1.0694394  1.06994559], self.intercept: 1.0061357850733204\n",
      "iteration - 6473 -> loss: 0.0002804842849766449, self.slope: [1.06944802 1.06995431], self.intercept: 1.006136585743088\n",
      "iteration - 6474 -> loss: 0.000280469181487835, self.slope: [1.06945665 1.06996303], self.intercept: 1.0061373863772753\n",
      "iteration - 6475 -> loss: 0.00028045407967760265, self.slope: [1.06946527 1.06997175], self.intercept: 1.0061381869758852\n",
      "iteration - 6476 -> loss: 0.00028043897954565584, self.slope: [1.06947389 1.06998047], self.intercept: 1.006138987538923\n",
      "iteration - 6477 -> loss: 0.000280423881091733, self.slope: [1.06948251 1.06998919], self.intercept: 1.0061397880663925\n",
      "iteration - 6478 -> loss: 0.0002804087843155281, self.slope: [1.06949113 1.06999791], self.intercept: 1.0061405885582975\n",
      "iteration - 6479 -> loss: 0.00028039368921674583, self.slope: [1.06949975 1.07000662], self.intercept: 1.0061413890146382\n",
      "iteration - 6480 -> loss: 0.0002803785957951357, self.slope: [1.06950838 1.07001534], self.intercept: 1.0061421894354194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 6481 -> loss: 0.0002803635040503915, self.slope: [1.06951699 1.07002406], self.intercept: 1.006142989820646\n",
      "iteration - 6482 -> loss: 0.0002803484139822659, self.slope: [1.06952561 1.07003277], self.intercept: 1.00614379017032\n",
      "iteration - 6483 -> loss: 0.0002803333255904318, self.slope: [1.06953423 1.07004149], self.intercept: 1.0061445904844453\n",
      "iteration - 6484 -> loss: 0.0002803182388746373, self.slope: [1.06954285 1.0700502 ], self.intercept: 1.0061453907630253\n",
      "iteration - 6485 -> loss: 0.00028030315383457635, self.slope: [1.06955147 1.07005891], self.intercept: 1.0061461910060634\n",
      "iteration - 6486 -> loss: 0.0002802880704699627, self.slope: [1.06956009 1.07006763], self.intercept: 1.0061469912135632\n",
      "iteration - 6487 -> loss: 0.0002802729887805393, self.slope: [1.0695687  1.07007634], self.intercept: 1.0061477913855281\n",
      "iteration - 6488 -> loss: 0.0002802579087660208, self.slope: [1.06957732 1.07008505], self.intercept: 1.0061485915219628\n",
      "iteration - 6489 -> loss: 0.0002802428304261086, self.slope: [1.06958594 1.07009377], self.intercept: 1.0061493916228677\n",
      "iteration - 6490 -> loss: 0.00028022775376053947, self.slope: [1.06959455 1.07010248], self.intercept: 1.0061501916882483\n",
      "iteration - 6491 -> loss: 0.0002802126787689889, self.slope: [1.06960317 1.07011119], self.intercept: 1.0061509917181084\n",
      "iteration - 6492 -> loss: 0.00028019760545123644, self.slope: [1.06961178 1.0701199 ], self.intercept: 1.0061517917124503\n",
      "iteration - 6493 -> loss: 0.0002801825338069426, self.slope: [1.06962039 1.07012861], self.intercept: 1.0061525916712781\n",
      "iteration - 6494 -> loss: 0.00028016746383588013, self.slope: [1.06962901 1.07013732], self.intercept: 1.0061533915945944\n",
      "iteration - 6495 -> loss: 0.0002801523955377072, self.slope: [1.06963762 1.07014603], self.intercept: 1.0061541914824037\n",
      "iteration - 6496 -> loss: 0.00028013732891217784, self.slope: [1.06964623 1.07015474], self.intercept: 1.006154991334708\n",
      "iteration - 6497 -> loss: 0.0002801222639590035, self.slope: [1.06965485 1.07016345], self.intercept: 1.0061557911515113\n",
      "iteration - 6498 -> loss: 0.0002801072006779114, self.slope: [1.06966346 1.07017215], self.intercept: 1.0061565909328198\n",
      "iteration - 6499 -> loss: 0.00028009213906859324, self.slope: [1.06967207 1.07018086], self.intercept: 1.0061573906786325\n",
      "iteration - 6500 -> loss: 0.00028007707913081377, self.slope: [1.06968068 1.07018957], self.intercept: 1.0061581903889558\n",
      "iteration - 6501 -> loss: 0.00028006202086424255, self.slope: [1.06968929 1.07019827], self.intercept: 1.0061589900637935\n",
      "iteration - 6502 -> loss: 0.00028004696426862214, self.slope: [1.0696979  1.07020698], self.intercept: 1.0061597897031462\n",
      "iteration - 6503 -> loss: 0.0002800319093436699, self.slope: [1.06970651 1.07021568], self.intercept: 1.0061605893070196\n",
      "iteration - 6504 -> loss: 0.00028001685608909177, self.slope: [1.06971512 1.07022439], self.intercept: 1.0061613888754155\n",
      "iteration - 6505 -> loss: 0.0002800018045046183, self.slope: [1.06972372 1.07023309], self.intercept: 1.0061621884083383\n",
      "iteration - 6506 -> loss: 0.00027998675458995446, self.slope: [1.06973233 1.0702418 ], self.intercept: 1.0061629879057927\n",
      "iteration - 6507 -> loss: 0.00027997170634484417, self.slope: [1.06974094 1.0702505 ], self.intercept: 1.006163787367779\n",
      "iteration - 6508 -> loss: 0.00027995665976898097, self.slope: [1.06974955 1.0702592 ], self.intercept: 1.0061645867943032\n",
      "iteration - 6509 -> loss: 0.00027994161486209865, self.slope: [1.06975815 1.07026791], self.intercept: 1.006165386185368\n",
      "iteration - 6510 -> loss: 0.00027992657162390956, self.slope: [1.06976676 1.07027661], self.intercept: 1.0061661855409765\n",
      "iteration - 6511 -> loss: 0.0002799115300541388, self.slope: [1.06977536 1.07028531], self.intercept: 1.0061669848611332\n",
      "iteration - 6512 -> loss: 0.0002798964901524933, self.slope: [1.06978397 1.07029401], self.intercept: 1.0061677841458405\n",
      "iteration - 6513 -> loss: 0.00027988145191870157, self.slope: [1.06979257 1.07030271], self.intercept: 1.0061685833951024\n",
      "iteration - 6514 -> loss: 0.00027986641535247147, self.slope: [1.06980118 1.07031141], self.intercept: 1.006169382608922\n",
      "iteration - 6515 -> loss: 0.0002798513804535367, self.slope: [1.06980978 1.07032011], self.intercept: 1.0061701817873019\n",
      "iteration - 6516 -> loss: 0.00027983634722161875, self.slope: [1.06981838 1.07032881], self.intercept: 1.0061709809302453\n",
      "iteration - 6517 -> loss: 0.00027982131565641244, self.slope: [1.06982699 1.07033751], self.intercept: 1.0061717800377585\n",
      "iteration - 6518 -> loss: 0.0002798062857576698, self.slope: [1.06983559 1.07034621], self.intercept: 1.0061725791098426\n",
      "iteration - 6519 -> loss: 0.00027979125752508637, self.slope: [1.06984419 1.07035491], self.intercept: 1.0061733781465014\n",
      "iteration - 6520 -> loss: 0.0002797762309583929, self.slope: [1.06985279 1.0703636 ], self.intercept: 1.0061741771477384\n",
      "iteration - 6521 -> loss: 0.0002797612060572903, self.slope: [1.06986139 1.0703723 ], self.intercept: 1.0061749761135574\n",
      "iteration - 6522 -> loss: 0.000279746182821524, self.slope: [1.06986999 1.070381  ], self.intercept: 1.0061757750439615\n",
      "iteration - 6523 -> loss: 0.00027973116125080364, self.slope: [1.06987859 1.07038969], self.intercept: 1.006176573938953\n",
      "iteration - 6524 -> loss: 0.0002797161413448444, self.slope: [1.06988719 1.07039839], self.intercept: 1.0061773727985377\n",
      "iteration - 6525 -> loss: 0.00027970112310335963, self.slope: [1.06989579 1.07040708], self.intercept: 1.0061781716227183\n",
      "iteration - 6526 -> loss: 0.00027968610652607606, self.slope: [1.06990439 1.07041578], self.intercept: 1.0061789704114963\n",
      "iteration - 6527 -> loss: 0.00027967109161273893, self.slope: [1.06991298 1.07042447], self.intercept: 1.0061797691648773\n",
      "iteration - 6528 -> loss: 0.0002796560783630261, self.slope: [1.06992158 1.07043316], self.intercept: 1.0061805678828635\n",
      "iteration - 6529 -> loss: 0.0002796410667766932, self.slope: [1.06993018 1.07044186], self.intercept: 1.0061813665654604\n",
      "iteration - 6530 -> loss: 0.00027962605685341883, self.slope: [1.06993877 1.07045055], self.intercept: 1.006182165212668\n",
      "iteration - 6531 -> loss: 0.0002796110485929678, self.slope: [1.06994737 1.07045924], self.intercept: 1.0061829638244917\n",
      "iteration - 6532 -> loss: 0.0002795960419950427, self.slope: [1.06995596 1.07046793], self.intercept: 1.006183762400935\n",
      "iteration - 6533 -> loss: 0.00027958103705934327, self.slope: [1.06996456 1.07047662], self.intercept: 1.0061845609420004\n",
      "iteration - 6534 -> loss: 0.0002795660337856164, self.slope: [1.06997315 1.07048531], self.intercept: 1.0061853594476915\n",
      "iteration - 6535 -> loss: 0.0002795510321735815, self.slope: [1.06998175 1.070494  ], self.intercept: 1.0061861579180125\n",
      "iteration - 6536 -> loss: 0.0002795360322229504, self.slope: [1.06999034 1.07050269], self.intercept: 1.0061869563529664\n",
      "iteration - 6537 -> loss: 0.00027952103393343237, self.slope: [1.06999893 1.07051138], self.intercept: 1.0061877547525573\n",
      "iteration - 6538 -> loss: 0.0002795060373047732, self.slope: [1.07000752 1.07052007], self.intercept: 1.0061885531167873\n",
      "iteration - 6539 -> loss: 0.0002794910423366771, self.slope: [1.07001612 1.07052876], self.intercept: 1.00618935144566\n",
      "iteration - 6540 -> loss: 0.00027947604902884806, self.slope: [1.07002471 1.07053745], self.intercept: 1.0061901497391796\n",
      "iteration - 6541 -> loss: 0.0002794610573810573, self.slope: [1.0700333  1.07054613], self.intercept: 1.0061909479973503\n",
      "iteration - 6542 -> loss: 0.00027944606739297996, self.slope: [1.07004189 1.07055482], self.intercept: 1.0061917462201742\n",
      "iteration - 6543 -> loss: 0.00027943107906436743, self.slope: [1.07005048 1.07056351], self.intercept: 1.006192544407655\n",
      "iteration - 6544 -> loss: 0.0002794160923949106, self.slope: [1.07005907 1.07057219], self.intercept: 1.0061933425597958\n",
      "iteration - 6545 -> loss: 0.00027940110738433767, self.slope: [1.07006766 1.07058088], self.intercept: 1.0061941406765995\n",
      "iteration - 6546 -> loss: 0.00027938612403240214, self.slope: [1.07007625 1.07058956], self.intercept: 1.0061949387580709\n",
      "iteration - 6547 -> loss: 0.0002793711423387872, self.slope: [1.07008483 1.07059825], self.intercept: 1.006195736804213\n",
      "iteration - 6548 -> loss: 0.00027935616230321083, self.slope: [1.07009342 1.07060693], self.intercept: 1.0061965348150277\n",
      "iteration - 6549 -> loss: 0.0002793411839254458, self.slope: [1.07010201 1.07061562], self.intercept: 1.0061973327905207\n",
      "iteration - 6550 -> loss: 0.00027932620720515054, self.slope: [1.07011059 1.0706243 ], self.intercept: 1.0061981307306942\n",
      "iteration - 6551 -> loss: 0.0002793112321420943, self.slope: [1.07011918 1.07063298], self.intercept: 1.0061989286355506\n",
      "iteration - 6552 -> loss: 0.0002792962587359634, self.slope: [1.07012777 1.07064166], self.intercept: 1.0061997265050957\n",
      "iteration - 6553 -> loss: 0.00027928128698649125, self.slope: [1.07013635 1.07065034], self.intercept: 1.0062005243393317\n",
      "iteration - 6554 -> loss: 0.0002792663168934088, self.slope: [1.07014494 1.07065903], self.intercept: 1.0062013221382622\n",
      "iteration - 6555 -> loss: 0.00027925134845644415, self.slope: [1.07015352 1.07066771], self.intercept: 1.0062021199018898\n",
      "iteration - 6556 -> loss: 0.00027923638167529313, self.slope: [1.0701621  1.07067639], self.intercept: 1.0062029176302194\n",
      "iteration - 6557 -> loss: 0.00027922141654968907, self.slope: [1.07017069 1.07068507], self.intercept: 1.0062037153232537\n",
      "iteration - 6558 -> loss: 0.00027920645307935615, self.slope: [1.07017927 1.07069374], self.intercept: 1.0062045129809953\n",
      "iteration - 6559 -> loss: 0.0002791914912640212, self.slope: [1.07018785 1.07070242], self.intercept: 1.0062053106034479\n",
      "iteration - 6560 -> loss: 0.00027917653110339543, self.slope: [1.07019643 1.0707111 ], self.intercept: 1.006206108190616\n",
      "iteration - 6561 -> loss: 0.0002791615725972138, self.slope: [1.07020502 1.07071978], self.intercept: 1.006206905742501\n",
      "iteration - 6562 -> loss: 0.00027914661574519157, self.slope: [1.0702136  1.07072846], self.intercept: 1.0062077032591077\n",
      "iteration - 6563 -> loss: 0.0002791316605470388, self.slope: [1.07022218 1.07073713], self.intercept: 1.0062085007404384\n",
      "iteration - 6564 -> loss: 0.0002791167070024828, self.slope: [1.07023076 1.07074581], self.intercept: 1.0062092981864987\n",
      "iteration - 6565 -> loss: 0.00027910175511126336, self.slope: [1.07023934 1.07075448], self.intercept: 1.006210095597291\n",
      "iteration - 6566 -> loss: 0.00027908680487309385, self.slope: [1.07024791 1.07076316], self.intercept: 1.0062108929728193\n",
      "iteration - 6567 -> loss: 0.0002790718562876993, self.slope: [1.07025649 1.07077183], self.intercept: 1.0062116903130849\n",
      "iteration - 6568 -> loss: 0.00027905690935478274, self.slope: [1.07026507 1.07078051], self.intercept: 1.0062124876180925\n",
      "iteration - 6569 -> loss: 0.00027904196407407654, self.slope: [1.07027365 1.07078918], self.intercept: 1.006213284887844\n",
      "iteration - 6570 -> loss: 0.00027902702044531953, self.slope: [1.07028223 1.07079786], self.intercept: 1.0062140821223453\n",
      "iteration - 6571 -> loss: 0.0002790120784682095, self.slope: [1.0702908  1.07080653], self.intercept: 1.0062148793215986\n",
      "iteration - 6572 -> loss: 0.0002789971381424845, self.slope: [1.07029938 1.0708152 ], self.intercept: 1.0062156764856083\n",
      "iteration - 6573 -> loss: 0.0002789821994678836, self.slope: [1.07030795 1.07082387], self.intercept: 1.0062164736143775\n",
      "iteration - 6574 -> loss: 0.0002789672624441001, self.slope: [1.07031653 1.07083255], self.intercept: 1.0062172707079076\n",
      "iteration - 6575 -> loss: 0.0002789523270708681, self.slope: [1.0703251  1.07084122], self.intercept: 1.0062180677662034\n",
      "iteration - 6576 -> loss: 0.00027893739334790133, self.slope: [1.07033368 1.07084989], self.intercept: 1.0062188647892678\n",
      "iteration - 6577 -> loss: 0.0002789224612749362, self.slope: [1.07034225 1.07085856], self.intercept: 1.0062196617771053\n",
      "iteration - 6578 -> loss: 0.0002789075308516889, self.slope: [1.07035082 1.07086723], self.intercept: 1.0062204587297188\n",
      "iteration - 6579 -> loss: 0.0002788926020778922, self.slope: [1.0703594 1.0708759], self.intercept: 1.006221255647112\n",
      "iteration - 6580 -> loss: 0.0002788776749532503, self.slope: [1.07036797 1.07088456], self.intercept: 1.006222052529287\n",
      "iteration - 6581 -> loss: 0.0002788627494775121, self.slope: [1.07037654 1.07089323], self.intercept: 1.0062228493762473\n",
      "iteration - 6582 -> loss: 0.00027884782565036777, self.slope: [1.07038511 1.0709019 ], self.intercept: 1.006223646188\n",
      "iteration - 6583 -> loss: 0.00027883290347157567, self.slope: [1.07039368 1.07091057], self.intercept: 1.0062244429645426\n",
      "iteration - 6584 -> loss: 0.00027881798294084287, self.slope: [1.07040225 1.07091923], self.intercept: 1.0062252397058815\n",
      "iteration - 6585 -> loss: 0.0002788030640578734, self.slope: [1.07041082 1.0709279 ], self.intercept: 1.0062260364120206\n",
      "iteration - 6586 -> loss: 0.00027878814682243103, self.slope: [1.07041939 1.07093657], self.intercept: 1.0062268330829627\n",
      "iteration - 6587 -> loss: 0.0002787732312342248, self.slope: [1.07042796 1.07094523], self.intercept: 1.0062276297187107\n",
      "iteration - 6588 -> loss: 0.0002787583172929435, self.slope: [1.07043653 1.0709539 ], self.intercept: 1.0062284263192691\n",
      "iteration - 6589 -> loss: 0.00027874340499836777, self.slope: [1.0704451  1.07096256], self.intercept: 1.0062292228846417\n",
      "iteration - 6590 -> loss: 0.0002787284943501922, self.slope: [1.07045366 1.07097122], self.intercept: 1.0062300194148297\n",
      "iteration - 6591 -> loss: 0.0002787135853481238, self.slope: [1.07046223 1.07097989], self.intercept: 1.0062308159098377\n",
      "iteration - 6592 -> loss: 0.0002786986779919081, self.slope: [1.0704708  1.07098855], self.intercept: 1.0062316123696673\n",
      "iteration - 6593 -> loss: 0.00027868377228127983, self.slope: [1.07047936 1.07099721], self.intercept: 1.0062324087943249\n",
      "iteration - 6594 -> loss: 0.00027866886821595484, self.slope: [1.07048793 1.07100588], self.intercept: 1.006233205183812\n",
      "iteration - 6595 -> loss: 0.0002786539657956295, self.slope: [1.07049649 1.07101454], self.intercept: 1.0062340015381335\n",
      "iteration - 6596 -> loss: 0.00027863906502005863, self.slope: [1.07050506 1.0710232 ], self.intercept: 1.0062347978572912\n",
      "iteration - 6597 -> loss: 0.00027862416588896266, self.slope: [1.07051362 1.07103186], self.intercept: 1.0062355941412895\n",
      "iteration - 6598 -> loss: 0.0002786092684020568, self.slope: [1.07052219 1.07104052], self.intercept: 1.0062363903901312\n",
      "iteration - 6599 -> loss: 0.0002785943725590601, self.slope: [1.07053075 1.07104918], self.intercept: 1.0062371866038207\n",
      "iteration - 6600 -> loss: 0.00027857947835971685, self.slope: [1.07053931 1.07105784], self.intercept: 1.0062379827823598\n",
      "iteration - 6601 -> loss: 0.00027856458580372836, self.slope: [1.07054787 1.0710665 ], self.intercept: 1.0062387789257534\n",
      "iteration - 6602 -> loss: 0.00027854969489085764, self.slope: [1.07055644 1.07107515], self.intercept: 1.0062395750340043\n",
      "iteration - 6603 -> loss: 0.0002785348056207705, self.slope: [1.070565   1.07108381], self.intercept: 1.0062403711071146\n",
      "iteration - 6604 -> loss: 0.00027851991799325636, self.slope: [1.07057356 1.07109247], self.intercept: 1.006241167145089\n",
      "iteration - 6605 -> loss: 0.00027850503200798927, self.slope: [1.07058212 1.07110113], self.intercept: 1.0062419631479302\n",
      "iteration - 6606 -> loss: 0.00027849014766471514, self.slope: [1.07059068 1.07110978], self.intercept: 1.0062427591156429\n",
      "iteration - 6607 -> loss: 0.00027847526496316776, self.slope: [1.07059924 1.07111844], self.intercept: 1.0062435550482283\n",
      "iteration - 6608 -> loss: 0.0002784603839030448, self.slope: [1.0706078  1.07112709], self.intercept: 1.0062443509456924\n",
      "iteration - 6609 -> loss: 0.00027844550448409496, self.slope: [1.07061635 1.07113575], self.intercept: 1.0062451468080371\n",
      "iteration - 6610 -> loss: 0.00027843062670604256, self.slope: [1.07062491 1.0711444 ], self.intercept: 1.006245942635266\n",
      "iteration - 6611 -> loss: 0.00027841575056860684, self.slope: [1.07063347 1.07115306], self.intercept: 1.0062467384273819\n",
      "iteration - 6612 -> loss: 0.00027840087607150076, self.slope: [1.07064203 1.07116171], self.intercept: 1.00624753418439\n",
      "iteration - 6613 -> loss: 0.0002783860032144713, self.slope: [1.07065058 1.07117036], self.intercept: 1.0062483299062916\n",
      "iteration - 6614 -> loss: 0.0002783711319972346, self.slope: [1.07065914 1.07117902], self.intercept: 1.0062491255930908\n",
      "iteration - 6615 -> loss: 0.0002783562624194999, self.slope: [1.07066769 1.07118767], self.intercept: 1.006249921244791\n",
      "iteration - 6616 -> loss: 0.00027834139448102135, self.slope: [1.07067625 1.07119632], self.intercept: 1.0062507168613937\n",
      "iteration - 6617 -> loss: 0.0002783265281815059, self.slope: [1.0706848  1.07120497], self.intercept: 1.006251512442906\n",
      "iteration - 6618 -> loss: 0.00027831166352069, self.slope: [1.07069336 1.07121362], self.intercept: 1.0062523079893286\n",
      "iteration - 6619 -> loss: 0.00027829680049828786, self.slope: [1.07070191 1.07122227], self.intercept: 1.0062531035006652\n",
      "iteration - 6620 -> loss: 0.0002782819391140298, self.slope: [1.07071046 1.07123092], self.intercept: 1.0062538989769196\n",
      "iteration - 6621 -> loss: 0.0002782670793676369, self.slope: [1.07071902 1.07123957], self.intercept: 1.006254694418097\n",
      "iteration - 6622 -> loss: 0.0002782522212588408, self.slope: [1.07072757 1.07124822], self.intercept: 1.0062554898241989\n",
      "iteration - 6623 -> loss: 0.0002782373647873768, self.slope: [1.07073612 1.07125687], self.intercept: 1.0062562851952277\n",
      "iteration - 6624 -> loss: 0.0002782225099529639, self.slope: [1.07074467 1.07126551], self.intercept: 1.0062570805311881\n",
      "iteration - 6625 -> loss: 0.0002782076567553164, self.slope: [1.07075322 1.07127416], self.intercept: 1.0062578758320837\n",
      "iteration - 6626 -> loss: 0.0002781928051941701, self.slope: [1.07076177 1.07128281], self.intercept: 1.0062586710979167\n",
      "iteration - 6627 -> loss: 0.0002781779552692588, self.slope: [1.07077032 1.07129146], self.intercept: 1.0062594663286915\n",
      "iteration - 6628 -> loss: 0.0002781631069802842, self.slope: [1.07077887 1.0713001 ], self.intercept: 1.006260261524411\n",
      "iteration - 6629 -> loss: 0.0002781482603270078, self.slope: [1.07078742 1.07130875], self.intercept: 1.0062610566850785\n",
      "iteration - 6630 -> loss: 0.0002781334153091217, self.slope: [1.07079597 1.07131739], self.intercept: 1.0062618518106985\n",
      "iteration - 6631 -> loss: 0.0002781185719263595, self.slope: [1.07080452 1.07132604], self.intercept: 1.0062626469012723\n",
      "iteration - 6632 -> loss: 0.0002781037301784672, self.slope: [1.07081306 1.07133468], self.intercept: 1.0062634419568055\n",
      "iteration - 6633 -> loss: 0.00027808889006515516, self.slope: [1.07082161 1.07134332], self.intercept: 1.0062642369772998\n",
      "iteration - 6634 -> loss: 0.0002780740515861709, self.slope: [1.07083016 1.07135197], self.intercept: 1.0062650319627593\n",
      "iteration - 6635 -> loss: 0.0002780592147412094, self.slope: [1.0708387  1.07136061], self.intercept: 1.0062658269131866\n",
      "iteration - 6636 -> loss: 0.00027804437953000977, self.slope: [1.07084725 1.07136925], self.intercept: 1.0062666218285865\n",
      "iteration - 6637 -> loss: 0.0002780295459522917, self.slope: [1.07085579 1.07137789], self.intercept: 1.0062674167089616\n",
      "iteration - 6638 -> loss: 0.00027801471400780783, self.slope: [1.07086434 1.07138653], self.intercept: 1.0062682115543145\n",
      "iteration - 6639 -> loss: 0.00027799988369625855, self.slope: [1.07087288 1.07139517], self.intercept: 1.0062690063646487\n",
      "iteration - 6640 -> loss: 0.00027798505501738904, self.slope: [1.07088143 1.07140382], self.intercept: 1.0062698011399696\n",
      "iteration - 6641 -> loss: 0.0002779702279709099, self.slope: [1.07088997 1.07141245], self.intercept: 1.0062705958802785\n",
      "iteration - 6642 -> loss: 0.0002779554025565593, self.slope: [1.07089851 1.07142109], self.intercept: 1.0062713905855805\n",
      "iteration - 6643 -> loss: 0.0002779405787740698, self.slope: [1.07090705 1.07142973], self.intercept: 1.0062721852558763\n",
      "iteration - 6644 -> loss: 0.0002779257566231454, self.slope: [1.0709156  1.07143837], self.intercept: 1.0062729798911703\n",
      "iteration - 6645 -> loss: 0.0002779109361035324, self.slope: [1.07092414 1.07144701], self.intercept: 1.0062737744914672\n",
      "iteration - 6646 -> loss: 0.0002778961172149591, self.slope: [1.07093268 1.07145565], self.intercept: 1.0062745690567685\n",
      "iteration - 6647 -> loss: 0.0002778812999571444, self.slope: [1.07094122 1.07146428], self.intercept: 1.006275363587079\n",
      "iteration - 6648 -> loss: 0.0002778664843298182, self.slope: [1.07094976 1.07147292], self.intercept: 1.0062761580824011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 6649 -> loss: 0.000277851670332701, self.slope: [1.0709583  1.07148156], self.intercept: 1.0062769525427384\n",
      "iteration - 6650 -> loss: 0.0002778368579655341, self.slope: [1.07096684 1.07149019], self.intercept: 1.0062777469680946\n",
      "iteration - 6651 -> loss: 0.0002778220472280351, self.slope: [1.07097538 1.07149883], self.intercept: 1.006278541358473\n",
      "iteration - 6652 -> loss: 0.0002778072381199276, self.slope: [1.07098391 1.07150746], self.intercept: 1.0062793357138764\n",
      "iteration - 6653 -> loss: 0.00027779243064095444, self.slope: [1.07099245 1.07151609], self.intercept: 1.0062801300343087\n",
      "iteration - 6654 -> loss: 0.00027777762479085056, self.slope: [1.07100099 1.07152473], self.intercept: 1.006280924319775\n",
      "iteration - 6655 -> loss: 0.00027776282056931554, self.slope: [1.07100952 1.07153336], self.intercept: 1.0062817185702757\n",
      "iteration - 6656 -> loss: 0.00027774801797608424, self.slope: [1.07101806 1.07154199], self.intercept: 1.0062825127858144\n",
      "iteration - 6657 -> loss: 0.00027773321701090583, self.slope: [1.0710266  1.07155063], self.intercept: 1.006283306966396\n",
      "iteration - 6658 -> loss: 0.00027771841767348097, self.slope: [1.07103513 1.07155926], self.intercept: 1.006284101112023\n",
      "iteration - 6659 -> loss: 0.0002777036199635461, self.slope: [1.07104367 1.07156789], self.intercept: 1.0062848952227004\n",
      "iteration - 6660 -> loss: 0.00027768882388084273, self.slope: [1.0710522  1.07157652], self.intercept: 1.0062856892984289\n",
      "iteration - 6661 -> loss: 0.00027767402942508666, self.slope: [1.07106073 1.07158515], self.intercept: 1.006286483339214\n",
      "iteration - 6662 -> loss: 0.00027765923659601966, self.slope: [1.07106927 1.07159378], self.intercept: 1.0062872773450584\n",
      "iteration - 6663 -> loss: 0.0002776444453933412, self.slope: [1.0710778  1.07160241], self.intercept: 1.0062880713159654\n",
      "iteration - 6664 -> loss: 0.0002776296558168117, self.slope: [1.07108633 1.07161104], self.intercept: 1.0062888652519373\n",
      "iteration - 6665 -> loss: 0.00027761486786614633, self.slope: [1.07109486 1.07161967], self.intercept: 1.0062896591529777\n",
      "iteration - 6666 -> loss: 0.00027760008154106445, self.slope: [1.07110339 1.0716283 ], self.intercept: 1.0062904530190913\n",
      "iteration - 6667 -> loss: 0.00027758529684131526, self.slope: [1.07111193 1.07163692], self.intercept: 1.00629124685028\n",
      "iteration - 6668 -> loss: 0.0002775705137665986, self.slope: [1.07112046 1.07164555], self.intercept: 1.0062920406465476\n",
      "iteration - 6669 -> loss: 0.00027755573231667005, self.slope: [1.07112899 1.07165418], self.intercept: 1.0062928344078979\n",
      "iteration - 6670 -> loss: 0.000277540952491245, self.slope: [1.07113751 1.0716628 ], self.intercept: 1.0062936281343344\n",
      "iteration - 6671 -> loss: 0.00027752617429005277, self.slope: [1.07114604 1.07167143], self.intercept: 1.0062944218258596\n",
      "iteration - 6672 -> loss: 0.00027751139771284484, self.slope: [1.07115457 1.07168005], self.intercept: 1.0062952154824778\n",
      "iteration - 6673 -> loss: 0.0002774966227593151, self.slope: [1.0711631  1.07168868], self.intercept: 1.0062960091041924\n",
      "iteration - 6674 -> loss: 0.0002774818494291919, self.slope: [1.07117163 1.0716973 ], self.intercept: 1.006296802691004\n",
      "iteration - 6675 -> loss: 0.0002774670777222317, self.slope: [1.07118015 1.07170593], self.intercept: 1.0062975962429197\n",
      "iteration - 6676 -> loss: 0.0002774523076381722, self.slope: [1.07118868 1.07171455], self.intercept: 1.00629838975994\n",
      "iteration - 6677 -> loss: 0.0002774375391766955, self.slope: [1.07119721 1.07172317], self.intercept: 1.006299183242069\n",
      "iteration - 6678 -> loss: 0.00027742277233756845, self.slope: [1.07120573 1.07173179], self.intercept: 1.0062999766893113\n",
      "iteration - 6679 -> loss: 0.0002774080071205073, self.slope: [1.07121426 1.07174042], self.intercept: 1.0063007701016689\n",
      "iteration - 6680 -> loss: 0.000277393243525256, self.slope: [1.07122278 1.07174904], self.intercept: 1.0063015634791468\n",
      "iteration - 6681 -> loss: 0.0002773784815515227, self.slope: [1.07123131 1.07175766], self.intercept: 1.006302356821746\n",
      "iteration - 6682 -> loss: 0.0002773637211990414, self.slope: [1.07123983 1.07176628], self.intercept: 1.0063031501294726\n",
      "iteration - 6683 -> loss: 0.00027734896246753705, self.slope: [1.07124835 1.0717749 ], self.intercept: 1.0063039434023275\n",
      "iteration - 6684 -> loss: 0.0002773342053567556, self.slope: [1.07125688 1.07178352], self.intercept: 1.0063047366403153\n",
      "iteration - 6685 -> loss: 0.00027731944986643793, self.slope: [1.0712654  1.07179214], self.intercept: 1.0063055298434382\n",
      "iteration - 6686 -> loss: 0.000277304695996281, self.slope: [1.07127392 1.07180076], self.intercept: 1.006306323011702\n",
      "iteration - 6687 -> loss: 0.00027728994374602415, self.slope: [1.07128244 1.07180937], self.intercept: 1.0063071161451083\n",
      "iteration - 6688 -> loss: 0.00027727519311540903, self.slope: [1.07129096 1.07181799], self.intercept: 1.0063079092436598\n",
      "iteration - 6689 -> loss: 0.00027726044410415974, self.slope: [1.07129948 1.07182661], self.intercept: 1.00630870230736\n",
      "iteration - 6690 -> loss: 0.0002772456967119821, self.slope: [1.071308   1.07183523], self.intercept: 1.0063094953362137\n",
      "iteration - 6691 -> loss: 0.00027723095093865573, self.slope: [1.07131652 1.07184384], self.intercept: 1.0063102883302235\n",
      "iteration - 6692 -> loss: 0.00027721620678387783, self.slope: [1.07132504 1.07185246], self.intercept: 1.0063110812893923\n",
      "iteration - 6693 -> loss: 0.00027720146424737533, self.slope: [1.07133356 1.07186107], self.intercept: 1.0063118742137227\n",
      "iteration - 6694 -> loss: 0.00027718672332890134, self.slope: [1.07134208 1.07186969], self.intercept: 1.0063126671032199\n",
      "iteration - 6695 -> loss: 0.0002771719840281517, self.slope: [1.0713506 1.0718783], self.intercept: 1.0063134599578867\n",
      "iteration - 6696 -> loss: 0.00027715724634489613, self.slope: [1.07135911 1.07188692], self.intercept: 1.0063142527777271\n",
      "iteration - 6697 -> loss: 0.0002771425102788448, self.slope: [1.07136763 1.07189553], self.intercept: 1.0063150455627423\n",
      "iteration - 6698 -> loss: 0.0002771277758297186, self.slope: [1.07137615 1.07190414], self.intercept: 1.0063158383129374\n",
      "iteration - 6699 -> loss: 0.0002771130429972688, self.slope: [1.07138466 1.07191275], self.intercept: 1.0063166310283154\n",
      "iteration - 6700 -> loss: 0.0002770983117811995, self.slope: [1.07139318 1.07192137], self.intercept: 1.0063174237088792\n",
      "iteration - 6701 -> loss: 0.00027708358218127917, self.slope: [1.07140169 1.07192998], self.intercept: 1.00631821635463\n",
      "iteration - 6702 -> loss: 0.00027706885419721247, self.slope: [1.07141021 1.07193859], self.intercept: 1.0063190089655738\n",
      "iteration - 6703 -> loss: 0.00027705412782872427, self.slope: [1.07141872 1.0719472 ], self.intercept: 1.0063198015417156\n",
      "iteration - 6704 -> loss: 0.0002770394030755611, self.slope: [1.07142723 1.07195581], self.intercept: 1.0063205940830557\n",
      "iteration - 6705 -> loss: 0.000277024679937451, self.slope: [1.07143575 1.07196442], self.intercept: 1.0063213865895984\n",
      "iteration - 6706 -> loss: 0.0002770099584141148, self.slope: [1.07144426 1.07197303], self.intercept: 1.0063221790613448\n",
      "iteration - 6707 -> loss: 0.000276995238505304, self.slope: [1.07145277 1.07198164], self.intercept: 1.0063229714983026\n",
      "iteration - 6708 -> loss: 0.00027698052021073096, self.slope: [1.07146128 1.07199025], self.intercept: 1.0063237639004734\n",
      "iteration - 6709 -> loss: 0.00027696580353013344, self.slope: [1.07146979 1.07199885], self.intercept: 1.00632455626786\n",
      "iteration - 6710 -> loss: 0.00027695108846323267, self.slope: [1.0714783  1.07200746], self.intercept: 1.0063253486004664\n",
      "iteration - 6711 -> loss: 0.00027693637500977956, self.slope: [1.07148681 1.07201607], self.intercept: 1.0063261408982944\n",
      "iteration - 6712 -> loss: 0.00027692166316948755, self.slope: [1.07149532 1.07202467], self.intercept: 1.0063269331613476\n",
      "iteration - 6713 -> loss: 0.00027690695294210304, self.slope: [1.07150383 1.07203328], self.intercept: 1.0063277253896306\n",
      "iteration - 6714 -> loss: 0.00027689224432734334, self.slope: [1.07151234 1.07204189], self.intercept: 1.006328517583147\n",
      "iteration - 6715 -> loss: 0.0002768775373249589, self.slope: [1.07152085 1.07205049], self.intercept: 1.0063293097418988\n",
      "iteration - 6716 -> loss: 0.00027686283193465664, self.slope: [1.07152936 1.07205909], self.intercept: 1.006330101865889\n",
      "iteration - 6717 -> loss: 0.00027684812815617166, self.slope: [1.07153786 1.0720677 ], self.intercept: 1.006330893955123\n",
      "iteration - 6718 -> loss: 0.0002768334259892582, self.slope: [1.07154637 1.0720763 ], self.intercept: 1.0063316860096014\n",
      "iteration - 6719 -> loss: 0.0002768187254336254, self.slope: [1.07155488 1.07208491], self.intercept: 1.006332478029329\n",
      "iteration - 6720 -> loss: 0.00027680402648902486, self.slope: [1.07156338 1.07209351], self.intercept: 1.00633327001431\n",
      "iteration - 6721 -> loss: 0.00027678932915516395, self.slope: [1.07157189 1.07210211], self.intercept: 1.0063340619645476\n",
      "iteration - 6722 -> loss: 0.00027677463343180075, self.slope: [1.07158039 1.07211071], self.intercept: 1.0063348538800427\n",
      "iteration - 6723 -> loss: 0.0002767599393186461, self.slope: [1.0715889  1.07211931], self.intercept: 1.0063356457608006\n",
      "iteration - 6724 -> loss: 0.0002767452468154358, self.slope: [1.0715974  1.07212791], self.intercept: 1.0063364376068233\n",
      "iteration - 6725 -> loss: 0.00027673055592191374, self.slope: [1.0716059  1.07213651], self.intercept: 1.0063372294181154\n",
      "iteration - 6726 -> loss: 0.00027671586663779963, self.slope: [1.07161441 1.07214511], self.intercept: 1.00633802119468\n",
      "iteration - 6727 -> loss: 0.0002767011789628271, self.slope: [1.07162291 1.07215371], self.intercept: 1.0063388129365205\n",
      "iteration - 6728 -> loss: 0.00027668649289674143, self.slope: [1.07163141 1.07216231], self.intercept: 1.0063396046436408\n",
      "iteration - 6729 -> loss: 0.00027667180843925264, self.slope: [1.07163991 1.07217091], self.intercept: 1.0063403963160442\n",
      "iteration - 6730 -> loss: 0.0002766571255901052, self.slope: [1.07164841 1.07217951], self.intercept: 1.0063411879537305\n",
      "iteration - 6731 -> loss: 0.0002766424443490505, self.slope: [1.07165692 1.07218811], self.intercept: 1.0063419795567061\n",
      "iteration - 6732 -> loss: 0.0002766277647157811, self.slope: [1.07166542 1.0721967 ], self.intercept: 1.0063427711249746\n",
      "iteration - 6733 -> loss: 0.00027661308669007313, self.slope: [1.07167392 1.0722053 ], self.intercept: 1.0063435626585382\n",
      "iteration - 6734 -> loss: 0.0002765984102716143, self.slope: [1.07168241 1.0722139 ], self.intercept: 1.006344354157401\n",
      "iteration - 6735 -> loss: 0.0002765837354601756, self.slope: [1.07169091 1.07222249], self.intercept: 1.0063451456215669\n",
      "iteration - 6736 -> loss: 0.000276569062255457, self.slope: [1.07169941 1.07223109], self.intercept: 1.0063459370510384\n",
      "iteration - 6737 -> loss: 0.0002765543906572164, self.slope: [1.07170791 1.07223968], self.intercept: 1.0063467284458174\n",
      "iteration - 6738 -> loss: 0.00027653972066519, self.slope: [1.07171641 1.07224828], self.intercept: 1.00634751980591\n",
      "iteration - 6739 -> loss: 0.0002765250522790909, self.slope: [1.0717249  1.07225687], self.intercept: 1.0063483111313174\n",
      "iteration - 6740 -> loss: 0.00027651038549865496, self.slope: [1.0717334  1.07226546], self.intercept: 1.0063491024220443\n",
      "iteration - 6741 -> loss: 0.0002764957203236205, self.slope: [1.0717419  1.07227405], self.intercept: 1.0063498936780932\n",
      "iteration - 6742 -> loss: 0.0002764810567537278, self.slope: [1.07175039 1.07228265], self.intercept: 1.0063506848994679\n",
      "iteration - 6743 -> loss: 0.0002764663947887021, self.slope: [1.07175889 1.07229124], self.intercept: 1.0063514760861707\n",
      "iteration - 6744 -> loss: 0.00027645173442826857, self.slope: [1.07176738 1.07229983], self.intercept: 1.0063522672382044\n",
      "iteration - 6745 -> loss: 0.00027643707567218866, self.slope: [1.07177587 1.07230842], self.intercept: 1.0063530583555735\n",
      "iteration - 6746 -> loss: 0.00027642241852016396, self.slope: [1.07178437 1.07231701], self.intercept: 1.0063538494382833\n",
      "iteration - 6747 -> loss: 0.00027640776297194083, self.slope: [1.07179286 1.0723256 ], self.intercept: 1.006354640486335\n",
      "iteration - 6748 -> loss: 0.00027639310902723504, self.slope: [1.07180135 1.07233419], self.intercept: 1.006355431499731\n",
      "iteration - 6749 -> loss: 0.00027637845668580075, self.slope: [1.07180985 1.07234278], self.intercept: 1.0063562224784766\n",
      "iteration - 6750 -> loss: 0.0002763638059474036, self.slope: [1.07181834 1.07235137], self.intercept: 1.0063570134225737\n",
      "iteration - 6751 -> loss: 0.00027634915681170355, self.slope: [1.07182683 1.07235996], self.intercept: 1.0063578043320243\n",
      "iteration - 6752 -> loss: 0.00027633450927848883, self.slope: [1.07183532 1.07236855], self.intercept: 1.0063585952068337\n",
      "iteration - 6753 -> loss: 0.00027631986334746646, self.slope: [1.07184381 1.07237713], self.intercept: 1.0063593860470055\n",
      "iteration - 6754 -> loss: 0.0002763052190183837, self.slope: [1.0718523  1.07238572], self.intercept: 1.0063601768525423\n",
      "iteration - 6755 -> loss: 0.00027629057629098, self.slope: [1.07186079 1.07239431], self.intercept: 1.0063609676234475\n",
      "iteration - 6756 -> loss: 0.0002762759351649783, self.slope: [1.07186928 1.07240289], self.intercept: 1.006361758359725\n",
      "iteration - 6757 -> loss: 0.0002762612956401013, self.slope: [1.07187777 1.07241148], self.intercept: 1.0063625490613768\n",
      "iteration - 6758 -> loss: 0.00027624665771609584, self.slope: [1.07188625 1.07242006], self.intercept: 1.006363339728407\n",
      "iteration - 6759 -> loss: 0.0002762320213927028, self.slope: [1.07189474 1.07242865], self.intercept: 1.0063641303608184\n",
      "iteration - 6760 -> loss: 0.0002762173866696661, self.slope: [1.07190323 1.07243723], self.intercept: 1.0063649209586163\n",
      "iteration - 6761 -> loss: 0.00027620275354667295, self.slope: [1.07191172 1.07244581], self.intercept: 1.0063657115218017\n",
      "iteration - 6762 -> loss: 0.00027618812202350026, self.slope: [1.0719202 1.0724544], self.intercept: 1.0063665020503791\n",
      "iteration - 6763 -> loss: 0.00027617349209986346, self.slope: [1.07192869 1.07246298], self.intercept: 1.0063672925443499\n",
      "iteration - 6764 -> loss: 0.0002761588637755316, self.slope: [1.07193717 1.07247156], self.intercept: 1.0063680830037187\n",
      "iteration - 6765 -> loss: 0.00027614423705019775, self.slope: [1.07194566 1.07248014], self.intercept: 1.006368873428489\n",
      "iteration - 6766 -> loss: 0.0002761296119236022, self.slope: [1.07195414 1.07248872], self.intercept: 1.006369663818664\n",
      "iteration - 6767 -> loss: 0.00027611498839549007, self.slope: [1.07196263 1.0724973 ], self.intercept: 1.0063704541742486\n",
      "iteration - 6768 -> loss: 0.00027610036646559077, self.slope: [1.07197111 1.07250588], self.intercept: 1.0063712444952442\n",
      "iteration - 6769 -> loss: 0.00027608574613364594, self.slope: [1.07197959 1.07251446], self.intercept: 1.0063720347816545\n",
      "iteration - 6770 -> loss: 0.00027607112739937866, self.slope: [1.07198807 1.07252304], self.intercept: 1.0063728250334825\n",
      "iteration - 6771 -> loss: 0.00027605651026253665, self.slope: [1.07199656 1.07253162], self.intercept: 1.0063736152507319\n",
      "iteration - 6772 -> loss: 0.00027604189472285075, self.slope: [1.07200504 1.0725402 ], self.intercept: 1.0063744054334047\n",
      "iteration - 6773 -> loss: 0.00027602728078005305, self.slope: [1.07201352 1.07254878], self.intercept: 1.0063751955815052\n",
      "iteration - 6774 -> loss: 0.0002760126684338744, self.slope: [1.072022   1.07255736], self.intercept: 1.006375985695036\n",
      "iteration - 6775 -> loss: 0.00027599805768404933, self.slope: [1.07203048 1.07256593], self.intercept: 1.0063767757740025\n",
      "iteration - 6776 -> loss: 0.00027598344853033596, self.slope: [1.07203896 1.07257451], self.intercept: 1.0063775658184058\n",
      "iteration - 6777 -> loss: 0.00027596884097243684, self.slope: [1.07204744 1.07258309], self.intercept: 1.006378355828252\n",
      "iteration - 6778 -> loss: 0.00027595423501010737, self.slope: [1.07205592 1.07259166], self.intercept: 1.0063791458035425\n",
      "iteration - 6779 -> loss: 0.00027593963064309005, self.slope: [1.07206439 1.07260024], self.intercept: 1.0063799357442793\n",
      "iteration - 6780 -> loss: 0.00027592502787109643, self.slope: [1.07207287 1.07260881], self.intercept: 1.0063807256504669\n",
      "iteration - 6781 -> loss: 0.0002759104266938664, self.slope: [1.07208135 1.07261739], self.intercept: 1.00638151552211\n",
      "iteration - 6782 -> loss: 0.0002758958271111498, self.slope: [1.07208983 1.07262596], self.intercept: 1.0063823053592102\n",
      "iteration - 6783 -> loss: 0.0002758812291226733, self.slope: [1.0720983  1.07263453], self.intercept: 1.006383095161769\n",
      "iteration - 6784 -> loss: 0.00027586663272818115, self.slope: [1.07210678 1.0726431 ], self.intercept: 1.0063838849297937\n",
      "iteration - 6785 -> loss: 0.00027585203792738935, self.slope: [1.07211525 1.07265168], self.intercept: 1.0063846746632852\n",
      "iteration - 6786 -> loss: 0.0002758374447200484, self.slope: [1.07212373 1.07266025], self.intercept: 1.0063854643622474\n",
      "iteration - 6787 -> loss: 0.0002758228531058928, self.slope: [1.0721322  1.07266882], self.intercept: 1.0063862540266841\n",
      "iteration - 6788 -> loss: 0.00027580826308465584, self.slope: [1.07214068 1.07267739], self.intercept: 1.006387043656598\n",
      "iteration - 6789 -> loss: 0.0002757936746560828, self.slope: [1.07214915 1.07268596], self.intercept: 1.0063878332519915\n",
      "iteration - 6790 -> loss: 0.0002757790878199093, self.slope: [1.07215762 1.07269453], self.intercept: 1.0063886228128684\n",
      "iteration - 6791 -> loss: 0.00027576450257584234, self.slope: [1.0721661 1.0727031], self.intercept: 1.0063894123392338\n",
      "iteration - 6792 -> loss: 0.00027574991892364697, self.slope: [1.07217457 1.07271167], self.intercept: 1.0063902018310884\n",
      "iteration - 6793 -> loss: 0.00027573533686305475, self.slope: [1.07218304 1.07272024], self.intercept: 1.0063909912884357\n",
      "iteration - 6794 -> loss: 0.00027572075639379213, self.slope: [1.07219151 1.07272881], self.intercept: 1.006391780711283\n",
      "iteration - 6795 -> loss: 0.0002757061775156013, self.slope: [1.07219998 1.07273737], self.intercept: 1.006392570099628\n",
      "iteration - 6796 -> loss: 0.0002756916002282302, self.slope: [1.07220845 1.07274594], self.intercept: 1.0063933594534766\n",
      "iteration - 6797 -> loss: 0.00027567702453138874, self.slope: [1.07221692 1.07275451], self.intercept: 1.0063941487728314\n",
      "iteration - 6798 -> loss: 0.0002756624504248421, self.slope: [1.07222539 1.07276308], self.intercept: 1.0063949380576964\n",
      "iteration - 6799 -> loss: 0.0002756478779083132, self.slope: [1.07223386 1.07277164], self.intercept: 1.0063957273080761\n",
      "iteration - 6800 -> loss: 0.00027563330698151915, self.slope: [1.07224233 1.07278021], self.intercept: 1.0063965165239712\n",
      "iteration - 6801 -> loss: 0.0002756187376442339, self.slope: [1.0722508  1.07278877], self.intercept: 1.0063973057053874\n",
      "iteration - 6802 -> loss: 0.0002756041698961558, self.slope: [1.07225926 1.07279734], self.intercept: 1.0063980948523272\n",
      "iteration - 6803 -> loss: 0.00027558960373707197, self.slope: [1.07226773 1.0728059 ], self.intercept: 1.006398883964792\n",
      "iteration - 6804 -> loss: 0.00027557503916666266, self.slope: [1.0722762  1.07281446], self.intercept: 1.0063996730427864\n",
      "iteration - 6805 -> loss: 0.00027556047618470164, self.slope: [1.07228466 1.07282303], self.intercept: 1.0064004620863145\n",
      "iteration - 6806 -> loss: 0.00027554591479091606, self.slope: [1.07229313 1.07283159], self.intercept: 1.0064012510953795\n",
      "iteration - 6807 -> loss: 0.00027553135498503944, self.slope: [1.07230159 1.07284015], self.intercept: 1.0064020400699834\n",
      "iteration - 6808 -> loss: 0.0002755167967668076, self.slope: [1.07231006 1.07284871], self.intercept: 1.0064028290101295\n",
      "iteration - 6809 -> loss: 0.0002755022401359734, self.slope: [1.07231852 1.07285727], self.intercept: 1.006403617915823\n",
      "iteration - 6810 -> loss: 0.00027548768509225093, self.slope: [1.07232698 1.07286583], self.intercept: 1.006404406787065\n",
      "iteration - 6811 -> loss: 0.0002754731316353991, self.slope: [1.07233545 1.07287439], self.intercept: 1.0064051956238607\n",
      "iteration - 6812 -> loss: 0.000275458579765129, self.slope: [1.07234391 1.07288295], self.intercept: 1.0064059844262125\n",
      "iteration - 6813 -> loss: 0.00027544402948120303, self.slope: [1.07235237 1.07289151], self.intercept: 1.0064067731941226\n",
      "iteration - 6814 -> loss: 0.00027542948078332867, self.slope: [1.07236083 1.07290007], self.intercept: 1.006407561927595\n",
      "iteration - 6815 -> loss: 0.0002754149336712785, self.slope: [1.0723693  1.07290863], self.intercept: 1.0064083506266335\n",
      "iteration - 6816 -> loss: 0.0002754003881447589, self.slope: [1.07237776 1.07291719], self.intercept: 1.0064091392912407\n",
      "iteration - 6817 -> loss: 0.0002753858442035456, self.slope: [1.07238622 1.07292575], self.intercept: 1.0064099279214194\n",
      "iteration - 6818 -> loss: 0.00027537130184734844, self.slope: [1.07239468 1.0729343 ], self.intercept: 1.006410716517174\n",
      "iteration - 6819 -> loss: 0.000275356761075901, self.slope: [1.07240314 1.07294286], self.intercept: 1.0064115050785079\n",
      "iteration - 6820 -> loss: 0.0002753422218889584, self.slope: [1.0724116  1.07295142], self.intercept: 1.0064122936054234\n",
      "iteration - 6821 -> loss: 0.000275327684286248, self.slope: [1.07242005 1.07295997], self.intercept: 1.0064130820979253\n",
      "iteration - 6822 -> loss: 0.000275313148267498, self.slope: [1.07242851 1.07296853], self.intercept: 1.0064138705560155\n",
      "iteration - 6823 -> loss: 0.0002752986138324843, self.slope: [1.07243697 1.07297708], self.intercept: 1.006414658979698\n",
      "iteration - 6824 -> loss: 0.00027528408098089776, self.slope: [1.07244543 1.07298564], self.intercept: 1.0064154473689741\n",
      "iteration - 6825 -> loss: 0.0002752695497124999, self.slope: [1.07245388 1.07299419], self.intercept: 1.00641623572385\n",
      "iteration - 6826 -> loss: 0.0002752550200270291, self.slope: [1.07246234 1.07300274], self.intercept: 1.0064170240443273\n",
      "iteration - 6827 -> loss: 0.0002752404919242126, self.slope: [1.0724708 1.0730113], self.intercept: 1.0064178123304102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 6828 -> loss: 0.00027522596540380424, self.slope: [1.07247925 1.07301985], self.intercept: 1.0064186005821005\n",
      "iteration - 6829 -> loss: 0.0002752114404655103, self.slope: [1.07248771 1.0730284 ], self.intercept: 1.0064193887994033\n",
      "iteration - 6830 -> loss: 0.0002751969171091211, self.slope: [1.07249616 1.07303695], self.intercept: 1.0064201769823198\n",
      "iteration - 6831 -> loss: 0.0002751823953343295, self.slope: [1.07250461 1.0730455 ], self.intercept: 1.0064209651308549\n",
      "iteration - 6832 -> loss: 0.0002751678751409084, self.slope: [1.07251307 1.07305405], self.intercept: 1.0064217532450124\n",
      "iteration - 6833 -> loss: 0.0002751533565285692, self.slope: [1.07252152 1.0730626 ], self.intercept: 1.0064225413247945\n",
      "iteration - 6834 -> loss: 0.00027513883949705615, self.slope: [1.07252997 1.07307115], self.intercept: 1.0064233293702034\n",
      "iteration - 6835 -> loss: 0.00027512432404611174, self.slope: [1.07253843 1.0730797 ], self.intercept: 1.0064241173812443\n",
      "iteration - 6836 -> loss: 0.0002751098101754733, self.slope: [1.07254688 1.07308825], self.intercept: 1.0064249053579186\n",
      "iteration - 6837 -> loss: 0.00027509529788489144, self.slope: [1.07255533 1.0730968 ], self.intercept: 1.0064256933002316\n",
      "iteration - 6838 -> loss: 0.00027508078717408224, self.slope: [1.07256378 1.07310535], self.intercept: 1.0064264812081851\n",
      "iteration - 6839 -> loss: 0.0002750662780428018, self.slope: [1.07257223 1.07311389], self.intercept: 1.0064272690817835\n",
      "iteration - 6840 -> loss: 0.00027505177049078717, self.slope: [1.07258068 1.07312244], self.intercept: 1.0064280569210298\n",
      "iteration - 6841 -> loss: 0.00027503726451776685, self.slope: [1.07258913 1.07313099], self.intercept: 1.0064288447259258\n",
      "iteration - 6842 -> loss: 0.0002750227601234915, self.slope: [1.07259758 1.07313953], self.intercept: 1.006429632496476\n",
      "iteration - 6843 -> loss: 0.0002750082573076738, self.slope: [1.07260603 1.07314808], self.intercept: 1.0064304202326835\n",
      "iteration - 6844 -> loss: 0.0002749937560700921, self.slope: [1.07261447 1.07315662], self.intercept: 1.006431207934551\n",
      "iteration - 6845 -> loss: 0.0002749792564104725, self.slope: [1.07262292 1.07316517], self.intercept: 1.0064319956020817\n",
      "iteration - 6846 -> loss: 0.00027496475832853776, self.slope: [1.07263137 1.07317371], self.intercept: 1.0064327832352808\n",
      "iteration - 6847 -> loss: 0.000274950261824033, self.slope: [1.07263981 1.07318226], self.intercept: 1.0064335708341494\n",
      "iteration - 6848 -> loss: 0.0002749357668967183, self.slope: [1.07264826 1.0731908 ], self.intercept: 1.006434358398693\n",
      "iteration - 6849 -> loss: 0.0002749212735463117, self.slope: [1.07265671 1.07319934], self.intercept: 1.0064351459289123\n",
      "iteration - 6850 -> loss: 0.0002749067817725621, self.slope: [1.07266515 1.07320788], self.intercept: 1.0064359334248114\n",
      "iteration - 6851 -> loss: 0.00027489229157520235, self.slope: [1.0726736  1.07321643], self.intercept: 1.0064367208863954\n",
      "iteration - 6852 -> loss: 0.00027487780295396415, self.slope: [1.07268204 1.07322497], self.intercept: 1.0064375083136654\n",
      "iteration - 6853 -> loss: 0.00027486331590862156, self.slope: [1.07269048 1.07323351], self.intercept: 1.0064382957066242\n",
      "iteration - 6854 -> loss: 0.000274848830438866, self.slope: [1.07269893 1.07324205], self.intercept: 1.0064390830652767\n",
      "iteration - 6855 -> loss: 0.00027483434654446473, self.slope: [1.07270737 1.07325059], self.intercept: 1.0064398703896265\n",
      "iteration - 6856 -> loss: 0.000274819864225174, self.slope: [1.07271581 1.07325913], self.intercept: 1.0064406576796738\n",
      "iteration - 6857 -> loss: 0.00027480538348069895, self.slope: [1.07272425 1.07326767], self.intercept: 1.0064414449354266\n",
      "iteration - 6858 -> loss: 0.00027479090431078984, self.slope: [1.07273269 1.07327621], self.intercept: 1.0064422321568836\n",
      "iteration - 6859 -> loss: 0.00027477642671520734, self.slope: [1.07274114 1.07328474], self.intercept: 1.0064430193440503\n",
      "iteration - 6860 -> loss: 0.00027476195069366956, self.slope: [1.07274958 1.07329328], self.intercept: 1.0064438064969305\n",
      "iteration - 6861 -> loss: 0.0002747474762459188, self.slope: [1.07275802 1.07330182], self.intercept: 1.0064445936155255\n",
      "iteration - 6862 -> loss: 0.00027473300337169484, self.slope: [1.07276646 1.07331036], self.intercept: 1.0064453806998412\n",
      "iteration - 6863 -> loss: 0.0002747185320707466, self.slope: [1.07277489 1.07331889], self.intercept: 1.006446167749879\n",
      "iteration - 6864 -> loss: 0.0002747040623428188, self.slope: [1.07278333 1.07332743], self.intercept: 1.0064469547656425\n",
      "iteration - 6865 -> loss: 0.0002746895941876379, self.slope: [1.07279177 1.07333596], self.intercept: 1.006447741747135\n",
      "iteration - 6866 -> loss: 0.0002746751276049439, self.slope: [1.07280021 1.0733445 ], self.intercept: 1.006448528694359\n",
      "iteration - 6867 -> loss: 0.0002746606625944843, self.slope: [1.07280865 1.07335303], self.intercept: 1.006449315607318\n",
      "iteration - 6868 -> loss: 0.00027464619915598535, self.slope: [1.07281708 1.07336157], self.intercept: 1.0064501024860155\n",
      "iteration - 6869 -> loss: 0.0002746317372892233, self.slope: [1.07282552 1.0733701 ], self.intercept: 1.0064508893304553\n",
      "iteration - 6870 -> loss: 0.0002746172769938938, self.slope: [1.07283396 1.07337863], self.intercept: 1.0064516761406412\n",
      "iteration - 6871 -> loss: 0.0002746028182697732, self.slope: [1.07284239 1.07338716], self.intercept: 1.0064524629165754\n",
      "iteration - 6872 -> loss: 0.0002745883611165744, self.slope: [1.07285083 1.0733957 ], self.intercept: 1.006453249658261\n",
      "iteration - 6873 -> loss: 0.000274573905534058, self.slope: [1.07285926 1.07340423], self.intercept: 1.0064540363657015\n",
      "iteration - 6874 -> loss: 0.0002745594515219666, self.slope: [1.07286769 1.07341276], self.intercept: 1.0064548230389005\n",
      "iteration - 6875 -> loss: 0.00027454499908002844, self.slope: [1.07287613 1.07342129], self.intercept: 1.0064556096778607\n",
      "iteration - 6876 -> loss: 0.00027453054820797423, self.slope: [1.07288456 1.07342982], self.intercept: 1.0064563962825857\n",
      "iteration - 6877 -> loss: 0.0002745160989055746, self.slope: [1.07289299 1.07343835], self.intercept: 1.0064571828530784\n",
      "iteration - 6878 -> loss: 0.0002745016511725423, self.slope: [1.07290143 1.07344688], self.intercept: 1.0064579693893425\n",
      "iteration - 6879 -> loss: 0.00027448720500864343, self.slope: [1.07290986 1.07345541], self.intercept: 1.0064587558913813\n",
      "iteration - 6880 -> loss: 0.0002744727604136083, self.slope: [1.07291829 1.07346394], self.intercept: 1.0064595423591973\n",
      "iteration - 6881 -> loss: 0.0002744583173871657, self.slope: [1.07292672 1.07347247], self.intercept: 1.0064603287927936\n",
      "iteration - 6882 -> loss: 0.00027444387592907485, self.slope: [1.07293515 1.07348099], self.intercept: 1.0064611151921738\n",
      "iteration - 6883 -> loss: 0.0002744294360390777, self.slope: [1.07294358 1.07348952], self.intercept: 1.006461901557341\n",
      "iteration - 6884 -> loss: 0.0002744149977169086, self.slope: [1.07295201 1.07349805], self.intercept: 1.0064626878882994\n",
      "iteration - 6885 -> loss: 0.0002744005609622964, self.slope: [1.07296044 1.07350657], self.intercept: 1.0064634741850498\n",
      "iteration - 6886 -> loss: 0.00027438612577499973, self.slope: [1.07296887 1.0735151 ], self.intercept: 1.006464260447599\n",
      "iteration - 6887 -> loss: 0.0002743716921547596, self.slope: [1.07297729 1.07352362], self.intercept: 1.0064650466759495\n",
      "iteration - 6888 -> loss: 0.0002743572601013045, self.slope: [1.07298572 1.07353215], self.intercept: 1.0064658328701026\n",
      "iteration - 6889 -> loss: 0.0002743428296143788, self.slope: [1.07299415 1.07354067], self.intercept: 1.006466619030062\n",
      "iteration - 6890 -> loss: 0.00027432840069373796, self.slope: [1.07300257 1.0735492 ], self.intercept: 1.0064674051558316\n",
      "iteration - 6891 -> loss: 0.00027431397333911334, self.slope: [1.073011   1.07355772], self.intercept: 1.0064681912474136\n",
      "iteration - 6892 -> loss: 0.0002742995475502546, self.slope: [1.07301943 1.07356624], self.intercept: 1.0064689773048132\n",
      "iteration - 6893 -> loss: 0.0002742851233269028, self.slope: [1.07302785 1.07357477], self.intercept: 1.0064697633280326\n",
      "iteration - 6894 -> loss: 0.0002742707006687842, self.slope: [1.07303628 1.07358329], self.intercept: 1.0064705493170758\n",
      "iteration - 6895 -> loss: 0.00027425627957566363, self.slope: [1.0730447  1.07359181], self.intercept: 1.006471335271943\n",
      "iteration - 6896 -> loss: 0.0002742418600472672, self.slope: [1.07305312 1.07360033], self.intercept: 1.0064721211926408\n",
      "iteration - 6897 -> loss: 0.00027422744208333873, self.slope: [1.07306155 1.07360885], self.intercept: 1.0064729070791716\n",
      "iteration - 6898 -> loss: 0.00027421302568362107, self.slope: [1.07306997 1.07361737], self.intercept: 1.0064736929315377\n",
      "iteration - 6899 -> loss: 0.0002741986108478671, self.slope: [1.07307839 1.07362589], self.intercept: 1.0064744787497435\n",
      "iteration - 6900 -> loss: 0.0002741841975758085, self.slope: [1.07308682 1.07363441], self.intercept: 1.0064752645337904\n",
      "iteration - 6901 -> loss: 0.0002741697858671712, self.slope: [1.07309524 1.07364293], self.intercept: 1.0064760502836843\n",
      "iteration - 6902 -> loss: 0.0002741553757217369, self.slope: [1.07310366 1.07365145], self.intercept: 1.0064768359994272\n",
      "iteration - 6903 -> loss: 0.00027414096713922095, self.slope: [1.07311208 1.07365996], self.intercept: 1.0064776216810223\n",
      "iteration - 6904 -> loss: 0.000274126560119365, self.slope: [1.0731205  1.07366848], self.intercept: 1.0064784073284732\n",
      "iteration - 6905 -> loss: 0.00027411215466193904, self.slope: [1.07312892 1.073677  ], self.intercept: 1.0064791929417827\n",
      "iteration - 6906 -> loss: 0.00027409775076664986, self.slope: [1.07313734 1.07368552], self.intercept: 1.0064799785209524\n",
      "iteration - 6907 -> loss: 0.00027408334843325973, self.slope: [1.07314576 1.07369403], self.intercept: 1.006480764065987\n",
      "iteration - 6908 -> loss: 0.00027406894766149824, self.slope: [1.07315417 1.07370255], self.intercept: 1.0064815495768915\n",
      "iteration - 6909 -> loss: 0.00027405454845114293, self.slope: [1.07316259 1.07371106], self.intercept: 1.006482335053667\n",
      "iteration - 6910 -> loss: 0.0002740401508018742, self.slope: [1.07317101 1.07371958], self.intercept: 1.0064831204963167\n",
      "iteration - 6911 -> loss: 0.000274025754713487, self.slope: [1.07317943 1.07372809], self.intercept: 1.0064839059048452\n",
      "iteration - 6912 -> loss: 0.0002740113601857096, self.slope: [1.07318784 1.0737366 ], self.intercept: 1.0064846912792536\n",
      "iteration - 6913 -> loss: 0.00027399696721829285, self.slope: [1.07319626 1.07374512], self.intercept: 1.0064854766195466\n",
      "iteration - 6914 -> loss: 0.00027398257581096145, self.slope: [1.07320467 1.07375363], self.intercept: 1.0064862619257273\n",
      "iteration - 6915 -> loss: 0.0002739681859634705, self.slope: [1.07321309 1.07376214], self.intercept: 1.0064870471977987\n",
      "iteration - 6916 -> loss: 0.0002739537976755675, self.slope: [1.0732215  1.07377065], self.intercept: 1.0064878324357656\n",
      "iteration - 6917 -> loss: 0.00027393941094698256, self.slope: [1.07322992 1.07377917], self.intercept: 1.0064886176396286\n",
      "iteration - 6918 -> loss: 0.00027392502577746686, self.slope: [1.07323833 1.07378768], self.intercept: 1.006489402809393\n",
      "iteration - 6919 -> loss: 0.0002739106421667458, self.slope: [1.07324675 1.07379619], self.intercept: 1.0064901879450605\n",
      "iteration - 6920 -> loss: 0.0002738962601146115, self.slope: [1.07325516 1.0738047 ], self.intercept: 1.0064909730466352\n",
      "iteration - 6921 -> loss: 0.0002738818796207613, self.slope: [1.07326357 1.07381321], self.intercept: 1.0064917581141197\n",
      "iteration - 6922 -> loss: 0.00027386750068494556, self.slope: [1.07327198 1.07382172], self.intercept: 1.006492543147519\n",
      "iteration - 6923 -> loss: 0.00027385312330692577, self.slope: [1.07328039 1.07383023], self.intercept: 1.0064933281468338\n",
      "iteration - 6924 -> loss: 0.0002738387474864341, self.slope: [1.0732888  1.07383873], self.intercept: 1.006494113112069\n",
      "iteration - 6925 -> loss: 0.0002738243732232087, self.slope: [1.07329721 1.07384724], self.intercept: 1.0064948980432262\n",
      "iteration - 6926 -> loss: 0.000273810000517001, self.slope: [1.07330562 1.07385575], self.intercept: 1.0064956829403102\n",
      "iteration - 6927 -> loss: 0.0002737956293675572, self.slope: [1.07331403 1.07386426], self.intercept: 1.0064964678033228\n",
      "iteration - 6928 -> loss: 0.00027378125977462825, self.slope: [1.07332244 1.07387276], self.intercept: 1.0064972526322695\n",
      "iteration - 6929 -> loss: 0.0002737668917379254, self.slope: [1.07333085 1.07388127], self.intercept: 1.006498037427152\n",
      "iteration - 6930 -> loss: 0.00027375252525724074, self.slope: [1.07333926 1.07388977], self.intercept: 1.0064988221879752\n",
      "iteration - 6931 -> loss: 0.0002737381603322732, self.slope: [1.07334767 1.07389828], self.intercept: 1.0064996069147407\n",
      "iteration - 6932 -> loss: 0.00027372379696278615, self.slope: [1.07335608 1.07390678], self.intercept: 1.006500391607451\n",
      "iteration - 6933 -> loss: 0.0002737094351485286, self.slope: [1.07336448 1.07391529], self.intercept: 1.006501176266111\n",
      "iteration - 6934 -> loss: 0.0002736950748892325, self.slope: [1.07337289 1.07392379], self.intercept: 1.0065019608907215\n",
      "iteration - 6935 -> loss: 0.0002736807161846647, self.slope: [1.07338129 1.07393229], self.intercept: 1.0065027454812876\n",
      "iteration - 6936 -> loss: 0.0002736663590345532, self.slope: [1.0733897 1.0739408], self.intercept: 1.0065035300378131\n",
      "iteration - 6937 -> loss: 0.0002736520034386113, self.slope: [1.0733981 1.0739493], self.intercept: 1.0065043145603003\n",
      "iteration - 6938 -> loss: 0.0002736376493966507, self.slope: [1.07340651 1.0739578 ], self.intercept: 1.0065050990487516\n",
      "iteration - 6939 -> loss: 0.00027362329690837437, self.slope: [1.07341491 1.0739663 ], self.intercept: 1.0065058835031715\n",
      "iteration - 6940 -> loss: 0.0002736089459735241, self.slope: [1.07342332 1.0739748 ], self.intercept: 1.0065066679235632\n",
      "iteration - 6941 -> loss: 0.0002735945965918591, self.slope: [1.07343172 1.0739833 ], self.intercept: 1.0065074523099287\n",
      "iteration - 6942 -> loss: 0.00027358024876311535, self.slope: [1.07344012 1.0739918 ], self.intercept: 1.006508236662272\n",
      "iteration - 6943 -> loss: 0.00027356590248704725, self.slope: [1.07344852 1.0740003 ], self.intercept: 1.0065090209805967\n",
      "iteration - 6944 -> loss: 0.00027355155776337967, self.slope: [1.07345693 1.0740088 ], self.intercept: 1.0065098052649049\n",
      "iteration - 6945 -> loss: 0.0002735372145918874, self.slope: [1.07346533 1.0740173 ], self.intercept: 1.0065105895152007\n",
      "iteration - 6946 -> loss: 0.0002735228729722989, self.slope: [1.07347373 1.0740258 ], self.intercept: 1.006511373731488\n",
      "iteration - 6947 -> loss: 0.0002735085329043382, self.slope: [1.07348213 1.0740343 ], self.intercept: 1.0065121579137695\n",
      "iteration - 6948 -> loss: 0.0002734941943877991, self.slope: [1.07349053 1.07404279], self.intercept: 1.0065129420620471\n",
      "iteration - 6949 -> loss: 0.00027347985742238995, self.slope: [1.07349893 1.07405129], self.intercept: 1.0065137261763262\n",
      "iteration - 6950 -> loss: 0.0002734655220078479, self.slope: [1.07350733 1.07405979], self.intercept: 1.0065145102566062\n",
      "iteration - 6951 -> loss: 0.00027345118814393936, self.slope: [1.07351573 1.07406828], self.intercept: 1.0065152943028945\n",
      "iteration - 6952 -> loss: 0.00027343685583041137, self.slope: [1.07352412 1.07407678], self.intercept: 1.0065160783151932\n",
      "iteration - 6953 -> loss: 0.0002734225250670068, self.slope: [1.07353252 1.07408527], self.intercept: 1.0065168622935035\n",
      "iteration - 6954 -> loss: 0.0002734081958534658, self.slope: [1.07354092 1.07409377], self.intercept: 1.0065176462378311\n",
      "iteration - 6955 -> loss: 0.0002733938681895308, self.slope: [1.07354932 1.07410226], self.intercept: 1.0065184301481784\n",
      "iteration - 6956 -> loss: 0.0002733795420749586, self.slope: [1.07355771 1.07411076], self.intercept: 1.0065192140245482\n",
      "iteration - 6957 -> loss: 0.00027336521750947996, self.slope: [1.07356611 1.07411925], self.intercept: 1.006519997866945\n",
      "iteration - 6958 -> loss: 0.0002733508944928475, self.slope: [1.0735745  1.07412774], self.intercept: 1.0065207816753705\n",
      "iteration - 6959 -> loss: 0.0002733365730248163, self.slope: [1.0735829  1.07413623], self.intercept: 1.006521565449828\n",
      "iteration - 6960 -> loss: 0.00027332225310511813, self.slope: [1.07359129 1.07414473], self.intercept: 1.0065223491903206\n",
      "iteration - 6961 -> loss: 0.0002733079347334911, self.slope: [1.07359969 1.07415322], self.intercept: 1.0065231328968527\n",
      "iteration - 6962 -> loss: 0.0002732936179097019, self.slope: [1.07360808 1.07416171], self.intercept: 1.0065239165694262\n",
      "iteration - 6963 -> loss: 0.0002732793026334926, self.slope: [1.07361647 1.0741702 ], self.intercept: 1.006524700208045\n",
      "iteration - 6964 -> loss: 0.00027326498890461304, self.slope: [1.07362486 1.07417869], self.intercept: 1.0065254838127125\n",
      "iteration - 6965 -> loss: 0.0002732506767227817, self.slope: [1.07363326 1.07418718], self.intercept: 1.0065262673834319\n",
      "iteration - 6966 -> loss: 0.0002732363660877757, self.slope: [1.07364165 1.07419567], self.intercept: 1.0065270509202062\n",
      "iteration - 6967 -> loss: 0.00027322205699932214, self.slope: [1.07365004 1.07420416], self.intercept: 1.0065278344230373\n",
      "iteration - 6968 -> loss: 0.0002732077494571862, self.slope: [1.07365843 1.07421264], self.intercept: 1.0065286178919308\n",
      "iteration - 6969 -> loss: 0.0002731934434610863, self.slope: [1.07366682 1.07422113], self.intercept: 1.006529401326889\n",
      "iteration - 6970 -> loss: 0.0002731791390108017, self.slope: [1.07367521 1.07422962], self.intercept: 1.006530184727914\n",
      "iteration - 6971 -> loss: 0.00027316483610603977, self.slope: [1.0736836  1.07423811], self.intercept: 1.0065309680950112\n",
      "iteration - 6972 -> loss: 0.0002731505347465864, self.slope: [1.07369199 1.07424659], self.intercept: 1.0065317514281806\n",
      "iteration - 6973 -> loss: 0.0002731362349321606, self.slope: [1.07370038 1.07425508], self.intercept: 1.0065325347274288\n",
      "iteration - 6974 -> loss: 0.0002731219366625056, self.slope: [1.07370877 1.07426356], self.intercept: 1.0065333179927571\n",
      "iteration - 6975 -> loss: 0.000273107639937399, self.slope: [1.07371715 1.07427205], self.intercept: 1.0065341012241682\n",
      "iteration - 6976 -> loss: 0.00027309334475656793, self.slope: [1.07372554 1.07428053], self.intercept: 1.0065348844216677\n",
      "iteration - 6977 -> loss: 0.0002730790511197584, self.slope: [1.07373393 1.07428902], self.intercept: 1.0065356675852553\n",
      "iteration - 6978 -> loss: 0.00027306475902672006, self.slope: [1.07374231 1.0742975 ], self.intercept: 1.006536450714937\n",
      "iteration - 6979 -> loss: 0.0002730504684771925, self.slope: [1.0737507  1.07430598], self.intercept: 1.0065372338107152\n",
      "iteration - 6980 -> loss: 0.0002730361794709259, self.slope: [1.07375908 1.07431447], self.intercept: 1.0065380168725941\n",
      "iteration - 6981 -> loss: 0.00027302189200767896, self.slope: [1.07376747 1.07432295], self.intercept: 1.006538799900574\n",
      "iteration - 6982 -> loss: 0.00027300760608718676, self.slope: [1.07377585 1.07433143], self.intercept: 1.0065395828946606\n",
      "iteration - 6983 -> loss: 0.00027299332170920053, self.slope: [1.07378424 1.07433991], self.intercept: 1.006540365854856\n",
      "iteration - 6984 -> loss: 0.0002729790388734669, self.slope: [1.07379262 1.07434839], self.intercept: 1.0065411487811649\n",
      "iteration - 6985 -> loss: 0.0002729647575797097, self.slope: [1.073801   1.07435687], self.intercept: 1.0065419316735893\n",
      "iteration - 6986 -> loss: 0.0002729504778277235, self.slope: [1.07380939 1.07436535], self.intercept: 1.006542714532132\n",
      "iteration - 6987 -> loss: 0.0002729361996172195, self.slope: [1.07381777 1.07437383], self.intercept: 1.0065434973567966\n",
      "iteration - 6988 -> loss: 0.0002729219229479558, self.slope: [1.07382615 1.07438231], self.intercept: 1.0065442801475861\n",
      "iteration - 6989 -> loss: 0.0002729076478196707, self.slope: [1.07383453 1.07439079], self.intercept: 1.0065450629045047\n",
      "iteration - 6990 -> loss: 0.0002728933742321401, self.slope: [1.07384291 1.07439927], self.intercept: 1.0065458456275544\n",
      "iteration - 6991 -> loss: 0.00027287910218507514, self.slope: [1.07385129 1.07440775], self.intercept: 1.0065466283167395\n",
      "iteration - 6992 -> loss: 0.00027286483167824173, self.slope: [1.07385967 1.07441622], self.intercept: 1.0065474109720627\n",
      "iteration - 6993 -> loss: 0.00027285056271138567, self.slope: [1.07386805 1.0744247 ], self.intercept: 1.0065481935935259\n",
      "iteration - 6994 -> loss: 0.0002728362952842603, self.slope: [1.07387643 1.07443318], self.intercept: 1.0065489761811328\n",
      "iteration - 6995 -> loss: 0.0002728220293965991, self.slope: [1.07388481 1.07444165], self.intercept: 1.0065497587348882\n",
      "iteration - 6996 -> loss: 0.0002728077650481595, self.slope: [1.07389319 1.07445013], self.intercept: 1.0065505412547944\n",
      "iteration - 6997 -> loss: 0.00027279350223868783, self.slope: [1.07390156 1.0744586 ], self.intercept: 1.0065513237408554\n",
      "iteration - 6998 -> loss: 0.00027277924096792775, self.slope: [1.07390994 1.07446708], self.intercept: 1.0065521061930733\n",
      "iteration - 6999 -> loss: 0.0002727649812356409, self.slope: [1.07391832 1.07447555], self.intercept: 1.0065528886114528\n",
      "iteration - 7000 -> loss: 0.00027275072304154926, self.slope: [1.07392669 1.07448403], self.intercept: 1.0065536709959937\n",
      "iteration - 7001 -> loss: 0.00027273646638543525, self.slope: [1.07393507 1.0744925 ], self.intercept: 1.0065544533467012\n",
      "iteration - 7002 -> loss: 0.000272722211267012, self.slope: [1.07394344 1.07450097], self.intercept: 1.0065552356635785\n",
      "iteration - 7003 -> loss: 0.00027270795768605553, self.slope: [1.07395182 1.07450944], self.intercept: 1.0065560179466306\n",
      "iteration - 7004 -> loss: 0.000272693705642293, self.slope: [1.07396019 1.07451792], self.intercept: 1.006556800195857\n",
      "iteration - 7005 -> loss: 0.0002726794551354909, self.slope: [1.07396857 1.07452639], self.intercept: 1.006557582411263\n",
      "iteration - 7006 -> loss: 0.0002726652061653881, self.slope: [1.07397694 1.07453486], self.intercept: 1.0065583645928504\n",
      "iteration - 7007 -> loss: 0.00027265095873172366, self.slope: [1.07398531 1.07454333], self.intercept: 1.0065591467406259\n",
      "iteration - 7008 -> loss: 0.0002726367128342466, self.slope: [1.07399369 1.0745518 ], self.intercept: 1.0065599288545892\n",
      "iteration - 7009 -> loss: 0.00027262246847273075, self.slope: [1.07400206 1.07456027], self.intercept: 1.0065607109347463\n",
      "iteration - 7010 -> loss: 0.0002726082256469093, self.slope: [1.07401043 1.07456874], self.intercept: 1.0065614929810973\n",
      "iteration - 7011 -> loss: 0.00027259398435650924, self.slope: [1.0740188  1.07457721], self.intercept: 1.0065622749936465\n",
      "iteration - 7012 -> loss: 0.00027257974460132125, self.slope: [1.07402717 1.07458567], self.intercept: 1.006563056972397\n",
      "iteration - 7013 -> loss: 0.0002725655063810658, self.slope: [1.07403554 1.07459414], self.intercept: 1.0065638389173517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 7014 -> loss: 0.0002725512696955036, self.slope: [1.07404391 1.07460261], self.intercept: 1.0065646208285155\n",
      "iteration - 7015 -> loss: 0.00027253703454436297, self.slope: [1.07405228 1.07461108], self.intercept: 1.0065654027058906\n",
      "iteration - 7016 -> loss: 0.0002725228009274211, self.slope: [1.07406065 1.07461954], self.intercept: 1.0065661845494789\n",
      "iteration - 7017 -> loss: 0.0002725085688444023, self.slope: [1.07406902 1.07462801], self.intercept: 1.006566966359286\n",
      "iteration - 7018 -> loss: 0.0002724943382950742, self.slope: [1.07407739 1.07463647], self.intercept: 1.0065677481353132\n",
      "iteration - 7019 -> loss: 0.0002724801092791678, self.slope: [1.07408575 1.07464494], self.intercept: 1.0065685298775644\n",
      "iteration - 7020 -> loss: 0.00027246588179645633, self.slope: [1.07409412 1.0746534 ], self.intercept: 1.0065693115860443\n",
      "iteration - 7021 -> loss: 0.0002724516558466595, self.slope: [1.07410249 1.07466187], self.intercept: 1.0065700932607535\n",
      "iteration - 7022 -> loss: 0.0002724374314295442, self.slope: [1.07411085 1.07467033], self.intercept: 1.0065708749016962\n",
      "iteration - 7023 -> loss: 0.00027242320854486485, self.slope: [1.07411922 1.07467879], self.intercept: 1.0065716565088754\n",
      "iteration - 7024 -> loss: 0.000272408987192359, self.slope: [1.07412758 1.07468726], self.intercept: 1.0065724380822942\n",
      "iteration - 7025 -> loss: 0.0002723947673717819, self.slope: [1.07413595 1.07469572], self.intercept: 1.006573219621955\n",
      "iteration - 7026 -> loss: 0.0002723805490828717, self.slope: [1.07414431 1.07470418], self.intercept: 1.0065740011278639\n",
      "iteration - 7027 -> loss: 0.0002723663323253901, self.slope: [1.07415268 1.07471264], self.intercept: 1.0065747826000222\n",
      "iteration - 7028 -> loss: 0.00027235211709909763, self.slope: [1.07416104 1.0747211 ], self.intercept: 1.0065755640384317\n",
      "iteration - 7029 -> loss: 0.00027233790340373045, self.slope: [1.0741694  1.07472956], self.intercept: 1.006576345443098\n",
      "iteration - 7030 -> loss: 0.00027232369123900477, self.slope: [1.07417776 1.07473802], self.intercept: 1.0065771268140222\n",
      "iteration - 7031 -> loss: 0.0002723094806047223, self.slope: [1.07418613 1.07474648], self.intercept: 1.0065779081512094\n",
      "iteration - 7032 -> loss: 0.0002722952715006192, self.slope: [1.07419449 1.07475494], self.intercept: 1.0065786894546616\n",
      "iteration - 7033 -> loss: 0.0002722810639264325, self.slope: [1.07420285 1.0747634 ], self.intercept: 1.006579470724382\n",
      "iteration - 7034 -> loss: 0.0002722668578819041, self.slope: [1.07421121 1.07477186], self.intercept: 1.006580251960373\n",
      "iteration - 7035 -> loss: 0.0002722526533668235, self.slope: [1.07421957 1.07478032], self.intercept: 1.0065810331626397\n",
      "iteration - 7036 -> loss: 0.0002722384503808932, self.slope: [1.07422793 1.07478878], self.intercept: 1.0065818143311847\n",
      "iteration - 7037 -> loss: 0.00027222424892390444, self.slope: [1.07423629 1.07479723], self.intercept: 1.0065825954660108\n",
      "iteration - 7038 -> loss: 0.0002722100489955738, self.slope: [1.07424465 1.07480569], self.intercept: 1.0065833765671204\n",
      "iteration - 7039 -> loss: 0.0002721958505956789, self.slope: [1.07425301 1.07481414], self.intercept: 1.0065841576345171\n",
      "iteration - 7040 -> loss: 0.0002721816537239415, self.slope: [1.07426136 1.0748226 ], self.intercept: 1.0065849386682044\n",
      "iteration - 7041 -> loss: 0.00027216745838013856, self.slope: [1.07426972 1.07483106], self.intercept: 1.0065857196681853\n",
      "iteration - 7042 -> loss: 0.0002721532645640062, self.slope: [1.07427808 1.07483951], self.intercept: 1.0065865006344634\n",
      "iteration - 7043 -> loss: 0.0002721390722752953, self.slope: [1.07428644 1.07484796], self.intercept: 1.0065872815670425\n",
      "iteration - 7044 -> loss: 0.000272124881513763, self.slope: [1.07429479 1.07485642], self.intercept: 1.0065880624659254\n",
      "iteration - 7045 -> loss: 0.00027211069227912996, self.slope: [1.07430315 1.07486487], self.intercept: 1.0065888433311136\n",
      "iteration - 7046 -> loss: 0.00027209650457120225, self.slope: [1.0743115  1.07487332], self.intercept: 1.0065896241626107\n",
      "iteration - 7047 -> loss: 0.0002720823183896804, self.slope: [1.07431986 1.07488178], self.intercept: 1.0065904049604222\n",
      "iteration - 7048 -> loss: 0.00027206813373435387, self.slope: [1.07432821 1.07489023], self.intercept: 1.0065911857245495\n",
      "iteration - 7049 -> loss: 0.0002720539506049377, self.slope: [1.07433657 1.07489868], self.intercept: 1.0065919664549956\n",
      "iteration - 7050 -> loss: 0.0002720397690011938, self.slope: [1.07434492 1.07490713], self.intercept: 1.006592747151763\n",
      "iteration - 7051 -> loss: 0.0002720255889228827, self.slope: [1.07435327 1.07491558], self.intercept: 1.0065935278148572\n",
      "iteration - 7052 -> loss: 0.00027201141036975246, self.slope: [1.07436162 1.07492403], self.intercept: 1.0065943084442799\n",
      "iteration - 7053 -> loss: 0.00027199723334155284, self.slope: [1.07436998 1.07493248], self.intercept: 1.0065950890400337\n",
      "iteration - 7054 -> loss: 0.00027198305783801677, self.slope: [1.07437833 1.07494093], self.intercept: 1.0065958696021229\n",
      "iteration - 7055 -> loss: 0.00027196888385894896, self.slope: [1.07438668 1.07494938], self.intercept: 1.00659665013055\n",
      "iteration - 7056 -> loss: 0.0002719547114040224, self.slope: [1.07439503 1.07495783], self.intercept: 1.0065974306253178\n",
      "iteration - 7057 -> loss: 0.00027194054047304883, self.slope: [1.07440338 1.07496627], self.intercept: 1.006598211086429\n",
      "iteration - 7058 -> loss: 0.0002719263710657453, self.slope: [1.07441173 1.07497472], self.intercept: 1.006598991513888\n",
      "iteration - 7059 -> loss: 0.0002719122031818927, self.slope: [1.07442008 1.07498317], self.intercept: 1.0065997719076987\n",
      "iteration - 7060 -> loss: 0.00027189803682121135, self.slope: [1.07442843 1.07499162], self.intercept: 1.0066005522678623\n",
      "iteration - 7061 -> loss: 0.00027188387198348195, self.slope: [1.07443678 1.07500006], self.intercept: 1.0066013325943841\n",
      "iteration - 7062 -> loss: 0.000271869708668433, self.slope: [1.07444512 1.07500851], self.intercept: 1.0066021128872658\n",
      "iteration - 7063 -> loss: 0.00027185554687582375, self.slope: [1.07445347 1.07501695], self.intercept: 1.0066028931465087\n",
      "iteration - 7064 -> loss: 0.0002718413866054105, self.slope: [1.07446182 1.0750254 ], self.intercept: 1.0066036733721204\n",
      "iteration - 7065 -> loss: 0.00027182722785694386, self.slope: [1.07447017 1.07503384], self.intercept: 1.0066044535640999\n",
      "iteration - 7066 -> loss: 0.0002718130706301607, self.slope: [1.07447851 1.07504229], self.intercept: 1.0066052337224536\n",
      "iteration - 7067 -> loss: 0.00027179891492482353, self.slope: [1.07448686 1.07505073], self.intercept: 1.0066060138471837\n",
      "iteration - 7068 -> loss: 0.00027178476074069, self.slope: [1.0744952  1.07505917], self.intercept: 1.0066067939382928\n",
      "iteration - 7069 -> loss: 0.00027177060807752096, self.slope: [1.07450355 1.07506761], self.intercept: 1.0066075739957847\n",
      "iteration - 7070 -> loss: 0.00027175645693502015, self.slope: [1.07451189 1.07507606], self.intercept: 1.006608354019662\n",
      "iteration - 7071 -> loss: 0.0002717423073129919, self.slope: [1.07452024 1.0750845 ], self.intercept: 1.0066091340099268\n",
      "iteration - 7072 -> loss: 0.00027172815921118433, self.slope: [1.07452858 1.07509294], self.intercept: 1.0066099139665836\n",
      "iteration - 7073 -> loss: 0.000271714012629309, self.slope: [1.07453692 1.07510138], self.intercept: 1.0066106938896358\n",
      "iteration - 7074 -> loss: 0.0002716998675671466, self.slope: [1.07454526 1.07510982], self.intercept: 1.0066114737790846\n",
      "iteration - 7075 -> loss: 0.00027168572402446037, self.slope: [1.07455361 1.07511826], self.intercept: 1.0066122536349356\n",
      "iteration - 7076 -> loss: 0.00027167158200097017, self.slope: [1.07456195 1.0751267 ], self.intercept: 1.0066130334571919\n",
      "iteration - 7077 -> loss: 0.0002716574414964505, self.slope: [1.07457029 1.07513514], self.intercept: 1.0066138132458553\n",
      "iteration - 7078 -> loss: 0.00027164330251064643, self.slope: [1.07457863 1.07514358], self.intercept: 1.0066145930009287\n",
      "iteration - 7079 -> loss: 0.0002716291650433145, self.slope: [1.07458697 1.07515201], self.intercept: 1.0066153727224163\n",
      "iteration - 7080 -> loss: 0.0002716150290941971, self.slope: [1.07459531 1.07516045], self.intercept: 1.0066161524103212\n",
      "iteration - 7081 -> loss: 0.0002716008946630568, self.slope: [1.07460365 1.07516889], self.intercept: 1.006616932064647\n",
      "iteration - 7082 -> loss: 0.0002715867617496476, self.slope: [1.07461199 1.07517732], self.intercept: 1.006617711685394\n",
      "iteration - 7083 -> loss: 0.00027157263035372346, self.slope: [1.07462033 1.07518576], self.intercept: 1.0066184912725682\n",
      "iteration - 7084 -> loss: 0.0002715585004750105, self.slope: [1.07462866 1.0751942 ], self.intercept: 1.0066192708261719\n",
      "iteration - 7085 -> loss: 0.0002715443721132969, self.slope: [1.074637   1.07520263], self.intercept: 1.006620050346208\n",
      "iteration - 7086 -> loss: 0.0002715302452683157, self.slope: [1.07464534 1.07521107], self.intercept: 1.00662082983268\n",
      "iteration - 7087 -> loss: 0.00027151611993982085, self.slope: [1.07465368 1.0752195 ], self.intercept: 1.0066216092855917\n",
      "iteration - 7088 -> loss: 0.00027150199612757767, self.slope: [1.07466201 1.07522794], self.intercept: 1.0066223887049452\n",
      "iteration - 7089 -> loss: 0.0002714878738313357, self.slope: [1.07467035 1.07523637], self.intercept: 1.0066231680907438\n",
      "iteration - 7090 -> loss: 0.0002714737530508321, self.slope: [1.07467868 1.0752448 ], self.intercept: 1.0066239474429906\n",
      "iteration - 7091 -> loss: 0.0002714596337858171, self.slope: [1.07468702 1.07525323], self.intercept: 1.0066247267616881\n",
      "iteration - 7092 -> loss: 0.0002714455160360592, self.slope: [1.07469535 1.07526167], self.intercept: 1.006625506046841\n",
      "iteration - 7093 -> loss: 0.00027143139980132235, self.slope: [1.07470369 1.0752701 ], self.intercept: 1.006626285298452\n",
      "iteration - 7094 -> loss: 0.00027141728508133905, self.slope: [1.07471202 1.07527853], self.intercept: 1.0066270645165234\n",
      "iteration - 7095 -> loss: 0.00027140317187586914, self.slope: [1.07472035 1.07528696], self.intercept: 1.006627843701059\n",
      "iteration - 7096 -> loss: 0.0002713890601846476, self.slope: [1.07472869 1.07529539], self.intercept: 1.0066286228520627\n",
      "iteration - 7097 -> loss: 0.000271374950007467, self.slope: [1.07473702 1.07530382], self.intercept: 1.0066294019695372\n",
      "iteration - 7098 -> loss: 0.00027136084134405937, self.slope: [1.07474535 1.07531225], self.intercept: 1.0066301810534837\n",
      "iteration - 7099 -> loss: 0.0002713467341941538, self.slope: [1.07475368 1.07532068], self.intercept: 1.0066309601039065\n",
      "iteration - 7100 -> loss: 0.0002713326285575492, self.slope: [1.07476201 1.07532911], self.intercept: 1.0066317391208097\n",
      "iteration - 7101 -> loss: 0.00027131852443397915, self.slope: [1.07477034 1.07533753], self.intercept: 1.006632518104197\n",
      "iteration - 7102 -> loss: 0.0002713044218231811, self.slope: [1.07477867 1.07534596], self.intercept: 1.0066332970540701\n",
      "iteration - 7103 -> loss: 0.00027129032072493434, self.slope: [1.074787   1.07535439], self.intercept: 1.0066340759704326\n",
      "iteration - 7104 -> loss: 0.0002712762211389561, self.slope: [1.07479533 1.07536282], self.intercept: 1.0066348548532882\n",
      "iteration - 7105 -> loss: 0.00027126212306505265, self.slope: [1.07480366 1.07537124], self.intercept: 1.006635633702639\n",
      "iteration - 7106 -> loss: 0.0002712480265029301, self.slope: [1.07481199 1.07537967], self.intercept: 1.0066364125184883\n",
      "iteration - 7107 -> loss: 0.00027123393145238355, self.slope: [1.07482031 1.07538809], self.intercept: 1.0066371913008398\n",
      "iteration - 7108 -> loss: 0.00027121983791312604, self.slope: [1.07482864 1.07539652], self.intercept: 1.0066379700496964\n",
      "iteration - 7109 -> loss: 0.000271205745884941, self.slope: [1.07483697 1.07540494], self.intercept: 1.0066387487650608\n",
      "iteration - 7110 -> loss: 0.0002711916553675749, self.slope: [1.07484529 1.07541337], self.intercept: 1.0066395274469355\n",
      "iteration - 7111 -> loss: 0.0002711775663607673, self.slope: [1.07485362 1.07542179], self.intercept: 1.0066403060953248\n",
      "iteration - 7112 -> loss: 0.0002711634788642841, self.slope: [1.07486195 1.07543021], self.intercept: 1.0066410847102325\n",
      "iteration - 7113 -> loss: 0.000271149392877895, self.slope: [1.07487027 1.07543864], self.intercept: 1.006641863291661\n",
      "iteration - 7114 -> loss: 0.0002711353084013205, self.slope: [1.07487859 1.07544706], self.intercept: 1.0066426418396133\n",
      "iteration - 7115 -> loss: 0.0002711212254343334, self.slope: [1.07488692 1.07545548], self.intercept: 1.0066434203540928\n",
      "iteration - 7116 -> loss: 0.0002711071439766921, self.slope: [1.07489524 1.0754639 ], self.intercept: 1.006644198835102\n",
      "iteration - 7117 -> loss: 0.0002710930640281473, self.slope: [1.07490357 1.07547232], self.intercept: 1.0066449772826445\n",
      "iteration - 7118 -> loss: 0.00027107898558844377, self.slope: [1.07491189 1.07548074], self.intercept: 1.0066457556967223\n",
      "iteration - 7119 -> loss: 0.00027106490865735585, self.slope: [1.07492021 1.07548916], self.intercept: 1.0066465340773396\n",
      "iteration - 7120 -> loss: 0.0002710508332346082, self.slope: [1.07492853 1.07549758], self.intercept: 1.0066473124245003\n",
      "iteration - 7121 -> loss: 0.00027103675931999506, self.slope: [1.07493685 1.075506  ], self.intercept: 1.006648090738207\n",
      "iteration - 7122 -> loss: 0.00027102268691322335, self.slope: [1.07494517 1.07551442], self.intercept: 1.0066488690184616\n",
      "iteration - 7123 -> loss: 0.00027100861601409514, self.slope: [1.07495349 1.07552284], self.intercept: 1.0066496472652682\n",
      "iteration - 7124 -> loss: 0.0002709945466223388, self.slope: [1.07496181 1.07553126], self.intercept: 1.0066504254786302\n",
      "iteration - 7125 -> loss: 0.00027098047873770235, self.slope: [1.07497013 1.07553967], self.intercept: 1.0066512036585504\n",
      "iteration - 7126 -> loss: 0.0002709664123599688, self.slope: [1.07497845 1.07554809], self.intercept: 1.0066519818050321\n",
      "iteration - 7127 -> loss: 0.00027095234748886085, self.slope: [1.07498677 1.07555651], self.intercept: 1.0066527599180775\n",
      "iteration - 7128 -> loss: 0.0002709382841241496, self.slope: [1.07499509 1.07556492], self.intercept: 1.006653537997691\n",
      "iteration - 7129 -> loss: 0.00027092422226558964, self.slope: [1.07500341 1.07557334], self.intercept: 1.0066543160438752\n",
      "iteration - 7130 -> loss: 0.0002709101619129461, self.slope: [1.07501172 1.07558175], self.intercept: 1.006655094056634\n",
      "iteration - 7131 -> loss: 0.000270896103065955, self.slope: [1.07502004 1.07559017], self.intercept: 1.0066558720359688\n",
      "iteration - 7132 -> loss: 0.0002708820457243696, self.slope: [1.07502836 1.07559858], self.intercept: 1.0066566499818836\n",
      "iteration - 7133 -> loss: 0.0002708679898879711, self.slope: [1.07503667 1.075607  ], self.intercept: 1.0066574278943825\n",
      "iteration - 7134 -> loss: 0.0002708539355564938, self.slope: [1.07504499 1.07561541], self.intercept: 1.0066582057734679\n",
      "iteration - 7135 -> loss: 0.00027083988272969483, self.slope: [1.0750533  1.07562382], self.intercept: 1.0066589836191433\n",
      "iteration - 7136 -> loss: 0.0002708258314073248, self.slope: [1.07506162 1.07563223], self.intercept: 1.006659761431412\n",
      "iteration - 7137 -> loss: 0.0002708117815891675, self.slope: [1.07506993 1.07564065], self.intercept: 1.006660539210275\n",
      "iteration - 7138 -> loss: 0.00027079773327494166, self.slope: [1.07507825 1.07564906], self.intercept: 1.006661316955737\n",
      "iteration - 7139 -> loss: 0.00027078368646441876, self.slope: [1.07508656 1.07565747], self.intercept: 1.0066620946678018\n",
      "iteration - 7140 -> loss: 0.00027076964115736816, self.slope: [1.07509487 1.07566588], self.intercept: 1.0066628723464714\n",
      "iteration - 7141 -> loss: 0.0002707555973535207, self.slope: [1.07510318 1.07567429], self.intercept: 1.0066636499917498\n",
      "iteration - 7142 -> loss: 0.00027074155505264237, self.slope: [1.0751115 1.0756827], self.intercept: 1.0066644276036394\n",
      "iteration - 7143 -> loss: 0.0002707275142544952, self.slope: [1.07511981 1.07569111], self.intercept: 1.0066652051821423\n",
      "iteration - 7144 -> loss: 0.00027071347495881393, self.slope: [1.07512812 1.07569952], self.intercept: 1.0066659827272653\n",
      "iteration - 7145 -> loss: 0.0002706994371653816, self.slope: [1.07513643 1.07570793], self.intercept: 1.0066667602390078\n",
      "iteration - 7146 -> loss: 0.00027068540087394954, self.slope: [1.07514474 1.07571633], self.intercept: 1.006667537717374\n",
      "iteration - 7147 -> loss: 0.00027067136608424744, self.slope: [1.07515305 1.07572474], self.intercept: 1.0066683151623659\n",
      "iteration - 7148 -> loss: 0.00027065733279606273, self.slope: [1.07516136 1.07573315], self.intercept: 1.006669092573989\n",
      "iteration - 7149 -> loss: 0.00027064330100913156, self.slope: [1.07516967 1.07574156], self.intercept: 1.0066698699522454\n",
      "iteration - 7150 -> loss: 0.00027062927072321895, self.slope: [1.07517798 1.07574996], self.intercept: 1.0066706472971396\n",
      "iteration - 7151 -> loss: 0.00027061524193806744, self.slope: [1.07518628 1.07575837], self.intercept: 1.0066714246086712\n",
      "iteration - 7152 -> loss: 0.00027060121465346686, self.slope: [1.07519459 1.07576677], self.intercept: 1.0066722018868461\n",
      "iteration - 7153 -> loss: 0.0002705871888691411, self.slope: [1.0752029  1.07577518], self.intercept: 1.0066729791316669\n",
      "iteration - 7154 -> loss: 0.0002705731645848515, self.slope: [1.0752112  1.07578358], self.intercept: 1.0066737563431378\n",
      "iteration - 7155 -> loss: 0.0002705591418003672, self.slope: [1.07521951 1.07579199], self.intercept: 1.0066745335212597\n",
      "iteration - 7156 -> loss: 0.0002705451205154346, self.slope: [1.07522782 1.07580039], self.intercept: 1.0066753106660358\n",
      "iteration - 7157 -> loss: 0.00027053110072981605, self.slope: [1.07523612 1.07580879], self.intercept: 1.00667608777747\n",
      "iteration - 7158 -> loss: 0.00027051708244325417, self.slope: [1.07524443 1.07581719], self.intercept: 1.0066768648555666\n",
      "iteration - 7159 -> loss: 0.00027050306565552394, self.slope: [1.07525273 1.0758256 ], self.intercept: 1.0066776419003265\n",
      "iteration - 7160 -> loss: 0.0002704890503663726, self.slope: [1.07526103 1.075834  ], self.intercept: 1.0066784189117548\n",
      "iteration - 7161 -> loss: 0.00027047503657555324, self.slope: [1.07526934 1.0758424 ], self.intercept: 1.006679195889853\n",
      "iteration - 7162 -> loss: 0.0002704610242828308, self.slope: [1.07527764 1.0758508 ], self.intercept: 1.006679972834625\n",
      "iteration - 7163 -> loss: 0.0002704470134879623, self.slope: [1.07528594 1.0758592 ], self.intercept: 1.006680749746074\n",
      "iteration - 7164 -> loss: 0.00027043300419068756, self.slope: [1.07529424 1.0758676 ], self.intercept: 1.0066815266242026\n",
      "iteration - 7165 -> loss: 0.0002704189963907881, self.slope: [1.07530255 1.075876  ], self.intercept: 1.0066823034690155\n",
      "iteration - 7166 -> loss: 0.0002704049900879968, self.slope: [1.07531085 1.0758844 ], self.intercept: 1.0066830802805131\n",
      "iteration - 7167 -> loss: 0.0002703909852820955, self.slope: [1.07531915 1.0758928 ], self.intercept: 1.0066838570586996\n",
      "iteration - 7168 -> loss: 0.0002703769819728336, self.slope: [1.07532745 1.0759012 ], self.intercept: 1.0066846338035778\n",
      "iteration - 7169 -> loss: 0.00027036298015996275, self.slope: [1.07533575 1.07590959], self.intercept: 1.0066854105151541\n",
      "iteration - 7170 -> loss: 0.00027034897984322474, self.slope: [1.07534405 1.07591799], self.intercept: 1.006686187193428\n",
      "iteration - 7171 -> loss: 0.0002703349810223989, self.slope: [1.07535235 1.07592639], self.intercept: 1.0066869638384035\n",
      "iteration - 7172 -> loss: 0.0002703209836972506, self.slope: [1.07536064 1.07593478], self.intercept: 1.0066877404500845\n",
      "iteration - 7173 -> loss: 0.00027030698786749153, self.slope: [1.07536894 1.07594318], self.intercept: 1.006688517028473\n",
      "iteration - 7174 -> loss: 0.00027029299353293853, self.slope: [1.07537724 1.07595158], self.intercept: 1.0066892935735723\n",
      "iteration - 7175 -> loss: 0.0002702790006933081, self.slope: [1.07538554 1.07595997], self.intercept: 1.0066900700853856\n",
      "iteration - 7176 -> loss: 0.0002702650093483733, self.slope: [1.07539383 1.07596836], self.intercept: 1.0066908465639168\n",
      "iteration - 7177 -> loss: 0.0002702510194978962, self.slope: [1.07540213 1.07597676], self.intercept: 1.0066916230091685\n",
      "iteration - 7178 -> loss: 0.00027023703114160166, self.slope: [1.07541043 1.07598515], self.intercept: 1.0066923994211439\n",
      "iteration - 7179 -> loss: 0.0002702230442792952, self.slope: [1.07541872 1.07599355], self.intercept: 1.0066931757998443\n",
      "iteration - 7180 -> loss: 0.0002702090589107078, self.slope: [1.07542702 1.07600194], self.intercept: 1.0066939521452758\n",
      "iteration - 7181 -> loss: 0.00027019507503561204, self.slope: [1.07543531 1.07601033], self.intercept: 1.0066947284574386\n",
      "iteration - 7182 -> loss: 0.00027018109265371975, self.slope: [1.0754436  1.07601872], self.intercept: 1.0066955047363386\n",
      "iteration - 7183 -> loss: 0.00027016711176484367, self.slope: [1.0754519  1.07602711], self.intercept: 1.0066962809819777\n",
      "iteration - 7184 -> loss: 0.00027015313236873807, self.slope: [1.07546019 1.07603551], self.intercept: 1.0066970571943585\n",
      "iteration - 7185 -> loss: 0.0002701391544651285, self.slope: [1.07546848 1.0760439 ], self.intercept: 1.006697833373486\n",
      "iteration - 7186 -> loss: 0.0002701251780537915, self.slope: [1.07547678 1.07605229], self.intercept: 1.0066986095193609\n",
      "iteration - 7187 -> loss: 0.0002701112031344835, self.slope: [1.07548507 1.07606068], self.intercept: 1.0066993856319875\n",
      "iteration - 7188 -> loss: 0.00027009722970696033, self.slope: [1.07549336 1.07606906], self.intercept: 1.0067001617113673\n",
      "iteration - 7189 -> loss: 0.00027008325777097694, self.slope: [1.07550165 1.07607745], self.intercept: 1.0067009377575058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 7190 -> loss: 0.0002700692873262953, self.slope: [1.07550994 1.07608584], self.intercept: 1.0067017137704057\n",
      "iteration - 7191 -> loss: 0.00027005531837267355, self.slope: [1.07551823 1.07609423], self.intercept: 1.0067024897500703\n",
      "iteration - 7192 -> loss: 0.0002700413509098837, self.slope: [1.07552652 1.07610262], self.intercept: 1.0067032656965003\n",
      "iteration - 7193 -> loss: 0.0002700273849376585, self.slope: [1.07553481 1.076111  ], self.intercept: 1.0067040416096995\n",
      "iteration - 7194 -> loss: 0.0002700134204557696, self.slope: [1.0755431  1.07611939], self.intercept: 1.0067048174896733\n",
      "iteration - 7195 -> loss: 0.00026999945746396877, self.slope: [1.07555139 1.07612778], self.intercept: 1.0067055933364228\n",
      "iteration - 7196 -> loss: 0.00026998549596203764, self.slope: [1.07555967 1.07613616], self.intercept: 1.0067063691499518\n",
      "iteration - 7197 -> loss: 0.0002699715359497036, self.slope: [1.07556796 1.07614455], self.intercept: 1.006707144930263\n",
      "iteration - 7198 -> loss: 0.00026995757742674713, self.slope: [1.07557625 1.07615293], self.intercept: 1.0067079206773595\n",
      "iteration - 7199 -> loss: 0.0002699436203929245, self.slope: [1.07558453 1.07616132], self.intercept: 1.0067086963912453\n",
      "iteration - 7200 -> loss: 0.00026992966484795964, self.slope: [1.07559282 1.0761697 ], self.intercept: 1.0067094720719216\n",
      "iteration - 7201 -> loss: 0.0002699157107916641, self.slope: [1.0756011  1.07617808], self.intercept: 1.0067102477193945\n",
      "iteration - 7202 -> loss: 0.00026990175822376444, self.slope: [1.07560939 1.07618647], self.intercept: 1.006711023333665\n",
      "iteration - 7203 -> loss: 0.0002698878071440387, self.slope: [1.07561767 1.07619485], self.intercept: 1.0067117989147356\n",
      "iteration - 7204 -> loss: 0.0002698738575522277, self.slope: [1.07562596 1.07620323], self.intercept: 1.0067125744626104\n",
      "iteration - 7205 -> loss: 0.00026985990944810293, self.slope: [1.07563424 1.07621161], self.intercept: 1.006713349977293\n",
      "iteration - 7206 -> loss: 0.00026984596283141074, self.slope: [1.07564253 1.07621999], self.intercept: 1.006714125458784\n",
      "iteration - 7207 -> loss: 0.0002698320177019253, self.slope: [1.07565081 1.07622838], self.intercept: 1.0067149009070897\n",
      "iteration - 7208 -> loss: 0.0002698180740593957, self.slope: [1.07565909 1.07623676], self.intercept: 1.006715676322212\n",
      "iteration - 7209 -> loss: 0.0002698041319035781, self.slope: [1.07566737 1.07624514], self.intercept: 1.0067164517041545\n",
      "iteration - 7210 -> loss: 0.00026979019123424004, self.slope: [1.07567565 1.07625352], self.intercept: 1.0067172270529186\n",
      "iteration - 7211 -> loss: 0.0002697762520511409, self.slope: [1.07568393 1.07626189], self.intercept: 1.0067180023685078\n",
      "iteration - 7212 -> loss: 0.0002697623143540368, self.slope: [1.07569222 1.07627027], self.intercept: 1.0067187776509263\n",
      "iteration - 7213 -> loss: 0.0002697483781426819, self.slope: [1.0757005  1.07627865], self.intercept: 1.006719552900177\n",
      "iteration - 7214 -> loss: 0.00026973444341685216, self.slope: [1.07570878 1.07628703], self.intercept: 1.0067203281162629\n",
      "iteration - 7215 -> loss: 0.00026972051017628033, self.slope: [1.07571705 1.07629541], self.intercept: 1.0067211032991865\n",
      "iteration - 7216 -> loss: 0.0002697065784207595, self.slope: [1.07572533 1.07630378], self.intercept: 1.0067218784489527\n",
      "iteration - 7217 -> loss: 0.00026969264815002473, self.slope: [1.07573361 1.07631216], self.intercept: 1.0067226535655622\n",
      "iteration - 7218 -> loss: 0.0002696787193638264, self.slope: [1.07574189 1.07632053], self.intercept: 1.0067234286490185\n",
      "iteration - 7219 -> loss: 0.0002696647920619675, self.slope: [1.07575017 1.07632891], self.intercept: 1.0067242036993256\n",
      "iteration - 7220 -> loss: 0.00026965086624416756, self.slope: [1.07575844 1.07633729], self.intercept: 1.0067249787164867\n",
      "iteration - 7221 -> loss: 0.00026963694191019705, self.slope: [1.07576672 1.07634566], self.intercept: 1.0067257537005043\n",
      "iteration - 7222 -> loss: 0.0002696230190598155, self.slope: [1.075775   1.07635403], self.intercept: 1.006726528651381\n",
      "iteration - 7223 -> loss: 0.00026960909769279144, self.slope: [1.07578327 1.07636241], self.intercept: 1.006727303569121\n",
      "iteration - 7224 -> loss: 0.00026959517780887637, self.slope: [1.07579155 1.07637078], self.intercept: 1.006728078453727\n",
      "iteration - 7225 -> loss: 0.0002695812594078368, self.slope: [1.07579982 1.07637915], self.intercept: 1.0067288533052026\n",
      "iteration - 7226 -> loss: 0.00026956734248943066, self.slope: [1.0758081  1.07638753], self.intercept: 1.006729628123551\n",
      "iteration - 7227 -> loss: 0.0002695534270534025, self.slope: [1.07581637 1.0763959 ], self.intercept: 1.006730402908773\n",
      "iteration - 7228 -> loss: 0.0002695395130995402, self.slope: [1.07582464 1.07640427], self.intercept: 1.0067311776608738\n",
      "iteration - 7229 -> loss: 0.0002695256006275934, self.slope: [1.07583292 1.07641264], self.intercept: 1.006731952379854\n",
      "iteration - 7230 -> loss: 0.000269511689637295, self.slope: [1.07584119 1.07642101], self.intercept: 1.0067327270657191\n",
      "iteration - 7231 -> loss: 0.00026949778012844676, self.slope: [1.07584946 1.07642938], self.intercept: 1.0067335017184738\n",
      "iteration - 7232 -> loss: 0.00026948387210078145, self.slope: [1.07585773 1.07643775], self.intercept: 1.0067342763381166\n",
      "iteration - 7233 -> loss: 0.000269469965554083, self.slope: [1.075866   1.07644612], self.intercept: 1.006735050924654\n",
      "iteration - 7234 -> loss: 0.0002694560604880887, self.slope: [1.07587428 1.07645449], self.intercept: 1.0067358254780894\n",
      "iteration - 7235 -> loss: 0.00026944215690256836, self.slope: [1.07588255 1.07646286], self.intercept: 1.006736599998423\n",
      "iteration - 7236 -> loss: 0.0002694282547973019, self.slope: [1.07589082 1.07647123], self.intercept: 1.00673737448566\n",
      "iteration - 7237 -> loss: 0.0002694143541720015, self.slope: [1.07589909 1.07647959], self.intercept: 1.006738148939804\n",
      "iteration - 7238 -> loss: 0.0002694004550264691, self.slope: [1.07590735 1.07648796], self.intercept: 1.006738923360856\n",
      "iteration - 7239 -> loss: 0.00026938655736046153, self.slope: [1.07591562 1.07649633], self.intercept: 1.0067396977488194\n",
      "iteration - 7240 -> loss: 0.0002693726611737208, self.slope: [1.07592389 1.07650469], self.intercept: 1.0067404721036994\n",
      "iteration - 7241 -> loss: 0.0002693587664660252, self.slope: [1.07593216 1.07651306], self.intercept: 1.0067412464254957\n",
      "iteration - 7242 -> loss: 0.00026934487323713855, self.slope: [1.07594043 1.07652142], self.intercept: 1.0067420207142146\n",
      "iteration - 7243 -> loss: 0.0002693309814867907, self.slope: [1.07594869 1.07652979], self.intercept: 1.0067427949698573\n",
      "iteration - 7244 -> loss: 0.0002693170912147755, self.slope: [1.07595696 1.07653815], self.intercept: 1.0067435691924282\n",
      "iteration - 7245 -> loss: 0.00026930320242084667, self.slope: [1.07596522 1.07654652], self.intercept: 1.0067443433819299\n",
      "iteration - 7246 -> loss: 0.00026928931510474924, self.slope: [1.07597349 1.07655488], self.intercept: 1.0067451175383644\n",
      "iteration - 7247 -> loss: 0.0002692754292662664, self.slope: [1.07598176 1.07656324], self.intercept: 1.0067458916617362\n",
      "iteration - 7248 -> loss: 0.00026926154490515433, self.slope: [1.07599002 1.07657161], self.intercept: 1.0067466657520485\n",
      "iteration - 7249 -> loss: 0.0002692476620211589, self.slope: [1.07599828 1.07657997], self.intercept: 1.0067474398093015\n",
      "iteration - 7250 -> loss: 0.00026923378061405936, self.slope: [1.07600655 1.07658833], self.intercept: 1.0067482138335027\n",
      "iteration - 7251 -> loss: 0.0002692199006836082, self.slope: [1.07601481 1.07659669], self.intercept: 1.006748987824652\n",
      "iteration - 7252 -> loss: 0.0002692060222295665, self.slope: [1.07602307 1.07660505], self.intercept: 1.006749761782754\n",
      "iteration - 7253 -> loss: 0.0002691921452517076, self.slope: [1.07603134 1.07661341], self.intercept: 1.0067505357078097\n",
      "iteration - 7254 -> loss: 0.0002691782697497652, self.slope: [1.0760396  1.07662177], self.intercept: 1.0067513095998246\n",
      "iteration - 7255 -> loss: 0.0002691643957235232, self.slope: [1.07604786 1.07663013], self.intercept: 1.0067520834588004\n",
      "iteration - 7256 -> loss: 0.0002691505231727479, self.slope: [1.07605612 1.07663849], self.intercept: 1.0067528572847408\n",
      "iteration - 7257 -> loss: 0.000269136652097173, self.slope: [1.07606438 1.07664685], self.intercept: 1.006753631077649\n",
      "iteration - 7258 -> loss: 0.000269122782496595, self.slope: [1.07607264 1.07665521], self.intercept: 1.0067544048375272\n",
      "iteration - 7259 -> loss: 0.00026910891437075343, self.slope: [1.0760809  1.07666357], self.intercept: 1.0067551785643787\n",
      "iteration - 7260 -> loss: 0.00026909504771942304, self.slope: [1.07608916 1.07667192], self.intercept: 1.0067559522582086\n",
      "iteration - 7261 -> loss: 0.00026908118254235456, self.slope: [1.07609742 1.07668028], self.intercept: 1.0067567259190184\n",
      "iteration - 7262 -> loss: 0.0002690673188393052, self.slope: [1.07610568 1.07668864], self.intercept: 1.0067574995468096\n",
      "iteration - 7263 -> loss: 0.0002690534566100737, self.slope: [1.07611393 1.07669699], self.intercept: 1.006758273141586\n",
      "iteration - 7264 -> loss: 0.0002690395958543625, self.slope: [1.07612219 1.07670535], self.intercept: 1.0067590467033523\n",
      "iteration - 7265 -> loss: 0.0002690257365719893, self.slope: [1.07613045 1.0767137 ], self.intercept: 1.0067598202321097\n",
      "iteration - 7266 -> loss: 0.00026901187876267655, self.slope: [1.07613871 1.07672206], self.intercept: 1.0067605937278625\n",
      "iteration - 7267 -> loss: 0.00026899802242620613, self.slope: [1.07614696 1.07673041], self.intercept: 1.0067613671906133\n",
      "iteration - 7268 -> loss: 0.0002689841675623477, self.slope: [1.07615522 1.07673877], self.intercept: 1.0067621406203657\n",
      "iteration - 7269 -> loss: 0.00026897031417084276, self.slope: [1.07616347 1.07674712], self.intercept: 1.0067629140171224\n",
      "iteration - 7270 -> loss: 0.00026895646225146534, self.slope: [1.07617173 1.07675547], self.intercept: 1.006763687380887\n",
      "iteration - 7271 -> loss: 0.00026894261180396387, self.slope: [1.07617998 1.07676383], self.intercept: 1.006764460711662\n",
      "iteration - 7272 -> loss: 0.00026892876282813116, self.slope: [1.07618824 1.07677218], self.intercept: 1.0067652340094497\n",
      "iteration - 7273 -> loss: 0.0002689149153237036, self.slope: [1.07619649 1.07678053], self.intercept: 1.0067660072742541\n",
      "iteration - 7274 -> loss: 0.0002689010692904647, self.slope: [1.07620474 1.07678888], self.intercept: 1.0067667805060778\n",
      "iteration - 7275 -> loss: 0.00026888722472813437, self.slope: [1.076213   1.07679723], self.intercept: 1.0067675537049243\n",
      "iteration - 7276 -> loss: 0.00026887338163653063, self.slope: [1.07622125 1.07680558], self.intercept: 1.0067683268707968\n",
      "iteration - 7277 -> loss: 0.00026885954001538336, self.slope: [1.0762295  1.07681393], self.intercept: 1.0067691000036987\n",
      "iteration - 7278 -> loss: 0.0002688456998644563, self.slope: [1.07623775 1.07682228], self.intercept: 1.0067698731036323\n",
      "iteration - 7279 -> loss: 0.0002688318611835235, self.slope: [1.076246   1.07683063], self.intercept: 1.0067706461706016\n",
      "iteration - 7280 -> loss: 0.00026881802397233127, self.slope: [1.07625425 1.07683898], self.intercept: 1.006771419204607\n",
      "iteration - 7281 -> loss: 0.00026880418823066324, self.slope: [1.0762625  1.07684733], self.intercept: 1.0067721922056543\n",
      "iteration - 7282 -> loss: 0.0002687903539582815, self.slope: [1.07627075 1.07685567], self.intercept: 1.0067729651737451\n",
      "iteration - 7283 -> loss: 0.0002687765211549263, self.slope: [1.076279   1.07686402], self.intercept: 1.006773738108883\n",
      "iteration - 7284 -> loss: 0.00026876268982037956, self.slope: [1.07628725 1.07687237], self.intercept: 1.0067745110110722\n",
      "iteration - 7285 -> loss: 0.00026874885995439987, self.slope: [1.0762955  1.07688071], self.intercept: 1.0067752838803132\n",
      "iteration - 7286 -> loss: 0.00026873503155675204, self.slope: [1.07630374 1.07688906], self.intercept: 1.0067760567166106\n",
      "iteration - 7287 -> loss: 0.0002687212046271867, self.slope: [1.07631199 1.07689741], self.intercept: 1.006776829519968\n",
      "iteration - 7288 -> loss: 0.0002687073791655067, self.slope: [1.07632024 1.07690575], self.intercept: 1.006777602290388\n",
      "iteration - 7289 -> loss: 0.00026869355517143484, self.slope: [1.07632849 1.07691409], self.intercept: 1.0067783750278723\n",
      "iteration - 7290 -> loss: 0.00026867973264472204, self.slope: [1.07633673 1.07692244], self.intercept: 1.006779147732427\n",
      "iteration - 7291 -> loss: 0.0002686659115851799, self.slope: [1.07634498 1.07693078], self.intercept: 1.006779920404052\n",
      "iteration - 7292 -> loss: 0.0002686520919925431, self.slope: [1.07635322 1.07693913], self.intercept: 1.0067806930427508\n",
      "iteration - 7293 -> loss: 0.0002686382738665751, self.slope: [1.07636147 1.07694747], self.intercept: 1.0067814656485286\n",
      "iteration - 7294 -> loss: 0.00026862445720703625, self.slope: [1.07636971 1.07695581], self.intercept: 1.006782238221388\n",
      "iteration - 7295 -> loss: 0.00026861064201371266, self.slope: [1.07637795 1.07696415], self.intercept: 1.0067830107613305\n",
      "iteration - 7296 -> loss: 0.00026859682828634155, self.slope: [1.0763862  1.07697249], self.intercept: 1.0067837832683597\n",
      "iteration - 7297 -> loss: 0.00026858301602471717, self.slope: [1.07639444 1.07698084], self.intercept: 1.0067845557424784\n",
      "iteration - 7298 -> loss: 0.0002685692052285653, self.slope: [1.07640268 1.07698918], self.intercept: 1.0067853281836916\n",
      "iteration - 7299 -> loss: 0.00026855539589766813, self.slope: [1.07641093 1.07699752], self.intercept: 1.0067861005919994\n",
      "iteration - 7300 -> loss: 0.00026854158803180827, self.slope: [1.07641917 1.07700586], self.intercept: 1.0067868729674072\n",
      "iteration - 7301 -> loss: 0.00026852778163072625, self.slope: [1.07642741 1.0770142 ], self.intercept: 1.0067876453099165\n",
      "iteration - 7302 -> loss: 0.0002685139766941972, self.slope: [1.07643565 1.07702253], self.intercept: 1.0067884176195314\n",
      "iteration - 7303 -> loss: 0.00026850017322195747, self.slope: [1.07644389 1.07703087], self.intercept: 1.0067891898962558\n",
      "iteration - 7304 -> loss: 0.00026848637121380765, self.slope: [1.07645213 1.07703921], self.intercept: 1.0067899621400895\n",
      "iteration - 7305 -> loss: 0.0002684725706694915, self.slope: [1.07646037 1.07704755], self.intercept: 1.0067907343510385\n",
      "iteration - 7306 -> loss: 0.0002684587715887821, self.slope: [1.07646861 1.07705589], self.intercept: 1.0067915065291038\n",
      "iteration - 7307 -> loss: 0.00026844497397144967, self.slope: [1.07647685 1.07706422], self.intercept: 1.0067922786742909\n",
      "iteration - 7308 -> loss: 0.0002684311778172408, self.slope: [1.07648508 1.07707256], self.intercept: 1.006793050786601\n",
      "iteration - 7309 -> loss: 0.0002684173831259461, self.slope: [1.07649332 1.07708089], self.intercept: 1.0067938228660376\n",
      "iteration - 7310 -> loss: 0.0002684035898972995, self.slope: [1.07650156 1.07708923], self.intercept: 1.0067945949126036\n",
      "iteration - 7311 -> loss: 0.0002683897981310714, self.slope: [1.07650979 1.07709756], self.intercept: 1.0067953669263032\n",
      "iteration - 7312 -> loss: 0.0002683760078270403, self.slope: [1.07651803 1.0771059 ], self.intercept: 1.0067961389071376\n",
      "iteration - 7313 -> loss: 0.00026836221898494906, self.slope: [1.07652627 1.07711423], self.intercept: 1.00679691085511\n",
      "iteration - 7314 -> loss: 0.00026834843160460954, self.slope: [1.0765345  1.07712257], self.intercept: 1.006797682770225\n",
      "iteration - 7315 -> loss: 0.00026833464568572896, self.slope: [1.07654274 1.0771309 ], self.intercept: 1.0067984546524853\n",
      "iteration - 7316 -> loss: 0.00026832086122810246, self.slope: [1.07655097 1.07713923], self.intercept: 1.0067992265018921\n",
      "iteration - 7317 -> loss: 0.0002683070782314951, self.slope: [1.07655921 1.07714756], self.intercept: 1.00679999831845\n",
      "iteration - 7318 -> loss: 0.0002682932966956594, self.slope: [1.07656744 1.0771559 ], self.intercept: 1.0068007701021624\n",
      "iteration - 7319 -> loss: 0.0002682795166203652, self.slope: [1.07657567 1.07716423], self.intercept: 1.0068015418530312\n",
      "iteration - 7320 -> loss: 0.00026826573800539194, self.slope: [1.07658391 1.07717256], self.intercept: 1.0068023135710604\n",
      "iteration - 7321 -> loss: 0.0002682519608504815, self.slope: [1.07659214 1.07718089], self.intercept: 1.006803085256253\n",
      "iteration - 7322 -> loss: 0.0002682381851554011, self.slope: [1.07660037 1.07718922], self.intercept: 1.0068038569086124\n",
      "iteration - 7323 -> loss: 0.0002682244109199357, self.slope: [1.0766086  1.07719755], self.intercept: 1.0068046285281398\n",
      "iteration - 7324 -> loss: 0.0002682106381438225, self.slope: [1.07661683 1.07720588], self.intercept: 1.0068054001148397\n",
      "iteration - 7325 -> loss: 0.00026819686682686013, self.slope: [1.07662506 1.07721421], self.intercept: 1.0068061716687147\n",
      "iteration - 7326 -> loss: 0.0002681830969687982, self.slope: [1.07663329 1.07722254], self.intercept: 1.006806943189768\n",
      "iteration - 7327 -> loss: 0.00026816932856938704, self.slope: [1.07664152 1.07723086], self.intercept: 1.0068077146780026\n",
      "iteration - 7328 -> loss: 0.0002681555616284049, self.slope: [1.07664975 1.07723919], self.intercept: 1.0068084861334219\n",
      "iteration - 7329 -> loss: 0.0002681417961456387, self.slope: [1.07665798 1.07724752], self.intercept: 1.0068092575560297\n",
      "iteration - 7330 -> loss: 0.0002681280321208184, self.slope: [1.07666621 1.07725584], self.intercept: 1.0068100289458264\n",
      "iteration - 7331 -> loss: 0.00026811426955371736, self.slope: [1.07667444 1.07726417], self.intercept: 1.0068108003028167\n",
      "iteration - 7332 -> loss: 0.00026810050844410015, self.slope: [1.07668266 1.0772725 ], self.intercept: 1.006811571627003\n",
      "iteration - 7333 -> loss: 0.00026808674879175956, self.slope: [1.07669089 1.07728082], self.intercept: 1.0068123429183893\n",
      "iteration - 7334 -> loss: 0.0002680729905964314, self.slope: [1.07669912 1.07728915], self.intercept: 1.0068131141769794\n",
      "iteration - 7335 -> loss: 0.000268059233857891, self.slope: [1.07670734 1.07729747], self.intercept: 1.0068138854027746\n",
      "iteration - 7336 -> loss: 0.0002680454785758998, self.slope: [1.07671557 1.07730579], self.intercept: 1.0068146565957785\n",
      "iteration - 7337 -> loss: 0.0002680317247502389, self.slope: [1.07672379 1.07731412], self.intercept: 1.0068154277559933\n",
      "iteration - 7338 -> loss: 0.0002680179723806624, self.slope: [1.07673202 1.07732244], self.intercept: 1.0068161988834223\n",
      "iteration - 7339 -> loss: 0.0002680042214669135, self.slope: [1.07674024 1.07733076], self.intercept: 1.0068169699780698\n",
      "iteration - 7340 -> loss: 0.0002679904720088011, self.slope: [1.07674847 1.07733909], self.intercept: 1.0068177410399388\n",
      "iteration - 7341 -> loss: 0.00026797672400606757, self.slope: [1.07675669 1.07734741], self.intercept: 1.0068185120690316\n",
      "iteration - 7342 -> loss: 0.0002679629774584755, self.slope: [1.07676491 1.07735573], self.intercept: 1.0068192830653513\n",
      "iteration - 7343 -> loss: 0.0002679492323658153, self.slope: [1.07677314 1.07736405], self.intercept: 1.0068200540289005\n",
      "iteration - 7344 -> loss: 0.000267935488727828, self.slope: [1.07678136 1.07737237], self.intercept: 1.0068208249596826\n",
      "iteration - 7345 -> loss: 0.00026792174654427617, self.slope: [1.07678958 1.07738069], self.intercept: 1.0068215958576996\n",
      "iteration - 7346 -> loss: 0.00026790800581494507, self.slope: [1.0767978  1.07738901], self.intercept: 1.0068223667229557\n",
      "iteration - 7347 -> loss: 0.0002678942665396109, self.slope: [1.07680602 1.07739733], self.intercept: 1.0068231375554548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 7348 -> loss: 0.0002678805287180017, self.slope: [1.07681424 1.07740565], self.intercept: 1.0068239083551986\n",
      "iteration - 7349 -> loss: 0.0002678667923498919, self.slope: [1.07682246 1.07741397], self.intercept: 1.0068246791221904\n",
      "iteration - 7350 -> loss: 0.00026785305743508617, self.slope: [1.07683068 1.07742228], self.intercept: 1.0068254498564342\n",
      "iteration - 7351 -> loss: 0.00026783932397331884, self.slope: [1.0768389 1.0774306], self.intercept: 1.0068262205579321\n",
      "iteration - 7352 -> loss: 0.0002678255919643659, self.slope: [1.07684712 1.07743892], self.intercept: 1.006826991226686\n",
      "iteration - 7353 -> loss: 0.0002678118614079715, self.slope: [1.07685534 1.07744724], self.intercept: 1.0068277618627008\n",
      "iteration - 7354 -> loss: 0.0002677981323039503, self.slope: [1.07686356 1.07745555], self.intercept: 1.0068285324659785\n",
      "iteration - 7355 -> loss: 0.00026778440465202675, self.slope: [1.07687177 1.07746387], self.intercept: 1.0068293030365223\n",
      "iteration - 7356 -> loss: 0.00026777067845197436, self.slope: [1.07687999 1.07747218], self.intercept: 1.0068300735743363\n",
      "iteration - 7357 -> loss: 0.0002677569537035788, self.slope: [1.07688821 1.0774805 ], self.intercept: 1.0068308440794222\n",
      "iteration - 7358 -> loss: 0.00026774323040658896, self.slope: [1.07689642 1.07748881], self.intercept: 1.0068316145517842\n",
      "iteration - 7359 -> loss: 0.0002677295085607715, self.slope: [1.07690464 1.07749713], self.intercept: 1.0068323849914242\n",
      "iteration - 7360 -> loss: 0.00026771578816590545, self.slope: [1.07691285 1.07750544], self.intercept: 1.0068331553983456\n",
      "iteration - 7361 -> loss: 0.0002677020692217486, self.slope: [1.07692107 1.07751375], self.intercept: 1.0068339257725516\n",
      "iteration - 7362 -> loss: 0.000267688351728076, self.slope: [1.07692928 1.07752206], self.intercept: 1.006834696114044\n",
      "iteration - 7363 -> loss: 0.0002676746356846556, self.slope: [1.0769375  1.07753038], self.intercept: 1.006835466422827\n",
      "iteration - 7364 -> loss: 0.0002676609210912438, self.slope: [1.07694571 1.07753869], self.intercept: 1.0068362366989039\n",
      "iteration - 7365 -> loss: 0.00026764720794760833, self.slope: [1.07695392 1.077547  ], self.intercept: 1.0068370069422772\n",
      "iteration - 7366 -> loss: 0.00026763349625351796, self.slope: [1.07696214 1.07755531], self.intercept: 1.006837777152949\n",
      "iteration - 7367 -> loss: 0.00026761978600875523, self.slope: [1.07697035 1.07756362], self.intercept: 1.0068385473309251\n",
      "iteration - 7368 -> loss: 0.00026760607721306915, self.slope: [1.07697856 1.07757193], self.intercept: 1.006839317476206\n",
      "iteration - 7369 -> loss: 0.00026759236986622926, self.slope: [1.07698677 1.07758024], self.intercept: 1.0068400875887957\n",
      "iteration - 7370 -> loss: 0.0002675786639680097, self.slope: [1.07699498 1.07758855], self.intercept: 1.0068408576686971\n",
      "iteration - 7371 -> loss: 0.0002675649595181809, self.slope: [1.07700319 1.07759686], self.intercept: 1.0068416277159138\n",
      "iteration - 7372 -> loss: 0.0002675512565164883, self.slope: [1.0770114  1.07760517], self.intercept: 1.0068423977304475\n",
      "iteration - 7373 -> loss: 0.00026753755496274, self.slope: [1.07701961 1.07761347], self.intercept: 1.0068431677123006\n",
      "iteration - 7374 -> loss: 0.0002675238548566676, self.slope: [1.07702782 1.07762178], self.intercept: 1.006843937661479\n",
      "iteration - 7375 -> loss: 0.00026751015619804895, self.slope: [1.07703603 1.07763009], self.intercept: 1.006844707577984\n",
      "iteration - 7376 -> loss: 0.0002674964589866465, self.slope: [1.07704424 1.0776384 ], self.intercept: 1.0068454774618179\n",
      "iteration - 7377 -> loss: 0.0002674827632222444, self.slope: [1.07705245 1.0776467 ], self.intercept: 1.0068462473129853\n",
      "iteration - 7378 -> loss: 0.00026746906890459194, self.slope: [1.07706065 1.07765501], self.intercept: 1.0068470171314876\n",
      "iteration - 7379 -> loss: 0.0002674553760334698, self.slope: [1.07706886 1.07766331], self.intercept: 1.0068477869173302\n",
      "iteration - 7380 -> loss: 0.00026744168460865453, self.slope: [1.07707707 1.07767162], self.intercept: 1.0068485566705139\n",
      "iteration - 7381 -> loss: 0.0002674279946298752, self.slope: [1.07708527 1.07767992], self.intercept: 1.006849326391042\n",
      "iteration - 7382 -> loss: 0.0002674143060969516, self.slope: [1.07709348 1.07768823], self.intercept: 1.00685009607892\n",
      "iteration - 7383 -> loss: 0.00026740061900961645, self.slope: [1.07710168 1.07769653], self.intercept: 1.0068508657341468\n",
      "iteration - 7384 -> loss: 0.0002673869333676482, self.slope: [1.07710989 1.07770483], self.intercept: 1.006851635356729\n",
      "iteration - 7385 -> loss: 0.00026737324917080183, self.slope: [1.07711809 1.07771313], self.intercept: 1.006852404946667\n",
      "iteration - 7386 -> loss: 0.00026735956641887746, self.slope: [1.07712629 1.07772144], self.intercept: 1.0068531745039655\n",
      "iteration - 7387 -> loss: 0.0002673458851116237, self.slope: [1.0771345  1.07772974], self.intercept: 1.006853944028627\n",
      "iteration - 7388 -> loss: 0.00026733220524881627, self.slope: [1.0771427  1.07773804], self.intercept: 1.0068547135206536\n",
      "iteration - 7389 -> loss: 0.00026731852683018896, self.slope: [1.0771509  1.07774634], self.intercept: 1.0068554829800491\n",
      "iteration - 7390 -> loss: 0.000267304849855559, self.slope: [1.07715911 1.07775464], self.intercept: 1.0068562524068172\n",
      "iteration - 7391 -> loss: 0.00026729117432467466, self.slope: [1.07716731 1.07776294], self.intercept: 1.0068570218009592\n",
      "iteration - 7392 -> loss: 0.0002672775002372949, self.slope: [1.07717551 1.07777124], self.intercept: 1.0068577911624796\n",
      "iteration - 7393 -> loss: 0.000267263827593201, self.slope: [1.07718371 1.07777954], self.intercept: 1.0068585604913811\n",
      "iteration - 7394 -> loss: 0.0002672501563921467, self.slope: [1.07719191 1.07778784], self.intercept: 1.006859329787668\n",
      "iteration - 7395 -> loss: 0.000267236486633928, self.slope: [1.07720011 1.07779614], self.intercept: 1.006860099051342\n",
      "iteration - 7396 -> loss: 0.00026722281831829345, self.slope: [1.07720831 1.07780443], self.intercept: 1.0068608682824038\n",
      "iteration - 7397 -> loss: 0.0002672091514450088, self.slope: [1.07721651 1.07781273], self.intercept: 1.0068616374808597\n",
      "iteration - 7398 -> loss: 0.0002671954860138588, self.slope: [1.07722471 1.07782103], self.intercept: 1.0068624066467118\n",
      "iteration - 7399 -> loss: 0.0002671818220245974, self.slope: [1.0772329  1.07782932], self.intercept: 1.0068631757799635\n",
      "iteration - 7400 -> loss: 0.0002671681594769976, self.slope: [1.0772411  1.07783762], self.intercept: 1.0068639448806158\n",
      "iteration - 7401 -> loss: 0.0002671544983708311, self.slope: [1.0772493  1.07784592], self.intercept: 1.0068647139486744\n",
      "iteration - 7402 -> loss: 0.0002671408387058677, self.slope: [1.0772575  1.07785421], self.intercept: 1.0068654829841401\n",
      "iteration - 7403 -> loss: 0.00026712718048187514, self.slope: [1.07726569 1.07786251], self.intercept: 1.0068662519870173\n",
      "iteration - 7404 -> loss: 0.0002671135236986248, self.slope: [1.07727389 1.0778708 ], self.intercept: 1.006867020957309\n",
      "iteration - 7405 -> loss: 0.00026709986835587557, self.slope: [1.07728208 1.07787909], self.intercept: 1.0068677898950174\n",
      "iteration - 7406 -> loss: 0.00026708621445340424, self.slope: [1.07729028 1.07788739], self.intercept: 1.0068685588001465\n",
      "iteration - 7407 -> loss: 0.00026707256199098536, self.slope: [1.07729847 1.07789568], self.intercept: 1.0068693276726988\n",
      "iteration - 7408 -> loss: 0.0002670589109683822, self.slope: [1.07730667 1.07790397], self.intercept: 1.0068700965126751\n",
      "iteration - 7409 -> loss: 0.00026704526138536625, self.slope: [1.07731486 1.07791227], self.intercept: 1.0068708653200817\n",
      "iteration - 7410 -> loss: 0.00026703161324170924, self.slope: [1.07732305 1.07792056], self.intercept: 1.0068716340949209\n",
      "iteration - 7411 -> loss: 0.0002670179665371721, self.slope: [1.07733125 1.07792885], self.intercept: 1.0068724028371956\n",
      "iteration - 7412 -> loss: 0.0002670043212715275, self.slope: [1.07733944 1.07793714], self.intercept: 1.0068731715469073\n",
      "iteration - 7413 -> loss: 0.00026699067744454826, self.slope: [1.07734763 1.07794543], self.intercept: 1.0068739402240605\n",
      "iteration - 7414 -> loss: 0.0002669770350560061, self.slope: [1.07735582 1.07795372], self.intercept: 1.0068747088686583\n",
      "iteration - 7415 -> loss: 0.0002669633941056606, self.slope: [1.07736401 1.07796201], self.intercept: 1.0068754774807025\n",
      "iteration - 7416 -> loss: 0.00026694975459329274, self.slope: [1.07737221 1.0779703 ], self.intercept: 1.006876246060197\n",
      "iteration - 7417 -> loss: 0.0002669361165186604, self.slope: [1.0773804  1.07797859], self.intercept: 1.0068770146071455\n",
      "iteration - 7418 -> loss: 0.000266922479881551, self.slope: [1.07738859 1.07798688], self.intercept: 1.0068777831215503\n",
      "iteration - 7419 -> loss: 0.0002669088446817113, self.slope: [1.07739677 1.07799516], self.intercept: 1.0068785516034147\n",
      "iteration - 7420 -> loss: 0.00026689521091893007, self.slope: [1.07740496 1.07800345], self.intercept: 1.00687932005274\n",
      "iteration - 7421 -> loss: 0.0002668815785929692, self.slope: [1.07741315 1.07801174], self.intercept: 1.0068800884695313\n",
      "iteration - 7422 -> loss: 0.00026686794770360424, self.slope: [1.07742134 1.07802002], self.intercept: 1.006880856853791\n",
      "iteration - 7423 -> loss: 0.00026685431825058866, self.slope: [1.07742953 1.07802831], self.intercept: 1.0068816252055197\n",
      "iteration - 7424 -> loss: 0.00026684069023372793, self.slope: [1.07743772 1.0780366 ], self.intercept: 1.0068823935247249\n",
      "iteration - 7425 -> loss: 0.00026682706365274906, self.slope: [1.0774459  1.07804488], self.intercept: 1.0068831618114056\n",
      "iteration - 7426 -> loss: 0.00026681343850745514, self.slope: [1.07745409 1.07805317], self.intercept: 1.006883930065568\n",
      "iteration - 7427 -> loss: 0.00026679981479760446, self.slope: [1.07746227 1.07806145], self.intercept: 1.0068846982872126\n",
      "iteration - 7428 -> loss: 0.0002667861925229576, self.slope: [1.07747046 1.07806973], self.intercept: 1.0068854664763431\n",
      "iteration - 7429 -> loss: 0.0002667725716832966, self.slope: [1.07747864 1.07807802], self.intercept: 1.0068862346329632\n",
      "iteration - 7430 -> loss: 0.0002667589522784016, self.slope: [1.07748683 1.0780863 ], self.intercept: 1.0068870027570755\n",
      "iteration - 7431 -> loss: 0.00026674533430802927, self.slope: [1.07749501 1.07809458], self.intercept: 1.0068877708486812\n",
      "iteration - 7432 -> loss: 0.0002667317177719356, self.slope: [1.0775032  1.07810287], self.intercept: 1.0068885389077864\n",
      "iteration - 7433 -> loss: 0.0002667181026699136, self.slope: [1.07751138 1.07811115], self.intercept: 1.0068893069343932\n",
      "iteration - 7434 -> loss: 0.00026670448900174045, self.slope: [1.07751956 1.07811943], self.intercept: 1.0068900749285037\n",
      "iteration - 7435 -> loss: 0.0002666908767671755, self.slope: [1.07752775 1.07812771], self.intercept: 1.0068908428901215\n",
      "iteration - 7436 -> loss: 0.0002666772659659653, self.slope: [1.07753593 1.07813599], self.intercept: 1.0068916108192487\n",
      "iteration - 7437 -> loss: 0.00026666365659791037, self.slope: [1.07754411 1.07814427], self.intercept: 1.0068923787158879\n",
      "iteration - 7438 -> loss: 0.0002666500486627945, self.slope: [1.07755229 1.07815255], self.intercept: 1.0068931465800455\n",
      "iteration - 7439 -> loss: 0.00026663644216035304, self.slope: [1.07756047 1.07816083], self.intercept: 1.0068939144117222\n",
      "iteration - 7440 -> loss: 0.000266622837090371, self.slope: [1.07756865 1.07816911], self.intercept: 1.0068946822109195\n",
      "iteration - 7441 -> loss: 0.00026660923345261565, self.slope: [1.07757683 1.07817739], self.intercept: 1.006895449977643\n",
      "iteration - 7442 -> loss: 0.0002665956312468697, self.slope: [1.07758501 1.07818566], self.intercept: 1.006896217711894\n",
      "iteration - 7443 -> loss: 0.00026658203047289744, self.slope: [1.07759319 1.07819394], self.intercept: 1.0068969854136756\n",
      "iteration - 7444 -> loss: 0.0002665684311304706, self.slope: [1.07760137 1.07820222], self.intercept: 1.0068977530829915\n",
      "iteration - 7445 -> loss: 0.0002665548332193696, self.slope: [1.07760955 1.07821049], self.intercept: 1.006898520719844\n",
      "iteration - 7446 -> loss: 0.00026654123673934175, self.slope: [1.07761772 1.07821877], self.intercept: 1.0068992883242374\n",
      "iteration - 7447 -> loss: 0.00026652764169016223, self.slope: [1.0776259  1.07822705], self.intercept: 1.0069000558961732\n",
      "iteration - 7448 -> loss: 0.0002665140480716531, self.slope: [1.07763408 1.07823532], self.intercept: 1.006900823435655\n",
      "iteration - 7449 -> loss: 0.0002665004558835166, self.slope: [1.07764225 1.0782436 ], self.intercept: 1.0069015909426868\n",
      "iteration - 7450 -> loss: 0.00026648686512554815, self.slope: [1.07765043 1.07825187], self.intercept: 1.0069023584172696\n",
      "iteration - 7451 -> loss: 0.000266473275797533, self.slope: [1.07765861 1.07826015], self.intercept: 1.0069031258594061\n",
      "iteration - 7452 -> loss: 0.000266459687899225, self.slope: [1.07766678 1.07826842], self.intercept: 1.0069038932691015\n",
      "iteration - 7453 -> loss: 0.0002664461014304123, self.slope: [1.07767496 1.07827669], self.intercept: 1.006904660646357\n",
      "iteration - 7454 -> loss: 0.0002664325163908492, self.slope: [1.07768313 1.07828496], self.intercept: 1.0069054279911784\n",
      "iteration - 7455 -> loss: 0.0002664189327803252, self.slope: [1.0776913  1.07829324], self.intercept: 1.0069061953035656\n",
      "iteration - 7456 -> loss: 0.0002664053505985975, self.slope: [1.07769948 1.07830151], self.intercept: 1.0069069625835219\n",
      "iteration - 7457 -> loss: 0.0002663917698454492, self.slope: [1.07770765 1.07830978], self.intercept: 1.006907729831052\n",
      "iteration - 7458 -> loss: 0.00026637819052064847, self.slope: [1.07771582 1.07831805], self.intercept: 1.006908497046158\n",
      "iteration - 7459 -> loss: 0.0002663646126239594, self.slope: [1.07772399 1.07832632], self.intercept: 1.0069092642288429\n",
      "iteration - 7460 -> loss: 0.00026635103615515457, self.slope: [1.07773217 1.07833459], self.intercept: 1.0069100313791082\n",
      "iteration - 7461 -> loss: 0.0002663374611140262, self.slope: [1.07774034 1.07834286], self.intercept: 1.0069107984969603\n",
      "iteration - 7462 -> loss: 0.0002663238875003116, self.slope: [1.07774851 1.07835113], self.intercept: 1.0069115655823995\n",
      "iteration - 7463 -> loss: 0.0002663103153138119, self.slope: [1.07775668 1.0783594 ], self.intercept: 1.0069123326354295\n",
      "iteration - 7464 -> loss: 0.0002662967445542918, self.slope: [1.07776485 1.07836767], self.intercept: 1.0069130996560511\n",
      "iteration - 7465 -> loss: 0.0002662831752215147, self.slope: [1.07777302 1.07837594], self.intercept: 1.0069138666442716\n",
      "iteration - 7466 -> loss: 0.0002662696073152651, self.slope: [1.07778119 1.0783842 ], self.intercept: 1.006914633600093\n",
      "iteration - 7467 -> loss: 0.0002662560408352976, self.slope: [1.07778935 1.07839247], self.intercept: 1.0069154005235157\n",
      "iteration - 7468 -> loss: 0.00026624247578140215, self.slope: [1.07779752 1.07840074], self.intercept: 1.0069161674145437\n",
      "iteration - 7469 -> loss: 0.0002662289121533482, self.slope: [1.07780569 1.078409  ], self.intercept: 1.0069169342731812\n",
      "iteration - 7470 -> loss: 0.0002662153499509006, self.slope: [1.07781386 1.07841727], self.intercept: 1.0069177010994292\n",
      "iteration - 7471 -> loss: 0.00026620178917383585, self.slope: [1.07782202 1.07842553], self.intercept: 1.0069184678932916\n",
      "iteration - 7472 -> loss: 0.00026618822982192895, self.slope: [1.07783019 1.0784338 ], self.intercept: 1.0069192346547715\n",
      "iteration - 7473 -> loss: 0.0002661746718949569, self.slope: [1.07783836 1.07844206], self.intercept: 1.0069200013838724\n",
      "iteration - 7474 -> loss: 0.0002661611153926765, self.slope: [1.07784652 1.07845033], self.intercept: 1.0069207680805972\n",
      "iteration - 7475 -> loss: 0.00026614756031486563, self.slope: [1.07785469 1.07845859], self.intercept: 1.0069215347449474\n",
      "iteration - 7476 -> loss: 0.0002661340066613143, self.slope: [1.07786285 1.07846685], self.intercept: 1.0069223013769275\n",
      "iteration - 7477 -> loss: 0.00026612045443177813, self.slope: [1.07787102 1.07847512], self.intercept: 1.0069230679765402\n",
      "iteration - 7478 -> loss: 0.0002661069036260292, self.slope: [1.07787918 1.07848338], self.intercept: 1.0069238345437879\n",
      "iteration - 7479 -> loss: 0.00026609335424383296, self.slope: [1.07788734 1.07849164], self.intercept: 1.0069246010786737\n",
      "iteration - 7480 -> loss: 0.00026607980628498914, self.slope: [1.07789551 1.0784999 ], self.intercept: 1.006925367581201\n",
      "iteration - 7481 -> loss: 0.0002660662597492605, self.slope: [1.07790367 1.07850816], self.intercept: 1.0069261340513735\n",
      "iteration - 7482 -> loss: 0.0002660527146363939, self.slope: [1.07791183 1.07851642], self.intercept: 1.0069269004891936\n",
      "iteration - 7483 -> loss: 0.00026603917094619213, self.slope: [1.07791999 1.07852468], self.intercept: 1.0069276668946627\n",
      "iteration - 7484 -> loss: 0.000266025628678427, self.slope: [1.07792815 1.07853294], self.intercept: 1.0069284332677846\n",
      "iteration - 7485 -> loss: 0.00026601208783285697, self.slope: [1.07793631 1.0785412 ], self.intercept: 1.0069291996085652\n",
      "iteration - 7486 -> loss: 0.00026599854840925614, self.slope: [1.07794447 1.07854946], self.intercept: 1.0069299659170041\n",
      "iteration - 7487 -> loss: 0.00026598501040742627, self.slope: [1.07795263 1.07855772], self.intercept: 1.0069307321931051\n",
      "iteration - 7488 -> loss: 0.0002659714738270822, self.slope: [1.07796079 1.07856598], self.intercept: 1.0069314984368705\n",
      "iteration - 7489 -> loss: 0.00026595793866805354, self.slope: [1.07796895 1.07857424], self.intercept: 1.0069322646483045\n",
      "iteration - 7490 -> loss: 0.0002659444049300989, self.slope: [1.07797711 1.07858249], self.intercept: 1.0069330308274098\n",
      "iteration - 7491 -> loss: 0.00026593087261298236, self.slope: [1.07798527 1.07859075], self.intercept: 1.006933796974188\n",
      "iteration - 7492 -> loss: 0.00026591734171648395, self.slope: [1.07799343 1.07859901], self.intercept: 1.006934563088644\n",
      "iteration - 7493 -> loss: 0.0002659038122403571, self.slope: [1.07800158 1.07860726], self.intercept: 1.0069353291707805\n",
      "iteration - 7494 -> loss: 0.00026589028418441793, self.slope: [1.07800974 1.07861552], self.intercept: 1.0069360952205988\n",
      "iteration - 7495 -> loss: 0.0002658767575483915, self.slope: [1.0780179  1.07862377], self.intercept: 1.0069368612381042\n",
      "iteration - 7496 -> loss: 0.0002658632323320773, self.slope: [1.07802605 1.07863203], self.intercept: 1.0069376272232995\n",
      "iteration - 7497 -> loss: 0.0002658497085352616, self.slope: [1.07803421 1.07864028], self.intercept: 1.006938393176186\n",
      "iteration - 7498 -> loss: 0.000265836186157685, self.slope: [1.07804236 1.07864854], self.intercept: 1.006939159096767\n",
      "iteration - 7499 -> loss: 0.00026582266519914146, self.slope: [1.07805052 1.07865679], self.intercept: 1.006939924985045\n",
      "iteration - 7500 -> loss: 0.0002658091456594116, self.slope: [1.07805867 1.07866504], self.intercept: 1.0069406908410246\n",
      "iteration - 7501 -> loss: 0.0002657956275382607, self.slope: [1.07806683 1.07867329], self.intercept: 1.0069414566647068\n",
      "iteration - 7502 -> loss: 0.0002657821108354448, self.slope: [1.07807498 1.07868155], self.intercept: 1.0069422224560962\n",
      "iteration - 7503 -> loss: 0.00026576859555076907, self.slope: [1.07808313 1.0786898 ], self.intercept: 1.0069429882151955\n",
      "iteration - 7504 -> loss: 0.000265755081683983, self.slope: [1.07809129 1.07869805], self.intercept: 1.0069437539420072\n",
      "iteration - 7505 -> loss: 0.00026574156923487273, self.slope: [1.07809944 1.0787063 ], self.intercept: 1.0069445196365343\n",
      "iteration - 7506 -> loss: 0.00026572805820321917, self.slope: [1.07810759 1.07871455], self.intercept: 1.0069452852987808\n",
      "iteration - 7507 -> loss: 0.0002657145485887893, self.slope: [1.07811574 1.0787228 ], self.intercept: 1.0069460509287484\n",
      "iteration - 7508 -> loss: 0.0002657010403913484, self.slope: [1.07812389 1.07873105], self.intercept: 1.00694681652644\n",
      "iteration - 7509 -> loss: 0.00026568753361067617, self.slope: [1.07813204 1.0787393 ], self.intercept: 1.006947582091859\n",
      "iteration - 7510 -> loss: 0.00026567402824655953, self.slope: [1.07814019 1.07874755], self.intercept: 1.0069483476250076\n",
      "iteration - 7511 -> loss: 0.00026566052429875407, self.slope: [1.07814834 1.07875579], self.intercept: 1.0069491131258905\n",
      "iteration - 7512 -> loss: 0.0002656470217670499, self.slope: [1.07815649 1.07876404], self.intercept: 1.00694987859451\n",
      "iteration - 7513 -> loss: 0.0002656335206512114, self.slope: [1.07816464 1.07877229], self.intercept: 1.0069506440308686\n",
      "iteration - 7514 -> loss: 0.0002656200209510046, self.slope: [1.07817279 1.07878054], self.intercept: 1.0069514094349687\n",
      "iteration - 7515 -> loss: 0.0002656065226662346, self.slope: [1.07818093 1.07878878], self.intercept: 1.0069521748068146\n",
      "iteration - 7516 -> loss: 0.0002655930257966455, self.slope: [1.07818908 1.07879703], self.intercept: 1.0069529401464083\n",
      "iteration - 7517 -> loss: 0.0002655795303420257, self.slope: [1.07819723 1.07880527], self.intercept: 1.0069537054537534\n",
      "iteration - 7518 -> loss: 0.0002655660363021438, self.slope: [1.07820538 1.07881352], self.intercept: 1.006954470728853\n",
      "iteration - 7519 -> loss: 0.0002655525436767743, self.slope: [1.07821352 1.07882176], self.intercept: 1.0069552359717093\n",
      "iteration - 7520 -> loss: 0.0002655390524657084, self.slope: [1.07822167 1.07883001], self.intercept: 1.0069560011823258\n",
      "iteration - 7521 -> loss: 0.000265525562668701, self.slope: [1.07822981 1.07883825], self.intercept: 1.0069567663607044\n",
      "iteration - 7522 -> loss: 0.0002655120742855352, self.slope: [1.07823796 1.0788465 ], self.intercept: 1.0069575315068504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 7523 -> loss: 0.0002654985873159958, self.slope: [1.0782461  1.07885474], self.intercept: 1.0069582966207629\n",
      "iteration - 7524 -> loss: 0.00026548510175982803, self.slope: [1.07825425 1.07886298], self.intercept: 1.0069590617024484\n",
      "iteration - 7525 -> loss: 0.00026547161761684236, self.slope: [1.07826239 1.07887122], self.intercept: 1.0069598267519086\n",
      "iteration - 7526 -> loss: 0.00026545813488677985, self.slope: [1.07827053 1.07887947], self.intercept: 1.0069605917691458\n",
      "iteration - 7527 -> loss: 0.00026544465356945175, self.slope: [1.07827867 1.07888771], self.intercept: 1.0069613567541644\n",
      "iteration - 7528 -> loss: 0.00026543117366459155, self.slope: [1.07828682 1.07889595], self.intercept: 1.0069621217069673\n",
      "iteration - 7529 -> loss: 0.000265417695172006, self.slope: [1.07829496 1.07890419], self.intercept: 1.0069628866275568\n",
      "iteration - 7530 -> loss: 0.0002654042180914638, self.slope: [1.0783031  1.07891243], self.intercept: 1.0069636515159346\n",
      "iteration - 7531 -> loss: 0.0002653907424227479, self.slope: [1.07831124 1.07892067], self.intercept: 1.0069644163721059\n",
      "iteration - 7532 -> loss: 0.0002653772681656199, self.slope: [1.07831938 1.07892891], self.intercept: 1.0069651811960727\n",
      "iteration - 7533 -> loss: 0.00026536379531986494, self.slope: [1.07832752 1.07893715], self.intercept: 1.006965945987838\n",
      "iteration - 7534 -> loss: 0.0002653503238852371, self.slope: [1.07833566 1.07894538], self.intercept: 1.0069667107474036\n",
      "iteration - 7535 -> loss: 0.0002653368538615368, self.slope: [1.0783438  1.07895362], self.intercept: 1.006967475474774\n",
      "iteration - 7536 -> loss: 0.0002653233852485414, self.slope: [1.07835194 1.07896186], self.intercept: 1.0069682401699513\n",
      "iteration - 7537 -> loss: 0.00026530991804599754, self.slope: [1.07836008 1.0789701 ], self.intercept: 1.0069690048329405\n",
      "iteration - 7538 -> loss: 0.0002652964522537089, self.slope: [1.07836821 1.07897833], self.intercept: 1.0069697694637416\n",
      "iteration - 7539 -> loss: 0.0002652829878714314, self.slope: [1.07837635 1.07898657], self.intercept: 1.006970534062359\n",
      "iteration - 7540 -> loss: 0.00026526952489896506, self.slope: [1.07838449 1.0789948 ], self.intercept: 1.0069712986287953\n",
      "iteration - 7541 -> loss: 0.0002652560633360593, self.slope: [1.07839263 1.07900304], self.intercept: 1.0069720631630545\n",
      "iteration - 7542 -> loss: 0.0002652426031825079, self.slope: [1.07840076 1.07901127], self.intercept: 1.006972827665139\n",
      "iteration - 7543 -> loss: 0.00026522914443807854, self.slope: [1.0784089  1.07901951], self.intercept: 1.0069735921350498\n",
      "iteration - 7544 -> loss: 0.0002652156871025494, self.slope: [1.07841703 1.07902774], self.intercept: 1.0069743565727924\n",
      "iteration - 7545 -> loss: 0.00026520223117570214, self.slope: [1.07842517 1.07903598], self.intercept: 1.0069751209783684\n",
      "iteration - 7546 -> loss: 0.00026518877665730544, self.slope: [1.0784333  1.07904421], self.intercept: 1.00697588535178\n",
      "iteration - 7547 -> loss: 0.0002651753235471254, self.slope: [1.07844144 1.07905244], self.intercept: 1.0069766496930337\n",
      "iteration - 7548 -> loss: 0.0002651618718449714, self.slope: [1.07844957 1.07906067], self.intercept: 1.0069774140021288\n",
      "iteration - 7549 -> loss: 0.00026514842155057894, self.slope: [1.0784577  1.07906891], self.intercept: 1.00697817827907\n",
      "iteration - 7550 -> loss: 0.00026513497266375047, self.slope: [1.07846584 1.07907714], self.intercept: 1.0069789425238589\n",
      "iteration - 7551 -> loss: 0.00026512152518425595, self.slope: [1.07847397 1.07908537], self.intercept: 1.0069797067364998\n",
      "iteration - 7552 -> loss: 0.0002651080791118658, self.slope: [1.0784821 1.0790936], self.intercept: 1.0069804709169954\n",
      "iteration - 7553 -> loss: 0.00026509463444637413, self.slope: [1.07849023 1.07910183], self.intercept: 1.006981235065348\n",
      "iteration - 7554 -> loss: 0.0002650811911875324, self.slope: [1.07849836 1.07911006], self.intercept: 1.0069819991815594\n",
      "iteration - 7555 -> loss: 0.00026506774933514397, self.slope: [1.07850649 1.07911829], self.intercept: 1.0069827632656363\n",
      "iteration - 7556 -> loss: 0.0002650543088889601, self.slope: [1.07851462 1.07912652], self.intercept: 1.006983527317578\n",
      "iteration - 7557 -> loss: 0.0002650408698487618, self.slope: [1.07852275 1.07913475], self.intercept: 1.006984291337389\n",
      "iteration - 7558 -> loss: 0.0002650274322143352, self.slope: [1.07853088 1.07914297], self.intercept: 1.006985055325072\n",
      "iteration - 7559 -> loss: 0.0002650139959854664, self.slope: [1.07853901 1.0791512 ], self.intercept: 1.0069858192806298\n",
      "iteration - 7560 -> loss: 0.00026500056116190404, self.slope: [1.07854714 1.07915943], self.intercept: 1.0069865832040648\n",
      "iteration - 7561 -> loss: 0.0002649871277434575, self.slope: [1.07855527 1.07916765], self.intercept: 1.0069873470953814\n",
      "iteration - 7562 -> loss: 0.00026497369572987757, self.slope: [1.07856339 1.07917588], self.intercept: 1.0069881109545826\n",
      "iteration - 7563 -> loss: 0.00026496026512094913, self.slope: [1.07857152 1.07918411], self.intercept: 1.0069888747816693\n",
      "iteration - 7564 -> loss: 0.0002649468359164421, self.slope: [1.07857965 1.07919233], self.intercept: 1.0069896385766461\n",
      "iteration - 7565 -> loss: 0.00026493340811616236, self.slope: [1.07858777 1.07920056], self.intercept: 1.0069904023395149\n",
      "iteration - 7566 -> loss: 0.00026491998171984383, self.slope: [1.0785959  1.07920878], self.intercept: 1.0069911660702804\n",
      "iteration - 7567 -> loss: 0.0002649065567272987, self.slope: [1.07860403 1.07921701], self.intercept: 1.0069919297689445\n",
      "iteration - 7568 -> loss: 0.0002648931331382839, self.slope: [1.07861215 1.07922523], self.intercept: 1.0069926934355096\n",
      "iteration - 7569 -> loss: 0.0002648797109525949, self.slope: [1.07862028 1.07923345], self.intercept: 1.0069934570699783\n",
      "iteration - 7570 -> loss: 0.0002648662901699975, self.slope: [1.0786284  1.07924168], self.intercept: 1.0069942206723543\n",
      "iteration - 7571 -> loss: 0.00026485287079025137, self.slope: [1.07863652 1.0792499 ], self.intercept: 1.006994984242642\n",
      "iteration - 7572 -> loss: 0.0002648394528131629, self.slope: [1.07864465 1.07925812], self.intercept: 1.0069957477808416\n",
      "iteration - 7573 -> loss: 0.0002648260362384927, self.slope: [1.07865277 1.07926634], self.intercept: 1.006996511286957\n",
      "iteration - 7574 -> loss: 0.0002648126210660271, self.slope: [1.07866089 1.07927456], self.intercept: 1.006997274760992\n",
      "iteration - 7575 -> loss: 0.0002647992072955508, self.slope: [1.07866901 1.07928278], self.intercept: 1.0069980382029504\n",
      "iteration - 7576 -> loss: 0.0002647857949268025, self.slope: [1.07867714 1.079291  ], self.intercept: 1.0069988016128328\n",
      "iteration - 7577 -> loss: 0.0002647723839596175, self.slope: [1.07868526 1.07929922], self.intercept: 1.0069995649906438\n",
      "iteration - 7578 -> loss: 0.0002647589743937193, self.slope: [1.07869338 1.07930744], self.intercept: 1.007000328336385\n",
      "iteration - 7579 -> loss: 0.00026474556622892447, self.slope: [1.0787015  1.07931566], self.intercept: 1.0070010916500591\n",
      "iteration - 7580 -> loss: 0.00026473215946499026, self.slope: [1.07870962 1.07932388], self.intercept: 1.0070018549316717\n",
      "iteration - 7581 -> loss: 0.00026471875410170734, self.slope: [1.07871774 1.0793321 ], self.intercept: 1.0070026181812235\n",
      "iteration - 7582 -> loss: 0.00026470535013883433, self.slope: [1.07872586 1.07934032], self.intercept: 1.0070033813987163\n",
      "iteration - 7583 -> loss: 0.00026469194757616603, self.slope: [1.07873397 1.07934853], self.intercept: 1.0070041445841553\n",
      "iteration - 7584 -> loss: 0.0002646785464134742, self.slope: [1.07874209 1.07935675], self.intercept: 1.0070049077375423\n",
      "iteration - 7585 -> loss: 0.00026466514665053766, self.slope: [1.07875021 1.07936497], self.intercept: 1.0070056708588808\n",
      "iteration - 7586 -> loss: 0.0002646517482871232, self.slope: [1.07875833 1.07937318], self.intercept: 1.0070064339481735\n",
      "iteration - 7587 -> loss: 0.0002646383513230463, self.slope: [1.07876644 1.0793814 ], self.intercept: 1.0070071970054237\n",
      "iteration - 7588 -> loss: 0.00026462495575802994, self.slope: [1.07877456 1.07938962], self.intercept: 1.0070079600306332\n",
      "iteration - 7589 -> loss: 0.00026461156159189, self.slope: [1.07878268 1.07939783], self.intercept: 1.0070087230238058\n",
      "iteration - 7590 -> loss: 0.00026459816882440845, self.slope: [1.07879079 1.07940604], self.intercept: 1.0070094859849443\n",
      "iteration - 7591 -> loss: 0.00026458477745535015, self.slope: [1.07879891 1.07941426], self.intercept: 1.0070102489140522\n",
      "iteration - 7592 -> loss: 0.000264571387484475, self.slope: [1.07880702 1.07942247], self.intercept: 1.0070110118111304\n",
      "iteration - 7593 -> loss: 0.0002645579989115935, self.slope: [1.07881514 1.07943068], self.intercept: 1.0070117746761844\n",
      "iteration - 7594 -> loss: 0.0002645446117364563, self.slope: [1.07882325 1.0794389 ], self.intercept: 1.0070125375092165\n",
      "iteration - 7595 -> loss: 0.00026453122595885637, self.slope: [1.07883136 1.07944711], self.intercept: 1.0070133003102297\n",
      "iteration - 7596 -> loss: 0.0002645178415785954, self.slope: [1.07883948 1.07945532], self.intercept: 1.0070140630792266\n",
      "iteration - 7597 -> loss: 0.00026450445859541293, self.slope: [1.07884759 1.07946353], self.intercept: 1.0070148258162097\n",
      "iteration - 7598 -> loss: 0.00026449107700910287, self.slope: [1.0788557  1.07947174], self.intercept: 1.0070155885211816\n",
      "iteration - 7599 -> loss: 0.0002644776968194464, self.slope: [1.07886381 1.07947995], self.intercept: 1.0070163511941461\n",
      "iteration - 7600 -> loss: 0.0002644643180261979, self.slope: [1.07887193 1.07948816], self.intercept: 1.007017113835105\n",
      "iteration - 7601 -> loss: 0.00026445094062918853, self.slope: [1.07888004 1.07949637], self.intercept: 1.0070178764440627\n",
      "iteration - 7602 -> loss: 0.0002644375646281508, self.slope: [1.07888815 1.07950458], self.intercept: 1.0070186390210203\n",
      "iteration - 7603 -> loss: 0.0002644241900228766, self.slope: [1.07889626 1.07951279], self.intercept: 1.0070194015659826\n",
      "iteration - 7604 -> loss: 0.00026441081681315376, self.slope: [1.07890437 1.079521  ], self.intercept: 1.007020164078952\n",
      "iteration - 7605 -> loss: 0.0002643974449987533, self.slope: [1.07891248 1.07952921], self.intercept: 1.0070209265599308\n",
      "iteration - 7606 -> loss: 0.00026438407457944645, self.slope: [1.07892058 1.07953742], self.intercept: 1.0070216890089234\n",
      "iteration - 7607 -> loss: 0.00026437070555502233, self.slope: [1.07892869 1.07954562], self.intercept: 1.0070224514259325\n",
      "iteration - 7608 -> loss: 0.00026435733792527414, self.slope: [1.0789368  1.07955383], self.intercept: 1.007023213810959\n",
      "iteration - 7609 -> loss: 0.0002643439716899403, self.slope: [1.07894491 1.07956204], self.intercept: 1.0070239761640063\n",
      "iteration - 7610 -> loss: 0.0002643306068488368, self.slope: [1.07895301 1.07957024], self.intercept: 1.0070247384850795\n",
      "iteration - 7611 -> loss: 0.00026431724340172567, self.slope: [1.07896112 1.07957845], self.intercept: 1.0070255007741795\n",
      "iteration - 7612 -> loss: 0.00026430388134840536, self.slope: [1.07896923 1.07958665], self.intercept: 1.00702626303131\n",
      "iteration - 7613 -> loss: 0.00026429052068862273, self.slope: [1.07897733 1.07959486], self.intercept: 1.0070270252564724\n",
      "iteration - 7614 -> loss: 0.00026427716142217233, self.slope: [1.07898544 1.07960306], self.intercept: 1.0070277874496707\n",
      "iteration - 7615 -> loss: 0.00026426380354884464, self.slope: [1.07899354 1.07961127], self.intercept: 1.0070285496109086\n",
      "iteration - 7616 -> loss: 0.00026425044706840476, self.slope: [1.07900165 1.07961947], self.intercept: 1.0070293117401894\n",
      "iteration - 7617 -> loss: 0.00026423709198064886, self.slope: [1.07900975 1.07962767], self.intercept: 1.0070300738375146\n",
      "iteration - 7618 -> loss: 0.0002642237382853408, self.slope: [1.07901786 1.07963587], self.intercept: 1.0070308359028872\n",
      "iteration - 7619 -> loss: 0.0002642103859822642, self.slope: [1.07902596 1.07964408], self.intercept: 1.0070315979363107\n",
      "iteration - 7620 -> loss: 0.00026419703507119647, self.slope: [1.07903406 1.07965228], self.intercept: 1.007032359937788\n",
      "iteration - 7621 -> loss: 0.0002641836855519177, self.slope: [1.07904216 1.07966048], self.intercept: 1.0070331219073212\n",
      "iteration - 7622 -> loss: 0.0002641703374242097, self.slope: [1.07905027 1.07966868], self.intercept: 1.007033883844914\n",
      "iteration - 7623 -> loss: 0.0002641569906878453, self.slope: [1.07905837 1.07967688], self.intercept: 1.0070346457505697\n",
      "iteration - 7624 -> loss: 0.00026414364534263284, self.slope: [1.07906647 1.07968508], self.intercept: 1.007035407624291\n",
      "iteration - 7625 -> loss: 0.0002641303013883042, self.slope: [1.07907457 1.07969328], self.intercept: 1.007036169466079\n",
      "iteration - 7626 -> loss: 0.00026411695882468453, self.slope: [1.07908267 1.07970148], self.intercept: 1.00703693127594\n",
      "iteration - 7627 -> loss: 0.00026410361765152114, self.slope: [1.07909077 1.07970968], self.intercept: 1.0070376930538745\n",
      "iteration - 7628 -> loss: 0.0002640902778686057, self.slope: [1.07909887 1.07971788], self.intercept: 1.0070384547998854\n",
      "iteration - 7629 -> loss: 0.0002640769394757234, self.slope: [1.07910697 1.07972607], self.intercept: 1.0070392165139763\n",
      "iteration - 7630 -> loss: 0.0002640636024726548, self.slope: [1.07911507 1.07973427], self.intercept: 1.0070399781961508\n",
      "iteration - 7631 -> loss: 0.00026405026685916383, self.slope: [1.07912316 1.07974247], self.intercept: 1.00704073984641\n",
      "iteration - 7632 -> loss: 0.00026403693263506053, self.slope: [1.07913126 1.07975066], self.intercept: 1.0070415014647576\n",
      "iteration - 7633 -> loss: 0.0002640235998000985, self.slope: [1.07913936 1.07975886], self.intercept: 1.0070422630511966\n",
      "iteration - 7634 -> loss: 0.00026401026835405953, self.slope: [1.07914746 1.07976706], self.intercept: 1.00704302460573\n",
      "iteration - 7635 -> loss: 0.0002639969382967323, self.slope: [1.07915555 1.07977525], self.intercept: 1.0070437861283614\n",
      "iteration - 7636 -> loss: 0.0002639836096279059, self.slope: [1.07916365 1.07978345], self.intercept: 1.0070445476190915\n",
      "iteration - 7637 -> loss: 0.0002639702823473392, self.slope: [1.07917174 1.07979164], self.intercept: 1.007045309077927\n",
      "iteration - 7638 -> loss: 0.00026395695645483377, self.slope: [1.07917984 1.07979983], self.intercept: 1.0070460705048678\n",
      "iteration - 7639 -> loss: 0.00026394363195015257, self.slope: [1.07918793 1.07980803], self.intercept: 1.0070468318999173\n",
      "iteration - 7640 -> loss: 0.00026393030883306974, self.slope: [1.07919603 1.07981622], self.intercept: 1.007047593263077\n",
      "iteration - 7641 -> loss: 0.0002639169871034026, self.slope: [1.07920412 1.07982441], self.intercept: 1.0070483545943525\n",
      "iteration - 7642 -> loss: 0.0002639036667608893, self.slope: [1.07921221 1.07983261], self.intercept: 1.0070491158937454\n",
      "iteration - 7643 -> loss: 0.0002638903478053385, self.slope: [1.07922031 1.0798408 ], self.intercept: 1.0070498771612595\n",
      "iteration - 7644 -> loss: 0.0002638770302365275, self.slope: [1.0792284  1.07984899], self.intercept: 1.007050638396897\n",
      "iteration - 7645 -> loss: 0.0002638637140542201, self.slope: [1.07923649 1.07985718], self.intercept: 1.007051399600661\n",
      "iteration - 7646 -> loss: 0.00026385039925822066, self.slope: [1.07924458 1.07986537], self.intercept: 1.007052160772554\n",
      "iteration - 7647 -> loss: 0.00026383708584828427, self.slope: [1.07925268 1.07987356], self.intercept: 1.0070529219125792\n",
      "iteration - 7648 -> loss: 0.0002638237738242179, self.slope: [1.07926077 1.07988175], self.intercept: 1.00705368302074\n",
      "iteration - 7649 -> loss: 0.00026381046318577696, self.slope: [1.07926886 1.07988994], self.intercept: 1.0070544440970386\n",
      "iteration - 7650 -> loss: 0.0002637971539327731, self.slope: [1.07927695 1.07989813], self.intercept: 1.0070552051414776\n",
      "iteration - 7651 -> loss: 0.00026378384606495943, self.slope: [1.07928504 1.07990632], self.intercept: 1.0070559661540606\n",
      "iteration - 7652 -> loss: 0.00026377053958212977, self.slope: [1.07929313 1.07991451], self.intercept: 1.00705672713479\n",
      "iteration - 7653 -> loss: 0.00026375723448404035, self.slope: [1.07930121 1.07992269], self.intercept: 1.0070574880836698\n",
      "iteration - 7654 -> loss: 0.00026374393077051636, self.slope: [1.0793093  1.07993088], self.intercept: 1.007058249000702\n",
      "iteration - 7655 -> loss: 0.0002637306284413139, self.slope: [1.07931739 1.07993907], self.intercept: 1.0070590098858894\n",
      "iteration - 7656 -> loss: 0.00026371732749621695, self.slope: [1.07932548 1.07994725], self.intercept: 1.0070597707392337\n",
      "iteration - 7657 -> loss: 0.00026370402793500513, self.slope: [1.07933356 1.07995544], self.intercept: 1.0070605315607397\n",
      "iteration - 7658 -> loss: 0.00026369072975747035, self.slope: [1.07934165 1.07996362], self.intercept: 1.0070612923504108\n",
      "iteration - 7659 -> loss: 0.00026367743296337314, self.slope: [1.07934974 1.07997181], self.intercept: 1.0070620531082484\n",
      "iteration - 7660 -> loss: 0.000263664137552511, self.slope: [1.07935782 1.07997999], self.intercept: 1.0070628138342557\n",
      "iteration - 7661 -> loss: 0.0002636508435246678, self.slope: [1.07936591 1.07998818], self.intercept: 1.007063574528436\n",
      "iteration - 7662 -> loss: 0.00026363755087960175, self.slope: [1.07937399 1.07999636], self.intercept: 1.0070643351907917\n",
      "iteration - 7663 -> loss: 0.00026362425961712067, self.slope: [1.07938208 1.08000455], self.intercept: 1.0070650958213265\n",
      "iteration - 7664 -> loss: 0.0002636109697370026, self.slope: [1.07939016 1.08001273], self.intercept: 1.0070658564200432\n",
      "iteration - 7665 -> loss: 0.0002635976812390197, self.slope: [1.07939825 1.08002091], self.intercept: 1.0070666169869429\n",
      "iteration - 7666 -> loss: 0.00026358439412295354, self.slope: [1.07940633 1.08002909], self.intercept: 1.0070673775220313\n",
      "iteration - 7667 -> loss: 0.0002635711083885901, self.slope: [1.07941441 1.08003728], self.intercept: 1.0070681380253088\n",
      "iteration - 7668 -> loss: 0.0002635578240357172, self.slope: [1.07942249 1.08004546], self.intercept: 1.0070688984967797\n",
      "iteration - 7669 -> loss: 0.00026354454106411636, self.slope: [1.07943058 1.08005364], self.intercept: 1.0070696589364472\n",
      "iteration - 7670 -> loss: 0.0002635312594735461, self.slope: [1.07943866 1.08006182], self.intercept: 1.0070704193443138\n",
      "iteration - 7671 -> loss: 0.0002635179792638135, self.slope: [1.07944674 1.08007   ], self.intercept: 1.0070711797203813\n",
      "iteration - 7672 -> loss: 0.0002635047004346952, self.slope: [1.07945482 1.08007818], self.intercept: 1.007071940064654\n",
      "iteration - 7673 -> loss: 0.0002634914229859671, self.slope: [1.0794629  1.08008636], self.intercept: 1.007072700377134\n",
      "iteration - 7674 -> loss: 0.0002634781469174132, self.slope: [1.07947098 1.08009454], self.intercept: 1.0070734606578242\n",
      "iteration - 7675 -> loss: 0.0002634648722288203, self.slope: [1.07947906 1.08010271], self.intercept: 1.0070742209067278\n",
      "iteration - 7676 -> loss: 0.00026345159891996836, self.slope: [1.07948714 1.08011089], self.intercept: 1.007074981123848\n",
      "iteration - 7677 -> loss: 0.00026343832699063407, self.slope: [1.07949522 1.08011907], self.intercept: 1.0070757413091858\n",
      "iteration - 7678 -> loss: 0.00026342505644060427, self.slope: [1.07950329 1.08012725], self.intercept: 1.0070765014627465\n",
      "iteration - 7679 -> loss: 0.0002634117872696613, self.slope: [1.07951137 1.08013542], self.intercept: 1.007077261584532\n",
      "iteration - 7680 -> loss: 0.0002633985194775832, self.slope: [1.07951945 1.0801436 ], self.intercept: 1.0070780216745463\n",
      "iteration - 7681 -> loss: 0.0002633852530641742, self.slope: [1.07952753 1.08015178], self.intercept: 1.0070787817327915\n",
      "iteration - 7682 -> loss: 0.0002633719880291716, self.slope: [1.0795356  1.08015995], self.intercept: 1.0070795417592704\n",
      "iteration - 7683 -> loss: 0.000263358724372415, self.slope: [1.07954368 1.08016813], self.intercept: 1.0070803017539847\n",
      "iteration - 7684 -> loss: 0.00026334546209363496, self.slope: [1.07955175 1.0801763 ], self.intercept: 1.007081061716938\n",
      "iteration - 7685 -> loss: 0.0002633322011926523, self.slope: [1.07955983 1.08018447], self.intercept: 1.0070818216481343\n",
      "iteration - 7686 -> loss: 0.000263318941669223, self.slope: [1.0795679  1.08019265], self.intercept: 1.0070825815475744\n",
      "iteration - 7687 -> loss: 0.00026330568352312897, self.slope: [1.07957598 1.08020082], self.intercept: 1.0070833414152638\n",
      "iteration - 7688 -> loss: 0.00026329242675419225, self.slope: [1.07958405 1.08020899], self.intercept: 1.0070841012512035\n",
      "iteration - 7689 -> loss: 0.0002632791713621541, self.slope: [1.07959213 1.08021717], self.intercept: 1.0070848610553975\n",
      "iteration - 7690 -> loss: 0.00026326591734680225, self.slope: [1.0796002  1.08022534], self.intercept: 1.0070856208278482\n",
      "iteration - 7691 -> loss: 0.0002632526647079385, self.slope: [1.07960827 1.08023351], self.intercept: 1.0070863805685577\n",
      "iteration - 7692 -> loss: 0.00026323941344532113, self.slope: [1.07961634 1.08024168], self.intercept: 1.0070871402775294\n",
      "iteration - 7693 -> loss: 0.00026322616355876997, self.slope: [1.07962442 1.08024985], self.intercept: 1.0070878999547677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 7694 -> loss: 0.00026321291504803406, self.slope: [1.07963249 1.08025802], self.intercept: 1.007088659600274\n",
      "iteration - 7695 -> loss: 0.00026319966791291566, self.slope: [1.07964056 1.08026619], self.intercept: 1.007089419214051\n",
      "iteration - 7696 -> loss: 0.00026318642215316746, self.slope: [1.07964863 1.08027436], self.intercept: 1.0070901787961024\n",
      "iteration - 7697 -> loss: 0.0002631731777686146, self.slope: [1.0796567  1.08028253], self.intercept: 1.0070909383464306\n",
      "iteration - 7698 -> loss: 0.0002631599347590192, self.slope: [1.07966477 1.0802907 ], self.intercept: 1.007091697865039\n",
      "iteration - 7699 -> loss: 0.0002631466931241568, self.slope: [1.07967284 1.08029887], self.intercept: 1.0070924573519295\n",
      "iteration - 7700 -> loss: 0.0002631334528638299, self.slope: [1.07968091 1.08030704], self.intercept: 1.0070932168071063\n",
      "iteration - 7701 -> loss: 0.0002631202139777986, self.slope: [1.07968897 1.0803152 ], self.intercept: 1.0070939762305706\n",
      "iteration - 7702 -> loss: 0.00026310697646587147, self.slope: [1.07969704 1.08032337], self.intercept: 1.007094735622326\n",
      "iteration - 7703 -> loss: 0.0002630937403278162, self.slope: [1.07970511 1.08033154], self.intercept: 1.0070954949823756\n",
      "iteration - 7704 -> loss: 0.00026308050556342105, self.slope: [1.07971318 1.0803397 ], self.intercept: 1.0070962543107225\n",
      "iteration - 7705 -> loss: 0.00026306727217246324, self.slope: [1.07972124 1.08034787], self.intercept: 1.0070970136073696\n",
      "iteration - 7706 -> loss: 0.0002630540401547292, self.slope: [1.07972931 1.08035603], self.intercept: 1.0070977728723194\n",
      "iteration - 7707 -> loss: 0.00026304080951001276, self.slope: [1.07973738 1.0803642 ], self.intercept: 1.0070985321055757\n",
      "iteration - 7708 -> loss: 0.00026302758023809134, self.slope: [1.07974544 1.08037236], self.intercept: 1.0070992913071404\n",
      "iteration - 7709 -> loss: 0.00026301435233873566, self.slope: [1.07975351 1.08038053], self.intercept: 1.0071000504770176\n",
      "iteration - 7710 -> loss: 0.0002630011258117429, self.slope: [1.07976157 1.08038869], self.intercept: 1.0071008096152085\n",
      "iteration - 7711 -> loss: 0.0002629879006569096, self.slope: [1.07976963 1.08039685], self.intercept: 1.0071015687217157\n",
      "iteration - 7712 -> loss: 0.0002629746768739815, self.slope: [1.0797777  1.08040502], self.intercept: 1.0071023277965434\n",
      "iteration - 7713 -> loss: 0.00026296145446279203, self.slope: [1.07978576 1.08041318], self.intercept: 1.0071030868396942\n",
      "iteration - 7714 -> loss: 0.00026294823342306835, self.slope: [1.07979382 1.08042134], self.intercept: 1.0071038458511699\n",
      "iteration - 7715 -> loss: 0.00026293501375464646, self.slope: [1.07980189 1.0804295 ], self.intercept: 1.0071046048309746\n",
      "iteration - 7716 -> loss: 0.0002629217954572728, self.slope: [1.07980995 1.08043766], self.intercept: 1.0071053637791116\n",
      "iteration - 7717 -> loss: 0.00026290857853075153, self.slope: [1.07981801 1.08044582], self.intercept: 1.007106122695583\n",
      "iteration - 7718 -> loss: 0.00026289536297487083, self.slope: [1.07982607 1.08045398], self.intercept: 1.0071068815803912\n",
      "iteration - 7719 -> loss: 0.00026288214878940135, self.slope: [1.07983413 1.08046214], self.intercept: 1.0071076404335397\n",
      "iteration - 7720 -> loss: 0.000262868935974124, self.slope: [1.07984219 1.0804703 ], self.intercept: 1.007108399255032\n",
      "iteration - 7721 -> loss: 0.0002628557245288449, self.slope: [1.07985025 1.08047846], self.intercept: 1.0071091580448708\n",
      "iteration - 7722 -> loss: 0.0002628425144533093, self.slope: [1.07985831 1.08048662], self.intercept: 1.0071099168030568\n",
      "iteration - 7723 -> loss: 0.0002628293057473596, self.slope: [1.07986637 1.08049478], self.intercept: 1.0071106755295958\n",
      "iteration - 7724 -> loss: 0.00026281609841073277, self.slope: [1.07987443 1.08050294], self.intercept: 1.0071114342244896\n",
      "iteration - 7725 -> loss: 0.00026280289244322346, self.slope: [1.07988249 1.08051109], self.intercept: 1.0071121928877407\n",
      "iteration - 7726 -> loss: 0.00026278968784461566, self.slope: [1.07989055 1.08051925], self.intercept: 1.007112951519352\n",
      "iteration - 7727 -> loss: 0.0002627764846147082, self.slope: [1.0798986  1.08052741], self.intercept: 1.0071137101193257\n",
      "iteration - 7728 -> loss: 0.0002627632827532692, self.slope: [1.07990666 1.08053556], self.intercept: 1.0071144686876652\n",
      "iteration - 7729 -> loss: 0.0002627500822600903, self.slope: [1.07991472 1.08054372], self.intercept: 1.007115227224374\n",
      "iteration - 7730 -> loss: 0.0002627368831349572, self.slope: [1.07992277 1.08055187], self.intercept: 1.0071159857294554\n",
      "iteration - 7731 -> loss: 0.00026272368537764794, self.slope: [1.07993083 1.08056003], self.intercept: 1.0071167442029108\n",
      "iteration - 7732 -> loss: 0.0002627104889879608, self.slope: [1.07993888 1.08056818], self.intercept: 1.007117502644744\n",
      "iteration - 7733 -> loss: 0.0002626972939656782, self.slope: [1.07994694 1.08057634], self.intercept: 1.0071182610549578\n",
      "iteration - 7734 -> loss: 0.0002626841003105669, self.slope: [1.07995499 1.08058449], self.intercept: 1.0071190194335549\n",
      "iteration - 7735 -> loss: 0.000262670908022429, self.slope: [1.07996305 1.08059264], self.intercept: 1.0071197777805379\n",
      "iteration - 7736 -> loss: 0.00026265771710104057, self.slope: [1.0799711 1.0806008], self.intercept: 1.0071205360959101\n",
      "iteration - 7737 -> loss: 0.0002626445275461877, self.slope: [1.07997915 1.08060895], self.intercept: 1.007121294379674\n",
      "iteration - 7738 -> loss: 0.0002626313393576628, self.slope: [1.07998721 1.0806171 ], self.intercept: 1.007122052631832\n",
      "iteration - 7739 -> loss: 0.0002626181525352527, self.slope: [1.07999526 1.08062525], self.intercept: 1.0071228108523897\n",
      "iteration - 7740 -> loss: 0.00026260496707871365, self.slope: [1.08000331 1.0806334 ], self.intercept: 1.0071235690413478\n",
      "iteration - 7741 -> loss: 0.0002625917829878642, self.slope: [1.08001136 1.08064155], self.intercept: 1.0071243271987087\n",
      "iteration - 7742 -> loss: 0.0002625786002624927, self.slope: [1.08001941 1.0806497 ], self.intercept: 1.007125085324475\n",
      "iteration - 7743 -> loss: 0.0002625654189023491, self.slope: [1.08002747 1.08065785], self.intercept: 1.0071258434186507\n",
      "iteration - 7744 -> loss: 0.00026255223890725893, self.slope: [1.08003552 1.080666  ], self.intercept: 1.0071266014812388\n",
      "iteration - 7745 -> loss: 0.0002625390602769581, self.slope: [1.08004357 1.08067415], self.intercept: 1.0071273595122414\n",
      "iteration - 7746 -> loss: 0.000262525883011286, self.slope: [1.08005161 1.0806823 ], self.intercept: 1.0071281175116624\n",
      "iteration - 7747 -> loss: 0.0002625127071099992, self.slope: [1.08005966 1.08069045], self.intercept: 1.0071288754795042\n",
      "iteration - 7748 -> loss: 0.0002624995325728771, self.slope: [1.08006771 1.0806986 ], self.intercept: 1.0071296334157682\n",
      "iteration - 7749 -> loss: 0.00026248635939972334, self.slope: [1.08007576 1.08070674], self.intercept: 1.0071303913204586\n",
      "iteration - 7750 -> loss: 0.00026247318759031665, self.slope: [1.08008381 1.08071489], self.intercept: 1.0071311491935775\n",
      "iteration - 7751 -> loss: 0.00026246001714445486, self.slope: [1.08009186 1.08072304], self.intercept: 1.0071319070351292\n",
      "iteration - 7752 -> loss: 0.000262446848061887, self.slope: [1.0800999  1.08073118], self.intercept: 1.0071326648451162\n",
      "iteration - 7753 -> loss: 0.0002624336803424379, self.slope: [1.08010795 1.08073933], self.intercept: 1.0071334226235396\n",
      "iteration - 7754 -> loss: 0.000262420513985864, self.slope: [1.08011599 1.08074747], self.intercept: 1.0071341803704044\n",
      "iteration - 7755 -> loss: 0.0002624073489919771, self.slope: [1.08012404 1.08075562], self.intercept: 1.007134938085714\n",
      "iteration - 7756 -> loss: 0.000262394185360542, self.slope: [1.08013209 1.08076376], self.intercept: 1.0071356957694684\n",
      "iteration - 7757 -> loss: 0.0002623810230913709, self.slope: [1.08014013 1.08077191], self.intercept: 1.0071364534216722\n",
      "iteration - 7758 -> loss: 0.00026236786218420083, self.slope: [1.08014817 1.08078005], self.intercept: 1.0071372110423293\n",
      "iteration - 7759 -> loss: 0.00026235470263887467, self.slope: [1.08015622 1.08078819], self.intercept: 1.0071379686314401\n",
      "iteration - 7760 -> loss: 0.0002623415444551404, self.slope: [1.08016426 1.08079634], self.intercept: 1.007138726189009\n",
      "iteration - 7761 -> loss: 0.00026232838763279466, self.slope: [1.08017231 1.08080448], self.intercept: 1.0071394837150385\n",
      "iteration - 7762 -> loss: 0.00026231523217162947, self.slope: [1.08018035 1.08081262], self.intercept: 1.0071402412095316\n",
      "iteration - 7763 -> loss: 0.00026230207807143653, self.slope: [1.08018839 1.08082076], self.intercept: 1.0071409986724895\n",
      "iteration - 7764 -> loss: 0.00026228892533198227, self.slope: [1.08019643 1.0808289 ], self.intercept: 1.0071417561039189\n",
      "iteration - 7765 -> loss: 0.0002622757739530528, self.slope: [1.08020447 1.08083704], self.intercept: 1.0071425135038192\n",
      "iteration - 7766 -> loss: 0.0002622626239344634, self.slope: [1.08021251 1.08084518], self.intercept: 1.0071432708721941\n",
      "iteration - 7767 -> loss: 0.0002622494752759635, self.slope: [1.08022056 1.08085332], self.intercept: 1.0071440282090482\n",
      "iteration - 7768 -> loss: 0.00026223632797736586, self.slope: [1.0802286  1.08086146], self.intercept: 1.0071447855143816\n",
      "iteration - 7769 -> loss: 0.0002622231820384447, self.slope: [1.08023664 1.0808696 ], self.intercept: 1.0071455427881986\n",
      "iteration - 7770 -> loss: 0.00026221003745899204, self.slope: [1.08024467 1.08087774], self.intercept: 1.0071463000305012\n",
      "iteration - 7771 -> loss: 0.0002621968942387959, self.slope: [1.08025271 1.08088588], self.intercept: 1.0071470572412942\n",
      "iteration - 7772 -> loss: 0.0002621837523776403, self.slope: [1.08026075 1.08089401], self.intercept: 1.0071478144205797\n",
      "iteration - 7773 -> loss: 0.0002621706118752942, self.slope: [1.08026879 1.08090215], self.intercept: 1.00714857156836\n",
      "iteration - 7774 -> loss: 0.00026215747273159893, self.slope: [1.08027683 1.08091029], self.intercept: 1.0071493286846365\n",
      "iteration - 7775 -> loss: 0.0002621443349462674, self.slope: [1.08028486 1.08091842], self.intercept: 1.0071500857694151\n",
      "iteration - 7776 -> loss: 0.00026213119851913833, self.slope: [1.0802929  1.08092656], self.intercept: 1.0071508428226958\n",
      "iteration - 7777 -> loss: 0.0002621180634499678, self.slope: [1.08030094 1.0809347 ], self.intercept: 1.0071515998444829\n",
      "iteration - 7778 -> loss: 0.0002621049297385656, self.slope: [1.08030897 1.08094283], self.intercept: 1.0071523568347807\n",
      "iteration - 7779 -> loss: 0.00026209179738471305, self.slope: [1.08031701 1.08095097], self.intercept: 1.00715311379359\n",
      "iteration - 7780 -> loss: 0.00026207866638818363, self.slope: [1.08032504 1.0809591 ], self.intercept: 1.007153870720914\n",
      "iteration - 7781 -> loss: 0.000262065536748771, self.slope: [1.08033308 1.08096723], self.intercept: 1.0071546276167562\n",
      "iteration - 7782 -> loss: 0.00026205240846626144, self.slope: [1.08034111 1.08097537], self.intercept: 1.007155384481118\n",
      "iteration - 7783 -> loss: 0.00026203928154047116, self.slope: [1.08034915 1.0809835 ], self.intercept: 1.0071561413140047\n",
      "iteration - 7784 -> loss: 0.00026202615597114643, self.slope: [1.08035718 1.08099163], self.intercept: 1.0071568981154162\n",
      "iteration - 7785 -> loss: 0.0002620130317580982, self.slope: [1.08036521 1.08099977], self.intercept: 1.0071576548853565\n",
      "iteration - 7786 -> loss: 0.0002619999089011068, self.slope: [1.08037325 1.0810079 ], self.intercept: 1.0071584116238301\n",
      "iteration - 7787 -> loss: 0.0002619867873999551, self.slope: [1.08038128 1.08101603], self.intercept: 1.0071591683308367\n",
      "iteration - 7788 -> loss: 0.0002619736672544251, self.slope: [1.08038931 1.08102416], self.intercept: 1.0071599250063827\n",
      "iteration - 7789 -> loss: 0.0002619605484643066, self.slope: [1.08039734 1.08103229], self.intercept: 1.0071606816504695\n",
      "iteration - 7790 -> loss: 0.00026194743102940315, self.slope: [1.08040537 1.08104042], self.intercept: 1.0071614382630976\n",
      "iteration - 7791 -> loss: 0.00026193431494949586, self.slope: [1.0804134  1.08104855], self.intercept: 1.0071621948442728\n",
      "iteration - 7792 -> loss: 0.0002619212002243593, self.slope: [1.08042143 1.08105668], self.intercept: 1.0071629513939981\n",
      "iteration - 7793 -> loss: 0.00026190808685380023, self.slope: [1.08042946 1.08106481], self.intercept: 1.007163707912274\n",
      "iteration - 7794 -> loss: 0.0002618949748375924, self.slope: [1.08043749 1.08107294], self.intercept: 1.0071644643991065\n",
      "iteration - 7795 -> loss: 0.0002618818641755178, self.slope: [1.08044552 1.08108106], self.intercept: 1.0071652208544941\n",
      "iteration - 7796 -> loss: 0.0002618687548673736, self.slope: [1.08045355 1.08108919], self.intercept: 1.0071659772784434\n",
      "iteration - 7797 -> loss: 0.0002618556469129639, self.slope: [1.08046158 1.08109732], self.intercept: 1.0071667336709564\n",
      "iteration - 7798 -> loss: 0.00026184254031203717, self.slope: [1.08046961 1.08110545], self.intercept: 1.007167490032035\n",
      "iteration - 7799 -> loss: 0.0002618294350643952, self.slope: [1.08047763 1.08111357], self.intercept: 1.007168246361683\n",
      "iteration - 7800 -> loss: 0.00026181633116986096, self.slope: [1.08048566 1.0811217 ], self.intercept: 1.0071690026599016\n",
      "iteration - 7801 -> loss: 0.00026180322862818514, self.slope: [1.08049369 1.08112982], self.intercept: 1.007169758926695\n",
      "iteration - 7802 -> loss: 0.0002617901274391602, self.slope: [1.08050171 1.08113795], self.intercept: 1.007170515162066\n",
      "iteration - 7803 -> loss: 0.0002617770276025831, self.slope: [1.08050974 1.08114607], self.intercept: 1.0071712713660184\n",
      "iteration - 7804 -> loss: 0.0002617639291182362, self.slope: [1.08051776 1.0811542 ], self.intercept: 1.0071720275385543\n",
      "iteration - 7805 -> loss: 0.0002617508319859018, self.slope: [1.08052579 1.08116232], self.intercept: 1.0071727836796756\n",
      "iteration - 7806 -> loss: 0.0002617377362053799, self.slope: [1.08053381 1.08117045], self.intercept: 1.0071735397893853\n",
      "iteration - 7807 -> loss: 0.00026172464177647193, self.slope: [1.08054184 1.08117857], self.intercept: 1.0071742958676866\n",
      "iteration - 7808 -> loss: 0.00026171154869892915, self.slope: [1.08054986 1.08118669], self.intercept: 1.0071750519145806\n",
      "iteration - 7809 -> loss: 0.00026169845697256806, self.slope: [1.08055788 1.08119481], self.intercept: 1.0071758079300726\n",
      "iteration - 7810 -> loss: 0.00026168536659716495, self.slope: [1.0805659  1.08120294], self.intercept: 1.0071765639141659\n",
      "iteration - 7811 -> loss: 0.0002616722775725056, self.slope: [1.08057393 1.08121106], self.intercept: 1.007177319866863\n",
      "iteration - 7812 -> loss: 0.00026165918989838914, self.slope: [1.08058195 1.08121918], self.intercept: 1.007178075788165\n",
      "iteration - 7813 -> loss: 0.0002616461035745958, self.slope: [1.08058997 1.0812273 ], self.intercept: 1.0071788316780763\n",
      "iteration - 7814 -> loss: 0.000261633018600922, self.slope: [1.08059799 1.08123542], self.intercept: 1.0071795875365983\n",
      "iteration - 7815 -> loss: 0.0002616199349771318, self.slope: [1.08060601 1.08124354], self.intercept: 1.0071803433637365\n",
      "iteration - 7816 -> loss: 0.00026160685270305904, self.slope: [1.08061403 1.08125166], self.intercept: 1.0071810991594896\n",
      "iteration - 7817 -> loss: 0.00026159377177844005, self.slope: [1.08062205 1.08125978], self.intercept: 1.0071818549238643\n",
      "iteration - 7818 -> loss: 0.00026158069220310774, self.slope: [1.08063007 1.08126789], self.intercept: 1.0071826106568622\n",
      "iteration - 7819 -> loss: 0.0002615676139768286, self.slope: [1.08063809 1.08127601], self.intercept: 1.0071833663584846\n",
      "iteration - 7820 -> loss: 0.0002615545370993828, self.slope: [1.08064611 1.08128413], self.intercept: 1.007184122028736\n",
      "iteration - 7821 -> loss: 0.00026154146157058715, self.slope: [1.08065412 1.08129225], self.intercept: 1.0071848776676198\n",
      "iteration - 7822 -> loss: 0.0002615283873902086, self.slope: [1.08066214 1.08130036], self.intercept: 1.0071856332751374\n",
      "iteration - 7823 -> loss: 0.00026151531455803124, self.slope: [1.08067016 1.08130848], self.intercept: 1.0071863888512917\n",
      "iteration - 7824 -> loss: 0.00026150224307387016, self.slope: [1.08067818 1.0813166 ], self.intercept: 1.007187144396086\n",
      "iteration - 7825 -> loss: 0.00026148917293748866, self.slope: [1.08068619 1.08132471], self.intercept: 1.0071878999095238\n",
      "iteration - 7826 -> loss: 0.00026147610414867597, self.slope: [1.08069421 1.08133283], self.intercept: 1.007188655391606\n",
      "iteration - 7827 -> loss: 0.00026146303670724507, self.slope: [1.08070222 1.08134094], self.intercept: 1.0071894108423365\n",
      "iteration - 7828 -> loss: 0.0002614499706129754, self.slope: [1.08071024 1.08134906], self.intercept: 1.007190166261719\n",
      "iteration - 7829 -> loss: 0.0002614369058656401, self.slope: [1.08071825 1.08135717], self.intercept: 1.0071909216497554\n",
      "iteration - 7830 -> loss: 0.0002614238424650442, self.slope: [1.08072627 1.08136528], self.intercept: 1.0071916770064486\n",
      "iteration - 7831 -> loss: 0.0002614107804109617, self.slope: [1.08073428 1.0813734 ], self.intercept: 1.0071924323318024\n",
      "iteration - 7832 -> loss: 0.00026139771970321333, self.slope: [1.0807423  1.08138151], self.intercept: 1.0071931876258169\n",
      "iteration - 7833 -> loss: 0.0002613846603415486, self.slope: [1.08075031 1.08138962], self.intercept: 1.0071939428884982\n",
      "iteration - 7834 -> loss: 0.0002613716023257928, self.slope: [1.08075832 1.08139773], self.intercept: 1.0071946981198472\n",
      "iteration - 7835 -> loss: 0.00026135854565568324, self.slope: [1.08076633 1.08140584], self.intercept: 1.0071954533198673\n",
      "iteration - 7836 -> loss: 0.0002613454903310828, self.slope: [1.08077434 1.08141396], self.intercept: 1.0071962084885613\n",
      "iteration - 7837 -> loss: 0.0002613324363517221, self.slope: [1.08078236 1.08142207], self.intercept: 1.007196963625932\n",
      "iteration - 7838 -> loss: 0.00026131938371741503, self.slope: [1.08079037 1.08143018], self.intercept: 1.0071977187319816\n",
      "iteration - 7839 -> loss: 0.00026130633242793625, self.slope: [1.08079838 1.08143829], self.intercept: 1.0071984738067141\n",
      "iteration - 7840 -> loss: 0.0002612932824831045, self.slope: [1.08080639 1.0814464 ], self.intercept: 1.007199228850132\n",
      "iteration - 7841 -> loss: 0.0002612802338826745, self.slope: [1.0808144 1.0814545], self.intercept: 1.0071999838622363\n",
      "iteration - 7842 -> loss: 0.0002612671866264564, self.slope: [1.08082241 1.08146261], self.intercept: 1.0072007388430335\n",
      "iteration - 7843 -> loss: 0.0002612541407142322, self.slope: [1.08083042 1.08147072], self.intercept: 1.0072014937925244\n",
      "iteration - 7844 -> loss: 0.00026124109614580513, self.slope: [1.08083842 1.08147883], self.intercept: 1.0072022487107104\n",
      "iteration - 7845 -> loss: 0.0002612280529209509, self.slope: [1.08084643 1.08148694], self.intercept: 1.007203003597596\n",
      "iteration - 7846 -> loss: 0.0002612150110394561, self.slope: [1.08085444 1.08149504], self.intercept: 1.0072037584531839\n",
      "iteration - 7847 -> loss: 0.00026120197050112247, self.slope: [1.08086245 1.08150315], self.intercept: 1.0072045132774765\n",
      "iteration - 7848 -> loss: 0.00026118893130573623, self.slope: [1.08087045 1.08151126], self.intercept: 1.0072052680704782\n",
      "iteration - 7849 -> loss: 0.0002611758934530826, self.slope: [1.08087846 1.08151936], self.intercept: 1.0072060228321895\n",
      "iteration - 7850 -> loss: 0.0002611628569429587, self.slope: [1.08088647 1.08152747], self.intercept: 1.0072067775626141\n",
      "iteration - 7851 -> loss: 0.00026114982177515006, self.slope: [1.08089447 1.08153557], self.intercept: 1.0072075322617542\n",
      "iteration - 7852 -> loss: 0.00026113678794944357, self.slope: [1.08090248 1.08154368], self.intercept: 1.0072082869296137\n",
      "iteration - 7853 -> loss: 0.0002611237554656436, self.slope: [1.08091048 1.08155178], self.intercept: 1.0072090415661956\n",
      "iteration - 7854 -> loss: 0.0002611107243235152, self.slope: [1.08091848 1.08155988], self.intercept: 1.0072097961715016\n",
      "iteration - 7855 -> loss: 0.00026109769452287683, self.slope: [1.08092649 1.08156799], self.intercept: 1.007210550745536\n",
      "iteration - 7856 -> loss: 0.00026108466606349914, self.slope: [1.08093449 1.08157609], self.intercept: 1.0072113052883012\n",
      "iteration - 7857 -> loss: 0.0002610716389451772, self.slope: [1.08094249 1.08158419], self.intercept: 1.0072120597997987\n",
      "iteration - 7858 -> loss: 0.0002610586131676997, self.slope: [1.0809505  1.08159229], self.intercept: 1.0072128142800327\n",
      "iteration - 7859 -> loss: 0.00026104558873086826, self.slope: [1.0809585  1.08160039], self.intercept: 1.0072135687290045\n",
      "iteration - 7860 -> loss: 0.0002610325656344773, self.slope: [1.0809665  1.08160849], self.intercept: 1.007214323146719\n",
      "iteration - 7861 -> loss: 0.0002610195438782779, self.slope: [1.0809745 1.0816166], self.intercept: 1.0072150775331787\n",
      "iteration - 7862 -> loss: 0.0002610065234621057, self.slope: [1.0809825 1.0816247], self.intercept: 1.0072158318883848\n",
      "iteration - 7863 -> loss: 0.0002609935043857167, self.slope: [1.0809905 1.0816328], self.intercept: 1.0072165862123403\n",
      "iteration - 7864 -> loss: 0.00026098048664893964, self.slope: [1.0809985  1.08164089], self.intercept: 1.007217340505051\n",
      "iteration - 7865 -> loss: 0.0002609674702515352, self.slope: [1.0810065  1.08164899], self.intercept: 1.0072180947665168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 7866 -> loss: 0.00026095445519329504, self.slope: [1.0810145  1.08165709], self.intercept: 1.0072188489967406\n",
      "iteration - 7867 -> loss: 0.0002609414414740285, self.slope: [1.0810225  1.08166519], self.intercept: 1.0072196031957263\n",
      "iteration - 7868 -> loss: 0.00026092842909351246, self.slope: [1.0810305  1.08167329], self.intercept: 1.0072203573634755\n",
      "iteration - 7869 -> loss: 0.0002609154180515359, self.slope: [1.0810385  1.08168139], self.intercept: 1.0072211114999916\n",
      "iteration - 7870 -> loss: 0.0002609024083479022, self.slope: [1.0810465  1.08168948], self.intercept: 1.0072218656052758\n",
      "iteration - 7871 -> loss: 0.0002608893999823961, self.slope: [1.08105449 1.08169758], self.intercept: 1.007222619679334\n",
      "iteration - 7872 -> loss: 0.0002608763929548041, self.slope: [1.08106249 1.08170568], self.intercept: 1.0072233737221663\n",
      "iteration - 7873 -> loss: 0.00026086338726492007, self.slope: [1.08107049 1.08171377], self.intercept: 1.007224127733777\n",
      "iteration - 7874 -> loss: 0.0002608503829125382, self.slope: [1.08107848 1.08172187], self.intercept: 1.0072248817141696\n",
      "iteration - 7875 -> loss: 0.0002608373798974379, self.slope: [1.08108648 1.08172996], self.intercept: 1.007225635663347\n",
      "iteration - 7876 -> loss: 0.00026082437821941905, self.slope: [1.08109447 1.08173806], self.intercept: 1.00722638958131\n",
      "iteration - 7877 -> loss: 0.00026081137787828433, self.slope: [1.08110247 1.08174615], self.intercept: 1.0072271434680633\n",
      "iteration - 7878 -> loss: 0.00026079837887380426, self.slope: [1.08111046 1.08175424], self.intercept: 1.0072278973236073\n",
      "iteration - 7879 -> loss: 0.00026078538120578003, self.slope: [1.08111846 1.08176234], self.intercept: 1.0072286511479476\n",
      "iteration - 7880 -> loss: 0.00026077238487401416, self.slope: [1.08112645 1.08177043], self.intercept: 1.0072294049410864\n",
      "iteration - 7881 -> loss: 0.00026075938987825956, self.slope: [1.08113444 1.08177852], self.intercept: 1.0072301587030263\n",
      "iteration - 7882 -> loss: 0.0002607463962183638, self.slope: [1.08114243 1.08178661], self.intercept: 1.0072309124337697\n",
      "iteration - 7883 -> loss: 0.0002607334038940866, self.slope: [1.08115043 1.0817947 ], self.intercept: 1.007231666133319\n",
      "iteration - 7884 -> loss: 0.0002607204129051904, self.slope: [1.08115842 1.0818028 ], self.intercept: 1.0072324198016773\n",
      "iteration - 7885 -> loss: 0.0002607074232515294, self.slope: [1.08116641 1.08181089], self.intercept: 1.007233173438847\n",
      "iteration - 7886 -> loss: 0.00026069443493285124, self.slope: [1.0811744  1.08181898], self.intercept: 1.0072339270448323\n",
      "iteration - 7887 -> loss: 0.0002606814479489641, self.slope: [1.08118239 1.08182707], self.intercept: 1.007234680619635\n",
      "iteration - 7888 -> loss: 0.0002606684622996521, self.slope: [1.08119038 1.08183516], self.intercept: 1.007235434163258\n",
      "iteration - 7889 -> loss: 0.0002606554779847205, self.slope: [1.08119837 1.08184325], self.intercept: 1.007236187675705\n",
      "iteration - 7890 -> loss: 0.0002606424950039443, self.slope: [1.08120636 1.08185133], self.intercept: 1.0072369411569757\n",
      "iteration - 7891 -> loss: 0.0002606295133571089, self.slope: [1.08121435 1.08185942], self.intercept: 1.007237694607077\n",
      "iteration - 7892 -> loss: 0.0002606165330440187, self.slope: [1.08122234 1.08186751], self.intercept: 1.00723844802601\n",
      "iteration - 7893 -> loss: 0.00026060355406449636, self.slope: [1.08123033 1.0818756 ], self.intercept: 1.0072392014137777\n",
      "iteration - 7894 -> loss: 0.00026059057641827997, self.slope: [1.08123831 1.08188368], self.intercept: 1.007239954770383\n",
      "iteration - 7895 -> loss: 0.0002605776001051948, self.slope: [1.0812463  1.08189177], self.intercept: 1.0072407080958263\n",
      "iteration - 7896 -> loss: 0.0002605646251250136, self.slope: [1.08125429 1.08189986], self.intercept: 1.0072414613901137\n",
      "iteration - 7897 -> loss: 0.00026055165147755385, self.slope: [1.08126227 1.08190794], self.intercept: 1.0072422146532478\n",
      "iteration - 7898 -> loss: 0.00026053867916256055, self.slope: [1.08127026 1.08191603], self.intercept: 1.0072429678852295\n",
      "iteration - 7899 -> loss: 0.0002605257081798991, self.slope: [1.08127825 1.08192411], self.intercept: 1.0072437210860625\n",
      "iteration - 7900 -> loss: 0.0002605127385292898, self.slope: [1.08128623 1.0819322 ], self.intercept: 1.0072444742557503\n",
      "iteration - 7901 -> loss: 0.0002604997702105583, self.slope: [1.08129422 1.08194028], self.intercept: 1.0072452273942945\n",
      "iteration - 7902 -> loss: 0.00026048680322349286, self.slope: [1.0813022  1.08194837], self.intercept: 1.0072459805016978\n",
      "iteration - 7903 -> loss: 0.0002604738375679051, self.slope: [1.08131018 1.08195645], self.intercept: 1.007246733577965\n",
      "iteration - 7904 -> loss: 0.0002604608732435516, self.slope: [1.08131817 1.08196453], self.intercept: 1.0072474866230947\n",
      "iteration - 7905 -> loss: 0.0002604479102502481, self.slope: [1.08132615 1.08197261], self.intercept: 1.0072482396370925\n",
      "iteration - 7906 -> loss: 0.0002604349485877748, self.slope: [1.08133413 1.0819807 ], self.intercept: 1.0072489926199621\n",
      "iteration - 7907 -> loss: 0.00026042198825594316, self.slope: [1.08134212 1.08198878], self.intercept: 1.0072497455717069\n",
      "iteration - 7908 -> loss: 0.00026040902925451967, self.slope: [1.0813501  1.08199686], self.intercept: 1.0072504984923274\n",
      "iteration - 7909 -> loss: 0.000260396071583317, self.slope: [1.08135808 1.08200494], self.intercept: 1.0072512513818255\n",
      "iteration - 7910 -> loss: 0.0002603831152421236, self.slope: [1.08136606 1.08201302], self.intercept: 1.007252004240207\n",
      "iteration - 7911 -> loss: 0.00026037016023071347, self.slope: [1.08137404 1.0820211 ], self.intercept: 1.0072527570674743\n",
      "iteration - 7912 -> loss: 0.0002603572065489111, self.slope: [1.08138202 1.08202918], self.intercept: 1.0072535098636284\n",
      "iteration - 7913 -> loss: 0.00026034425419648664, self.slope: [1.08139    1.08203726], self.intercept: 1.0072542626286731\n",
      "iteration - 7914 -> loss: 0.0002603313031732389, self.slope: [1.08139798 1.08204534], self.intercept: 1.0072550153626105\n",
      "iteration - 7915 -> loss: 0.00026031835347895503, self.slope: [1.08140596 1.08205342], self.intercept: 1.007255768065445\n",
      "iteration - 7916 -> loss: 0.0002603054051134472, self.slope: [1.08141394 1.08206149], self.intercept: 1.0072565207371778\n",
      "iteration - 7917 -> loss: 0.0002602924580764991, self.slope: [1.08142192 1.08206957], self.intercept: 1.007257273377813\n",
      "iteration - 7918 -> loss: 0.0002602795123678871, self.slope: [1.08142989 1.08207765], self.intercept: 1.0072580259873516\n",
      "iteration - 7919 -> loss: 0.00026026656798742954, self.slope: [1.08143787 1.08208573], self.intercept: 1.0072587785657976\n",
      "iteration - 7920 -> loss: 0.00026025362493488623, self.slope: [1.08144585 1.0820938 ], self.intercept: 1.007259531113154\n",
      "iteration - 7921 -> loss: 0.0002602406832100911, self.slope: [1.08145382 1.08210188], self.intercept: 1.007260283629424\n",
      "iteration - 7922 -> loss: 0.00026022774281279253, self.slope: [1.0814618  1.08210995], self.intercept: 1.0072610361146088\n",
      "iteration - 7923 -> loss: 0.0002602148037428246, self.slope: [1.08146978 1.08211803], self.intercept: 1.007261788568712\n",
      "iteration - 7924 -> loss: 0.00026020186599996276, self.slope: [1.08147775 1.0821261 ], self.intercept: 1.0072625409917368\n",
      "iteration - 7925 -> loss: 0.00026018892958400955, self.slope: [1.08148573 1.08213418], self.intercept: 1.0072632933836858\n",
      "iteration - 7926 -> loss: 0.0002601759944947512, self.slope: [1.0814937  1.08214225], self.intercept: 1.0072640457445616\n",
      "iteration - 7927 -> loss: 0.0002601630607319679, self.slope: [1.08150167 1.08215032], self.intercept: 1.007264798074366\n",
      "iteration - 7928 -> loss: 0.0002601501282954607, self.slope: [1.08150965 1.0821584 ], self.intercept: 1.0072655503731036\n",
      "iteration - 7929 -> loss: 0.00026013719718505395, self.slope: [1.08151762 1.08216647], self.intercept: 1.007266302640777\n",
      "iteration - 7930 -> loss: 0.00026012426740049723, self.slope: [1.08152559 1.08217454], self.intercept: 1.007267054877389\n",
      "iteration - 7931 -> loss: 0.0002601113389416025, self.slope: [1.08153357 1.08218261], self.intercept: 1.0072678070829402\n",
      "iteration - 7932 -> loss: 0.00026009841180816456, self.slope: [1.08154154 1.08219069], self.intercept: 1.0072685592574349\n",
      "iteration - 7933 -> loss: 0.0002600854859999868, self.slope: [1.08154951 1.08219876], self.intercept: 1.007269311400876\n",
      "iteration - 7934 -> loss: 0.00026007256151683067, self.slope: [1.08155748 1.08220683], self.intercept: 1.0072700635132656\n",
      "iteration - 7935 -> loss: 0.00026005963835851675, self.slope: [1.08156545 1.0822149 ], self.intercept: 1.0072708155946095\n",
      "iteration - 7936 -> loss: 0.00026004671652483404, self.slope: [1.08157342 1.08222297], self.intercept: 1.007271567644907\n",
      "iteration - 7937 -> loss: 0.00026003379601558516, self.slope: [1.08158139 1.08223104], self.intercept: 1.0072723196641615\n",
      "iteration - 7938 -> loss: 0.00026002087683055274, self.slope: [1.08158936 1.0822391 ], self.intercept: 1.0072730716523755\n",
      "iteration - 7939 -> loss: 0.00026000795896952025, self.slope: [1.08159733 1.08224717], self.intercept: 1.007273823609554\n",
      "iteration - 7940 -> loss: 0.00025999504243230036, self.slope: [1.0816053  1.08225524], self.intercept: 1.0072745755356984\n",
      "iteration - 7941 -> loss: 0.0002599821272186694, self.slope: [1.08161327 1.08226331], self.intercept: 1.007275327430811\n",
      "iteration - 7942 -> loss: 0.0002599692133284489, self.slope: [1.08162123 1.08227138], self.intercept: 1.0072760792948952\n",
      "iteration - 7943 -> loss: 0.0002599563007614101, self.slope: [1.0816292  1.08227944], self.intercept: 1.0072768311279547\n",
      "iteration - 7944 -> loss: 0.00025994338951735533, self.slope: [1.08163717 1.08228751], self.intercept: 1.00727758292999\n",
      "iteration - 7945 -> loss: 0.0002599304795960634, self.slope: [1.08164514 1.08229558], self.intercept: 1.007278334701005\n",
      "iteration - 7946 -> loss: 0.0002599175709973382, self.slope: [1.0816531  1.08230364], self.intercept: 1.0072790864410017\n",
      "iteration - 7947 -> loss: 0.0002599046637209973, self.slope: [1.08166107 1.08231171], self.intercept: 1.0072798381499861\n",
      "iteration - 7948 -> loss: 0.0002598917577668058, self.slope: [1.08166903 1.08231977], self.intercept: 1.0072805898279569\n",
      "iteration - 7949 -> loss: 0.000259878853134562, self.slope: [1.081677   1.08232784], self.intercept: 1.00728134147492\n",
      "iteration - 7950 -> loss: 0.0002598659498240624, self.slope: [1.08168496 1.0823359 ], self.intercept: 1.0072820930908755\n",
      "iteration - 7951 -> loss: 0.000259853047835112, self.slope: [1.08169293 1.08234396], self.intercept: 1.0072828446758268\n",
      "iteration - 7952 -> loss: 0.00025984014716748263, self.slope: [1.08170089 1.08235203], self.intercept: 1.0072835962297788\n",
      "iteration - 7953 -> loss: 0.0002598272478209994, self.slope: [1.08170885 1.08236009], self.intercept: 1.0072843477527322\n",
      "iteration - 7954 -> loss: 0.0002598143497954474, self.slope: [1.08171682 1.08236815], self.intercept: 1.0072850992446911\n",
      "iteration - 7955 -> loss: 0.0002598014530906054, self.slope: [1.08172478 1.08237621], self.intercept: 1.0072858507056572\n",
      "iteration - 7956 -> loss: 0.0002597885577062704, self.slope: [1.08173274 1.08238427], self.intercept: 1.007286602135634\n",
      "iteration - 7957 -> loss: 0.0002597756636422458, self.slope: [1.0817407  1.08239234], self.intercept: 1.0072873535346232\n",
      "iteration - 7958 -> loss: 0.0002597627708983271, self.slope: [1.08174866 1.0824004 ], self.intercept: 1.0072881049026294\n",
      "iteration - 7959 -> loss: 0.00025974987947432484, self.slope: [1.08175662 1.08240846], self.intercept: 1.0072888562396547\n",
      "iteration - 7960 -> loss: 0.00025973698936997895, self.slope: [1.08176458 1.08241652], self.intercept: 1.0072896075457016\n",
      "iteration - 7961 -> loss: 0.0002597241005851529, self.slope: [1.08177254 1.08242458], self.intercept: 1.007290358820773\n",
      "iteration - 7962 -> loss: 0.0002597112131195925, self.slope: [1.0817805  1.08243264], self.intercept: 1.0072911100648703\n",
      "iteration - 7963 -> loss: 0.0002596983269731187, self.slope: [1.08178846 1.08244069], self.intercept: 1.0072918612779986\n",
      "iteration - 7964 -> loss: 0.00025968544214551546, self.slope: [1.08179642 1.08244875], self.intercept: 1.007292612460159\n",
      "iteration - 7965 -> loss: 0.00025967255863657365, self.slope: [1.08180438 1.08245681], self.intercept: 1.0072933636113537\n",
      "iteration - 7966 -> loss: 0.00025965967644609155, self.slope: [1.08181234 1.08246487], self.intercept: 1.0072941147315873\n",
      "iteration - 7967 -> loss: 0.0002596467955738753, self.slope: [1.0818203  1.08247292], self.intercept: 1.007294865820862\n",
      "iteration - 7968 -> loss: 0.00025963391601971386, self.slope: [1.08182825 1.08248098], self.intercept: 1.0072956168791802\n",
      "iteration - 7969 -> loss: 0.00025962103778339525, self.slope: [1.08183621 1.08248904], self.intercept: 1.0072963679065459\n",
      "iteration - 7970 -> loss: 0.00025960816086471487, self.slope: [1.08184417 1.08249709], self.intercept: 1.007297118902961\n",
      "iteration - 7971 -> loss: 0.0002595952852634736, self.slope: [1.08185212 1.08250515], self.intercept: 1.0072978698684274\n",
      "iteration - 7972 -> loss: 0.0002595824109794714, self.slope: [1.08186008 1.0825132 ], self.intercept: 1.0072986208029486\n",
      "iteration - 7973 -> loss: 0.000259569538012493, self.slope: [1.08186803 1.08252126], self.intercept: 1.0072993717065277\n",
      "iteration - 7974 -> loss: 0.0002595566663623457, self.slope: [1.08187599 1.08252931], self.intercept: 1.007300122579167\n",
      "iteration - 7975 -> loss: 0.00025954379602881545, self.slope: [1.08188394 1.08253737], self.intercept: 1.0073008734208704\n",
      "iteration - 7976 -> loss: 0.0002595309270116844, self.slope: [1.0818919  1.08254542], self.intercept: 1.0073016242316386\n",
      "iteration - 7977 -> loss: 0.00025951805931079426, self.slope: [1.08189985 1.08255347], self.intercept: 1.0073023750114771\n",
      "iteration - 7978 -> loss: 0.000259505192925889, self.slope: [1.0819078  1.08256152], self.intercept: 1.0073031257603877\n",
      "iteration - 7979 -> loss: 0.000259492327856788, self.slope: [1.08191575 1.08256958], self.intercept: 1.0073038764783728\n",
      "iteration - 7980 -> loss: 0.00025947946410329574, self.slope: [1.08192371 1.08257763], self.intercept: 1.0073046271654331\n",
      "iteration - 7981 -> loss: 0.0002594666016651872, self.slope: [1.08193166 1.08258568], self.intercept: 1.0073053778215728\n",
      "iteration - 7982 -> loss: 0.0002594537405422697, self.slope: [1.08193961 1.08259373], self.intercept: 1.0073061284467963\n",
      "iteration - 7983 -> loss: 0.00025944088073433176, self.slope: [1.08194756 1.08260178], self.intercept: 1.0073068790411053\n",
      "iteration - 7984 -> loss: 0.0002594280222411774, self.slope: [1.08195551 1.08260983], self.intercept: 1.007307629604502\n",
      "iteration - 7985 -> loss: 0.0002594151650626039, self.slope: [1.08196346 1.08261788], self.intercept: 1.0073083801369893\n",
      "iteration - 7986 -> loss: 0.00025940230919839995, self.slope: [1.08197141 1.08262593], self.intercept: 1.0073091306385702\n",
      "iteration - 7987 -> loss: 0.00025938945464835857, self.slope: [1.08197936 1.08263398], self.intercept: 1.0073098811092498\n",
      "iteration - 7988 -> loss: 0.0002593766014122822, self.slope: [1.08198731 1.08264203], self.intercept: 1.007310631549028\n",
      "iteration - 7989 -> loss: 0.0002593637494899741, self.slope: [1.08199526 1.08265008], self.intercept: 1.0073113819579078\n",
      "iteration - 7990 -> loss: 0.00025935089888121283, self.slope: [1.08200321 1.08265812], self.intercept: 1.007312132335891\n",
      "iteration - 7991 -> loss: 0.00025933804958580905, self.slope: [1.08201115 1.08266617], self.intercept: 1.0073128826829825\n",
      "iteration - 7992 -> loss: 0.00025932520160355446, self.slope: [1.0820191  1.08267422], self.intercept: 1.0073136329991836\n",
      "iteration - 7993 -> loss: 0.0002593123549342374, self.slope: [1.08202705 1.08268226], self.intercept: 1.0073143832844975\n",
      "iteration - 7994 -> loss: 0.00025929950957766565, self.slope: [1.08203499 1.08269031], self.intercept: 1.0073151335389285\n",
      "iteration - 7995 -> loss: 0.00025928666553362746, self.slope: [1.08204294 1.08269836], self.intercept: 1.0073158837624767\n",
      "iteration - 7996 -> loss: 0.00025927382280193577, self.slope: [1.08205089 1.0827064 ], self.intercept: 1.0073166339551465\n",
      "iteration - 7997 -> loss: 0.0002592609813823613, self.slope: [1.08205883 1.08271445], self.intercept: 1.0073173841169412\n",
      "iteration - 7998 -> loss: 0.0002592481412747147, self.slope: [1.08206678 1.08272249], self.intercept: 1.0073181342478623\n",
      "iteration - 7999 -> loss: 0.00025923530247879475, self.slope: [1.08207472 1.08273053], self.intercept: 1.0073188843479133\n",
      "iteration - 8000 -> loss: 0.00025922246499439285, self.slope: [1.08208266 1.08273858], self.intercept: 1.007319634417097\n",
      "iteration - 8001 -> loss: 0.0002592096288213078, self.slope: [1.08209061 1.08274662], self.intercept: 1.0073203844554162\n",
      "iteration - 8002 -> loss: 0.00025919679395933226, self.slope: [1.08209855 1.08275466], self.intercept: 1.0073211344628732\n",
      "iteration - 8003 -> loss: 0.00025918396040826834, self.slope: [1.08210649 1.0827627 ], self.intercept: 1.0073218844394705\n",
      "iteration - 8004 -> loss: 0.0002591711281678976, self.slope: [1.08211444 1.08277075], self.intercept: 1.0073226343852106\n",
      "iteration - 8005 -> loss: 0.0002591582972380386, self.slope: [1.08212238 1.08277879], self.intercept: 1.0073233843000982\n",
      "iteration - 8006 -> loss: 0.0002591454676184835, self.slope: [1.08213032 1.08278683], self.intercept: 1.007324134184135\n",
      "iteration - 8007 -> loss: 0.0002591326393090224, self.slope: [1.08213826 1.08279487], self.intercept: 1.0073248840373241\n",
      "iteration - 8008 -> loss: 0.0002591198123094431, self.slope: [1.0821462  1.08280291], self.intercept: 1.0073256338596666\n",
      "iteration - 8009 -> loss: 0.00025910698661957184, self.slope: [1.08215414 1.08281095], self.intercept: 1.0073263836511666\n",
      "iteration - 8010 -> loss: 0.0002590941622391681, self.slope: [1.08216208 1.08281899], self.intercept: 1.0073271334118263\n",
      "iteration - 8011 -> loss: 0.0002590813391680447, self.slope: [1.08217002 1.08282703], self.intercept: 1.0073278831416494\n",
      "iteration - 8012 -> loss: 0.00025906851740602367, self.slope: [1.08217796 1.08283507], self.intercept: 1.0073286328406383\n",
      "iteration - 8013 -> loss: 0.00025905569695286045, self.slope: [1.0821859  1.08284311], self.intercept: 1.0073293825087948\n",
      "iteration - 8014 -> loss: 0.000259042877808386, self.slope: [1.08219384 1.08285114], self.intercept: 1.0073301321461232\n",
      "iteration - 8015 -> loss: 0.0002590300599723762, self.slope: [1.08220178 1.08285918], self.intercept: 1.007330881752625\n",
      "iteration - 8016 -> loss: 0.0002590172434446316, self.slope: [1.08220971 1.08286722], self.intercept: 1.0073316313283025\n",
      "iteration - 8017 -> loss: 0.0002590044282249571, self.slope: [1.08221765 1.08287525], self.intercept: 1.0073323808731596\n",
      "iteration - 8018 -> loss: 0.00025899161431314037, self.slope: [1.08222559 1.08288329], self.intercept: 1.0073331303872\n",
      "iteration - 8019 -> loss: 0.00025897880170898646, self.slope: [1.08223352 1.08289133], self.intercept: 1.0073338798704248\n",
      "iteration - 8020 -> loss: 0.0002589659904122927, self.slope: [1.08224146 1.08289936], self.intercept: 1.007334629322838\n",
      "iteration - 8021 -> loss: 0.00025895318042285556, self.slope: [1.08224939 1.0829074 ], self.intercept: 1.007335378744441\n",
      "iteration - 8022 -> loss: 0.0002589403717404623, self.slope: [1.08225733 1.08291543], self.intercept: 1.0073361281352367\n",
      "iteration - 8023 -> loss: 0.0002589275643649268, self.slope: [1.08226526 1.08292347], self.intercept: 1.007336877495228\n",
      "iteration - 8024 -> loss: 0.0002589147582960423, self.slope: [1.0822732 1.0829315], self.intercept: 1.0073376268244185\n",
      "iteration - 8025 -> loss: 0.00025890195353359043, self.slope: [1.08228113 1.08293953], self.intercept: 1.0073383761228116\n",
      "iteration - 8026 -> loss: 0.0002588891500773929, self.slope: [1.08228906 1.08294757], self.intercept: 1.0073391253904065\n",
      "iteration - 8027 -> loss: 0.0002588763479272216, self.slope: [1.082297  1.0829556], self.intercept: 1.0073398746272095\n",
      "iteration - 8028 -> loss: 0.0002588635470829129, self.slope: [1.08230493 1.08296363], self.intercept: 1.0073406238332225\n",
      "iteration - 8029 -> loss: 0.00025885074754420745, self.slope: [1.08231286 1.08297166], self.intercept: 1.0073413730084482\n",
      "iteration - 8030 -> loss: 0.0002588379493109472, self.slope: [1.08232079 1.08297969], self.intercept: 1.0073421221528882\n",
      "iteration - 8031 -> loss: 0.00025882515238293945, self.slope: [1.08232873 1.08298772], self.intercept: 1.0073428712665464\n",
      "iteration - 8032 -> loss: 0.00025881235675993813, self.slope: [1.08233666 1.08299575], self.intercept: 1.0073436203494255\n",
      "iteration - 8033 -> loss: 0.00025879956244176844, self.slope: [1.08234459 1.08300378], self.intercept: 1.0073443694015274\n",
      "iteration - 8034 -> loss: 0.00025878676942822453, self.slope: [1.08235252 1.08301181], self.intercept: 1.0073451184228548\n",
      "iteration - 8035 -> loss: 0.00025877397771910496, self.slope: [1.08236045 1.08301984], self.intercept: 1.0073458674134126\n",
      "iteration - 8036 -> loss: 0.00025876118731420016, self.slope: [1.08236838 1.08302787], self.intercept: 1.007346616373201\n",
      "iteration - 8037 -> loss: 0.00025874839821331654, self.slope: [1.0823763 1.0830359], self.intercept: 1.0073473653022234\n",
      "iteration - 8038 -> loss: 0.00025873561041626144, self.slope: [1.08238423 1.08304393], self.intercept: 1.0073481142004859\n",
      "iteration - 8039 -> loss: 0.00025872282392280126, self.slope: [1.08239216 1.08305196], self.intercept: 1.0073488630679868\n",
      "iteration - 8040 -> loss: 0.00025871003873277116, self.slope: [1.08240009 1.08305998], self.intercept: 1.0073496119047303\n",
      "iteration - 8041 -> loss: 0.0002586972548459416, self.slope: [1.08240802 1.08306801], self.intercept: 1.00735036071072\n",
      "iteration - 8042 -> loss: 0.0002586844722621281, self.slope: [1.08241594 1.08307604], self.intercept: 1.007351109485958\n",
      "iteration - 8043 -> loss: 0.00025867169098113085, self.slope: [1.08242387 1.08308406], self.intercept: 1.0073518582304457\n",
      "iteration - 8044 -> loss: 0.0002586589110027211, self.slope: [1.0824318  1.08309209], self.intercept: 1.0073526069441885\n",
      "iteration - 8045 -> loss: 0.00025864613232672615, self.slope: [1.08243972 1.08310011], self.intercept: 1.0073533556271874\n",
      "iteration - 8046 -> loss: 0.0002586333549529239, self.slope: [1.08244765 1.08310814], self.intercept: 1.0073541042794447\n",
      "iteration - 8047 -> loss: 0.00025862057888113925, self.slope: [1.08245557 1.08311616], self.intercept: 1.0073548529009637\n",
      "iteration - 8048 -> loss: 0.0002586078041111401, self.slope: [1.0824635  1.08312419], self.intercept: 1.0073556014917469\n",
      "iteration - 8049 -> loss: 0.00025859503064276196, self.slope: [1.08247142 1.08313221], self.intercept: 1.0073563500517984\n",
      "iteration - 8050 -> loss: 0.00025858225847575527, self.slope: [1.08247934 1.08314023], self.intercept: 1.0073570985811202\n",
      "iteration - 8051 -> loss: 0.0002585694876099687, self.slope: [1.08248727 1.08314826], self.intercept: 1.0073578470797144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 8052 -> loss: 0.00025855671804515394, self.slope: [1.08249519 1.08315628], self.intercept: 1.0073585955475857\n",
      "iteration - 8053 -> loss: 0.0002585439497811387, self.slope: [1.08250311 1.0831643 ], self.intercept: 1.0073593439847344\n",
      "iteration - 8054 -> loss: 0.0002585311828177165, self.slope: [1.08251103 1.08317232], self.intercept: 1.0073600923911636\n",
      "iteration - 8055 -> loss: 0.00025851841715469735, self.slope: [1.08251895 1.08318034], self.intercept: 1.0073608407668775\n",
      "iteration - 8056 -> loss: 0.0002585056527918616, self.slope: [1.08252688 1.08318837], self.intercept: 1.0073615891118797\n",
      "iteration - 8057 -> loss: 0.00025849288972898935, self.slope: [1.0825348  1.08319639], self.intercept: 1.0073623374261695\n",
      "iteration - 8058 -> loss: 0.00025848012796594405, self.slope: [1.08254272 1.08320441], self.intercept: 1.0073630857097504\n",
      "iteration - 8059 -> loss: 0.0002584673675024648, self.slope: [1.08255064 1.08321243], self.intercept: 1.007363833962628\n",
      "iteration - 8060 -> loss: 0.0002584546083383709, self.slope: [1.08255856 1.08322044], self.intercept: 1.007364582184803\n",
      "iteration - 8061 -> loss: 0.00025844185047346866, self.slope: [1.08256648 1.08322846], self.intercept: 1.007365330376278\n",
      "iteration - 8062 -> loss: 0.0002584290939075264, self.slope: [1.08257439 1.08323648], self.intercept: 1.0073660785370566\n",
      "iteration - 8063 -> loss: 0.00025841633864039397, self.slope: [1.08258231 1.0832445 ], self.intercept: 1.0073668266671403\n",
      "iteration - 8064 -> loss: 0.00025840358467183204, self.slope: [1.08259023 1.08325252], self.intercept: 1.007367574766533\n",
      "iteration - 8065 -> loss: 0.0002583908320016511, self.slope: [1.08259815 1.08326053], self.intercept: 1.0073683228352366\n",
      "iteration - 8066 -> loss: 0.0002583780806296544, self.slope: [1.08260606 1.08326855], self.intercept: 1.0073690708732541\n",
      "iteration - 8067 -> loss: 0.00025836533055565596, self.slope: [1.08261398 1.08327657], self.intercept: 1.0073698188805889\n",
      "iteration - 8068 -> loss: 0.00025835258177940844, self.slope: [1.0826219  1.08328458], self.intercept: 1.007370566857242\n",
      "iteration - 8069 -> loss: 0.00025833983430074395, self.slope: [1.08262981 1.0832926 ], self.intercept: 1.0073713148032188\n",
      "iteration - 8070 -> loss: 0.00025832708811945426, self.slope: [1.08263773 1.08330061], self.intercept: 1.0073720627185203\n",
      "iteration - 8071 -> loss: 0.00025831434323535517, self.slope: [1.08264564 1.08330863], self.intercept: 1.0073728106031499\n",
      "iteration - 8072 -> loss: 0.0002583015996482184, self.slope: [1.08265356 1.08331664], self.intercept: 1.0073735584571102\n",
      "iteration - 8073 -> loss: 0.00025828885735786707, self.slope: [1.08266147 1.08332466], self.intercept: 1.007374306280403\n",
      "iteration - 8074 -> loss: 0.0002582761163640945, self.slope: [1.08266939 1.08333267], self.intercept: 1.0073750540730313\n",
      "iteration - 8075 -> loss: 0.00025826337666668255, self.slope: [1.0826773  1.08334068], self.intercept: 1.0073758018349988\n",
      "iteration - 8076 -> loss: 0.0002582506382654629, self.slope: [1.08268521 1.0833487 ], self.intercept: 1.007376549566308\n",
      "iteration - 8077 -> loss: 0.0002582379011602074, self.slope: [1.08269313 1.08335671], self.intercept: 1.0073772972669621\n",
      "iteration - 8078 -> loss: 0.0002582251653507537, self.slope: [1.08270104 1.08336472], self.intercept: 1.0073780449369611\n",
      "iteration - 8079 -> loss: 0.000258212430836832, self.slope: [1.08270895 1.08337273], self.intercept: 1.0073787925763114\n",
      "iteration - 8080 -> loss: 0.00025819969761830804, self.slope: [1.08271686 1.08338074], self.intercept: 1.007379540185013\n",
      "iteration - 8081 -> loss: 0.00025818696569495877, self.slope: [1.08272477 1.08338875], self.intercept: 1.0073802877630709\n",
      "iteration - 8082 -> loss: 0.00025817423506657846, self.slope: [1.08273268 1.08339676], self.intercept: 1.0073810353104866\n",
      "iteration - 8083 -> loss: 0.00025816150573298346, self.slope: [1.08274059 1.08340477], self.intercept: 1.0073817828272624\n",
      "iteration - 8084 -> loss: 0.0002581487776939484, self.slope: [1.0827485  1.08341278], self.intercept: 1.0073825303134012\n",
      "iteration - 8085 -> loss: 0.00025813605094928706, self.slope: [1.08275641 1.08342079], self.intercept: 1.0073832777689051\n",
      "iteration - 8086 -> loss: 0.0002581233254988193, self.slope: [1.08276432 1.0834288 ], self.intercept: 1.0073840251937785\n",
      "iteration - 8087 -> loss: 0.0002581106013423043, self.slope: [1.08277223 1.08343681], self.intercept: 1.0073847725880238\n",
      "iteration - 8088 -> loss: 0.0002580978784795734, self.slope: [1.08278014 1.08344482], self.intercept: 1.0073855199516433\n",
      "iteration - 8089 -> loss: 0.0002580851569104155, self.slope: [1.08278804 1.08345282], self.intercept: 1.007386267284639\n",
      "iteration - 8090 -> loss: 0.0002580724366346356, self.slope: [1.08279595 1.08346083], self.intercept: 1.0073870145870147\n",
      "iteration - 8091 -> loss: 0.00025805971765202975, self.slope: [1.08280386 1.08346884], self.intercept: 1.0073877618587737\n",
      "iteration - 8092 -> loss: 0.00025804699996239116, self.slope: [1.08281177 1.08347684], self.intercept: 1.007388509099917\n",
      "iteration - 8093 -> loss: 0.00025803428356553816, self.slope: [1.08281967 1.08348485], self.intercept: 1.0073892563104472\n",
      "iteration - 8094 -> loss: 0.00025802156846125294, self.slope: [1.08282758 1.08349285], self.intercept: 1.0073900034903698\n",
      "iteration - 8095 -> loss: 0.00025800885464935796, self.slope: [1.08283548 1.08350086], self.intercept: 1.0073907506396858\n",
      "iteration - 8096 -> loss: 0.00025799614212963963, self.slope: [1.08284339 1.08350886], self.intercept: 1.0073914977583969\n",
      "iteration - 8097 -> loss: 0.0002579834309018888, self.slope: [1.08285129 1.08351687], self.intercept: 1.0073922448465058\n",
      "iteration - 8098 -> loss: 0.0002579707209659294, self.slope: [1.0828592  1.08352487], self.intercept: 1.0073929919040174\n",
      "iteration - 8099 -> loss: 0.0002579580123215336, self.slope: [1.0828671  1.08353288], self.intercept: 1.0073937389309329\n",
      "iteration - 8100 -> loss: 0.00025794530496853267, self.slope: [1.082875   1.08354088], self.intercept: 1.007394485927256\n",
      "iteration - 8101 -> loss: 0.0002579325989067166, self.slope: [1.08288291 1.08354888], self.intercept: 1.0073952328929896\n",
      "iteration - 8102 -> loss: 0.00025791989413585374, self.slope: [1.08289081 1.08355688], self.intercept: 1.0073959798281344\n",
      "iteration - 8103 -> loss: 0.00025790719065579826, self.slope: [1.08289871 1.08356488], self.intercept: 1.0073967267326942\n",
      "iteration - 8104 -> loss: 0.00025789448846631085, self.slope: [1.08290661 1.08357289], self.intercept: 1.0073974736066724\n",
      "iteration - 8105 -> loss: 0.0002578817875672078, self.slope: [1.08291451 1.08358089], self.intercept: 1.0073982204500698\n",
      "iteration - 8106 -> loss: 0.00025786908795830165, self.slope: [1.08292241 1.08358889], self.intercept: 1.007398967262891\n",
      "iteration - 8107 -> loss: 0.0002578563896393883, self.slope: [1.08293031 1.08359689], self.intercept: 1.0073997140451383\n",
      "iteration - 8108 -> loss: 0.0002578436926102409, self.slope: [1.08293821 1.08360489], self.intercept: 1.0074004607968152\n",
      "iteration - 8109 -> loss: 0.00025783099687068796, self.slope: [1.08294611 1.08361289], self.intercept: 1.0074012075179246\n",
      "iteration - 8110 -> loss: 0.0002578183024205281, self.slope: [1.08295401 1.08362089], self.intercept: 1.0074019542084673\n",
      "iteration - 8111 -> loss: 0.00025780560925954023, self.slope: [1.08296191 1.08362888], self.intercept: 1.007402700868446\n",
      "iteration - 8112 -> loss: 0.000257792917387573, self.slope: [1.08296981 1.08363688], self.intercept: 1.0074034474978657\n",
      "iteration - 8113 -> loss: 0.0002577802268043876, self.slope: [1.08297771 1.08364488], self.intercept: 1.007404194096727\n",
      "iteration - 8114 -> loss: 0.00025776753750978565, self.slope: [1.08298561 1.08365288], self.intercept: 1.0074049406650334\n",
      "iteration - 8115 -> loss: 0.0002577548495035849, self.slope: [1.0829935  1.08366087], self.intercept: 1.0074056872027881\n",
      "iteration - 8116 -> loss: 0.00025774216278558773, self.slope: [1.0830014  1.08366887], self.intercept: 1.0074064337099928\n",
      "iteration - 8117 -> loss: 0.0002577294773555757, self.slope: [1.0830093  1.08367687], self.intercept: 1.0074071801866513\n",
      "iteration - 8118 -> loss: 0.00025771679321336707, self.slope: [1.08301719 1.08368486], self.intercept: 1.0074079266327631\n",
      "iteration - 8119 -> loss: 0.00025770411035875977, self.slope: [1.08302509 1.08369286], self.intercept: 1.007408673048336\n",
      "iteration - 8120 -> loss: 0.00025769142879156865, self.slope: [1.08303298 1.08370085], self.intercept: 1.0074094194333707\n",
      "iteration - 8121 -> loss: 0.00025767874851157326, self.slope: [1.08304088 1.08370885], self.intercept: 1.0074101657878682\n",
      "iteration - 8122 -> loss: 0.00025766606951857117, self.slope: [1.08304877 1.08371684], self.intercept: 1.0074109121118338\n",
      "iteration - 8123 -> loss: 0.0002576533918123829, self.slope: [1.08305667 1.08372483], self.intercept: 1.0074116584052693\n",
      "iteration - 8124 -> loss: 0.0002576407153927972, self.slope: [1.08306456 1.08373283], self.intercept: 1.007412404668177\n",
      "iteration - 8125 -> loss: 0.0002576280402596111, self.slope: [1.08307245 1.08374082], self.intercept: 1.0074131509005593\n",
      "iteration - 8126 -> loss: 0.0002576153664126702, self.slope: [1.08308035 1.08374881], self.intercept: 1.0074138971024202\n",
      "iteration - 8127 -> loss: 0.0002576026938517269, self.slope: [1.08308824 1.08375681], self.intercept: 1.0074146432737612\n",
      "iteration - 8128 -> loss: 0.0002575900225766036, self.slope: [1.08309613 1.0837648 ], self.intercept: 1.007415389414585\n",
      "iteration - 8129 -> loss: 0.0002575773525870875, self.slope: [1.08310402 1.08377279], self.intercept: 1.007416135524895\n",
      "iteration - 8130 -> loss: 0.00025756468388300134, self.slope: [1.08311191 1.08378078], self.intercept: 1.0074168816046927\n",
      "iteration - 8131 -> loss: 0.00025755201646413065, self.slope: [1.0831198  1.08378877], self.intercept: 1.007417627653984\n",
      "iteration - 8132 -> loss: 0.00025753935033027243, self.slope: [1.08312769 1.08379676], self.intercept: 1.0074183736727667\n",
      "iteration - 8133 -> loss: 0.00025752668548123325, self.slope: [1.08313558 1.08380475], self.intercept: 1.0074191196610451\n",
      "iteration - 8134 -> loss: 0.00025751402191684933, self.slope: [1.08314347 1.08381274], self.intercept: 1.0074198656188234\n",
      "iteration - 8135 -> loss: 0.00025750135963689214, self.slope: [1.08315136 1.08382073], self.intercept: 1.007420611546105\n",
      "iteration - 8136 -> loss: 0.0002574886986411495, self.slope: [1.08315925 1.08382872], self.intercept: 1.0074213574428914\n",
      "iteration - 8137 -> loss: 0.00025747603892945767, self.slope: [1.08316714 1.0838367 ], self.intercept: 1.0074221033091857\n",
      "iteration - 8138 -> loss: 0.000257463380501584, self.slope: [1.08317503 1.08384469], self.intercept: 1.0074228491449893\n",
      "iteration - 8139 -> loss: 0.00025745072335736673, self.slope: [1.08318291 1.08385268], self.intercept: 1.0074235949503065\n",
      "iteration - 8140 -> loss: 0.0002574380674965657, self.slope: [1.0831908  1.08386067], self.intercept: 1.0074243407251398\n",
      "iteration - 8141 -> loss: 0.0002574254129190351, self.slope: [1.08319869 1.08386865], self.intercept: 1.007425086469492\n",
      "iteration - 8142 -> loss: 0.0002574127596245409, self.slope: [1.08320657 1.08387664], self.intercept: 1.0074258321833647\n",
      "iteration - 8143 -> loss: 0.00025740010761288396, self.slope: [1.08321446 1.08388462], self.intercept: 1.0074265778667608\n",
      "iteration - 8144 -> loss: 0.00025738745688387853, self.slope: [1.08322235 1.08389261], self.intercept: 1.0074273235196833\n",
      "iteration - 8145 -> loss: 0.0002573748074373448, self.slope: [1.08323023 1.08390059], self.intercept: 1.0074280691421345\n",
      "iteration - 8146 -> loss: 0.00025736215927304513, self.slope: [1.08323811 1.08390858], self.intercept: 1.0074288147341193\n",
      "iteration - 8147 -> loss: 0.00025734951239081, self.slope: [1.083246   1.08391656], self.intercept: 1.007429560295639\n",
      "iteration - 8148 -> loss: 0.00025733686679044464, self.slope: [1.08325388 1.08392455], self.intercept: 1.0074303058266962\n",
      "iteration - 8149 -> loss: 0.00025732422247173203, self.slope: [1.08326177 1.08393253], self.intercept: 1.0074310513272924\n",
      "iteration - 8150 -> loss: 0.0002573115794344984, self.slope: [1.08326965 1.08394051], self.intercept: 1.0074317967974318\n",
      "iteration - 8151 -> loss: 0.000257298937678509, self.slope: [1.08327753 1.08394849], self.intercept: 1.007432542237117\n",
      "iteration - 8152 -> loss: 0.0002572862972036023, self.slope: [1.08328541 1.08395648], self.intercept: 1.0074332876463497\n",
      "iteration - 8153 -> loss: 0.00025727365800958, self.slope: [1.0832933  1.08396446], self.intercept: 1.0074340330251346\n",
      "iteration - 8154 -> loss: 0.000257261020096225, self.slope: [1.08330118 1.08397244], self.intercept: 1.0074347783734727\n",
      "iteration - 8155 -> loss: 0.00025724838346336063, self.slope: [1.08330906 1.08398042], self.intercept: 1.0074355236913668\n",
      "iteration - 8156 -> loss: 0.00025723574811076856, self.slope: [1.08331694 1.0839884 ], self.intercept: 1.0074362689788194\n",
      "iteration - 8157 -> loss: 0.0002572231140382547, self.slope: [1.08332482 1.08399638], self.intercept: 1.0074370142358335\n",
      "iteration - 8158 -> loss: 0.0002572104812456549, self.slope: [1.0833327  1.08400436], self.intercept: 1.0074377594624107\n",
      "iteration - 8159 -> loss: 0.0002571978497327191, self.slope: [1.08334058 1.08401234], self.intercept: 1.0074385046585566\n",
      "iteration - 8160 -> loss: 0.0002571852194992952, self.slope: [1.08334846 1.08402032], self.intercept: 1.0074392498242721\n",
      "iteration - 8161 -> loss: 0.0002571725905451839, self.slope: [1.08335634 1.0840283 ], self.intercept: 1.007439994959561\n",
      "iteration - 8162 -> loss: 0.0002571599628701469, self.slope: [1.08336421 1.08403628], self.intercept: 1.007440740064425\n",
      "iteration - 8163 -> loss: 0.000257147336474025, self.slope: [1.08337209 1.08404425], self.intercept: 1.0074414851388678\n",
      "iteration - 8164 -> loss: 0.0002571347113566145, self.slope: [1.08337997 1.08405223], self.intercept: 1.0074422301828911\n",
      "iteration - 8165 -> loss: 0.00025712208751772493, self.slope: [1.08338785 1.08406021], self.intercept: 1.007442975196498\n",
      "iteration - 8166 -> loss: 0.0002571094649571405, self.slope: [1.08339572 1.08406818], self.intercept: 1.007443720179691\n",
      "iteration - 8167 -> loss: 0.0002570968436746627, self.slope: [1.0834036  1.08407616], self.intercept: 1.0074444651324728\n",
      "iteration - 8168 -> loss: 0.000257084223670125, self.slope: [1.08341148 1.08408413], self.intercept: 1.0074452100548448\n",
      "iteration - 8169 -> loss: 0.0002570716049432988, self.slope: [1.08341935 1.08409211], self.intercept: 1.0074459549468116\n",
      "iteration - 8170 -> loss: 0.0002570589874940216, self.slope: [1.08342723 1.08410008], self.intercept: 1.0074466998083755\n",
      "iteration - 8171 -> loss: 0.00025704637132205224, self.slope: [1.0834351  1.08410806], self.intercept: 1.0074474446395374\n",
      "iteration - 8172 -> loss: 0.0002570337564272297, self.slope: [1.08344297 1.08411603], self.intercept: 1.007448189440303\n",
      "iteration - 8173 -> loss: 0.00025702114280936515, self.slope: [1.08345085 1.08412401], self.intercept: 1.0074489342106738\n",
      "iteration - 8174 -> loss: 0.00025700853046821593, self.slope: [1.08345872 1.08413198], self.intercept: 1.0074496789506526\n",
      "iteration - 8175 -> loss: 0.0002569959194036359, self.slope: [1.08346659 1.08413995], self.intercept: 1.0074504236602413\n",
      "iteration - 8176 -> loss: 0.0002569833096153919, self.slope: [1.08347447 1.08414793], self.intercept: 1.007451168339443\n",
      "iteration - 8177 -> loss: 0.0002569707011033095, self.slope: [1.08348234 1.0841559 ], self.intercept: 1.0074519129882609\n",
      "iteration - 8178 -> loss: 0.0002569580938671796, self.slope: [1.08349021 1.08416387], self.intercept: 1.0074526576066967\n",
      "iteration - 8179 -> loss: 0.0002569454879068055, self.slope: [1.08349808 1.08417184], self.intercept: 1.0074534021947543\n",
      "iteration - 8180 -> loss: 0.00025693288322202316, self.slope: [1.08350595 1.08417981], self.intercept: 1.0074541467524358\n",
      "iteration - 8181 -> loss: 0.0002569202798125957, self.slope: [1.08351382 1.08418778], self.intercept: 1.0074548912797439\n",
      "iteration - 8182 -> loss: 0.0002569076776783316, self.slope: [1.08352169 1.08419575], self.intercept: 1.00745563577668\n",
      "iteration - 8183 -> loss: 0.00025689507681905485, self.slope: [1.08352956 1.08420372], self.intercept: 1.0074563802432495\n",
      "iteration - 8184 -> loss: 0.00025688247723457076, self.slope: [1.08353743 1.08421169], self.intercept: 1.0074571246794541\n",
      "iteration - 8185 -> loss: 0.00025686987892467524, self.slope: [1.0835453  1.08421966], self.intercept: 1.0074578690852949\n",
      "iteration - 8186 -> loss: 0.0002568572818891717, self.slope: [1.08355317 1.08422763], self.intercept: 1.007458613460776\n",
      "iteration - 8187 -> loss: 0.000256844686127854, self.slope: [1.08356104 1.0842356 ], self.intercept: 1.0074593578059001\n",
      "iteration - 8188 -> loss: 0.00025683209164052397, self.slope: [1.08356891 1.08424356], self.intercept: 1.00746010212067\n",
      "iteration - 8189 -> loss: 0.0002568194984270156, self.slope: [1.08357677 1.08425153], self.intercept: 1.0074608464050867\n",
      "iteration - 8190 -> loss: 0.00025680690648711307, self.slope: [1.08358464 1.0842595 ], self.intercept: 1.0074615906591549\n",
      "iteration - 8191 -> loss: 0.0002567943158206226, self.slope: [1.08359251 1.08426746], self.intercept: 1.0074623348828768\n",
      "iteration - 8192 -> loss: 0.00025678172642733634, self.slope: [1.08360037 1.08427543], self.intercept: 1.0074630790762544\n",
      "iteration - 8193 -> loss: 0.0002567691383070934, self.slope: [1.08360824 1.0842834 ], self.intercept: 1.0074638232392912\n",
      "iteration - 8194 -> loss: 0.0002567565514596679, self.slope: [1.0836161  1.08429136], self.intercept: 1.0074645673719889\n",
      "iteration - 8195 -> loss: 0.00025674396588486756, self.slope: [1.08362397 1.08429933], self.intercept: 1.0074653114743513\n",
      "iteration - 8196 -> loss: 0.0002567313815825008, self.slope: [1.08363183 1.08430729], self.intercept: 1.0074660555463817\n",
      "iteration - 8197 -> loss: 0.00025671879855238374, self.slope: [1.0836397  1.08431525], self.intercept: 1.0074667995880802\n",
      "iteration - 8198 -> loss: 0.0002567062167942918, self.slope: [1.08364756 1.08432322], self.intercept: 1.0074675435994511\n",
      "iteration - 8199 -> loss: 0.0002566936363080699, self.slope: [1.08365543 1.08433118], self.intercept: 1.007468287580497\n",
      "iteration - 8200 -> loss: 0.0002566810570935044, self.slope: [1.08366329 1.08433914], self.intercept: 1.007469031531221\n",
      "iteration - 8201 -> loss: 0.00025666847915037605, self.slope: [1.08367115 1.08434711], self.intercept: 1.007469775451625\n",
      "iteration - 8202 -> loss: 0.0002566559024785254, self.slope: [1.08367901 1.08435507], self.intercept: 1.0074705193417133\n",
      "iteration - 8203 -> loss: 0.00025664332707775044, self.slope: [1.08368687 1.08436303], self.intercept: 1.0074712632014862\n",
      "iteration - 8204 -> loss: 0.00025663075294783466, self.slope: [1.08369474 1.08437099], self.intercept: 1.007472007030949\n",
      "iteration - 8205 -> loss: 0.000256618180088591, self.slope: [1.0837026  1.08437895], self.intercept: 1.0074727508301022\n",
      "iteration - 8206 -> loss: 0.0002566056084998482, self.slope: [1.08371046 1.08438691], self.intercept: 1.0074734945989505\n",
      "iteration - 8207 -> loss: 0.0002565930381813872, self.slope: [1.08371832 1.08439487], self.intercept: 1.0074742383374942\n",
      "iteration - 8208 -> loss: 0.00025658046913301717, self.slope: [1.08372618 1.08440283], self.intercept: 1.0074749820457387\n",
      "iteration - 8209 -> loss: 0.0002565679013545477, self.slope: [1.08373404 1.08441079], self.intercept: 1.007475725723683\n",
      "iteration - 8210 -> loss: 0.00025655533484577773, self.slope: [1.0837419  1.08441875], self.intercept: 1.007476469371332\n",
      "iteration - 8211 -> loss: 0.0002565427696065189, self.slope: [1.08374975 1.08442671], self.intercept: 1.0074772129886884\n",
      "iteration - 8212 -> loss: 0.000256530205636584, self.slope: [1.08375761 1.08443467], self.intercept: 1.0074779565757543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 8213 -> loss: 0.00025651764293574967, self.slope: [1.08376547 1.08444262], self.intercept: 1.0074787001325334\n",
      "iteration - 8214 -> loss: 0.000256505081503865, self.slope: [1.08377333 1.08445058], self.intercept: 1.0074794436590289\n",
      "iteration - 8215 -> loss: 0.0002564925213406912, self.slope: [1.08378118 1.08445854], self.intercept: 1.007480187155242\n",
      "iteration - 8216 -> loss: 0.000256479962446051, self.slope: [1.08378904 1.08446649], self.intercept: 1.0074809306211758\n",
      "iteration - 8217 -> loss: 0.00025646740481975646, self.slope: [1.0837969  1.08447445], self.intercept: 1.0074816740568333\n",
      "iteration - 8218 -> loss: 0.0002564548484616124, self.slope: [1.08380475 1.08448241], self.intercept: 1.0074824174622161\n",
      "iteration - 8219 -> loss: 0.00025644229337141875, self.slope: [1.08381261 1.08449036], self.intercept: 1.0074831608373271\n",
      "iteration - 8220 -> loss: 0.00025642973954896614, self.slope: [1.08382046 1.08449832], self.intercept: 1.0074839041821697\n",
      "iteration - 8221 -> loss: 0.00025641718699409197, self.slope: [1.08382832 1.08450627], self.intercept: 1.0074846474967476\n",
      "iteration - 8222 -> loss: 0.00025640463570659, self.slope: [1.08383617 1.08451422], self.intercept: 1.0074853907810615\n",
      "iteration - 8223 -> loss: 0.000256392085686255, self.slope: [1.08384403 1.08452218], self.intercept: 1.0074861340351149\n",
      "iteration - 8224 -> loss: 0.0002563795369329104, self.slope: [1.08385188 1.08453013], self.intercept: 1.0074868772589098\n",
      "iteration - 8225 -> loss: 0.0002563669894463493, self.slope: [1.08385973 1.08453808], self.intercept: 1.0074876204524494\n",
      "iteration - 8226 -> loss: 0.0002563544432263562, self.slope: [1.08386758 1.08454604], self.intercept: 1.0074883636157375\n",
      "iteration - 8227 -> loss: 0.0002563418982727809, self.slope: [1.08387544 1.08455399], self.intercept: 1.007489106748776\n",
      "iteration - 8228 -> loss: 0.00025632935458540484, self.slope: [1.08388329 1.08456194], self.intercept: 1.0074898498515679\n",
      "iteration - 8229 -> loss: 0.00025631681216404324, self.slope: [1.08389114 1.08456989], self.intercept: 1.0074905929241138\n",
      "iteration - 8230 -> loss: 0.00025630427100848774, self.slope: [1.08389899 1.08457784], self.intercept: 1.0074913359664186\n",
      "iteration - 8231 -> loss: 0.00025629173111855916, self.slope: [1.08390684 1.08458579], self.intercept: 1.0074920789784856\n",
      "iteration - 8232 -> loss: 0.0002562791924940492, self.slope: [1.08391469 1.08459374], self.intercept: 1.0074928219603148\n",
      "iteration - 8233 -> loss: 0.00025626665513478643, self.slope: [1.08392254 1.08460169], self.intercept: 1.0074935649119112\n",
      "iteration - 8234 -> loss: 0.00025625411904054926, self.slope: [1.08393039 1.08460964], self.intercept: 1.0074943078332765\n",
      "iteration - 8235 -> loss: 0.000256241584211163, self.slope: [1.08393824 1.08461759], self.intercept: 1.0074950507244118\n",
      "iteration - 8236 -> loss: 0.00025622905064643617, self.slope: [1.08394609 1.08462554], self.intercept: 1.0074957935853222\n",
      "iteration - 8237 -> loss: 0.00025621651834614745, self.slope: [1.08395394 1.08463349], self.intercept: 1.0074965364160104\n",
      "iteration - 8238 -> loss: 0.00025620398731014823, self.slope: [1.08396178 1.08464143], self.intercept: 1.0074972792164774\n",
      "iteration - 8239 -> loss: 0.00025619145753821273, self.slope: [1.08396963 1.08464938], self.intercept: 1.0074980219867276\n",
      "iteration - 8240 -> loss: 0.0002561789290301376, self.slope: [1.08397748 1.08465733], self.intercept: 1.0074987647267621\n",
      "iteration - 8241 -> loss: 0.0002561664017857488, self.slope: [1.08398532 1.08466528], self.intercept: 1.0074995074365847\n",
      "iteration - 8242 -> loss: 0.00025615387580486153, self.slope: [1.08399317 1.08467322], self.intercept: 1.0075002501161985\n",
      "iteration - 8243 -> loss: 0.00025614135108726325, self.slope: [1.08400102 1.08468117], self.intercept: 1.0075009927656045\n",
      "iteration - 8244 -> loss: 0.0002561288276327858, self.slope: [1.08400886 1.08468911], self.intercept: 1.007501735384806\n",
      "iteration - 8245 -> loss: 0.0002561163054411876, self.slope: [1.08401671 1.08469706], self.intercept: 1.0075024779738062\n",
      "iteration - 8246 -> loss: 0.0002561037845123163, self.slope: [1.08402455 1.084705  ], self.intercept: 1.0075032205326067\n",
      "iteration - 8247 -> loss: 0.0002560912648459734, self.slope: [1.08403239 1.08471295], self.intercept: 1.0075039630612117\n",
      "iteration - 8248 -> loss: 0.0002560787464419432, self.slope: [1.08404024 1.08472089], self.intercept: 1.0075047055596231\n",
      "iteration - 8249 -> loss: 0.0002560662293000653, self.slope: [1.08404808 1.08472883], self.intercept: 1.0075054480278431\n",
      "iteration - 8250 -> loss: 0.0002560537134201225, self.slope: [1.08405592 1.08473678], self.intercept: 1.0075061904658753\n",
      "iteration - 8251 -> loss: 0.000256041198801938, self.slope: [1.08406377 1.08474472], self.intercept: 1.0075069328737214\n",
      "iteration - 8252 -> loss: 0.0002560286854453069, self.slope: [1.08407161 1.08475266], self.intercept: 1.0075076752513843\n",
      "iteration - 8253 -> loss: 0.00025601617335003644, self.slope: [1.08407945 1.0847606 ], self.intercept: 1.0075084175988671\n",
      "iteration - 8254 -> loss: 0.0002560036625159384, self.slope: [1.08408729 1.08476854], self.intercept: 1.0075091599161725\n",
      "iteration - 8255 -> loss: 0.0002559911529427941, self.slope: [1.08409513 1.08477648], self.intercept: 1.007509902203303\n",
      "iteration - 8256 -> loss: 0.00025597864463046806, self.slope: [1.08410297 1.08478442], self.intercept: 1.0075106444602606\n",
      "iteration - 8257 -> loss: 0.00025596613757870797, self.slope: [1.08411081 1.08479236], self.intercept: 1.0075113866870493\n",
      "iteration - 8258 -> loss: 0.00025595363178735, self.slope: [1.08411865 1.0848003 ], self.intercept: 1.0075121288836713\n",
      "iteration - 8259 -> loss: 0.0002559411272562161, self.slope: [1.08412649 1.08480824], self.intercept: 1.0075128710501289\n",
      "iteration - 8260 -> loss: 0.00025592862398508164, self.slope: [1.08413433 1.08481618], self.intercept: 1.0075136131864237\n",
      "iteration - 8261 -> loss: 0.0002559161219737526, self.slope: [1.08414217 1.08482412], self.intercept: 1.007514355292561\n",
      "iteration - 8262 -> loss: 0.00025590362122206303, self.slope: [1.08415001 1.08483206], self.intercept: 1.007515097368542\n",
      "iteration - 8263 -> loss: 0.00025589112172981384, self.slope: [1.08415785 1.08484   ], self.intercept: 1.0075158394143693\n",
      "iteration - 8264 -> loss: 0.0002558786234967912, self.slope: [1.08416568 1.08484793], self.intercept: 1.0075165814300462\n",
      "iteration - 8265 -> loss: 0.00025586612652282276, self.slope: [1.08417352 1.08485587], self.intercept: 1.0075173234155739\n",
      "iteration - 8266 -> loss: 0.0002558536308077079, self.slope: [1.08418136 1.08486381], self.intercept: 1.0075180653709561\n",
      "iteration - 8267 -> loss: 0.00025584113635126077, self.slope: [1.08418919 1.08487174], self.intercept: 1.0075188072961956\n",
      "iteration - 8268 -> loss: 0.00025582864315328523, self.slope: [1.08419703 1.08487968], self.intercept: 1.0075195491912938\n",
      "iteration - 8269 -> loss: 0.00025581615121358356, self.slope: [1.08420486 1.08488761], self.intercept: 1.0075202910562564\n",
      "iteration - 8270 -> loss: 0.0002558036605319794, self.slope: [1.0842127  1.08489555], self.intercept: 1.0075210328910829\n",
      "iteration - 8271 -> loss: 0.0002557911711082515, self.slope: [1.08422053 1.08490348], self.intercept: 1.007521774695777\n",
      "iteration - 8272 -> loss: 0.0002557786829422304, self.slope: [1.08422837 1.08491142], self.intercept: 1.0075225164703416\n",
      "iteration - 8273 -> loss: 0.0002557661960337194, self.slope: [1.0842362  1.08491935], self.intercept: 1.0075232582147788\n",
      "iteration - 8274 -> loss: 0.00025575371038252885, self.slope: [1.08424404 1.08492729], self.intercept: 1.0075239999290921\n",
      "iteration - 8275 -> loss: 0.00025574122598845113, self.slope: [1.08425187 1.08493522], self.intercept: 1.007524741613284\n",
      "iteration - 8276 -> loss: 0.00025572874285131317, self.slope: [1.0842597  1.08494315], self.intercept: 1.0075254832673566\n",
      "iteration - 8277 -> loss: 0.0002557162609709146, self.slope: [1.08426753 1.08495108], self.intercept: 1.0075262248913128\n",
      "iteration - 8278 -> loss: 0.00025570378034706054, self.slope: [1.08427536 1.08495902], self.intercept: 1.0075269664851572\n",
      "iteration - 8279 -> loss: 0.00025569130097956235, self.slope: [1.0842832  1.08496695], self.intercept: 1.0075277080488874\n",
      "iteration - 8280 -> loss: 0.00025567882286823553, self.slope: [1.08429103 1.08497488], self.intercept: 1.0075284495825116\n",
      "iteration - 8281 -> loss: 0.0002556663460128669, self.slope: [1.08429886 1.08498281], self.intercept: 1.0075291910860305\n",
      "iteration - 8282 -> loss: 0.0002556538704132703, self.slope: [1.08430669 1.08499074], self.intercept: 1.0075299325594451\n",
      "iteration - 8283 -> loss: 0.0002556413960692966, self.slope: [1.08431452 1.08499867], self.intercept: 1.0075306740027599\n",
      "iteration - 8284 -> loss: 0.0002556289229806864, self.slope: [1.08432235 1.0850066 ], self.intercept: 1.007531415415977\n",
      "iteration - 8285 -> loss: 0.00025561645114730144, self.slope: [1.08433018 1.08501453], self.intercept: 1.0075321567990978\n",
      "iteration - 8286 -> loss: 0.0002556039805689051, self.slope: [1.084338   1.08502246], self.intercept: 1.007532898152127\n",
      "iteration - 8287 -> loss: 0.0002555915112453445, self.slope: [1.08434583 1.08503038], self.intercept: 1.0075336394750674\n",
      "iteration - 8288 -> loss: 0.00025557904317639375, self.slope: [1.08435366 1.08503831], self.intercept: 1.0075343807679202\n",
      "iteration - 8289 -> loss: 0.0002555665763619069, self.slope: [1.08436149 1.08504624], self.intercept: 1.0075351220306885\n",
      "iteration - 8290 -> loss: 0.000255554110801649, self.slope: [1.08436932 1.08505417], self.intercept: 1.007535863263375\n",
      "iteration - 8291 -> loss: 0.00025554164649545, self.slope: [1.08437714 1.08506209], self.intercept: 1.007536604465983\n",
      "iteration - 8292 -> loss: 0.00025552918344310375, self.slope: [1.08438497 1.08507002], self.intercept: 1.007537345638514\n",
      "iteration - 8293 -> loss: 0.00025551672164443655, self.slope: [1.08439279 1.08507794], self.intercept: 1.0075380867809725\n",
      "iteration - 8294 -> loss: 0.00025550426109923147, self.slope: [1.08440062 1.08508587], self.intercept: 1.0075388278933581\n",
      "iteration - 8295 -> loss: 0.0002554918018073279, self.slope: [1.08440844 1.08509379], self.intercept: 1.0075395689756754\n",
      "iteration - 8296 -> loss: 0.00025547934376852463, self.slope: [1.08441627 1.08510172], self.intercept: 1.0075403100279279\n",
      "iteration - 8297 -> loss: 0.0002554668869826145, self.slope: [1.08442409 1.08510964], self.intercept: 1.0075410510501175\n",
      "iteration - 8298 -> loss: 0.0002554544314494061, self.slope: [1.08443192 1.08511757], self.intercept: 1.0075417920422451\n",
      "iteration - 8299 -> loss: 0.0002554419771687468, self.slope: [1.08443974 1.08512549], self.intercept: 1.0075425330043144\n",
      "iteration - 8300 -> loss: 0.00025542952414041276, self.slope: [1.08444756 1.08513341], self.intercept: 1.0075432739363306\n",
      "iteration - 8301 -> loss: 0.00025541707236420477, self.slope: [1.08445539 1.08514134], self.intercept: 1.0075440148382937\n",
      "iteration - 8302 -> loss: 0.00025540462183994725, self.slope: [1.08446321 1.08514926], self.intercept: 1.0075447557102062\n",
      "iteration - 8303 -> loss: 0.0002553921725674537, self.slope: [1.08447103 1.08515718], self.intercept: 1.0075454965520716\n",
      "iteration - 8304 -> loss: 0.0002553797245465197, self.slope: [1.08447885 1.0851651 ], self.intercept: 1.007546237363893\n",
      "iteration - 8305 -> loss: 0.0002553672777769691, self.slope: [1.08448667 1.08517302], self.intercept: 1.0075469781456718\n",
      "iteration - 8306 -> loss: 0.0002553548322585874, self.slope: [1.08449449 1.08518094], self.intercept: 1.007547718897411\n",
      "iteration - 8307 -> loss: 0.00025534238799120707, self.slope: [1.08450231 1.08518886], self.intercept: 1.0075484596191135\n",
      "iteration - 8308 -> loss: 0.00025532994497462486, self.slope: [1.08451013 1.08519678], self.intercept: 1.007549200310783\n",
      "iteration - 8309 -> loss: 0.0002553175032086513, self.slope: [1.08451795 1.0852047 ], self.intercept: 1.0075499409724207\n",
      "iteration - 8310 -> loss: 0.00025530506269310613, self.slope: [1.08452577 1.08521262], self.intercept: 1.007550681604029\n",
      "iteration - 8311 -> loss: 0.0002552926234277845, self.slope: [1.08453359 1.08522054], self.intercept: 1.0075514222056121\n",
      "iteration - 8312 -> loss: 0.00025528018541249366, self.slope: [1.08454141 1.08522846], self.intercept: 1.0075521627771715\n",
      "iteration - 8313 -> loss: 0.00025526774864705217, self.slope: [1.08454923 1.08523638], self.intercept: 1.0075529033187107\n",
      "iteration - 8314 -> loss: 0.00025525531313127766, self.slope: [1.08455704 1.0852443 ], self.intercept: 1.0075536438302317\n",
      "iteration - 8315 -> loss: 0.000255242878864955, self.slope: [1.08456486 1.08525221], self.intercept: 1.0075543843117367\n",
      "iteration - 8316 -> loss: 0.0002552304458479221, self.slope: [1.08457268 1.08526013], self.intercept: 1.0075551247632288\n",
      "iteration - 8317 -> loss: 0.0002552180140799601, self.slope: [1.08458049 1.08526805], self.intercept: 1.007555865184711\n",
      "iteration - 8318 -> loss: 0.00025520558356090266, self.slope: [1.08458831 1.08527596], self.intercept: 1.0075566055761853\n",
      "iteration - 8319 -> loss: 0.00025519315429054775, self.slope: [1.08459613 1.08528388], self.intercept: 1.0075573459376546\n",
      "iteration - 8320 -> loss: 0.00025518072626869637, self.slope: [1.08460394 1.08529179], self.intercept: 1.0075580862691222\n",
      "iteration - 8321 -> loss: 0.00025516829949518696, self.slope: [1.08461176 1.08529971], self.intercept: 1.0075588265705901\n",
      "iteration - 8322 -> loss: 0.000255155873969786, self.slope: [1.08461957 1.08530762], self.intercept: 1.0075595668420598\n",
      "iteration - 8323 -> loss: 0.0002551434496923384, self.slope: [1.08462738 1.08531554], self.intercept: 1.0075603070835362\n",
      "iteration - 8324 -> loss: 0.00025513102666263745, self.slope: [1.0846352  1.08532345], self.intercept: 1.0075610472950216\n",
      "iteration - 8325 -> loss: 0.0002551186048805125, self.slope: [1.08464301 1.08533136], self.intercept: 1.0075617874765175\n",
      "iteration - 8326 -> loss: 0.00025510618434574647, self.slope: [1.08465082 1.08533928], self.intercept: 1.0075625276280262\n",
      "iteration - 8327 -> loss: 0.00025509376505815704, self.slope: [1.08465864 1.08534719], self.intercept: 1.0075632677495532\n",
      "iteration - 8328 -> loss: 0.0002550813470175581, self.slope: [1.08466645 1.0853551 ], self.intercept: 1.0075640078410977\n",
      "iteration - 8329 -> loss: 0.0002550689302237617, self.slope: [1.08467426 1.08536301], self.intercept: 1.0075647479026635\n",
      "iteration - 8330 -> loss: 0.0002550565146765795, self.slope: [1.08468207 1.08537092], self.intercept: 1.0075654879342537\n",
      "iteration - 8331 -> loss: 0.0002550441003758263, self.slope: [1.08468988 1.08537883], self.intercept: 1.0075662279358717\n",
      "iteration - 8332 -> loss: 0.0002550316873212895, self.slope: [1.08469769 1.08538674], self.intercept: 1.0075669679075177\n",
      "iteration - 8333 -> loss: 0.000255019275512791, self.slope: [1.0847055  1.08539465], self.intercept: 1.0075677078491976\n",
      "iteration - 8334 -> loss: 0.000255006864950142, self.slope: [1.08471331 1.08540256], self.intercept: 1.0075684477609121\n",
      "iteration - 8335 -> loss: 0.0002549944556331564, self.slope: [1.08472112 1.08541047], self.intercept: 1.0075691876426638\n",
      "iteration - 8336 -> loss: 0.00025498204756164186, self.slope: [1.08472893 1.08541838], self.intercept: 1.007569927494456\n",
      "iteration - 8337 -> loss: 0.00025496964073541673, self.slope: [1.08473674 1.08542629], self.intercept: 1.007570667316291\n",
      "iteration - 8338 -> loss: 0.00025495723515426405, self.slope: [1.08474454 1.0854342 ], self.intercept: 1.007571407108172\n",
      "iteration - 8339 -> loss: 0.000254944830818021, self.slope: [1.08475235 1.08544211], self.intercept: 1.0075721468701\n",
      "iteration - 8340 -> loss: 0.00025493242772649314, self.slope: [1.08476016 1.08545001], self.intercept: 1.0075728866020777\n",
      "iteration - 8341 -> loss: 0.00025492002587948525, self.slope: [1.08476797 1.08545792], self.intercept: 1.0075736263041095\n",
      "iteration - 8342 -> loss: 0.0002549076252768008, self.slope: [1.08477577 1.08546583], self.intercept: 1.0075743659761962\n",
      "iteration - 8343 -> loss: 0.00025489522591827334, self.slope: [1.08478358 1.08547373], self.intercept: 1.007575105618343\n",
      "iteration - 8344 -> loss: 0.0002548828278036817, self.slope: [1.08479138 1.08548164], self.intercept: 1.0075758452305505\n",
      "iteration - 8345 -> loss: 0.0002548704309328654, self.slope: [1.08479919 1.08548954], self.intercept: 1.007576584812821\n",
      "iteration - 8346 -> loss: 0.00025485803530562204, self.slope: [1.08480699 1.08549745], self.intercept: 1.0075773243651576\n",
      "iteration - 8347 -> loss: 0.0002548456409217544, self.slope: [1.0848148  1.08550535], self.intercept: 1.007578063887564\n",
      "iteration - 8348 -> loss: 0.00025483324778108525, self.slope: [1.0848226  1.08551326], self.intercept: 1.007578803380043\n",
      "iteration - 8349 -> loss: 0.00025482085588342365, self.slope: [1.08483041 1.08552116], self.intercept: 1.0075795428425947\n",
      "iteration - 8350 -> loss: 0.0002548084652285809, self.slope: [1.08483821 1.08552906], self.intercept: 1.0075802822752242\n",
      "iteration - 8351 -> loss: 0.0002547960758163603, self.slope: [1.08484601 1.08553697], self.intercept: 1.0075810216779328\n",
      "iteration - 8352 -> loss: 0.0002547836876465703, self.slope: [1.08485381 1.08554487], self.intercept: 1.0075817610507238\n",
      "iteration - 8353 -> loss: 0.00025477130071905273, self.slope: [1.08486162 1.08555277], self.intercept: 1.0075825003936003\n",
      "iteration - 8354 -> loss: 0.00025475891503356265, self.slope: [1.08486942 1.08556067], self.intercept: 1.0075832397065632\n",
      "iteration - 8355 -> loss: 0.00025474653058995335, self.slope: [1.08487722 1.08556857], self.intercept: 1.0075839789896157\n",
      "iteration - 8356 -> loss: 0.00025473414738805093, self.slope: [1.08488502 1.08557648], self.intercept: 1.0075847182427629\n",
      "iteration - 8357 -> loss: 0.00025472176542761155, self.slope: [1.08489282 1.08558438], self.intercept: 1.0075854574660044\n",
      "iteration - 8358 -> loss: 0.00025470938470847985, self.slope: [1.08490062 1.08559228], self.intercept: 1.0075861966593447\n",
      "iteration - 8359 -> loss: 0.00025469700523047135, self.slope: [1.08490842 1.08560018], self.intercept: 1.0075869358227842\n",
      "iteration - 8360 -> loss: 0.0002546846269933795, self.slope: [1.08491622 1.08560808], self.intercept: 1.0075876749563275\n",
      "iteration - 8361 -> loss: 0.00025467224999702254, self.slope: [1.08492402 1.08561597], self.intercept: 1.0075884140599773\n",
      "iteration - 8362 -> loss: 0.0002546598742412138, self.slope: [1.08493182 1.08562387], self.intercept: 1.0075891531337338\n",
      "iteration - 8363 -> loss: 0.00025464749972577377, self.slope: [1.08493962 1.08563177], self.intercept: 1.007589892177603\n",
      "iteration - 8364 -> loss: 0.00025463512645049533, self.slope: [1.08494741 1.08563967], self.intercept: 1.0075906311915865\n",
      "iteration - 8365 -> loss: 0.0002546227544152006, self.slope: [1.08495521 1.08564757], self.intercept: 1.0075913701756878\n",
      "iteration - 8366 -> loss: 0.000254610383619688, self.slope: [1.08496301 1.08565546], self.intercept: 1.007592109129906\n",
      "iteration - 8367 -> loss: 0.0002545980140637907, self.slope: [1.0849708  1.08566336], self.intercept: 1.007592848054246\n",
      "iteration - 8368 -> loss: 0.0002545856457472967, self.slope: [1.0849786  1.08567126], self.intercept: 1.0075935869487103\n",
      "iteration - 8369 -> loss: 0.00025457327867002956, self.slope: [1.0849864  1.08567915], self.intercept: 1.0075943258133024\n",
      "iteration - 8370 -> loss: 0.0002545609128318205, self.slope: [1.08499419 1.08568705], self.intercept: 1.0075950646480252\n",
      "iteration - 8371 -> loss: 0.00025454854823243965, self.slope: [1.08500199 1.08569494], self.intercept: 1.0075958034528796\n",
      "iteration - 8372 -> loss: 0.00025453618487173655, self.slope: [1.08500978 1.08570284], self.intercept: 1.007596542227869\n",
      "iteration - 8373 -> loss: 0.0002545238227494753, self.slope: [1.08501758 1.08571073], self.intercept: 1.0075972809729938\n",
      "iteration - 8374 -> loss: 0.00025451146186552636, self.slope: [1.08502537 1.08571863], self.intercept: 1.007598019688259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 8375 -> loss: 0.0002544991022196587, self.slope: [1.08503316 1.08572652], self.intercept: 1.0075987583736674\n",
      "iteration - 8376 -> loss: 0.00025448674381170277, self.slope: [1.08504096 1.08573441], self.intercept: 1.0075994970292208\n",
      "iteration - 8377 -> loss: 0.00025447438664147044, self.slope: [1.08504875 1.08574231], self.intercept: 1.007600235654922\n",
      "iteration - 8378 -> loss: 0.00025446203070876355, self.slope: [1.08505654 1.0857502 ], self.intercept: 1.0076009742507754\n",
      "iteration - 8379 -> loss: 0.0002544496760134031, self.slope: [1.08506433 1.08575809], self.intercept: 1.0076017128167813\n",
      "iteration - 8380 -> loss: 0.000254437322555193, self.slope: [1.08507212 1.08576598], self.intercept: 1.0076024513529416\n",
      "iteration - 8381 -> loss: 0.00025442497033395365, self.slope: [1.08507991 1.08577387], self.intercept: 1.0076031898592628\n",
      "iteration - 8382 -> loss: 0.0002544126193494775, self.slope: [1.0850877  1.08578176], self.intercept: 1.007603928335744\n",
      "iteration - 8383 -> loss: 0.000254400269601603, self.slope: [1.0850955  1.08578965], self.intercept: 1.0076046667823901\n",
      "iteration - 8384 -> loss: 0.0002543879210901235, self.slope: [1.08510328 1.08579754], self.intercept: 1.0076054051992018\n",
      "iteration - 8385 -> loss: 0.00025437557381487175, self.slope: [1.08511107 1.08580543], self.intercept: 1.0076061435861818\n",
      "iteration - 8386 -> loss: 0.00025436322777563485, self.slope: [1.08511886 1.08581332], self.intercept: 1.0076068819433346\n",
      "iteration - 8387 -> loss: 0.00025435088297223784, self.slope: [1.08512665 1.08582121], self.intercept: 1.0076076202706605\n",
      "iteration - 8388 -> loss: 0.0002543385394044918, self.slope: [1.08513444 1.0858291 ], self.intercept: 1.0076083585681637\n",
      "iteration - 8389 -> loss: 0.00025432619707220364, self.slope: [1.08514223 1.08583699], self.intercept: 1.007609096835846\n",
      "iteration - 8390 -> loss: 0.00025431385597520797, self.slope: [1.08515002 1.08584488], self.intercept: 1.00760983507371\n",
      "iteration - 8391 -> loss: 0.00025430151611327735, self.slope: [1.0851578  1.08585276], self.intercept: 1.0076105732817597\n",
      "iteration - 8392 -> loss: 0.0002542891774862694, self.slope: [1.08516559 1.08586065], self.intercept: 1.0076113114599954\n",
      "iteration - 8393 -> loss: 0.0002542768400939382, self.slope: [1.08517338 1.08586854], self.intercept: 1.007612049608422\n",
      "iteration - 8394 -> loss: 0.00025426450393615103, self.slope: [1.08518116 1.08587642], self.intercept: 1.0076127877270402\n",
      "iteration - 8395 -> loss: 0.00025425216901269994, self.slope: [1.08518895 1.08588431], self.intercept: 1.0076135258158545\n",
      "iteration - 8396 -> loss: 0.0002542398353233946, self.slope: [1.08519673 1.08589219], self.intercept: 1.0076142638748657\n",
      "iteration - 8397 -> loss: 0.0002542275028680555, self.slope: [1.08520452 1.08590008], self.intercept: 1.0076150019040775\n",
      "iteration - 8398 -> loss: 0.000254215171646488, self.slope: [1.0852123  1.08590796], self.intercept: 1.0076157399034926\n",
      "iteration - 8399 -> loss: 0.00025420284165850816, self.slope: [1.08522009 1.08591585], self.intercept: 1.0076164778731134\n",
      "iteration - 8400 -> loss: 0.00025419051290392376, self.slope: [1.08522787 1.08592373], self.intercept: 1.0076172158129422\n",
      "iteration - 8401 -> loss: 0.0002541781853825488, self.slope: [1.08523565 1.08593161], self.intercept: 1.0076179537229824\n",
      "iteration - 8402 -> loss: 0.0002541658590941929, self.slope: [1.08524343 1.0859395 ], self.intercept: 1.0076186916032368\n",
      "iteration - 8403 -> loss: 0.00025415353403868536, self.slope: [1.08525122 1.08594738], self.intercept: 1.0076194294537062\n",
      "iteration - 8404 -> loss: 0.00025414121021582185, self.slope: [1.085259   1.08595526], self.intercept: 1.007620167274395\n",
      "iteration - 8405 -> loss: 0.0002541288876254284, self.slope: [1.08526678 1.08596314], self.intercept: 1.007620905065304\n",
      "iteration - 8406 -> loss: 0.00025411656626730483, self.slope: [1.08527456 1.08597102], self.intercept: 1.007621642826437\n",
      "iteration - 8407 -> loss: 0.00025410424614126715, self.slope: [1.08528234 1.08597891], self.intercept: 1.007622380557797\n",
      "iteration - 8408 -> loss: 0.0002540919272471355, self.slope: [1.08529012 1.08598679], self.intercept: 1.0076231182593858\n",
      "iteration - 8409 -> loss: 0.00025407960958470345, self.slope: [1.0852979  1.08599467], self.intercept: 1.007623855931208\n",
      "iteration - 8410 -> loss: 0.0002540672931538176, self.slope: [1.08530568 1.08600255], self.intercept: 1.007624593573263\n",
      "iteration - 8411 -> loss: 0.0002540549779542486, self.slope: [1.08531346 1.08601043], self.intercept: 1.007625331185556\n",
      "iteration - 8412 -> loss: 0.0002540426639858592, self.slope: [1.08532124 1.0860183 ], self.intercept: 1.0076260687680885\n",
      "iteration - 8413 -> loss: 0.00025403035124842605, self.slope: [1.08532902 1.08602618], self.intercept: 1.0076268063208629\n",
      "iteration - 8414 -> loss: 0.0002540180397417577, self.slope: [1.0853368  1.08603406], self.intercept: 1.0076275438438818\n",
      "iteration - 8415 -> loss: 0.0002540057294656958, self.slope: [1.08534457 1.08604194], self.intercept: 1.0076282813371473\n",
      "iteration - 8416 -> loss: 0.00025399342042003894, self.slope: [1.08535235 1.08604982], self.intercept: 1.007629018800664\n",
      "iteration - 8417 -> loss: 0.0002539811126045889, self.slope: [1.08536013 1.08605769], self.intercept: 1.0076297562344343\n",
      "iteration - 8418 -> loss: 0.0002539688060191777, self.slope: [1.08536791 1.08606557], self.intercept: 1.0076304936384584\n",
      "iteration - 8419 -> loss: 0.0002539565006636227, self.slope: [1.08537568 1.08607345], self.intercept: 1.0076312310127409\n",
      "iteration - 8420 -> loss: 0.0002539441965377078, self.slope: [1.08538346 1.08608132], self.intercept: 1.0076319683572843\n",
      "iteration - 8421 -> loss: 0.0002539318936412853, self.slope: [1.08539123 1.0860892 ], self.intercept: 1.0076327056720897\n",
      "iteration - 8422 -> loss: 0.00025391959197412767, self.slope: [1.08539901 1.08609707], self.intercept: 1.0076334429571614\n",
      "iteration - 8423 -> loss: 0.00025390729153608053, self.slope: [1.08540678 1.08610495], self.intercept: 1.0076341802125\n",
      "iteration - 8424 -> loss: 0.0002538949923269443, self.slope: [1.08541456 1.08611282], self.intercept: 1.0076349174381118\n",
      "iteration - 8425 -> loss: 0.00025388269434653565, self.slope: [1.08542233 1.0861207 ], self.intercept: 1.007635654633996\n",
      "iteration - 8426 -> loss: 0.0002538703975946615, self.slope: [1.0854301  1.08612857], self.intercept: 1.0076363918001565\n",
      "iteration - 8427 -> loss: 0.0002538581020711521, self.slope: [1.08543788 1.08613644], self.intercept: 1.0076371289365957\n",
      "iteration - 8428 -> loss: 0.00025384580777579416, self.slope: [1.08544565 1.08614432], self.intercept: 1.0076378660433163\n",
      "iteration - 8429 -> loss: 0.00025383351470842326, self.slope: [1.08545342 1.08615219], self.intercept: 1.0076386031203206\n",
      "iteration - 8430 -> loss: 0.00025382122286884924, self.slope: [1.08546119 1.08616006], self.intercept: 1.007639340167612\n",
      "iteration - 8431 -> loss: 0.00025380893225687825, self.slope: [1.08546896 1.08616793], self.intercept: 1.007640077185192\n",
      "iteration - 8432 -> loss: 0.00025379664287234296, self.slope: [1.08547673 1.0861758 ], self.intercept: 1.0076408141730655\n",
      "iteration - 8433 -> loss: 0.00025378435471502906, self.slope: [1.08548451 1.08618367], self.intercept: 1.0076415511312322\n",
      "iteration - 8434 -> loss: 0.00025377206778476677, self.slope: [1.08549228 1.08619154], self.intercept: 1.0076422880596967\n",
      "iteration - 8435 -> loss: 0.00025375978208137947, self.slope: [1.08550005 1.08619941], self.intercept: 1.0076430249584598\n",
      "iteration - 8436 -> loss: 0.0002537474976046478, self.slope: [1.08550781 1.08620728], self.intercept: 1.0076437618275256\n",
      "iteration - 8437 -> loss: 0.0002537352143544213, self.slope: [1.08551558 1.08621515], self.intercept: 1.0076444986668947\n",
      "iteration - 8438 -> loss: 0.00025372293233049884, self.slope: [1.08552335 1.08622302], self.intercept: 1.0076452354765726\n",
      "iteration - 8439 -> loss: 0.0002537106515326996, self.slope: [1.08553112 1.08623089], self.intercept: 1.0076459722565596\n",
      "iteration - 8440 -> loss: 0.00025369837196082467, self.slope: [1.08553889 1.08623876], self.intercept: 1.0076467090068593\n",
      "iteration - 8441 -> loss: 0.000253686093614719, self.slope: [1.08554666 1.08624663], self.intercept: 1.0076474457274736\n",
      "iteration - 8442 -> loss: 0.00025367381649414687, self.slope: [1.08555442 1.08625449], self.intercept: 1.0076481824184067\n",
      "iteration - 8443 -> loss: 0.0002536615405989689, self.slope: [1.08556219 1.08626236], self.intercept: 1.0076489190796585\n",
      "iteration - 8444 -> loss: 0.000253649265928976, self.slope: [1.08556996 1.08627023], self.intercept: 1.0076496557112349\n",
      "iteration - 8445 -> loss: 0.00025363699248398986, self.slope: [1.08557772 1.08627809], self.intercept: 1.0076503923131368\n",
      "iteration - 8446 -> loss: 0.00025362472026381244, self.slope: [1.08558549 1.08628596], self.intercept: 1.0076511288853667\n",
      "iteration - 8447 -> loss: 0.00025361244926828106, self.slope: [1.08559325 1.08629383], self.intercept: 1.0076518654279278\n",
      "iteration - 8448 -> loss: 0.00025360017949719666, self.slope: [1.08560102 1.08630169], self.intercept: 1.0076526019408236\n",
      "iteration - 8449 -> loss: 0.000253587910950381, self.slope: [1.08560878 1.08630955], self.intercept: 1.007653338424055\n",
      "iteration - 8450 -> loss: 0.000253575643627628, self.slope: [1.08561655 1.08631742], self.intercept: 1.0076540748776248\n",
      "iteration - 8451 -> loss: 0.00025356337752876427, self.slope: [1.08562431 1.08632528], self.intercept: 1.0076548113015351\n",
      "iteration - 8452 -> loss: 0.00025355111265362143, self.slope: [1.08563207 1.08633315], self.intercept: 1.0076555476957905\n",
      "iteration - 8453 -> loss: 0.00025353884900199597, self.slope: [1.08563983 1.08634101], self.intercept: 1.0076562840603909\n",
      "iteration - 8454 -> loss: 0.00025352658657369626, self.slope: [1.0856476  1.08634887], self.intercept: 1.0076570203953412\n",
      "iteration - 8455 -> loss: 0.0002535143253685654, self.slope: [1.08565536 1.08635673], self.intercept: 1.0076577567006426\n",
      "iteration - 8456 -> loss: 0.0002535020653863731, self.slope: [1.08566312 1.0863646 ], self.intercept: 1.0076584929762973\n",
      "iteration - 8457 -> loss: 0.000253489806626981, self.slope: [1.08567088 1.08637246], self.intercept: 1.0076592292223099\n",
      "iteration - 8458 -> loss: 0.00025347754909017236, self.slope: [1.08567864 1.08638032], self.intercept: 1.0076599654386809\n",
      "iteration - 8459 -> loss: 0.000253465292775772, self.slope: [1.0856864  1.08638818], self.intercept: 1.0076607016254144\n",
      "iteration - 8460 -> loss: 0.00025345303768361854, self.slope: [1.08569416 1.08639604], self.intercept: 1.007661437782512\n",
      "iteration - 8461 -> loss: 0.0002534407838134632, self.slope: [1.08570192 1.0864039 ], self.intercept: 1.0076621739099776\n",
      "iteration - 8462 -> loss: 0.0002534285311651962, self.slope: [1.08570968 1.08641176], self.intercept: 1.0076629100078132\n",
      "iteration - 8463 -> loss: 0.00025341627973858854, self.slope: [1.08571744 1.08641962], self.intercept: 1.0076636460760218\n",
      "iteration - 8464 -> loss: 0.00025340402953346323, self.slope: [1.0857252  1.08642748], self.intercept: 1.0076643821146052\n",
      "iteration - 8465 -> loss: 0.0002533917805496307, self.slope: [1.08573296 1.08643534], self.intercept: 1.0076651181235645\n",
      "iteration - 8466 -> loss: 0.00025337953278691536, self.slope: [1.08574072 1.08644319], self.intercept: 1.0076658541029053\n",
      "iteration - 8467 -> loss: 0.00025336728624512797, self.slope: [1.08574847 1.08645105], self.intercept: 1.0076665900526287\n",
      "iteration - 8468 -> loss: 0.00025335504092408907, self.slope: [1.08575623 1.08645891], self.intercept: 1.0076673259727382\n",
      "iteration - 8469 -> loss: 0.0002533427968236118, self.slope: [1.08576399 1.08646676], self.intercept: 1.007668061863235\n",
      "iteration - 8470 -> loss: 0.0002533305539435003, self.slope: [1.08577174 1.08647462], self.intercept: 1.0076687977241232\n",
      "iteration - 8471 -> loss: 0.0002533183122835916, self.slope: [1.0857795  1.08648248], self.intercept: 1.007669533555404\n",
      "iteration - 8472 -> loss: 0.00025330607184367393, self.slope: [1.08578725 1.08649033], self.intercept: 1.0076702693570803\n",
      "iteration - 8473 -> loss: 0.0002532938326235893, self.slope: [1.08579501 1.08649819], self.intercept: 1.007671005129154\n",
      "iteration - 8474 -> loss: 0.00025328159462313345, self.slope: [1.08580276 1.08650604], self.intercept: 1.0076717408716287\n",
      "iteration - 8475 -> loss: 0.00025326935784212944, self.slope: [1.08581052 1.0865139 ], self.intercept: 1.007672476584508\n",
      "iteration - 8476 -> loss: 0.0002532571222803977, self.slope: [1.08581827 1.08652175], self.intercept: 1.0076732122677918\n",
      "iteration - 8477 -> loss: 0.00025324488793774256, self.slope: [1.08582602 1.08652961], self.intercept: 1.0076739479214853\n",
      "iteration - 8478 -> loss: 0.0002532326548139858, self.slope: [1.08583378 1.08653746], self.intercept: 1.0076746835455894\n",
      "iteration - 8479 -> loss: 0.00025322042290894817, self.slope: [1.08584153 1.08654531], self.intercept: 1.0076754191401087\n",
      "iteration - 8480 -> loss: 0.0002532081922224338, self.slope: [1.08584928 1.08655316], self.intercept: 1.0076761547050435\n",
      "iteration - 8481 -> loss: 0.0002531959627542711, self.slope: [1.08585703 1.08656102], self.intercept: 1.0076768902403985\n",
      "iteration - 8482 -> loss: 0.00025318373450425557, self.slope: [1.08586479 1.08656887], self.intercept: 1.007677625746175\n",
      "iteration - 8483 -> loss: 0.00025317150747222413, self.slope: [1.08587254 1.08657672], self.intercept: 1.0076783612223756\n",
      "iteration - 8484 -> loss: 0.00025315928165799807, self.slope: [1.08588029 1.08658457], self.intercept: 1.0076790966690028\n",
      "iteration - 8485 -> loss: 0.0002531470570613634, self.slope: [1.08588804 1.08659242], self.intercept: 1.0076798320860598\n",
      "iteration - 8486 -> loss: 0.000253134833682151, self.slope: [1.08589579 1.08660027], self.intercept: 1.007680567473547\n",
      "iteration - 8487 -> loss: 0.00025312261152018496, self.slope: [1.08590354 1.08660812], self.intercept: 1.00768130283147\n",
      "iteration - 8488 -> loss: 0.0002531103905752834, self.slope: [1.08591129 1.08661597], self.intercept: 1.0076820381598306\n",
      "iteration - 8489 -> loss: 0.00025309817084723344, self.slope: [1.08591903 1.08662382], self.intercept: 1.0076827734586296\n",
      "iteration - 8490 -> loss: 0.0002530859523358827, self.slope: [1.08592678 1.08663167], self.intercept: 1.0076835087278704\n",
      "iteration - 8491 -> loss: 0.0002530737350410394, self.slope: [1.08593453 1.08663952], self.intercept: 1.007684243967557\n",
      "iteration - 8492 -> loss: 0.0002530615189625005, self.slope: [1.08594228 1.08664736], self.intercept: 1.007684979177691\n",
      "iteration - 8493 -> loss: 0.0002530493041001068, self.slope: [1.08595003 1.08665521], self.intercept: 1.007685714358275\n",
      "iteration - 8494 -> loss: 0.0002530370904536747, self.slope: [1.08595777 1.08666306], self.intercept: 1.0076864495093119\n",
      "iteration - 8495 -> loss: 0.00025302487802299174, self.slope: [1.08596552 1.08667091], self.intercept: 1.007687184630805\n",
      "iteration - 8496 -> loss: 0.0002530126668079086, self.slope: [1.08597326 1.08667875], self.intercept: 1.0076879197227546\n",
      "iteration - 8497 -> loss: 0.0002530004568082148, self.slope: [1.08598101 1.0866866 ], self.intercept: 1.0076886547851651\n",
      "iteration - 8498 -> loss: 0.0002529882480237577, self.slope: [1.08598876 1.08669444], self.intercept: 1.007689389818038\n",
      "iteration - 8499 -> loss: 0.00025297604045430974, self.slope: [1.0859965  1.08670229], self.intercept: 1.0076901248213768\n",
      "iteration - 8500 -> loss: 0.00025296383409971436, self.slope: [1.08600424 1.08671013], self.intercept: 1.0076908597951837\n",
      "iteration - 8501 -> loss: 0.0002529516289597925, self.slope: [1.08601199 1.08671798], self.intercept: 1.0076915947394616\n",
      "iteration - 8502 -> loss: 0.0002529394250343516, self.slope: [1.08601973 1.08672582], self.intercept: 1.0076923296542117\n",
      "iteration - 8503 -> loss: 0.0002529272223232104, self.slope: [1.08602748 1.08673367], self.intercept: 1.007693064539439\n",
      "iteration - 8504 -> loss: 0.00025291502082618267, self.slope: [1.08603522 1.08674151], self.intercept: 1.0076937993951445\n",
      "iteration - 8505 -> loss: 0.0002529028205430948, self.slope: [1.08604296 1.08674935], self.intercept: 1.0076945342213306\n",
      "iteration - 8506 -> loss: 0.00025289062147375226, self.slope: [1.0860507  1.08675719], self.intercept: 1.0076952690179999\n",
      "iteration - 8507 -> loss: 0.0002528784236179755, self.slope: [1.08605845 1.08676504], self.intercept: 1.0076960037851546\n",
      "iteration - 8508 -> loss: 0.00025286622697556527, self.slope: [1.08606619 1.08677288], self.intercept: 1.0076967385228\n",
      "iteration - 8509 -> loss: 0.0002528540315463705, self.slope: [1.08607393 1.08678072], self.intercept: 1.0076974732309354\n",
      "iteration - 8510 -> loss: 0.0002528418373301871, self.slope: [1.08608167 1.08678856], self.intercept: 1.0076982079095655\n",
      "iteration - 8511 -> loss: 0.00025282964432682924, self.slope: [1.08608941 1.0867964 ], self.intercept: 1.0076989425586915\n",
      "iteration - 8512 -> loss: 0.00025281745253612784, self.slope: [1.08609715 1.08680424], self.intercept: 1.0076996771783173\n",
      "iteration - 8513 -> loss: 0.0002528052619578856, self.slope: [1.08610489 1.08681208], self.intercept: 1.0077004117684458\n",
      "iteration - 8514 -> loss: 0.00025279307259192793, self.slope: [1.08611263 1.08681992], self.intercept: 1.0077011463290773\n",
      "iteration - 8515 -> loss: 0.0002527808844380835, self.slope: [1.08612036 1.08682776], self.intercept: 1.0077018808602143\n",
      "iteration - 8516 -> loss: 0.0002527686974961307, self.slope: [1.0861281 1.0868356], self.intercept: 1.007702615361862\n",
      "iteration - 8517 -> loss: 0.0002527565117659255, self.slope: [1.08613584 1.08684344], self.intercept: 1.007703349834021\n",
      "iteration - 8518 -> loss: 0.00025274432724726044, self.slope: [1.08614358 1.08685127], self.intercept: 1.0077040842766944\n",
      "iteration - 8519 -> loss: 0.00025273214393998464, self.slope: [1.08615132 1.08685911], self.intercept: 1.0077048186898843\n",
      "iteration - 8520 -> loss: 0.00025271996184387244, self.slope: [1.08615905 1.08686695], self.intercept: 1.0077055530735952\n",
      "iteration - 8521 -> loss: 0.00025270778095877125, self.slope: [1.08616679 1.08687478], self.intercept: 1.0077062874278286\n",
      "iteration - 8522 -> loss: 0.000252695601284504, self.slope: [1.08617452 1.08688262], self.intercept: 1.007707021752586\n",
      "iteration - 8523 -> loss: 0.0002526834228208591, self.slope: [1.08618226 1.08689046], self.intercept: 1.0077077560478709\n",
      "iteration - 8524 -> loss: 0.00025267124556765746, self.slope: [1.08618999 1.08689829], self.intercept: 1.007708490313687\n",
      "iteration - 8525 -> loss: 0.000252659069524731, self.slope: [1.08619773 1.08690613], self.intercept: 1.0077092245500356\n",
      "iteration - 8526 -> loss: 0.0002526468946919037, self.slope: [1.08620546 1.08691396], self.intercept: 1.0077099587569185\n",
      "iteration - 8527 -> loss: 0.0002526347210689597, self.slope: [1.0862132 1.0869218], self.intercept: 1.0077106929343393\n",
      "iteration - 8528 -> loss: 0.00025262254865574983, self.slope: [1.08622093 1.08692963], self.intercept: 1.0077114270823007\n",
      "iteration - 8529 -> loss: 0.00025261037745209357, self.slope: [1.08622866 1.08693746], self.intercept: 1.0077121612008042\n",
      "iteration - 8530 -> loss: 0.00025259820745778173, self.slope: [1.0862364 1.0869453], self.intercept: 1.007712895289854\n",
      "iteration - 8531 -> loss: 0.0002525860386726509, self.slope: [1.08624413 1.08695313], self.intercept: 1.0077136293494515\n",
      "iteration - 8532 -> loss: 0.00025257387109649373, self.slope: [1.08625186 1.08696096], self.intercept: 1.0077143633795997\n",
      "iteration - 8533 -> loss: 0.0002525617047291853, self.slope: [1.08625959 1.08696879], self.intercept: 1.0077150973803002\n",
      "iteration - 8534 -> loss: 0.000252549539570478, self.slope: [1.08626732 1.08697663], self.intercept: 1.0077158313515562\n",
      "iteration - 8535 -> loss: 0.0002525373756202289, self.slope: [1.08627506 1.08698446], self.intercept: 1.00771656529337\n",
      "iteration - 8536 -> loss: 0.0002525252128782287, self.slope: [1.08628279 1.08699229], self.intercept: 1.0077172992057464\n",
      "iteration - 8537 -> loss: 0.0002525130513443152, self.slope: [1.08629052 1.08700012], self.intercept: 1.007718033088685\n",
      "iteration - 8538 -> loss: 0.00025250089101831746, self.slope: [1.08629825 1.08700795], self.intercept: 1.0077187669421908\n",
      "iteration - 8539 -> loss: 0.0002524887319000226, self.slope: [1.08630598 1.08701578], self.intercept: 1.0077195007662638\n",
      "iteration - 8540 -> loss: 0.00025247657398925837, self.slope: [1.0863137  1.08702361], self.intercept: 1.007720234560909\n",
      "iteration - 8541 -> loss: 0.0002524644172858526, self.slope: [1.08632143 1.08703144], self.intercept: 1.0077209683261283\n",
      "iteration - 8542 -> loss: 0.0002524522617896106, self.slope: [1.08632916 1.08703927], self.intercept: 1.0077217020619227\n",
      "iteration - 8543 -> loss: 0.0002524401075003662, self.slope: [1.08633689 1.08704709], self.intercept: 1.0077224357682952\n",
      "iteration - 8544 -> loss: 0.00025242795441792805, self.slope: [1.08634462 1.08705492], self.intercept: 1.0077231694452498\n",
      "iteration - 8545 -> loss: 0.00025241580254210675, self.slope: [1.08635234 1.08706275], self.intercept: 1.007723903092788\n",
      "iteration - 8546 -> loss: 0.00025240365187271884, self.slope: [1.08636007 1.08707058], self.intercept: 1.0077246367109145\n",
      "iteration - 8547 -> loss: 0.0002523915024096194, self.slope: [1.0863678 1.0870784], self.intercept: 1.0077253702996287\n",
      "iteration - 8548 -> loss: 0.0002523793541525781, self.slope: [1.08637552 1.08708623], self.intercept: 1.0077261038589354\n",
      "iteration - 8549 -> loss: 0.00025236720710144914, self.slope: [1.08638325 1.08709405], self.intercept: 1.0077268373888342\n",
      "iteration - 8550 -> loss: 0.0002523550612560223, self.slope: [1.08639097 1.08710188], self.intercept: 1.0077275708893314\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 8551 -> loss: 0.00025234291661612124, self.slope: [1.0863987 1.0871097], self.intercept: 1.0077283043604264\n",
      "iteration - 8552 -> loss: 0.0002523307731815946, self.slope: [1.08640642 1.08711753], self.intercept: 1.007729037802123\n",
      "iteration - 8553 -> loss: 0.00025231863095222457, self.slope: [1.08641414 1.08712535], self.intercept: 1.0077297712144253\n",
      "iteration - 8554 -> loss: 0.0002523064899278461, self.slope: [1.08642187 1.08713318], self.intercept: 1.0077305045973357\n",
      "iteration - 8555 -> loss: 0.00025229435010826895, self.slope: [1.08642959 1.087141  ], self.intercept: 1.007731237950855\n",
      "iteration - 8556 -> loss: 0.00025228221149332057, self.slope: [1.08643731 1.08714882], self.intercept: 1.0077319712749857\n",
      "iteration - 8557 -> loss: 0.00025227007408282166, self.slope: [1.08644504 1.08715665], self.intercept: 1.0077327045697315\n",
      "iteration - 8558 -> loss: 0.0002522579378765839, self.slope: [1.08645276 1.08716447], self.intercept: 1.0077334378350944\n",
      "iteration - 8559 -> loss: 0.00025224580287441285, self.slope: [1.08646048 1.08717229], self.intercept: 1.0077341710710774\n",
      "iteration - 8560 -> loss: 0.0002522336690761527, self.slope: [1.0864682  1.08718011], self.intercept: 1.0077349042776826\n",
      "iteration - 8561 -> loss: 0.00025222153648162026, self.slope: [1.08647592 1.08718793], self.intercept: 1.0077356374549127\n",
      "iteration - 8562 -> loss: 0.0002522094050906102, self.slope: [1.08648364 1.08719576], self.intercept: 1.0077363706027709\n",
      "iteration - 8563 -> loss: 0.00025219727490297306, self.slope: [1.08649136 1.08720358], self.intercept: 1.0077371037212584\n",
      "iteration - 8564 -> loss: 0.00025218514591848274, self.slope: [1.08649908 1.0872114 ], self.intercept: 1.0077378368103789\n",
      "iteration - 8565 -> loss: 0.0002521730181370038, self.slope: [1.0865068  1.08721922], self.intercept: 1.007738569870135\n",
      "iteration - 8566 -> loss: 0.0002521608915583256, self.slope: [1.08651452 1.08722703], self.intercept: 1.007739302900528\n",
      "iteration - 8567 -> loss: 0.00025214876618228537, self.slope: [1.08652224 1.08723485], self.intercept: 1.0077400359015618\n",
      "iteration - 8568 -> loss: 0.0002521366420086989, self.slope: [1.08652996 1.08724267], self.intercept: 1.0077407688732378\n",
      "iteration - 8569 -> loss: 0.0002521245190373774, self.slope: [1.08653767 1.08725049], self.intercept: 1.0077415018155593\n",
      "iteration - 8570 -> loss: 0.00025211239726814446, self.slope: [1.08654539 1.08725831], self.intercept: 1.0077422347285285\n",
      "iteration - 8571 -> loss: 0.0002521002767008128, self.slope: [1.08655311 1.08726613], self.intercept: 1.0077429676121468\n",
      "iteration - 8572 -> loss: 0.00025208815733519536, self.slope: [1.08656083 1.08727394], self.intercept: 1.0077437004664185\n",
      "iteration - 8573 -> loss: 0.0002520760391711362, self.slope: [1.08656854 1.08728176], self.intercept: 1.0077444332913474\n",
      "iteration - 8574 -> loss: 0.00025206392220844623, self.slope: [1.08657626 1.08728958], self.intercept: 1.0077451660869354\n",
      "iteration - 8575 -> loss: 0.00025205180644692843, self.slope: [1.08658397 1.08729739], self.intercept: 1.0077458988531836\n",
      "iteration - 8576 -> loss: 0.0002520396918864177, self.slope: [1.08659169 1.08730521], self.intercept: 1.0077466315900938\n",
      "iteration - 8577 -> loss: 0.00025202757852672966, self.slope: [1.0865994  1.08731302], self.intercept: 1.0077473642976713\n",
      "iteration - 8578 -> loss: 0.0002520154663676638, self.slope: [1.08660712 1.08732084], self.intercept: 1.0077480969759174\n",
      "iteration - 8579 -> loss: 0.0002520033554090776, self.slope: [1.08661483 1.08732865], self.intercept: 1.007748829624834\n",
      "iteration - 8580 -> loss: 0.00025199124565076955, self.slope: [1.08662254 1.08733646], self.intercept: 1.0077495622444235\n",
      "iteration - 8581 -> loss: 0.00025197913709255475, self.slope: [1.08663026 1.08734428], self.intercept: 1.0077502948346904\n",
      "iteration - 8582 -> loss: 0.00025196702973425653, self.slope: [1.08663797 1.08735209], self.intercept: 1.0077510273956358\n",
      "iteration - 8583 -> loss: 0.0002519549235757029, self.slope: [1.08664568 1.0873599 ], self.intercept: 1.0077517599272625\n",
      "iteration - 8584 -> loss: 0.0002519428186166896, self.slope: [1.08665339 1.08736772], self.intercept: 1.0077524924295707\n",
      "iteration - 8585 -> loss: 0.0002519307148570659, self.slope: [1.08666111 1.08737553], self.intercept: 1.0077532249025674\n",
      "iteration - 8586 -> loss: 0.0002519186122966317, self.slope: [1.08666882 1.08738334], self.intercept: 1.0077539573462524\n",
      "iteration - 8587 -> loss: 0.00025190651093522093, self.slope: [1.08667653 1.08739115], self.intercept: 1.0077546897606282\n",
      "iteration - 8588 -> loss: 0.0002518944107726289, self.slope: [1.08668424 1.08739896], self.intercept: 1.007755422145698\n",
      "iteration - 8589 -> loss: 0.00025188231180869766, self.slope: [1.08669195 1.08740677], self.intercept: 1.0077561545014633\n",
      "iteration - 8590 -> loss: 0.0002518702140432477, self.slope: [1.08669966 1.08741458], self.intercept: 1.0077568868279287\n",
      "iteration - 8591 -> loss: 0.00025185811747608516, self.slope: [1.08670737 1.08742239], self.intercept: 1.0077576191250943\n",
      "iteration - 8592 -> loss: 0.0002518460221070391, self.slope: [1.08671508 1.0874302 ], self.intercept: 1.0077583513929647\n",
      "iteration - 8593 -> loss: 0.0002518339279359313, self.slope: [1.08672278 1.08743801], self.intercept: 1.007759083631542\n",
      "iteration - 8594 -> loss: 0.00025182183496257185, self.slope: [1.08673049 1.08744582], self.intercept: 1.0077598158408294\n",
      "iteration - 8595 -> loss: 0.0002518097431867802, self.slope: [1.0867382  1.08745363], self.intercept: 1.0077605480208278\n",
      "iteration - 8596 -> loss: 0.00025179765260838547, self.slope: [1.08674591 1.08746143], self.intercept: 1.0077612801715397\n",
      "iteration - 8597 -> loss: 0.00025178556322719874, self.slope: [1.08675361 1.08746924], self.intercept: 1.0077620122929691\n",
      "iteration - 8598 -> loss: 0.0002517734750430616, self.slope: [1.08676132 1.08747705], self.intercept: 1.0077627443851183\n",
      "iteration - 8599 -> loss: 0.0002517613880557616, self.slope: [1.08676903 1.08748486], self.intercept: 1.0077634764479892\n",
      "iteration - 8600 -> loss: 0.0002517493022651463, self.slope: [1.08677673 1.08749266], self.intercept: 1.0077642084815848\n",
      "iteration - 8601 -> loss: 0.00025173721767100506, self.slope: [1.08678444 1.08750047], self.intercept: 1.0077649404859061\n",
      "iteration - 8602 -> loss: 0.00025172513427318345, self.slope: [1.08679214 1.08750827], self.intercept: 1.0077656724609583\n",
      "iteration - 8603 -> loss: 0.0002517130520714997, self.slope: [1.08679985 1.08751608], self.intercept: 1.007766404406743\n",
      "iteration - 8604 -> loss: 0.00025170097106577254, self.slope: [1.08680755 1.08752388], self.intercept: 1.007767136323261\n",
      "iteration - 8605 -> loss: 0.0002516888912558204, self.slope: [1.08681525 1.08753169], self.intercept: 1.0077678682105178\n",
      "iteration - 8606 -> loss: 0.0002516768126414662, self.slope: [1.08682296 1.08753949], self.intercept: 1.007768600068513\n",
      "iteration - 8607 -> loss: 0.000251664735222501, self.slope: [1.08683066 1.08754729], self.intercept: 1.0077693318972525\n",
      "iteration - 8608 -> loss: 0.00025165265899880105, self.slope: [1.08683836 1.0875551 ], self.intercept: 1.0077700636967355\n",
      "iteration - 8609 -> loss: 0.00025164058397013264, self.slope: [1.08684607 1.0875629 ], self.intercept: 1.0077707954669661\n",
      "iteration - 8610 -> loss: 0.00025162851013634733, self.slope: [1.08685377 1.0875707 ], self.intercept: 1.007771527207947\n",
      "iteration - 8611 -> loss: 0.000251616437497262, self.slope: [1.08686147 1.08757851], self.intercept: 1.007772258919682\n",
      "iteration - 8612 -> loss: 0.000251604366052688, self.slope: [1.08686917 1.08758631], self.intercept: 1.0077729906021704\n",
      "iteration - 8613 -> loss: 0.0002515922958024563, self.slope: [1.08687687 1.08759411], self.intercept: 1.007773722255417\n",
      "iteration - 8614 -> loss: 0.0002515802267463811, self.slope: [1.08688457 1.08760191], self.intercept: 1.0077744538794235\n",
      "iteration - 8615 -> loss: 0.00025156815888428325, self.slope: [1.08689227 1.08760971], self.intercept: 1.0077751854741923\n",
      "iteration - 8616 -> loss: 0.00025155609221598095, self.slope: [1.08689997 1.08761751], self.intercept: 1.007775917039726\n",
      "iteration - 8617 -> loss: 0.0002515440267412986, self.slope: [1.08690767 1.08762531], self.intercept: 1.007776648576027\n",
      "iteration - 8618 -> loss: 0.00025153196246005684, self.slope: [1.08691537 1.08763311], self.intercept: 1.0077773800830985\n",
      "iteration - 8619 -> loss: 0.0002515198993720863, self.slope: [1.08692307 1.08764091], self.intercept: 1.0077781115609432\n",
      "iteration - 8620 -> loss: 0.00025150783747717045, self.slope: [1.08693077 1.08764871], self.intercept: 1.0077788430095622\n",
      "iteration - 8621 -> loss: 0.00025149577677517523, self.slope: [1.08693846 1.0876565 ], self.intercept: 1.0077795744289602\n",
      "iteration - 8622 -> loss: 0.00025148371726590676, self.slope: [1.08694616 1.0876643 ], self.intercept: 1.0077803058191384\n",
      "iteration - 8623 -> loss: 0.0002514716589491686, self.slope: [1.08695386 1.0876721 ], self.intercept: 1.0077810371801006\n",
      "iteration - 8624 -> loss: 0.00025145960182480434, self.slope: [1.08696155 1.0876799 ], self.intercept: 1.007781768511847\n",
      "iteration - 8625 -> loss: 0.0002514475458926207, self.slope: [1.08696925 1.08768769], self.intercept: 1.0077824998143818\n",
      "iteration - 8626 -> loss: 0.0002514354911524571, self.slope: [1.08697695 1.08769549], self.intercept: 1.007783231087708\n",
      "iteration - 8627 -> loss: 0.00025142343760409773, self.slope: [1.08698464 1.08770329], self.intercept: 1.0077839623318259\n",
      "iteration - 8628 -> loss: 0.0002514113852474176, self.slope: [1.08699234 1.08771108], self.intercept: 1.0077846935467403\n",
      "iteration - 8629 -> loss: 0.0002513993340821934, self.slope: [1.08700003 1.08771888], self.intercept: 1.0077854247324527\n",
      "iteration - 8630 -> loss: 0.0002513872841082501, self.slope: [1.08700773 1.08772667], self.intercept: 1.0077861558889667\n",
      "iteration - 8631 -> loss: 0.00025137523532544064, self.slope: [1.08701542 1.08773447], self.intercept: 1.0077868870162843\n",
      "iteration - 8632 -> loss: 0.00025136318773354155, self.slope: [1.08702311 1.08774226], self.intercept: 1.007787618114407\n",
      "iteration - 8633 -> loss: 0.00025135114133239915, self.slope: [1.08703081 1.08775005], self.intercept: 1.0077883491833382\n",
      "iteration - 8634 -> loss: 0.000251339096121855, self.slope: [1.0870385  1.08775785], self.intercept: 1.0077890802230791\n",
      "iteration - 8635 -> loss: 0.0002513270521017003, self.slope: [1.08704619 1.08776564], self.intercept: 1.007789811233635\n",
      "iteration - 8636 -> loss: 0.00025131500927174657, self.slope: [1.08705388 1.08777343], self.intercept: 1.0077905422150066\n",
      "iteration - 8637 -> loss: 0.00025130296763184044, self.slope: [1.08706157 1.08778122], self.intercept: 1.007791273167195\n",
      "iteration - 8638 -> loss: 0.0002512909271818111, self.slope: [1.08706927 1.08778901], self.intercept: 1.0077920040902058\n",
      "iteration - 8639 -> loss: 0.0002512788879214422, self.slope: [1.08707696 1.08779681], self.intercept: 1.00779273498404\n",
      "iteration - 8640 -> loss: 0.00025126684985059635, self.slope: [1.08708465 1.0878046 ], self.intercept: 1.0077934658486998\n",
      "iteration - 8641 -> loss: 0.00025125481296906416, self.slope: [1.08709234 1.08781239], self.intercept: 1.0077941966841901\n",
      "iteration - 8642 -> loss: 0.000251242777276678, self.slope: [1.08710003 1.08782018], self.intercept: 1.0077949274905098\n",
      "iteration - 8643 -> loss: 0.0002512307427732747, self.slope: [1.08710772 1.08782797], self.intercept: 1.007795658267664\n",
      "iteration - 8644 -> loss: 0.00025121870945866564, self.slope: [1.0871154  1.08783576], self.intercept: 1.0077963890156543\n",
      "iteration - 8645 -> loss: 0.00025120667733265233, self.slope: [1.08712309 1.08784355], self.intercept: 1.0077971197344824\n",
      "iteration - 8646 -> loss: 0.0002511946463950798, self.slope: [1.08713078 1.08785133], self.intercept: 1.0077978504241516\n",
      "iteration - 8647 -> loss: 0.0002511826166457541, self.slope: [1.08713847 1.08785912], self.intercept: 1.0077985810846652\n",
      "iteration - 8648 -> loss: 0.00025117058808451636, self.slope: [1.08714616 1.08786691], self.intercept: 1.007799311716026\n",
      "iteration - 8649 -> loss: 0.0002511585607111805, self.slope: [1.08715384 1.0878747 ], self.intercept: 1.0078000423182354\n",
      "iteration - 8650 -> loss: 0.0002511465345255613, self.slope: [1.08716153 1.08788249], self.intercept: 1.0078007728912948\n",
      "iteration - 8651 -> loss: 0.0002511345095274845, self.slope: [1.08716922 1.08789027], self.intercept: 1.0078015034352095\n",
      "iteration - 8652 -> loss: 0.0002511224857167726, self.slope: [1.0871769  1.08789806], self.intercept: 1.0078022339499808\n",
      "iteration - 8653 -> loss: 0.00025111046309324916, self.slope: [1.08718459 1.08790584], self.intercept: 1.007802964435611\n",
      "iteration - 8654 -> loss: 0.00025109844165672405, self.slope: [1.08719227 1.08791363], self.intercept: 1.0078036948921023\n",
      "iteration - 8655 -> loss: 0.0002510864214070516, self.slope: [1.08719996 1.08792142], self.intercept: 1.0078044253194582\n",
      "iteration - 8656 -> loss: 0.0002510744023440268, self.slope: [1.08720764 1.0879292 ], self.intercept: 1.0078051557176804\n",
      "iteration - 8657 -> loss: 0.00025106238446747335, self.slope: [1.08721532 1.08793698], self.intercept: 1.007805886086771\n",
      "iteration - 8658 -> loss: 0.00025105036777721174, self.slope: [1.08722301 1.08794477], self.intercept: 1.0078066164267336\n",
      "iteration - 8659 -> loss: 0.0002510383522730743, self.slope: [1.08723069 1.08795255], self.intercept: 1.0078073467375708\n",
      "iteration - 8660 -> loss: 0.0002510263379548776, self.slope: [1.08723837 1.08796034], self.intercept: 1.007808077019284\n",
      "iteration - 8661 -> loss: 0.00025101432482245147, self.slope: [1.08724606 1.08796812], self.intercept: 1.0078088072718763\n",
      "iteration - 8662 -> loss: 0.0002510023128756042, self.slope: [1.08725374 1.0879759 ], self.intercept: 1.0078095374953497\n",
      "iteration - 8663 -> loss: 0.00025099030211416765, self.slope: [1.08726142 1.08798368], self.intercept: 1.0078102676897092\n",
      "iteration - 8664 -> loss: 0.0002509782925379572, self.slope: [1.0872691  1.08799146], self.intercept: 1.0078109978549543\n",
      "iteration - 8665 -> loss: 0.00025096628414680703, self.slope: [1.08727678 1.08799925], self.intercept: 1.007811727991089\n",
      "iteration - 8666 -> loss: 0.0002509542769405355, self.slope: [1.08728446 1.08800703], self.intercept: 1.0078124580981156\n",
      "iteration - 8667 -> loss: 0.00025094227091895, self.slope: [1.08729214 1.08801481], self.intercept: 1.0078131881760362\n",
      "iteration - 8668 -> loss: 0.00025093026608189703, self.slope: [1.08729982 1.08802259], self.intercept: 1.0078139182248536\n",
      "iteration - 8669 -> loss: 0.00025091826242917614, self.slope: [1.0873075  1.08803037], self.intercept: 1.0078146482445711\n",
      "iteration - 8670 -> loss: 0.0002509062599606349, self.slope: [1.08731518 1.08803815], self.intercept: 1.0078153782351906\n",
      "iteration - 8671 -> loss: 0.00025089425867608087, self.slope: [1.08732286 1.08804593], self.intercept: 1.0078161081967156\n",
      "iteration - 8672 -> loss: 0.00025088225857532425, self.slope: [1.08733054 1.08805371], self.intercept: 1.0078168381291472\n",
      "iteration - 8673 -> loss: 0.00025087025965820763, self.slope: [1.08733821 1.08806148], self.intercept: 1.0078175680324886\n",
      "iteration - 8674 -> loss: 0.00025085826192455904, self.slope: [1.08734589 1.08806926], self.intercept: 1.007818297906741\n",
      "iteration - 8675 -> loss: 0.00025084626537416615, self.slope: [1.08735357 1.08807704], self.intercept: 1.0078190277519075\n",
      "iteration - 8676 -> loss: 0.00025083427000689625, self.slope: [1.08736125 1.08808482], self.intercept: 1.0078197575679926\n",
      "iteration - 8677 -> loss: 0.00025082227582255684, self.slope: [1.08736892 1.08809259], self.intercept: 1.0078204873549956\n",
      "iteration - 8678 -> loss: 0.0002508102828209369, self.slope: [1.0873766  1.08810037], self.intercept: 1.0078212171129206\n",
      "iteration - 8679 -> loss: 0.0002507982910019021, self.slope: [1.08738427 1.08810815], self.intercept: 1.0078219468417713\n",
      "iteration - 8680 -> loss: 0.0002507863003652657, self.slope: [1.08739195 1.08811592], self.intercept: 1.007822676541549\n",
      "iteration - 8681 -> loss: 0.00025077431091085066, self.slope: [1.08739962 1.0881237 ], self.intercept: 1.0078234062122549\n",
      "iteration - 8682 -> loss: 0.00025076232263846024, self.slope: [1.0874073  1.08813147], self.intercept: 1.007824135853893\n",
      "iteration - 8683 -> loss: 0.0002507503355479372, self.slope: [1.08741497 1.08813925], self.intercept: 1.0078248654664663\n",
      "iteration - 8684 -> loss: 0.00025073834963910415, self.slope: [1.08742264 1.08814702], self.intercept: 1.0078255950499768\n",
      "iteration - 8685 -> loss: 0.0002507263649117817, self.slope: [1.08743032 1.08815479], self.intercept: 1.0078263246044286\n",
      "iteration - 8686 -> loss: 0.00025071438136577536, self.slope: [1.08743799 1.08816257], self.intercept: 1.0078270541298215\n",
      "iteration - 8687 -> loss: 0.00025070239900094947, self.slope: [1.08744566 1.08817034], self.intercept: 1.0078277836261598\n",
      "iteration - 8688 -> loss: 0.00025069041781708624, self.slope: [1.08745333 1.08817811], self.intercept: 1.0078285130934463\n",
      "iteration - 8689 -> loss: 0.00025067843781401264, self.slope: [1.08746101 1.08818589], self.intercept: 1.0078292425316808\n",
      "iteration - 8690 -> loss: 0.0002506664589915852, self.slope: [1.08746868 1.08819366], self.intercept: 1.0078299719408685\n",
      "iteration - 8691 -> loss: 0.00025065448134959696, self.slope: [1.08747635 1.08820143], self.intercept: 1.0078307013210093\n",
      "iteration - 8692 -> loss: 0.00025064250488787633, self.slope: [1.08748402 1.0882092 ], self.intercept: 1.0078314306721086\n",
      "iteration - 8693 -> loss: 0.0002506305296062566, self.slope: [1.08749169 1.08821697], self.intercept: 1.007832159994167\n",
      "iteration - 8694 -> loss: 0.0002506185555045525, self.slope: [1.08749936 1.08822474], self.intercept: 1.0078328892871882\n",
      "iteration - 8695 -> loss: 0.00025060658258259415, self.slope: [1.08750703 1.08823251], self.intercept: 1.007833618551175\n",
      "iteration - 8696 -> loss: 0.0002505946108401912, self.slope: [1.0875147  1.08824028], self.intercept: 1.0078343477861285\n",
      "iteration - 8697 -> loss: 0.0002505826402771951, self.slope: [1.08752237 1.08824805], self.intercept: 1.0078350769920534\n",
      "iteration - 8698 -> loss: 0.0002505706708933926, self.slope: [1.08753003 1.08825582], self.intercept: 1.0078358061689492\n",
      "iteration - 8699 -> loss: 0.000250558702688631, self.slope: [1.0875377  1.08826359], self.intercept: 1.0078365353168208\n",
      "iteration - 8700 -> loss: 0.0002505467356627366, self.slope: [1.08754537 1.08827135], self.intercept: 1.0078372644356697\n",
      "iteration - 8701 -> loss: 0.00025053476981551896, self.slope: [1.08755304 1.08827912], self.intercept: 1.0078379935254977\n",
      "iteration - 8702 -> loss: 0.00025052280514680923, self.slope: [1.0875607  1.08828689], self.intercept: 1.0078387225863086\n",
      "iteration - 8703 -> loss: 0.0002505108416564212, self.slope: [1.08756837 1.08829466], self.intercept: 1.0078394516181037\n",
      "iteration - 8704 -> loss: 0.0002504988793442027, self.slope: [1.08757604 1.08830242], self.intercept: 1.0078401806208874\n",
      "iteration - 8705 -> loss: 0.00025048691820994256, self.slope: [1.0875837  1.08831019], self.intercept: 1.0078409095946603\n",
      "iteration - 8706 -> loss: 0.0002504749582535024, self.slope: [1.08759137 1.08831796], self.intercept: 1.0078416385394262\n",
      "iteration - 8707 -> loss: 0.0002504629994746871, self.slope: [1.08759903 1.08832572], self.intercept: 1.0078423674551882\n",
      "iteration - 8708 -> loss: 0.00025045104187332176, self.slope: [1.08760669 1.08833349], self.intercept: 1.0078430963419465\n",
      "iteration - 8709 -> loss: 0.0002504390854492196, self.slope: [1.08761436 1.08834125], self.intercept: 1.0078438251997062\n",
      "iteration - 8710 -> loss: 0.0002504271302022236, self.slope: [1.08762202 1.08834901], self.intercept: 1.0078445540284682\n",
      "iteration - 8711 -> loss: 0.00025041517613214574, self.slope: [1.08762969 1.08835678], self.intercept: 1.0078452828282343\n",
      "iteration - 8712 -> loss: 0.00025040322323881974, self.slope: [1.08763735 1.08836454], self.intercept: 1.007846011599009\n",
      "iteration - 8713 -> loss: 0.000250391271522069, self.slope: [1.08764501 1.0883723 ], self.intercept: 1.0078467403407942\n",
      "iteration - 8714 -> loss: 0.00025037932098170184, self.slope: [1.08765267 1.08838007], self.intercept: 1.0078474690535908\n",
      "iteration - 8715 -> loss: 0.00025036737161754905, self.slope: [1.08766034 1.08838783], self.intercept: 1.0078481977374028\n",
      "iteration - 8716 -> loss: 0.00025035542342943486, self.slope: [1.087668   1.08839559], self.intercept: 1.0078489263922328\n",
      "iteration - 8717 -> loss: 0.00025034347641719783, self.slope: [1.08767566 1.08840335], self.intercept: 1.007849655018082\n",
      "iteration - 8718 -> loss: 0.00025033153058065186, self.slope: [1.08768332 1.08841111], self.intercept: 1.0078503836149535\n",
      "iteration - 8719 -> loss: 0.00025031958591962026, self.slope: [1.08769098 1.08841888], self.intercept: 1.007851112182851\n",
      "iteration - 8720 -> loss: 0.00025030764243393565, self.slope: [1.08769864 1.08842664], self.intercept: 1.0078518407217754\n",
      "iteration - 8721 -> loss: 0.0002502957001234015, self.slope: [1.0877063 1.0884344], self.intercept: 1.0078525692317306\n",
      "iteration - 8722 -> loss: 0.00025028375898785717, self.slope: [1.08771396 1.08844216], self.intercept: 1.0078532977127193\n",
      "iteration - 8723 -> loss: 0.0002502718190271391, self.slope: [1.08772162 1.08844992], self.intercept: 1.007854026164744\n",
      "iteration - 8724 -> loss: 0.0002502598802410366, self.slope: [1.08772927 1.08845767], self.intercept: 1.0078547545878036\n",
      "iteration - 8725 -> loss: 0.0002502479426294033, self.slope: [1.08773693 1.08846543], self.intercept: 1.0078554829819049\n",
      "iteration - 8726 -> loss: 0.000250236006192074, self.slope: [1.08774459 1.08847319], self.intercept: 1.0078562113470486\n",
      "iteration - 8727 -> loss: 0.00025022407092883394, self.slope: [1.08775225 1.08848095], self.intercept: 1.0078569396832386\n",
      "iteration - 8728 -> loss: 0.00025021213683954386, self.slope: [1.0877599  1.08848871], self.intercept: 1.0078576679904745\n",
      "iteration - 8729 -> loss: 0.0002502002039239972, self.slope: [1.08776756 1.08849646], self.intercept: 1.007858396268762\n",
      "iteration - 8730 -> loss: 0.00025018827218204306, self.slope: [1.08777522 1.08850422], self.intercept: 1.007859124518101\n",
      "iteration - 8731 -> loss: 0.0002501763416135137, self.slope: [1.08778287 1.08851198], self.intercept: 1.007859852738494\n",
      "iteration - 8732 -> loss: 0.0002501644122181994, self.slope: [1.08779053 1.08851973], self.intercept: 1.0078605809299461\n",
      "iteration - 8733 -> loss: 0.0002501524839959573, self.slope: [1.08779818 1.08852749], self.intercept: 1.0078613090924582\n",
      "iteration - 8734 -> loss: 0.00025014055694657993, self.slope: [1.08780584 1.08853524], self.intercept: 1.0078620372260323\n",
      "iteration - 8735 -> loss: 0.00025012863106994106, self.slope: [1.08781349 1.088543  ], self.intercept: 1.0078627653306735\n",
      "iteration - 8736 -> loss: 0.0002501167063658156, self.slope: [1.08782114 1.08855075], self.intercept: 1.007863493406382\n",
      "iteration - 8737 -> loss: 0.00025010478283405037, self.slope: [1.0878288  1.08855851], self.intercept: 1.00786422145316\n",
      "iteration - 8738 -> loss: 0.00025009286047447633, self.slope: [1.08783645 1.08856626], self.intercept: 1.0078649494710115\n",
      "iteration - 8739 -> loss: 0.0002500809392869077, self.slope: [1.0878441  1.08857401], self.intercept: 1.007865677459939\n",
      "iteration - 8740 -> loss: 0.0002500690192711707, self.slope: [1.08785175 1.08858177], self.intercept: 1.0078664054199424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 8741 -> loss: 0.00025005710042710043, self.slope: [1.08785941 1.08858952], self.intercept: 1.0078671333510267\n",
      "iteration - 8742 -> loss: 0.0002500451827544968, self.slope: [1.08786706 1.08859727], self.intercept: 1.0078678612531928\n",
      "iteration - 8743 -> loss: 0.00025003326625321396, self.slope: [1.08787471 1.08860502], self.intercept: 1.0078685891264463\n",
      "iteration - 8744 -> loss: 0.000250021350923067, self.slope: [1.08788236 1.08861277], self.intercept: 1.0078693169707862\n",
      "iteration - 8745 -> loss: 0.0002500094367638765, self.slope: [1.08789001 1.08862053], self.intercept: 1.0078700447862157\n",
      "iteration - 8746 -> loss: 0.0002499975237754712, self.slope: [1.08789766 1.08862828], self.intercept: 1.0078707725727387\n",
      "iteration - 8747 -> loss: 0.0002499856119576642, self.slope: [1.08790531 1.08863603], self.intercept: 1.0078715003303567\n",
      "iteration - 8748 -> loss: 0.00024997370131032515, self.slope: [1.08791296 1.08864378], self.intercept: 1.007872228059071\n",
      "iteration - 8749 -> loss: 0.0002499617918332148, self.slope: [1.08792061 1.08865153], self.intercept: 1.0078729557588868\n",
      "iteration - 8750 -> loss: 0.00024994988352621043, self.slope: [1.08792826 1.08865927], self.intercept: 1.0078736834298052\n",
      "iteration - 8751 -> loss: 0.00024993797638910644, self.slope: [1.0879359  1.08866702], self.intercept: 1.0078744110718296\n",
      "iteration - 8752 -> loss: 0.0002499260704217443, self.slope: [1.08794355 1.08867477], self.intercept: 1.007875138684962\n",
      "iteration - 8753 -> loss: 0.00024991416562393536, self.slope: [1.0879512  1.08868252], self.intercept: 1.007875866269204\n",
      "iteration - 8754 -> loss: 0.0002499022619955289, self.slope: [1.08795885 1.08869027], self.intercept: 1.0078765938245577\n",
      "iteration - 8755 -> loss: 0.00024989035953632796, self.slope: [1.08796649 1.08869801], self.intercept: 1.007877321351028\n",
      "iteration - 8756 -> loss: 0.00024987845824617216, self.slope: [1.08797414 1.08870576], self.intercept: 1.0078780488486148\n",
      "iteration - 8757 -> loss: 0.00024986655812487125, self.slope: [1.08798178 1.08871351], self.intercept: 1.007878776317321\n",
      "iteration - 8758 -> loss: 0.00024985465917226515, self.slope: [1.08798943 1.08872125], self.intercept: 1.0078795037571513\n",
      "iteration - 8759 -> loss: 0.000249842761388182, self.slope: [1.08799708 1.088729  ], self.intercept: 1.0078802311681052\n",
      "iteration - 8760 -> loss: 0.00024983086477243393, self.slope: [1.08800472 1.08873675], self.intercept: 1.0078809585501878\n",
      "iteration - 8761 -> loss: 0.00024981896932484165, self.slope: [1.08801236 1.08874449], self.intercept: 1.0078816859034005\n",
      "iteration - 8762 -> loss: 0.0002498070750452637, self.slope: [1.08802001 1.08875223], self.intercept: 1.0078824132277446\n",
      "iteration - 8763 -> loss: 0.0002497951819334987, self.slope: [1.08802765 1.08875998], self.intercept: 1.0078831405232238\n",
      "iteration - 8764 -> loss: 0.0002497832899893763, self.slope: [1.08803529 1.08876772], self.intercept: 1.0078838677898414\n",
      "iteration - 8765 -> loss: 0.0002497713992127264, self.slope: [1.08804294 1.08877547], self.intercept: 1.007884595027599\n",
      "iteration - 8766 -> loss: 0.00024975950960338136, self.slope: [1.08805058 1.08878321], self.intercept: 1.0078853222364992\n",
      "iteration - 8767 -> loss: 0.00024974762116114496, self.slope: [1.08805822 1.08879095], self.intercept: 1.007886049416544\n",
      "iteration - 8768 -> loss: 0.00024973573388586945, self.slope: [1.08806586 1.08879869], self.intercept: 1.007886776567737\n",
      "iteration - 8769 -> loss: 0.0002497238477773606, self.slope: [1.0880735  1.08880644], self.intercept: 1.0078875036900803\n",
      "iteration - 8770 -> loss: 0.0002497119628354692, self.slope: [1.08808115 1.08881418], self.intercept: 1.007888230783576\n",
      "iteration - 8771 -> loss: 0.00024970007905999016, self.slope: [1.08808879 1.08882192], self.intercept: 1.0078889578482262\n",
      "iteration - 8772 -> loss: 0.0002496881964507699, self.slope: [1.08809643 1.08882966], self.intercept: 1.0078896848840337\n",
      "iteration - 8773 -> loss: 0.00024967631500761363, self.slope: [1.08810407 1.0888374 ], self.intercept: 1.007890411891002\n",
      "iteration - 8774 -> loss: 0.0002496644347303756, self.slope: [1.0881117  1.08884514], self.intercept: 1.0078911388691316\n",
      "iteration - 8775 -> loss: 0.00024965255561887215, self.slope: [1.08811934 1.08885288], self.intercept: 1.0078918658184277\n",
      "iteration - 8776 -> loss: 0.00024964067767293093, self.slope: [1.08812698 1.08886062], self.intercept: 1.0078925927388913\n",
      "iteration - 8777 -> loss: 0.0002496288008923665, self.slope: [1.08813462 1.08886836], self.intercept: 1.0078933196305235\n",
      "iteration - 8778 -> loss: 0.00024961692527701243, self.slope: [1.08814226 1.0888761 ], self.intercept: 1.0078940464933284\n",
      "iteration - 8779 -> loss: 0.00024960505082671254, self.slope: [1.0881499  1.08888384], self.intercept: 1.0078947733273076\n",
      "iteration - 8780 -> loss: 0.0002495931775412657, self.slope: [1.08815753 1.08889157], self.intercept: 1.0078955001324645\n",
      "iteration - 8781 -> loss: 0.0002495813054205013, self.slope: [1.08816517 1.08889931], self.intercept: 1.0078962269088023\n",
      "iteration - 8782 -> loss: 0.00024956943446428014, self.slope: [1.08817281 1.08890705], self.intercept: 1.0078969536563227\n",
      "iteration - 8783 -> loss: 0.0002495575646723788, self.slope: [1.08818044 1.08891478], self.intercept: 1.0078976803750275\n",
      "iteration - 8784 -> loss: 0.00024954569604465236, self.slope: [1.08818808 1.08892252], self.intercept: 1.0078984070649195\n",
      "iteration - 8785 -> loss: 0.0002495338285809183, self.slope: [1.08819571 1.08893026], self.intercept: 1.0078991337260013\n",
      "iteration - 8786 -> loss: 0.0002495219622810163, self.slope: [1.08820335 1.08893799], self.intercept: 1.007899860358276\n",
      "iteration - 8787 -> loss: 0.0002495100971447523, self.slope: [1.08821098 1.08894573], self.intercept: 1.0079005869617457\n",
      "iteration - 8788 -> loss: 0.0002494982331719745, self.slope: [1.08821862 1.08895346], self.intercept: 1.0079013135364099\n",
      "iteration - 8789 -> loss: 0.00024948637036249733, self.slope: [1.08822625 1.0889612 ], self.intercept: 1.007902040082276\n",
      "iteration - 8790 -> loss: 0.00024947450871616453, self.slope: [1.08823388 1.08896893], self.intercept: 1.0079027665993436\n",
      "iteration - 8791 -> loss: 0.0002494626482327864, self.slope: [1.08824152 1.08897666], self.intercept: 1.0079034930876158\n",
      "iteration - 8792 -> loss: 0.00024945078891217167, self.slope: [1.08824915 1.0889844 ], self.intercept: 1.007904219547096\n",
      "iteration - 8793 -> loss: 0.0002494389307541933, self.slope: [1.08825678 1.08899213], self.intercept: 1.0079049459777867\n",
      "iteration - 8794 -> loss: 0.00024942707375863547, self.slope: [1.08826441 1.08899986], self.intercept: 1.0079056723796882\n",
      "iteration - 8795 -> loss: 0.0002494152179253577, self.slope: [1.08827204 1.08900759], self.intercept: 1.0079063987528052\n",
      "iteration - 8796 -> loss: 0.00024940336325413883, self.slope: [1.08827967 1.08901533], self.intercept: 1.0079071250971388\n",
      "iteration - 8797 -> loss: 0.00024939150974488374, self.slope: [1.08828731 1.08902306], self.intercept: 1.0079078514126925\n",
      "iteration - 8798 -> loss: 0.0002493796573973478, self.slope: [1.08829494 1.08903079], self.intercept: 1.0079085776994676\n",
      "iteration - 8799 -> loss: 0.0002493678062113921, self.slope: [1.08830257 1.08903852], self.intercept: 1.0079093039574663\n",
      "iteration - 8800 -> loss: 0.00024935595618682816, self.slope: [1.0883102  1.08904625], self.intercept: 1.007910030186693\n",
      "iteration - 8801 -> loss: 0.00024934410732349664, self.slope: [1.08831782 1.08905398], self.intercept: 1.00791075638715\n",
      "iteration - 8802 -> loss: 0.0002493322596212167, self.slope: [1.08832545 1.08906171], self.intercept: 1.0079114825588376\n",
      "iteration - 8803 -> loss: 0.0002493204130798409, self.slope: [1.08833308 1.08906944], self.intercept: 1.0079122087017613\n",
      "iteration - 8804 -> loss: 0.00024930856769915657, self.slope: [1.08834071 1.08907717], self.intercept: 1.0079129348159208\n",
      "iteration - 8805 -> loss: 0.0002492967234790026, self.slope: [1.08834834 1.0890849 ], self.intercept: 1.0079136609013193\n",
      "iteration - 8806 -> loss: 0.0002492848804192151, self.slope: [1.08835596 1.08909262], self.intercept: 1.0079143869579599\n",
      "iteration - 8807 -> loss: 0.0002492730385196261, self.slope: [1.08836359 1.08910035], self.intercept: 1.0079151129858455\n",
      "iteration - 8808 -> loss: 0.00024926119778005766, self.slope: [1.08837122 1.08910808], self.intercept: 1.007915838984978\n",
      "iteration - 8809 -> loss: 0.00024924935820033235, self.slope: [1.08837884 1.08911581], self.intercept: 1.0079165649553603\n",
      "iteration - 8810 -> loss: 0.0002492375197802757, self.slope: [1.08838647 1.08912353], self.intercept: 1.0079172908969942\n",
      "iteration - 8811 -> loss: 0.0002492256825197151, self.slope: [1.0883941  1.08913126], self.intercept: 1.0079180168098822\n",
      "iteration - 8812 -> loss: 0.00024921384641849115, self.slope: [1.08840172 1.08913898], self.intercept: 1.0079187426940266\n",
      "iteration - 8813 -> loss: 0.0002492020114764097, self.slope: [1.08840934 1.08914671], self.intercept: 1.00791946854943\n",
      "iteration - 8814 -> loss: 0.00024919017769332635, self.slope: [1.08841697 1.08915443], self.intercept: 1.0079201943760956\n",
      "iteration - 8815 -> loss: 0.0002491783450690533, self.slope: [1.08842459 1.08916216], self.intercept: 1.0079209201740247\n",
      "iteration - 8816 -> loss: 0.0002491665136034216, self.slope: [1.08843222 1.08916988], self.intercept: 1.007921645943221\n",
      "iteration - 8817 -> loss: 0.00024915468329626383, self.slope: [1.08843984 1.08917761], self.intercept: 1.0079223716836865\n",
      "iteration - 8818 -> loss: 0.0002491428541473885, self.slope: [1.08844746 1.08918533], self.intercept: 1.007923097395423\n",
      "iteration - 8819 -> loss: 0.0002491310261566312, self.slope: [1.08845508 1.08919305], self.intercept: 1.0079238230784349\n",
      "iteration - 8820 -> loss: 0.00024911919932382585, self.slope: [1.08846271 1.08920078], self.intercept: 1.0079245487327235\n",
      "iteration - 8821 -> loss: 0.00024910737364880454, self.slope: [1.08847033 1.0892085 ], self.intercept: 1.0079252743582905\n",
      "iteration - 8822 -> loss: 0.00024909554913138556, self.slope: [1.08847795 1.08921622], self.intercept: 1.0079259999551393\n",
      "iteration - 8823 -> loss: 0.0002490837257714111, self.slope: [1.08848557 1.08922394], self.intercept: 1.0079267255232705\n",
      "iteration - 8824 -> loss: 0.00024907190356869156, self.slope: [1.08849319 1.08923166], self.intercept: 1.0079274510626905\n",
      "iteration - 8825 -> loss: 0.00024906008252305155, self.slope: [1.08850081 1.08923938], self.intercept: 1.0079281765733983\n",
      "iteration - 8826 -> loss: 0.0002490482626343325, self.slope: [1.08850843 1.08924711], self.intercept: 1.007928902055396\n",
      "iteration - 8827 -> loss: 0.0002490364439023699, self.slope: [1.08851605 1.08925483], self.intercept: 1.0079296275086875\n",
      "iteration - 8828 -> loss: 0.00024902462632697334, self.slope: [1.08852367 1.08926255], self.intercept: 1.0079303529332773\n",
      "iteration - 8829 -> loss: 0.0002490128099079737, self.slope: [1.08853129 1.08927026], self.intercept: 1.007931078329165\n",
      "iteration - 8830 -> loss: 0.0002490009946452116, self.slope: [1.08853891 1.08927798], self.intercept: 1.0079318036963538\n",
      "iteration - 8831 -> loss: 0.0002489891805385236, self.slope: [1.08854652 1.0892857 ], self.intercept: 1.0079325290348475\n",
      "iteration - 8832 -> loss: 0.0002489773675876993, self.slope: [1.08855414 1.08929342], self.intercept: 1.007933254344647\n",
      "iteration - 8833 -> loss: 0.00024896555579260045, self.slope: [1.08856176 1.08930114], self.intercept: 1.0079339796257551\n",
      "iteration - 8834 -> loss: 0.00024895374515303915, self.slope: [1.08856937 1.08930886], self.intercept: 1.0079347048781735\n",
      "iteration - 8835 -> loss: 0.00024894193566885807, self.slope: [1.08857699 1.08931657], self.intercept: 1.0079354301019068\n",
      "iteration - 8836 -> loss: 0.00024893012733986084, self.slope: [1.08858461 1.08932429], self.intercept: 1.0079361552969555\n",
      "iteration - 8837 -> loss: 0.00024891832016591216, self.slope: [1.08859222 1.08933201], self.intercept: 1.0079368804633237\n",
      "iteration - 8838 -> loss: 0.0002489065141468016, self.slope: [1.08859984 1.08933972], self.intercept: 1.0079376056010123\n",
      "iteration - 8839 -> loss: 0.0002488947092823948, self.slope: [1.08860745 1.08934744], self.intercept: 1.0079383307100247\n",
      "iteration - 8840 -> loss: 0.0002488829055724769, self.slope: [1.08861507 1.08935515], self.intercept: 1.0079390557903627\n",
      "iteration - 8841 -> loss: 0.0002488711030169307, self.slope: [1.08862268 1.08936287], self.intercept: 1.0079397808420296\n",
      "iteration - 8842 -> loss: 0.0002488593016155319, self.slope: [1.08863029 1.08937058], self.intercept: 1.0079405058650268\n",
      "iteration - 8843 -> loss: 0.0002488475013681396, self.slope: [1.08863791 1.0893783 ], self.intercept: 1.0079412308593576\n",
      "iteration - 8844 -> loss: 0.0002488357022745716, self.slope: [1.08864552 1.08938601], self.intercept: 1.0079419558250236\n",
      "iteration - 8845 -> loss: 0.00024882390433466413, self.slope: [1.08865313 1.08939372], self.intercept: 1.0079426807620269\n",
      "iteration - 8846 -> loss: 0.00024881210754824933, self.slope: [1.08866075 1.08940144], self.intercept: 1.0079434056703729\n",
      "iteration - 8847 -> loss: 0.0002488003119151363, self.slope: [1.08866836 1.08940915], self.intercept: 1.0079441305500623\n",
      "iteration - 8848 -> loss: 0.0002487885174351797, self.slope: [1.08867597 1.08941686], self.intercept: 1.0079448554010966\n",
      "iteration - 8849 -> loss: 0.00024877672410819336, self.slope: [1.08868358 1.08942457], self.intercept: 1.0079455802234787\n",
      "iteration - 8850 -> loss: 0.00024876493193400827, self.slope: [1.08869119 1.08943229], self.intercept: 1.0079463050172117\n",
      "iteration - 8851 -> loss: 0.0002487531409124431, self.slope: [1.0886988 1.08944  ], self.intercept: 1.0079470297822977\n",
      "iteration - 8852 -> loss: 0.00024874135104333586, self.slope: [1.08870641 1.08944771], self.intercept: 1.0079477545187394\n",
      "iteration - 8853 -> loss: 0.000248729562326518, self.slope: [1.08871402 1.08945542], self.intercept: 1.0079484792265379\n",
      "iteration - 8854 -> loss: 0.00024871777476183544, self.slope: [1.08872163 1.08946313], self.intercept: 1.0079492039056985\n",
      "iteration - 8855 -> loss: 0.0002487059883490669, self.slope: [1.08872924 1.08947084], self.intercept: 1.0079499285562217\n",
      "iteration - 8856 -> loss: 0.0002486942030880986, self.slope: [1.08873685 1.08947855], self.intercept: 1.007950653178109\n",
      "iteration - 8857 -> loss: 0.000248682418978727, self.slope: [1.08874446 1.08948626], self.intercept: 1.0079513777713633\n",
      "iteration - 8858 -> loss: 0.0002486706360207863, self.slope: [1.08875206 1.08949396], self.intercept: 1.0079521023359892\n",
      "iteration - 8859 -> loss: 0.00024865885421410593, self.slope: [1.08875967 1.08950167], self.intercept: 1.0079528268719875\n",
      "iteration - 8860 -> loss: 0.0002486470735585079, self.slope: [1.08876728 1.08950938], self.intercept: 1.0079535513793614\n",
      "iteration - 8861 -> loss: 0.0002486352940538355, self.slope: [1.08877488 1.08951709], self.intercept: 1.007954275858113\n",
      "iteration - 8862 -> loss: 0.00024862351569991583, self.slope: [1.08878249 1.08952479], self.intercept: 1.0079550003082451\n",
      "iteration - 8863 -> loss: 0.0002486117384965809, self.slope: [1.0887901 1.0895325], self.intercept: 1.007955724729759\n",
      "iteration - 8864 -> loss: 0.0002485999624436471, self.slope: [1.0887977  1.08954021], self.intercept: 1.0079564491226598\n",
      "iteration - 8865 -> loss: 0.0002485881875409496, self.slope: [1.08880531 1.08954791], self.intercept: 1.0079571734869466\n",
      "iteration - 8866 -> loss: 0.0002485764137883215, self.slope: [1.08881291 1.08955562], self.intercept: 1.0079578978226238\n",
      "iteration - 8867 -> loss: 0.0002485646411856011, self.slope: [1.08882052 1.08956332], self.intercept: 1.0079586221296928\n",
      "iteration - 8868 -> loss: 0.0002485528697325929, self.slope: [1.08882812 1.08957103], self.intercept: 1.0079593464081584\n",
      "iteration - 8869 -> loss: 0.0002485410994291497, self.slope: [1.08883572 1.08957873], self.intercept: 1.0079600706580196\n",
      "iteration - 8870 -> loss: 0.000248529330275081, self.slope: [1.08884333 1.08958644], self.intercept: 1.0079607948792808\n",
      "iteration - 8871 -> loss: 0.00024851756227022714, self.slope: [1.08885093 1.08959414], self.intercept: 1.0079615190719442\n",
      "iteration - 8872 -> loss: 0.00024850579541441033, self.slope: [1.08885853 1.08960184], self.intercept: 1.0079622432360127\n",
      "iteration - 8873 -> loss: 0.0002484940297074907, self.slope: [1.08886613 1.08960955], self.intercept: 1.007962967371488\n",
      "iteration - 8874 -> loss: 0.000248482265149259, self.slope: [1.08887374 1.08961725], self.intercept: 1.0079636914783727\n",
      "iteration - 8875 -> loss: 0.0002484705017395514, self.slope: [1.08888134 1.08962495], self.intercept: 1.0079644155566698\n",
      "iteration - 8876 -> loss: 0.00024845873947822216, self.slope: [1.08888894 1.08963265], self.intercept: 1.007965139606381\n",
      "iteration - 8877 -> loss: 0.00024844697836506993, self.slope: [1.08889654 1.08964036], self.intercept: 1.00796586362751\n",
      "iteration - 8878 -> loss: 0.00024843521839996546, self.slope: [1.08890414 1.08964806], self.intercept: 1.0079665876200572\n",
      "iteration - 8879 -> loss: 0.0002484234595826993, self.slope: [1.08891174 1.08965576], self.intercept: 1.0079673115840277\n",
      "iteration - 8880 -> loss: 0.0002484117019131024, self.slope: [1.08891934 1.08966346], self.intercept: 1.0079680355194214\n",
      "iteration - 8881 -> loss: 0.0002483999453910357, self.slope: [1.08892694 1.08967116], self.intercept: 1.0079687594262412\n",
      "iteration - 8882 -> loss: 0.00024838819001629447, self.slope: [1.08893454 1.08967886], self.intercept: 1.007969483304492\n",
      "iteration - 8883 -> loss: 0.00024837643578874886, self.slope: [1.08894213 1.08968656], self.intercept: 1.0079702071541736\n",
      "iteration - 8884 -> loss: 0.0002483646827081794, self.slope: [1.08894973 1.08969425], self.intercept: 1.0079709309752882\n",
      "iteration - 8885 -> loss: 0.0002483529307744596, self.slope: [1.08895733 1.08970195], self.intercept: 1.007971654767841\n",
      "iteration - 8886 -> loss: 0.0002483411799873799, self.slope: [1.08896493 1.08970965], self.intercept: 1.007972378531833\n",
      "iteration - 8887 -> loss: 0.0002483294303468232, self.slope: [1.08897252 1.08971735], self.intercept: 1.0079731022672653\n",
      "iteration - 8888 -> loss: 0.0002483176818525636, self.slope: [1.08898012 1.08972505], self.intercept: 1.007973825974141\n",
      "iteration - 8889 -> loss: 0.0002483059345044659, self.slope: [1.08898772 1.08973274], self.intercept: 1.0079745496524655\n",
      "iteration - 8890 -> loss: 0.00024829418830233876, self.slope: [1.08899531 1.08974044], self.intercept: 1.0079752733022378\n",
      "iteration - 8891 -> loss: 0.0002482824432460562, self.slope: [1.08900291 1.08974814], self.intercept: 1.0079759969234612\n",
      "iteration - 8892 -> loss: 0.0002482706993353881, self.slope: [1.0890105  1.08975583], self.intercept: 1.0079767205161378\n",
      "iteration - 8893 -> loss: 0.00024825895657020614, self.slope: [1.0890181  1.08976353], self.intercept: 1.0079774440802711\n",
      "iteration - 8894 -> loss: 0.00024824721495033, self.slope: [1.08902569 1.08977122], self.intercept: 1.0079781676158632\n",
      "iteration - 8895 -> loss: 0.00024823547447556856, self.slope: [1.08903328 1.08977892], self.intercept: 1.007978891122915\n",
      "iteration - 8896 -> loss: 0.00024822373514577986, self.slope: [1.08904088 1.08978661], self.intercept: 1.0079796146014315\n",
      "iteration - 8897 -> loss: 0.00024821199696080734, self.slope: [1.08904847 1.08979431], self.intercept: 1.0079803380514152\n",
      "iteration - 8898 -> loss: 0.00024820025992043274, self.slope: [1.08905606 1.089802  ], self.intercept: 1.0079810614728666\n",
      "iteration - 8899 -> loss: 0.00024818852402451827, self.slope: [1.08906366 1.08980969], self.intercept: 1.0079817848657886\n",
      "iteration - 8900 -> loss: 0.00024817678927290096, self.slope: [1.08907125 1.08981739], self.intercept: 1.007982508230183\n",
      "iteration - 8901 -> loss: 0.00024816505566539396, self.slope: [1.08907884 1.08982508], self.intercept: 1.0079832315660548\n",
      "iteration - 8902 -> loss: 0.00024815332320184255, self.slope: [1.08908643 1.08983277], self.intercept: 1.0079839548734035\n",
      "iteration - 8903 -> loss: 0.000248141591882062, self.slope: [1.08909402 1.08984046], self.intercept: 1.0079846781522335\n",
      "iteration - 8904 -> loss: 0.0002481298617058976, self.slope: [1.08910161 1.08984815], self.intercept: 1.0079854014025464\n",
      "iteration - 8905 -> loss: 0.00024811813267316203, self.slope: [1.0891092  1.08985584], self.intercept: 1.0079861246243453\n",
      "iteration - 8906 -> loss: 0.0002481064047837031, self.slope: [1.08911679 1.08986353], self.intercept: 1.007986847817632\n",
      "iteration - 8907 -> loss: 0.0002480946780373504, self.slope: [1.08912438 1.08987123], self.intercept: 1.0079875709824087\n",
      "iteration - 8908 -> loss: 0.000248082952433917, self.slope: [1.08913197 1.08987891], self.intercept: 1.0079882941186786\n",
      "iteration - 8909 -> loss: 0.000248071227973258, self.slope: [1.08913956 1.0898866 ], self.intercept: 1.007989017226444\n",
      "iteration - 8910 -> loss: 0.0002480595046552008, self.slope: [1.08914715 1.08989429], self.intercept: 1.0079897403057074\n",
      "iteration - 8911 -> loss: 0.0002480477824795331, self.slope: [1.08915474 1.08990198], self.intercept: 1.007990463356471\n",
      "iteration - 8912 -> loss: 0.0002480360614461456, self.slope: [1.08916232 1.08990967], self.intercept: 1.007991186378737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 8913 -> loss: 0.0002480243415548488, self.slope: [1.08916991 1.08991736], self.intercept: 1.0079919093725076\n",
      "iteration - 8914 -> loss: 0.00024801262280545845, self.slope: [1.0891775  1.08992505], self.intercept: 1.0079926323377861\n",
      "iteration - 8915 -> loss: 0.00024800090519782166, self.slope: [1.08918508 1.08993273], self.intercept: 1.0079933552745746\n",
      "iteration - 8916 -> loss: 0.0002479891887317595, self.slope: [1.08919267 1.08994042], self.intercept: 1.0079940781828751\n",
      "iteration - 8917 -> loss: 0.0002479774734071124, self.slope: [1.08920025 1.08994811], self.intercept: 1.0079948010626911\n",
      "iteration - 8918 -> loss: 0.0002479657592237093, self.slope: [1.08920784 1.08995579], self.intercept: 1.0079955239140244\n",
      "iteration - 8919 -> loss: 0.00024795404618137393, self.slope: [1.08921543 1.08996348], self.intercept: 1.0079962467368777\n",
      "iteration - 8920 -> loss: 0.00024794233427994635, self.slope: [1.08922301 1.08997116], self.intercept: 1.007996969531252\n",
      "iteration - 8921 -> loss: 0.00024793062351926155, self.slope: [1.08923059 1.08997885], self.intercept: 1.007997692297151\n",
      "iteration - 8922 -> loss: 0.000247918913899135, self.slope: [1.08923818 1.08998653], self.intercept: 1.0079984150345769\n",
      "iteration - 8923 -> loss: 0.00024790720541940274, self.slope: [1.08924576 1.08999422], self.intercept: 1.0079991377435327\n",
      "iteration - 8924 -> loss: 0.00024789549807990125, self.slope: [1.08925334 1.0900019 ], self.intercept: 1.0079998604240203\n",
      "iteration - 8925 -> loss: 0.0002478837918804738, self.slope: [1.08926093 1.09000959], self.intercept: 1.0080005830760423\n",
      "iteration - 8926 -> loss: 0.00024787208682092756, self.slope: [1.08926851 1.09001727], self.intercept: 1.008001305699601\n",
      "iteration - 8927 -> loss: 0.0002478603829011043, self.slope: [1.08927609 1.09002495], self.intercept: 1.008002028294699\n",
      "iteration - 8928 -> loss: 0.0002478486801208352, self.slope: [1.08928367 1.09003263], self.intercept: 1.0080027508613396\n",
      "iteration - 8929 -> loss: 0.000247836978479954, self.slope: [1.08929125 1.09004032], self.intercept: 1.0080034733995233\n",
      "iteration - 8930 -> loss: 0.00024782527797828977, self.slope: [1.08929883 1.090048  ], self.intercept: 1.0080041959092536\n",
      "iteration - 8931 -> loss: 0.00024781357861568964, self.slope: [1.08930641 1.09005568], self.intercept: 1.0080049183905342\n",
      "iteration - 8932 -> loss: 0.0002478018803919499, self.slope: [1.08931399 1.09006336], self.intercept: 1.008005640843366\n",
      "iteration - 8933 -> loss: 0.0002477901833069493, self.slope: [1.08932157 1.09007104], self.intercept: 1.0080063632677503\n",
      "iteration - 8934 -> loss: 0.00024777848736047737, self.slope: [1.08932915 1.09007872], self.intercept: 1.0080070856636931\n",
      "iteration - 8935 -> loss: 0.00024776679255237834, self.slope: [1.08933673 1.0900864 ], self.intercept: 1.0080078080311927\n",
      "iteration - 8936 -> loss: 0.00024775509888249865, self.slope: [1.08934431 1.09009408], self.intercept: 1.0080085303702548\n",
      "iteration - 8937 -> loss: 0.0002477434063506432, self.slope: [1.08935189 1.09010176], self.intercept: 1.0080092526808786\n",
      "iteration - 8938 -> loss: 0.00024773171495667427, self.slope: [1.08935947 1.09010944], self.intercept: 1.0080099749630704\n",
      "iteration - 8939 -> loss: 0.0002477200247004015, self.slope: [1.08936704 1.09011712], self.intercept: 1.0080106972168301\n",
      "iteration - 8940 -> loss: 0.000247708335581672, self.slope: [1.08937462 1.0901248 ], self.intercept: 1.0080114194421606\n",
      "iteration - 8941 -> loss: 0.0002476966476003047, self.slope: [1.0893822  1.09013247], self.intercept: 1.0080121416390642\n",
      "iteration - 8942 -> loss: 0.0002476849607561415, self.slope: [1.08938977 1.09014015], self.intercept: 1.0080128638075438\n",
      "iteration - 8943 -> loss: 0.0002476732750490119, self.slope: [1.08939735 1.09014783], self.intercept: 1.0080135859476023\n",
      "iteration - 8944 -> loss: 0.0002476615904787267, self.slope: [1.08940493 1.0901555 ], self.intercept: 1.0080143080592405\n",
      "iteration - 8945 -> loss: 0.00024764990704515466, self.slope: [1.0894125  1.09016318], self.intercept: 1.0080150301424626\n",
      "iteration - 8946 -> loss: 0.00024763822474809985, self.slope: [1.08942008 1.09017086], self.intercept: 1.0080157521972684\n",
      "iteration - 8947 -> loss: 0.0002476265435874184, self.slope: [1.08942765 1.09017853], self.intercept: 1.0080164742236628\n",
      "iteration - 8948 -> loss: 0.00024761486356292267, self.slope: [1.08943522 1.09018621], self.intercept: 1.0080171962216478\n",
      "iteration - 8949 -> loss: 0.00024760318467444186, self.slope: [1.0894428  1.09019388], self.intercept: 1.0080179181912254\n",
      "iteration - 8950 -> loss: 0.00024759150692183125, self.slope: [1.08945037 1.09020155], self.intercept: 1.0080186401323992\n",
      "iteration - 8951 -> loss: 0.00024757983030490436, self.slope: [1.08945794 1.09020923], self.intercept: 1.0080193620451696\n",
      "iteration - 8952 -> loss: 0.0002475681548234946, self.slope: [1.08946552 1.0902169 ], self.intercept: 1.0080200839295408\n",
      "iteration - 8953 -> loss: 0.0002475564804774323, self.slope: [1.08947309 1.09022458], self.intercept: 1.0080208057855145\n",
      "iteration - 8954 -> loss: 0.00024754480726657345, self.slope: [1.08948066 1.09023225], self.intercept: 1.008021527613093\n",
      "iteration - 8955 -> loss: 0.00024753313519072247, self.slope: [1.08948823 1.09023992], self.intercept: 1.0080222494122788\n",
      "iteration - 8956 -> loss: 0.00024752146424971875, self.slope: [1.0894958  1.09024759], self.intercept: 1.0080229711830746\n",
      "iteration - 8957 -> loss: 0.00024750979444340877, self.slope: [1.08950337 1.09025526], self.intercept: 1.0080236929254829\n",
      "iteration - 8958 -> loss: 0.0002474981257716009, self.slope: [1.08951095 1.09026294], self.intercept: 1.0080244146395045\n",
      "iteration - 8959 -> loss: 0.00024748645823414295, self.slope: [1.08951852 1.09027061], self.intercept: 1.0080251363251442\n",
      "iteration - 8960 -> loss: 0.00024747479183087005, self.slope: [1.08952608 1.09027828], self.intercept: 1.008025857982403\n",
      "iteration - 8961 -> loss: 0.00024746312656161065, self.slope: [1.08953365 1.09028595], self.intercept: 1.0080265796112844\n",
      "iteration - 8962 -> loss: 0.00024745146242620094, self.slope: [1.08954122 1.09029362], self.intercept: 1.0080273012117897\n",
      "iteration - 8963 -> loss: 0.00024743979942445894, self.slope: [1.08954879 1.09030129], self.intercept: 1.008028022783922\n",
      "iteration - 8964 -> loss: 0.00024742813755623604, self.slope: [1.08955636 1.09030896], self.intercept: 1.0080287443276832\n",
      "iteration - 8965 -> loss: 0.0002474164768213578, self.slope: [1.08956393 1.09031662], self.intercept: 1.008029465843076\n",
      "iteration - 8966 -> loss: 0.0002474048172196493, self.slope: [1.08957149 1.09032429], self.intercept: 1.0080301873301025\n",
      "iteration - 8967 -> loss: 0.00024739315875095134, self.slope: [1.08957906 1.09033196], self.intercept: 1.0080309087887673\n",
      "iteration - 8968 -> loss: 0.0002473815014150969, self.slope: [1.08958663 1.09033963], self.intercept: 1.00803163021907\n",
      "iteration - 8969 -> loss: 0.0002473698452119128, self.slope: [1.08959419 1.0903473 ], self.intercept: 1.0080323516210146\n",
      "iteration - 8970 -> loss: 0.0002473581901412359, self.slope: [1.08960176 1.09035496], self.intercept: 1.008033072994603\n",
      "iteration - 8971 -> loss: 0.0002473465362028982, self.slope: [1.08960933 1.09036263], self.intercept: 1.008033794339837\n",
      "iteration - 8972 -> loss: 0.00024733488339675943, self.slope: [1.08961689 1.0903703 ], self.intercept: 1.00803451565672\n",
      "iteration - 8973 -> loss: 0.0002473232317225961, self.slope: [1.08962446 1.09037796], self.intercept: 1.0080352369452525\n",
      "iteration - 8974 -> loss: 0.0002473115811802857, self.slope: [1.08963202 1.09038563], self.intercept: 1.0080359582054395\n",
      "iteration - 8975 -> loss: 0.00024729993176964764, self.slope: [1.08963958 1.09039329], self.intercept: 1.0080366794372815\n",
      "iteration - 8976 -> loss: 0.000247288283490503, self.slope: [1.08964715 1.09040096], self.intercept: 1.0080374006407835\n",
      "iteration - 8977 -> loss: 0.00024727663634271257, self.slope: [1.08965471 1.09040862], self.intercept: 1.008038121815945\n",
      "iteration - 8978 -> loss: 0.0002472649903260847, self.slope: [1.08966227 1.09041628], self.intercept: 1.008038842962772\n",
      "iteration - 8979 -> loss: 0.00024725334544047355, self.slope: [1.08966984 1.09042395], self.intercept: 1.008039564081263\n",
      "iteration - 8980 -> loss: 0.0002472417016856916, self.slope: [1.0896774  1.09043161], self.intercept: 1.008040285171423\n",
      "iteration - 8981 -> loss: 0.0002472300590615863, self.slope: [1.08968496 1.09043927], self.intercept: 1.0080410062332514\n",
      "iteration - 8982 -> loss: 0.0002472184175679828, self.slope: [1.08969252 1.09044694], self.intercept: 1.0080417272667535\n",
      "iteration - 8983 -> loss: 0.000247206777204727, self.slope: [1.08970008 1.0904546 ], self.intercept: 1.0080424482719306\n",
      "iteration - 8984 -> loss: 0.00024719513797162444, self.slope: [1.08970764 1.09046226], self.intercept: 1.0080431692487857\n",
      "iteration - 8985 -> loss: 0.00024718349986853106, self.slope: [1.08971521 1.09046992], self.intercept: 1.0080438901973203\n",
      "iteration - 8986 -> loss: 0.0002471718628952702, self.slope: [1.08972277 1.09047758], self.intercept: 1.0080446111175378\n",
      "iteration - 8987 -> loss: 0.00024716022705169695, self.slope: [1.08973032 1.09048524], self.intercept: 1.0080453320094407\n",
      "iteration - 8988 -> loss: 0.0002471485923376207, self.slope: [1.08973788 1.0904929 ], self.intercept: 1.0080460528730304\n",
      "iteration - 8989 -> loss: 0.00024713695875289404, self.slope: [1.08974544 1.09050056], self.intercept: 1.0080467737083103\n",
      "iteration - 8990 -> loss: 0.0002471253262973196, self.slope: [1.089753   1.09050822], self.intercept: 1.0080474945152824\n",
      "iteration - 8991 -> loss: 0.00024711369497076825, self.slope: [1.08976056 1.09051588], self.intercept: 1.008048215293949\n",
      "iteration - 8992 -> loss: 0.0002471020647730497, self.slope: [1.08976812 1.09052354], self.intercept: 1.0080489360443128\n",
      "iteration - 8993 -> loss: 0.0002470904357040055, self.slope: [1.08977567 1.0905312 ], self.intercept: 1.008049656766374\n",
      "iteration - 8994 -> loss: 0.00024707880776345397, self.slope: [1.08978323 1.09053886], self.intercept: 1.0080503774601384\n",
      "iteration - 8995 -> loss: 0.00024706718095126516, self.slope: [1.08979079 1.09054652], self.intercept: 1.0080510981256081\n",
      "iteration - 8996 -> loss: 0.00024705555526723203, self.slope: [1.08979834 1.09055417], self.intercept: 1.0080518187627834\n",
      "iteration - 8997 -> loss: 0.0002470439307112259, self.slope: [1.0898059  1.09056183], self.intercept: 1.0080525393716682\n",
      "iteration - 8998 -> loss: 0.0002470323072830551, self.slope: [1.08981346 1.09056949], self.intercept: 1.0080532599522651\n",
      "iteration - 8999 -> loss: 0.00024702068498255394, self.slope: [1.08982101 1.09057714], self.intercept: 1.0080539805045752\n",
      "iteration - 9000 -> loss: 0.00024700906380956155, self.slope: [1.08982857 1.0905848 ], self.intercept: 1.0080547010286012\n",
      "iteration - 9001 -> loss: 0.0002469974437639072, self.slope: [1.08983612 1.09059245], self.intercept: 1.008055421524347\n",
      "iteration - 9002 -> loss: 0.0002469858248454444, self.slope: [1.08984367 1.09060011], self.intercept: 1.0080561419918153\n",
      "iteration - 9003 -> loss: 0.0002469742070539857, self.slope: [1.08985123 1.09060776], self.intercept: 1.0080568624310053\n",
      "iteration - 9004 -> loss: 0.0002469625903893714, self.slope: [1.08985878 1.09061542], self.intercept: 1.0080575828419205\n",
      "iteration - 9005 -> loss: 0.00024695097485143364, self.slope: [1.08986633 1.09062307], self.intercept: 1.0080583032245656\n",
      "iteration - 9006 -> loss: 0.00024693936044001974, self.slope: [1.08987389 1.09063073], self.intercept: 1.0080590235789406\n",
      "iteration - 9007 -> loss: 0.0002469277471549484, self.slope: [1.08988144 1.09063838], self.intercept: 1.0080597439050487\n",
      "iteration - 9008 -> loss: 0.0002469161349960383, self.slope: [1.08988899 1.09064603], self.intercept: 1.0080604642028934\n",
      "iteration - 9009 -> loss: 0.00024690452396319016, self.slope: [1.08989654 1.09065368], self.intercept: 1.008061184472476\n",
      "iteration - 9010 -> loss: 0.00024689291405615257, self.slope: [1.08990409 1.09066134], self.intercept: 1.0080619047137984\n",
      "iteration - 9011 -> loss: 0.00024688130527481363, self.slope: [1.08991164 1.09066899], self.intercept: 1.008062624926864\n",
      "iteration - 9012 -> loss: 0.00024686969761899153, self.slope: [1.08991919 1.09067664], self.intercept: 1.008063345111675\n",
      "iteration - 9013 -> loss: 0.0002468580910885101, self.slope: [1.08992674 1.09068429], self.intercept: 1.0080640652682331\n",
      "iteration - 9014 -> loss: 0.00024684648568323576, self.slope: [1.08993429 1.09069194], self.intercept: 1.0080647853965414\n",
      "iteration - 9015 -> loss: 0.0002468348814029834, self.slope: [1.08994184 1.09069959], self.intercept: 1.0080655054966021\n",
      "iteration - 9016 -> loss: 0.0002468232782475767, self.slope: [1.08994939 1.09070724], self.intercept: 1.0080662255684192\n",
      "iteration - 9017 -> loss: 0.0002468116762168602, self.slope: [1.08995694 1.09071489], self.intercept: 1.008066945611992\n",
      "iteration - 9018 -> loss: 0.00024680007531065754, self.slope: [1.08996449 1.09072254], self.intercept: 1.008067665627324\n",
      "iteration - 9019 -> loss: 0.0002467884755288292, self.slope: [1.08997204 1.09073019], self.intercept: 1.008068385614419\n",
      "iteration - 9020 -> loss: 0.0002467768768712015, self.slope: [1.08997958 1.09073784], self.intercept: 1.0080691055732773\n",
      "iteration - 9021 -> loss: 0.0002467652793375764, self.slope: [1.08998713 1.09074549], self.intercept: 1.0080698255039044\n",
      "iteration - 9022 -> loss: 0.0002467536829278347, self.slope: [1.08999468 1.09075313], self.intercept: 1.0080705454062995\n",
      "iteration - 9023 -> loss: 0.00024674208764178634, self.slope: [1.09000222 1.09076078], self.intercept: 1.008071265280467\n",
      "iteration - 9024 -> loss: 0.00024673049347926967, self.slope: [1.09000977 1.09076843], self.intercept: 1.0080719851264084\n",
      "iteration - 9025 -> loss: 0.0002467189004401198, self.slope: [1.09001732 1.09077607], self.intercept: 1.0080727049441278\n",
      "iteration - 9026 -> loss: 0.000246707308524168, self.slope: [1.09002486 1.09078372], self.intercept: 1.0080734247336256\n",
      "iteration - 9027 -> loss: 0.00024669571773126674, self.slope: [1.09003241 1.09079137], self.intercept: 1.0080741444949053\n",
      "iteration - 9028 -> loss: 0.00024668412806122373, self.slope: [1.09003995 1.09079901], self.intercept: 1.0080748642279684\n",
      "iteration - 9029 -> loss: 0.0002466725395138876, self.slope: [1.09004749 1.09080666], self.intercept: 1.008075583932817\n",
      "iteration - 9030 -> loss: 0.0002466609520890858, self.slope: [1.09005504 1.0908143 ], self.intercept: 1.008076303609454\n",
      "iteration - 9031 -> loss: 0.00024664936578667573, self.slope: [1.09006258 1.09082195], self.intercept: 1.008077023257883\n",
      "iteration - 9032 -> loss: 0.0002466377806064593, self.slope: [1.09007012 1.09082959], self.intercept: 1.008077742878106\n",
      "iteration - 9033 -> loss: 0.0002466261965483051, self.slope: [1.09007767 1.09083723], self.intercept: 1.0080784624701233\n",
      "iteration - 9034 -> loss: 0.0002466146136120173, self.slope: [1.09008521 1.09084488], self.intercept: 1.0080791820339392\n",
      "iteration - 9035 -> loss: 0.0002466030317974591, self.slope: [1.09009275 1.09085252], self.intercept: 1.0080799015695552\n",
      "iteration - 9036 -> loss: 0.00024659145110444096, self.slope: [1.09010029 1.09086016], self.intercept: 1.0080806210769755\n",
      "iteration - 9037 -> loss: 0.0002465798715328073, self.slope: [1.09010783 1.0908678 ], self.intercept: 1.0080813405562001\n",
      "iteration - 9038 -> loss: 0.00024656829308239875, self.slope: [1.09011538 1.09087545], self.intercept: 1.0080820600072344\n",
      "iteration - 9039 -> loss: 0.00024655671575303295, self.slope: [1.09012292 1.09088309], self.intercept: 1.0080827794300777\n",
      "iteration - 9040 -> loss: 0.0002465451395445682, self.slope: [1.09013046 1.09089073], self.intercept: 1.0080834988247347\n",
      "iteration - 9041 -> loss: 0.00024653356445684444, self.slope: [1.090138   1.09089837], self.intercept: 1.0080842181912062\n",
      "iteration - 9042 -> loss: 0.00024652199048966124, self.slope: [1.09014553 1.09090601], self.intercept: 1.0080849375294951\n",
      "iteration - 9043 -> loss: 0.00024651041764288184, self.slope: [1.09015307 1.09091365], self.intercept: 1.008085656839603\n",
      "iteration - 9044 -> loss: 0.0002464988459163389, self.slope: [1.09016061 1.09092129], self.intercept: 1.0080863761215322\n",
      "iteration - 9045 -> loss: 0.000246487275309869, self.slope: [1.09016815 1.09092893], self.intercept: 1.0080870953752872\n",
      "iteration - 9046 -> loss: 0.00024647570582327956, self.slope: [1.09017569 1.09093657], self.intercept: 1.0080878146008694\n",
      "iteration - 9047 -> loss: 0.0002464641374564626, self.slope: [1.09018323 1.09094421], self.intercept: 1.0080885337982814\n",
      "iteration - 9048 -> loss: 0.0002464525702091867, self.slope: [1.09019076 1.09095184], self.intercept: 1.008089252967525\n",
      "iteration - 9049 -> loss: 0.00024644100408132905, self.slope: [1.0901983  1.09095948], self.intercept: 1.0080899721086027\n",
      "iteration - 9050 -> loss: 0.00024642943907272853, self.slope: [1.09020584 1.09096712], self.intercept: 1.008090691221519\n",
      "iteration - 9051 -> loss: 0.00024641787518320127, self.slope: [1.09021337 1.09097476], self.intercept: 1.0080914103062721\n",
      "iteration - 9052 -> loss: 0.000246406312412593, self.slope: [1.09022091 1.09098239], self.intercept: 1.0080921293628666\n",
      "iteration - 9053 -> loss: 0.0002463947507607061, self.slope: [1.09022844 1.09099003], self.intercept: 1.0080928483913056\n",
      "iteration - 9054 -> loss: 0.00024638319022744185, self.slope: [1.09023598 1.09099767], self.intercept: 1.0080935673915907\n",
      "iteration - 9055 -> loss: 0.0002463716308125874, self.slope: [1.09024351 1.0910053 ], self.intercept: 1.0080942863637237\n",
      "iteration - 9056 -> loss: 0.0002463600725159871, self.slope: [1.09025105 1.09101294], self.intercept: 1.0080950053077087\n",
      "iteration - 9057 -> loss: 0.0002463485153374971, self.slope: [1.09025858 1.09102057], self.intercept: 1.0080957242235473\n",
      "iteration - 9058 -> loss: 0.0002463369592769262, self.slope: [1.09026611 1.09102821], self.intercept: 1.008096443111242\n",
      "iteration - 9059 -> loss: 0.00024632540433411625, self.slope: [1.09027365 1.09103584], self.intercept: 1.008097161970794\n",
      "iteration - 9060 -> loss: 0.0002463138505089192, self.slope: [1.09028118 1.09104347], self.intercept: 1.008097880802207\n",
      "iteration - 9061 -> loss: 0.0002463022978011535, self.slope: [1.09028871 1.09105111], self.intercept: 1.0080985996054828\n",
      "iteration - 9062 -> loss: 0.0002462907462106591, self.slope: [1.09029624 1.09105874], self.intercept: 1.0080993183806248\n",
      "iteration - 9063 -> loss: 0.0002462791957372752, self.slope: [1.09030377 1.09106637], self.intercept: 1.008100037127634\n",
      "iteration - 9064 -> loss: 0.0002462676463808387, self.slope: [1.09031131 1.09107401], self.intercept: 1.0081007558465134\n",
      "iteration - 9065 -> loss: 0.0002462560981411857, self.slope: [1.09031884 1.09108164], self.intercept: 1.0081014745372654\n",
      "iteration - 9066 -> loss: 0.0002462445510181327, self.slope: [1.09032637 1.09108927], self.intercept: 1.0081021931998917\n",
      "iteration - 9067 -> loss: 0.00024623300501154814, self.slope: [1.0903339 1.0910969], self.intercept: 1.0081029118343965\n",
      "iteration - 9068 -> loss: 0.0002462214601212461, self.slope: [1.09034143 1.09110453], self.intercept: 1.0081036304407804\n",
      "iteration - 9069 -> loss: 0.0002462099163470832, self.slope: [1.09034896 1.09111216], self.intercept: 1.008104349019046\n",
      "iteration - 9070 -> loss: 0.00024619837368886337, self.slope: [1.09035649 1.09111979], self.intercept: 1.0081050675691963\n",
      "iteration - 9071 -> loss: 0.00024618683214645744, self.slope: [1.09036401 1.09112742], self.intercept: 1.0081057860912346\n",
      "iteration - 9072 -> loss: 0.0002461752917196807, self.slope: [1.09037154 1.09113505], self.intercept: 1.008106504585163\n",
      "iteration - 9073 -> loss: 0.00024616375240835836, self.slope: [1.09037907 1.09114268], self.intercept: 1.0081072230509813\n",
      "iteration - 9074 -> loss: 0.0002461522142123568, self.slope: [1.0903866  1.09115031], self.intercept: 1.0081079414886944\n",
      "iteration - 9075 -> loss: 0.0002461406771315047, self.slope: [1.09039413 1.09115794], self.intercept: 1.008108659898305\n",
      "iteration - 9076 -> loss: 0.00024612914116561494, self.slope: [1.09040165 1.09116556], self.intercept: 1.0081093782798132\n",
      "iteration - 9077 -> loss: 0.00024611760631455294, self.slope: [1.09040918 1.09117319], self.intercept: 1.0081100966332235\n",
      "iteration - 9078 -> loss: 0.00024610607257814933, self.slope: [1.0904167  1.09118082], self.intercept: 1.0081108149585358\n",
      "iteration - 9079 -> loss: 0.0002460945399562227, self.slope: [1.09042423 1.09118845], self.intercept: 1.0081115332557555\n",
      "iteration - 9080 -> loss: 0.00024608300844861623, self.slope: [1.09043176 1.09119607], self.intercept: 1.008112251524884\n",
      "iteration - 9081 -> loss: 0.00024607147805517823, self.slope: [1.09043928 1.0912037 ], self.intercept: 1.0081129697659232\n",
      "iteration - 9082 -> loss: 0.0002460599487757377, self.slope: [1.09044681 1.09121132], self.intercept: 1.0081136879788744\n",
      "iteration - 9083 -> loss: 0.0002460484206101307, self.slope: [1.09045433 1.09121895], self.intercept: 1.0081144061637408\n",
      "iteration - 9084 -> loss: 0.0002460368935582003, self.slope: [1.09046185 1.09122657], self.intercept: 1.0081151243205262\n",
      "iteration - 9085 -> loss: 0.00024602536761976176, self.slope: [1.09046938 1.0912342 ], self.intercept: 1.0081158424492318\n",
      "iteration - 9086 -> loss: 0.0002460138427946837, self.slope: [1.0904769  1.09124182], self.intercept: 1.0081165605498603\n",
      "iteration - 9087 -> loss: 0.00024600231908278265, self.slope: [1.09048442 1.09124945], self.intercept: 1.008117278622414\n",
      "iteration - 9088 -> loss: 0.00024599079648389356, self.slope: [1.09049195 1.09125707], self.intercept: 1.0081179966668958\n",
      "iteration - 9089 -> loss: 0.00024597927499786504, self.slope: [1.09049947 1.09126469], self.intercept: 1.0081187146833066\n",
      "iteration - 9090 -> loss: 0.0002459677546245147, self.slope: [1.09050699 1.09127232], self.intercept: 1.0081194326716505\n",
      "iteration - 9091 -> loss: 0.00024595623536369997, self.slope: [1.09051451 1.09127994], self.intercept: 1.008120150631929\n",
      "iteration - 9092 -> loss: 0.00024594471721526504, self.slope: [1.09052203 1.09128756], self.intercept: 1.0081208685641443\n",
      "iteration - 9093 -> loss: 0.00024593320017901723, self.slope: [1.09052955 1.09129518], self.intercept: 1.0081215864683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 9094 -> loss: 0.0002459216842548132, self.slope: [1.09053707 1.0913028 ], self.intercept: 1.0081223043443963\n",
      "iteration - 9095 -> loss: 0.0002459101694424825, self.slope: [1.09054459 1.09131043], self.intercept: 1.0081230221924362\n",
      "iteration - 9096 -> loss: 0.00024589865574186785, self.slope: [1.09055211 1.09131805], self.intercept: 1.0081237400124228\n",
      "iteration - 9097 -> loss: 0.00024588714315279927, self.slope: [1.09055963 1.09132567], self.intercept: 1.0081244578043593\n",
      "iteration - 9098 -> loss: 0.00024587563167511754, self.slope: [1.09056715 1.09133329], self.intercept: 1.008125175568247\n",
      "iteration - 9099 -> loss: 0.00024586412130866704, self.slope: [1.09057467 1.09134091], self.intercept: 1.0081258933040893\n",
      "iteration - 9100 -> loss: 0.00024585261205326453, self.slope: [1.09058219 1.09134852], self.intercept: 1.0081266110118876\n",
      "iteration - 9101 -> loss: 0.00024584110390877374, self.slope: [1.0905897  1.09135614], self.intercept: 1.0081273286916448\n",
      "iteration - 9102 -> loss: 0.00024582959687500855, self.slope: [1.09059722 1.09136376], self.intercept: 1.0081280463433624\n",
      "iteration - 9103 -> loss: 0.0002458180909518174, self.slope: [1.09060474 1.09137138], self.intercept: 1.0081287639670429\n",
      "iteration - 9104 -> loss: 0.0002458065861390358, self.slope: [1.09061225 1.091379  ], self.intercept: 1.008129481562689\n",
      "iteration - 9105 -> loss: 0.00024579508243651333, self.slope: [1.09061977 1.09138662], self.intercept: 1.008130199130303\n",
      "iteration - 9106 -> loss: 0.00024578357984405424, self.slope: [1.09062729 1.09139423], self.intercept: 1.0081309166698877\n",
      "iteration - 9107 -> loss: 0.0002457720783615247, self.slope: [1.0906348  1.09140185], self.intercept: 1.0081316341814457\n",
      "iteration - 9108 -> loss: 0.00024576057798875894, self.slope: [1.09064232 1.09140946], self.intercept: 1.0081323516649792\n",
      "iteration - 9109 -> loss: 0.0002457490787255988, self.slope: [1.09064983 1.09141708], self.intercept: 1.0081330691204897\n",
      "iteration - 9110 -> loss: 0.00024573758057185973, self.slope: [1.09065735 1.0914247 ], self.intercept: 1.0081337865479805\n",
      "iteration - 9111 -> loss: 0.0002457260835273958, self.slope: [1.09066486 1.09143231], self.intercept: 1.0081345039474534\n",
      "iteration - 9112 -> loss: 0.00024571458759205, self.slope: [1.09067237 1.09143993], self.intercept: 1.0081352213189114\n",
      "iteration - 9113 -> loss: 0.0002457030927656209, self.slope: [1.09067989 1.09144754], self.intercept: 1.008135938662357\n",
      "iteration - 9114 -> loss: 0.00024569159904799933, self.slope: [1.0906874  1.09145515], self.intercept: 1.008136655977791\n",
      "iteration - 9115 -> loss: 0.00024568010643898476, self.slope: [1.09069491 1.09146277], self.intercept: 1.0081373732652166\n",
      "iteration - 9116 -> loss: 0.0002456686149384485, self.slope: [1.09070242 1.09147038], self.intercept: 1.0081380905246375\n",
      "iteration - 9117 -> loss: 0.00024565712454620113, self.slope: [1.09070994 1.09147799], self.intercept: 1.0081388077560551\n",
      "iteration - 9118 -> loss: 0.00024564563526208443, self.slope: [1.09071745 1.09148561], self.intercept: 1.0081395249594711\n",
      "iteration - 9119 -> loss: 0.0002456341470859447, self.slope: [1.09072496 1.09149322], self.intercept: 1.0081402421348882\n",
      "iteration - 9120 -> loss: 0.00024562266001761096, self.slope: [1.09073247 1.09150083], self.intercept: 1.008140959282309\n",
      "iteration - 9121 -> loss: 0.0002456111740569258, self.slope: [1.09073998 1.09150844], self.intercept: 1.008141676401737\n",
      "iteration - 9122 -> loss: 0.0002455996892037246, self.slope: [1.09074749 1.09151605], self.intercept: 1.0081423934931721\n",
      "iteration - 9123 -> loss: 0.0002455882054578439, self.slope: [1.090755   1.09152366], self.intercept: 1.0081431105566192\n",
      "iteration - 9124 -> loss: 0.00024557672281912314, self.slope: [1.09076251 1.09153127], self.intercept: 1.0081438275920787\n",
      "iteration - 9125 -> loss: 0.0002455652412874244, self.slope: [1.09077002 1.09153888], self.intercept: 1.0081445445995538\n",
      "iteration - 9126 -> loss: 0.00024555376086254866, self.slope: [1.09077753 1.09154649], self.intercept: 1.0081452615790476\n",
      "iteration - 9127 -> loss: 0.0002455422815443339, self.slope: [1.09078503 1.0915541 ], self.intercept: 1.0081459785305618\n",
      "iteration - 9128 -> loss: 0.00024553080333264735, self.slope: [1.09079254 1.09156171], self.intercept: 1.0081466954540974\n",
      "iteration - 9129 -> loss: 0.00024551932622731456, self.slope: [1.09080005 1.09156932], self.intercept: 1.0081474123496594\n",
      "iteration - 9130 -> loss: 0.0002455078502281648, self.slope: [1.09080756 1.09157693], self.intercept: 1.0081481292172485\n",
      "iteration - 9131 -> loss: 0.0002454963753350458, self.slope: [1.09081506 1.09158454], self.intercept: 1.0081488460568688\n",
      "iteration - 9132 -> loss: 0.0002454849015477959, self.slope: [1.09082257 1.09159214], self.intercept: 1.0081495628685206\n",
      "iteration - 9133 -> loss: 0.00024547342886623117, self.slope: [1.09083007 1.09159975], self.intercept: 1.008150279652207\n",
      "iteration - 9134 -> loss: 0.0002454619572902269, self.slope: [1.09083758 1.09160736], self.intercept: 1.00815099640793\n",
      "iteration - 9135 -> loss: 0.00024545048681960587, self.slope: [1.09084509 1.09161497], self.intercept: 1.0081517131356932\n",
      "iteration - 9136 -> loss: 0.00024543901745419143, self.slope: [1.09085259 1.09162257], self.intercept: 1.0081524298354962\n",
      "iteration - 9137 -> loss: 0.000245427549193834, self.slope: [1.09086009 1.09163018], self.intercept: 1.0081531465073448\n",
      "iteration - 9138 -> loss: 0.00024541608203837255, self.slope: [1.0908676  1.09163778], self.intercept: 1.0081538631512403\n",
      "iteration - 9139 -> loss: 0.00024540461598766226, self.slope: [1.0908751  1.09164539], self.intercept: 1.008154579767185\n",
      "iteration - 9140 -> loss: 0.0002453931510414942, self.slope: [1.09088261 1.09165299], self.intercept: 1.0081552963551794\n",
      "iteration - 9141 -> loss: 0.0002453816871997539, self.slope: [1.09089011 1.0916606 ], self.intercept: 1.0081560129152283\n",
      "iteration - 9142 -> loss: 0.0002453702244622628, self.slope: [1.09089761 1.0916682 ], self.intercept: 1.0081567294473333\n",
      "iteration - 9143 -> loss: 0.0002453587628288584, self.slope: [1.09090511 1.0916758 ], self.intercept: 1.0081574459514966\n",
      "iteration - 9144 -> loss: 0.00024534730229937366, self.slope: [1.09091262 1.09168341], self.intercept: 1.0081581624277194\n",
      "iteration - 9145 -> loss: 0.00024533584287366036, self.slope: [1.09092012 1.09169101], self.intercept: 1.0081588788760059\n",
      "iteration - 9146 -> loss: 0.0002453243845515415, self.slope: [1.09092762 1.09169861], self.intercept: 1.0081595952963562\n",
      "iteration - 9147 -> loss: 0.00024531292733286374, self.slope: [1.09093512 1.09170621], self.intercept: 1.0081603116887758\n",
      "iteration - 9148 -> loss: 0.00024530147121748757, self.slope: [1.09094262 1.09171381], self.intercept: 1.0081610280532654\n",
      "iteration - 9149 -> loss: 0.00024529001620520174, self.slope: [1.09095012 1.09172142], self.intercept: 1.008161744389828\n",
      "iteration - 9150 -> loss: 0.0002452785622958751, self.slope: [1.09095762 1.09172902], self.intercept: 1.0081624606984647\n",
      "iteration - 9151 -> loss: 0.00024526710948935917, self.slope: [1.09096512 1.09173662], self.intercept: 1.0081631769791792\n",
      "iteration - 9152 -> loss: 0.00024525565778547024, self.slope: [1.09097262 1.09174422], self.intercept: 1.0081638932319736\n",
      "iteration - 9153 -> loss: 0.00024524420718405955, self.slope: [1.09098012 1.09175182], self.intercept: 1.0081646094568495\n",
      "iteration - 9154 -> loss: 0.000245232757684952, self.slope: [1.09098761 1.09175942], self.intercept: 1.0081653256538103\n",
      "iteration - 9155 -> loss: 0.00024522130928801295, self.slope: [1.09099511 1.09176702], self.intercept: 1.0081660418228595\n",
      "iteration - 9156 -> loss: 0.0002452098619930588, self.slope: [1.09100261 1.09177462], self.intercept: 1.0081667579639961\n",
      "iteration - 9157 -> loss: 0.0002451984157999272, self.slope: [1.09101011 1.09178221], self.intercept: 1.008167474077224\n",
      "iteration - 9158 -> loss: 0.00024518697070846987, self.slope: [1.0910176  1.09178981], self.intercept: 1.0081681901625457\n",
      "iteration - 9159 -> loss: 0.00024517552671850864, self.slope: [1.0910251  1.09179741], self.intercept: 1.0081689062199637\n",
      "iteration - 9160 -> loss: 0.0002451640838299178, self.slope: [1.0910326  1.09180501], self.intercept: 1.00816962224948\n",
      "iteration - 9161 -> loss: 0.00024515264204249935, self.slope: [1.09104009 1.0918126 ], self.intercept: 1.008170338251098\n",
      "iteration - 9162 -> loss: 0.00024514120135609395, self.slope: [1.09104759 1.0918202 ], self.intercept: 1.008171054224818\n",
      "iteration - 9163 -> loss: 0.00024512976177055486, self.slope: [1.09105508 1.0918278 ], self.intercept: 1.0081717701706445\n",
      "iteration - 9164 -> loss: 0.0002451183232857258, self.slope: [1.09106258 1.09183539], self.intercept: 1.0081724860885777\n",
      "iteration - 9165 -> loss: 0.0002451068859014378, self.slope: [1.09107007 1.09184299], self.intercept: 1.0081732019786234\n",
      "iteration - 9166 -> loss: 0.000245095449617533, self.slope: [1.09107757 1.09185058], self.intercept: 1.0081739178407803\n",
      "iteration - 9167 -> loss: 0.0002450840144338342, self.slope: [1.09108506 1.09185818], self.intercept: 1.008174633675053\n",
      "iteration - 9168 -> loss: 0.00024507258035022105, self.slope: [1.09109255 1.09186577], self.intercept: 1.008175349481444\n",
      "iteration - 9169 -> loss: 0.00024506114736648705, self.slope: [1.09110005 1.09187337], self.intercept: 1.0081760652599538\n",
      "iteration - 9170 -> loss: 0.00024504971548250224, self.slope: [1.09110754 1.09188096], self.intercept: 1.0081767810105848\n",
      "iteration - 9171 -> loss: 0.000245038284698096, self.slope: [1.09111503 1.09188855], self.intercept: 1.0081774967333414\n",
      "iteration - 9172 -> loss: 0.0002450268550130828, self.slope: [1.09112252 1.09189615], self.intercept: 1.0081782124282255\n",
      "iteration - 9173 -> loss: 0.00024501542642735297, self.slope: [1.09113001 1.09190374], self.intercept: 1.008178928095238\n",
      "iteration - 9174 -> loss: 0.00024500399894071616, self.slope: [1.0911375  1.09191133], self.intercept: 1.0081796437343817\n",
      "iteration - 9175 -> loss: 0.00024499257255300845, self.slope: [1.09114499 1.09191892], self.intercept: 1.0081803593456606\n",
      "iteration - 9176 -> loss: 0.00024498114726408305, self.slope: [1.09115249 1.09192651], self.intercept: 1.0081810749290758\n",
      "iteration - 9177 -> loss: 0.0002449697230737583, self.slope: [1.09115997 1.09193411], self.intercept: 1.0081817904846289\n",
      "iteration - 9178 -> loss: 0.0002449582999818976, self.slope: [1.09116746 1.0919417 ], self.intercept: 1.008182506012324\n",
      "iteration - 9179 -> loss: 0.00024494687798832035, self.slope: [1.09117495 1.09194929], self.intercept: 1.008183221512161\n",
      "iteration - 9180 -> loss: 0.00024493545709287993, self.slope: [1.09118244 1.09195688], self.intercept: 1.0081839369841457\n",
      "iteration - 9181 -> loss: 0.000244924037295428, self.slope: [1.09118993 1.09196447], self.intercept: 1.0081846524282783\n",
      "iteration - 9182 -> loss: 0.0002449126185957797, self.slope: [1.09119742 1.09197206], self.intercept: 1.0081853678445614\n",
      "iteration - 9183 -> loss: 0.0002449012009937786, self.slope: [1.09120491 1.09197964], self.intercept: 1.0081860832329952\n",
      "iteration - 9184 -> loss: 0.00024488978448927934, self.slope: [1.09121239 1.09198723], self.intercept: 1.008186798593585\n",
      "iteration - 9185 -> loss: 0.0002448783690821042, self.slope: [1.09121988 1.09199482], self.intercept: 1.0081875139263328\n",
      "iteration - 9186 -> loss: 0.00024486695477209173, self.slope: [1.09122737 1.09200241], self.intercept: 1.0081882292312416\n",
      "iteration - 9187 -> loss: 0.00024485554155911156, self.slope: [1.09123485 1.09201   ], self.intercept: 1.0081889445083119\n",
      "iteration - 9188 -> loss: 0.00024484412944297465, self.slope: [1.09124234 1.09201758], self.intercept: 1.008189659757547\n",
      "iteration - 9189 -> loss: 0.0002448327184235282, self.slope: [1.09124983 1.09202517], self.intercept: 1.008190374978948\n",
      "iteration - 9190 -> loss: 0.00024482130850060987, self.slope: [1.09125731 1.09203276], self.intercept: 1.0081910901725182\n",
      "iteration - 9191 -> loss: 0.0002448098996740682, self.slope: [1.0912648  1.09204034], self.intercept: 1.0081918053382615\n",
      "iteration - 9192 -> loss: 0.0002447984919437464, self.slope: [1.09127228 1.09204793], self.intercept: 1.0081925204761777\n",
      "iteration - 9193 -> loss: 0.0002447870853094583, self.slope: [1.09127976 1.09205551], self.intercept: 1.008193235586271\n",
      "iteration - 9194 -> loss: 0.0002447756797710717, self.slope: [1.09128725 1.0920631 ], self.intercept: 1.0081939506685431\n",
      "iteration - 9195 -> loss: 0.00024476427532842403, self.slope: [1.09129473 1.09207068], self.intercept: 1.008194665722995\n",
      "iteration - 9196 -> loss: 0.000244752871981337, self.slope: [1.09130221 1.09207827], self.intercept: 1.0081953807496313\n",
      "iteration - 9197 -> loss: 0.0002447414697296638, self.slope: [1.0913097  1.09208585], self.intercept: 1.008196095748454\n",
      "iteration - 9198 -> loss: 0.00024473006857325186, self.slope: [1.09131718 1.09209344], self.intercept: 1.0081968107194637\n",
      "iteration - 9199 -> loss: 0.00024471866851192664, self.slope: [1.09132466 1.09210102], self.intercept: 1.0081975256626639\n",
      "iteration - 9200 -> loss: 0.00024470726954553974, self.slope: [1.09133214 1.0921086 ], self.intercept: 1.0081982405780578\n",
      "iteration - 9201 -> loss: 0.0002446958716739131, self.slope: [1.09133962 1.09211618], self.intercept: 1.0081989554656476\n",
      "iteration - 9202 -> loss: 0.00024468447489691124, self.slope: [1.0913471  1.09212377], self.intercept: 1.008199670325434\n",
      "iteration - 9203 -> loss: 0.00024467307921436135, self.slope: [1.09135459 1.09213135], self.intercept: 1.0082003851574193\n",
      "iteration - 9204 -> loss: 0.00024466168462610084, self.slope: [1.09136207 1.09213893], self.intercept: 1.0082010999616078\n",
      "iteration - 9205 -> loss: 0.00024465029113198523, self.slope: [1.09136955 1.09214651], self.intercept: 1.008201814738001\n",
      "iteration - 9206 -> loss: 0.00024463889873183855, self.slope: [1.09137702 1.09215409], self.intercept: 1.0082025294866015\n",
      "iteration - 9207 -> loss: 0.00024462750742550816, self.slope: [1.0913845  1.09216167], self.intercept: 1.00820324420741\n",
      "iteration - 9208 -> loss: 0.00024461611721283754, self.slope: [1.09139198 1.09216925], self.intercept: 1.0082039589004306\n",
      "iteration - 9209 -> loss: 0.00024460472809366375, self.slope: [1.09139946 1.09217683], self.intercept: 1.0082046735656653\n",
      "iteration - 9210 -> loss: 0.000244593340067833, self.slope: [1.09140694 1.09218441], self.intercept: 1.0082053882031177\n",
      "iteration - 9211 -> loss: 0.0002445819531351653, self.slope: [1.09141442 1.09219199], self.intercept: 1.0082061028127889\n",
      "iteration - 9212 -> loss: 0.00024457056729551823, self.slope: [1.09142189 1.09219957], self.intercept: 1.0082068173946797\n",
      "iteration - 9213 -> loss: 0.0002445591825487424, self.slope: [1.09142937 1.09220715], self.intercept: 1.0082075319487926\n",
      "iteration - 9214 -> loss: 0.00024454779889465303, self.slope: [1.09143685 1.09221472], self.intercept: 1.0082082464751339\n",
      "iteration - 9215 -> loss: 0.0002445364163331147, self.slope: [1.09144432 1.0922223 ], self.intercept: 1.0082089609737033\n",
      "iteration - 9216 -> loss: 0.0002445250348639576, self.slope: [1.0914518  1.09222988], self.intercept: 1.0082096754445027\n",
      "iteration - 9217 -> loss: 0.00024451365448702525, self.slope: [1.09145927 1.09223745], self.intercept: 1.0082103898875354\n",
      "iteration - 9218 -> loss: 0.0002445022752021504, self.slope: [1.09146675 1.09224503], self.intercept: 1.0082111043028017\n",
      "iteration - 9219 -> loss: 0.00024449089700917954, self.slope: [1.09147422 1.09225261], self.intercept: 1.0082118186903062\n",
      "iteration - 9220 -> loss: 0.00024447951990796355, self.slope: [1.0914817  1.09226018], self.intercept: 1.0082125330500507\n",
      "iteration - 9221 -> loss: 0.00024446814389831754, self.slope: [1.09148917 1.09226776], self.intercept: 1.0082132473820369\n",
      "iteration - 9222 -> loss: 0.0002444567689801147, self.slope: [1.09149665 1.09227533], self.intercept: 1.008213961686268\n",
      "iteration - 9223 -> loss: 0.00024444539515316993, self.slope: [1.09150412 1.09228291], self.intercept: 1.008214675962746\n",
      "iteration - 9224 -> loss: 0.0002444340224173381, self.slope: [1.09151159 1.09229048], self.intercept: 1.008215390211473\n",
      "iteration - 9225 -> loss: 0.0002444226507724507, self.slope: [1.09151906 1.09229805], self.intercept: 1.0082161044324511\n",
      "iteration - 9226 -> loss: 0.0002444112802183737, self.slope: [1.09152654 1.09230563], self.intercept: 1.0082168186256832\n",
      "iteration - 9227 -> loss: 0.000244399910754913, self.slope: [1.09153401 1.0923132 ], self.intercept: 1.008217532791172\n",
      "iteration - 9228 -> loss: 0.0002443885423819302, self.slope: [1.09154148 1.09232077], self.intercept: 1.0082182469289191\n",
      "iteration - 9229 -> loss: 0.00024437717509924743, self.slope: [1.09154895 1.09232835], self.intercept: 1.008218961038928\n",
      "iteration - 9230 -> loss: 0.0002443658089067544, self.slope: [1.09155642 1.09233592], self.intercept: 1.0082196751211983\n",
      "iteration - 9231 -> loss: 0.0002443544438042393, self.slope: [1.09156389 1.09234349], self.intercept: 1.008220389175735\n",
      "iteration - 9232 -> loss: 0.0002443430797915504, self.slope: [1.09157136 1.09235106], self.intercept: 1.0082211032025417\n",
      "iteration - 9233 -> loss: 0.00024433171686855516, self.slope: [1.09157883 1.09235863], self.intercept: 1.0082218172016177\n",
      "iteration - 9234 -> loss: 0.0002443203550350889, self.slope: [1.0915863 1.0923662], self.intercept: 1.0082225311729653\n",
      "iteration - 9235 -> loss: 0.00024430899429097935, self.slope: [1.09159377 1.09237377], self.intercept: 1.008223245116589\n",
      "iteration - 9236 -> loss: 0.00024429763463607577, self.slope: [1.09160124 1.09238134], self.intercept: 1.0082239590324893\n",
      "iteration - 9237 -> loss: 0.0002442862760701951, self.slope: [1.09160871 1.09238891], self.intercept: 1.0082246729206683\n",
      "iteration - 9238 -> loss: 0.0002442749185932251, self.slope: [1.09161617 1.09239648], self.intercept: 1.0082253867811306\n",
      "iteration - 9239 -> loss: 0.00024426356220496096, self.slope: [1.09162364 1.09240405], self.intercept: 1.0082261006138773\n",
      "iteration - 9240 -> loss: 0.0002442522069052925, self.slope: [1.09163111 1.09241162], self.intercept: 1.00822681441891\n",
      "iteration - 9241 -> loss: 0.0002442408526940238, self.slope: [1.09163858 1.09241919], self.intercept: 1.0082275281962327\n",
      "iteration - 9242 -> loss: 0.00024422949957101004, self.slope: [1.09164604 1.09242675], self.intercept: 1.0082282419458455\n",
      "iteration - 9243 -> loss: 0.00024421814753609124, self.slope: [1.09165351 1.09243432], self.intercept: 1.008228955667753\n",
      "iteration - 9244 -> loss: 0.0002442067965891075, self.slope: [1.09166097 1.09244189], self.intercept: 1.0082296693619572\n",
      "iteration - 9245 -> loss: 0.0002441954467299114, self.slope: [1.09166844 1.09244945], self.intercept: 1.0082303830284596\n",
      "iteration - 9246 -> loss: 0.00024418409795833035, self.slope: [1.0916759  1.09245702], self.intercept: 1.0082310966672623\n",
      "iteration - 9247 -> loss: 0.0002441727502741983, self.slope: [1.09168337 1.09246459], self.intercept: 1.008231810278367\n",
      "iteration - 9248 -> loss: 0.0002441614036773762, self.slope: [1.09169083 1.09247215], self.intercept: 1.0082325238617778\n",
      "iteration - 9249 -> loss: 0.00024415005816771153, self.slope: [1.0916983  1.09247972], self.intercept: 1.0082332374174956\n",
      "iteration - 9250 -> loss: 0.00024413871374502182, self.slope: [1.09170576 1.09248728], self.intercept: 1.0082339509455243\n",
      "iteration - 9251 -> loss: 0.00024412737040916077, self.slope: [1.09171322 1.09249485], self.intercept: 1.0082346644458635\n",
      "iteration - 9252 -> loss: 0.00024411602815996002, self.slope: [1.09172069 1.09250241], self.intercept: 1.0082353779185187\n",
      "iteration - 9253 -> loss: 0.0002441046869972999, self.slope: [1.09172815 1.09250997], self.intercept: 1.008236091363492\n",
      "iteration - 9254 -> loss: 0.00024409334692097317, self.slope: [1.09173561 1.09251754], self.intercept: 1.008236804780784\n",
      "iteration - 9255 -> loss: 0.0002440820079308414, self.slope: [1.09174307 1.0925251 ], self.intercept: 1.0082375181703978\n",
      "iteration - 9256 -> loss: 0.00024407067002674913, self.slope: [1.09175053 1.09253266], self.intercept: 1.0082382315323348\n",
      "iteration - 9257 -> loss: 0.0002440593332085586, self.slope: [1.09175799 1.09254023], self.intercept: 1.008238944866599\n",
      "iteration - 9258 -> loss: 0.00024404799747607196, self.slope: [1.09176545 1.09254779], self.intercept: 1.0082396581731916\n",
      "iteration - 9259 -> loss: 0.00024403666282915625, self.slope: [1.09177291 1.09255535], self.intercept: 1.0082403714521166\n",
      "iteration - 9260 -> loss: 0.0002440253292676371, self.slope: [1.09178037 1.09256291], self.intercept: 1.0082410847033736\n",
      "iteration - 9261 -> loss: 0.00024401399679137395, self.slope: [1.09178783 1.09257047], self.intercept: 1.0082417979269662\n",
      "iteration - 9262 -> loss: 0.00024400266540021567, self.slope: [1.09179529 1.09257803], self.intercept: 1.0082425111228972\n",
      "iteration - 9263 -> loss: 0.00024399133509397176, self.slope: [1.09180275 1.09258559], self.intercept: 1.0082432242911687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 9264 -> loss: 0.00024398000587250531, self.slope: [1.09181021 1.09259315], self.intercept: 1.008243937431783\n",
      "iteration - 9265 -> loss: 0.00024396867773567824, self.slope: [1.09181767 1.09260071], self.intercept: 1.0082446505447427\n",
      "iteration - 9266 -> loss: 0.00024395735068327134, self.slope: [1.09182513 1.09260827], self.intercept: 1.0082453636300504\n",
      "iteration - 9267 -> loss: 0.0002439460247151911, self.slope: [1.09183258 1.09261583], self.intercept: 1.0082460766877062\n",
      "iteration - 9268 -> loss: 0.00024393469983126945, self.slope: [1.09184004 1.09262339], self.intercept: 1.0082467897177154\n",
      "iteration - 9269 -> loss: 0.00024392337603132365, self.slope: [1.0918475  1.09263094], self.intercept: 1.0082475027200792\n",
      "iteration - 9270 -> loss: 0.00024391205331521156, self.slope: [1.09185495 1.0926385 ], self.intercept: 1.0082482156947972\n",
      "iteration - 9271 -> loss: 0.0002439007316827602, self.slope: [1.09186241 1.09264606], self.intercept: 1.0082489286418754\n",
      "iteration - 9272 -> loss: 0.00024388941113384413, self.slope: [1.09186986 1.09265362], self.intercept: 1.0082496415613142\n",
      "iteration - 9273 -> loss: 0.0002438780916682439, self.slope: [1.09187732 1.09266117], self.intercept: 1.0082503544531187\n",
      "iteration - 9274 -> loss: 0.00024386677328587964, self.slope: [1.09188477 1.09266873], self.intercept: 1.0082510673172882\n",
      "iteration - 9275 -> loss: 0.00024385545598655498, self.slope: [1.09189223 1.09267628], self.intercept: 1.008251780153826\n",
      "iteration - 9276 -> loss: 0.00024384413977012877, self.slope: [1.09189968 1.09268384], self.intercept: 1.008252492962733\n",
      "iteration - 9277 -> loss: 0.00024383282463639848, self.slope: [1.09190714 1.0926914 ], self.intercept: 1.0082532057440143\n",
      "iteration - 9278 -> loss: 0.0002438215105852582, self.slope: [1.09191459 1.09269895], self.intercept: 1.0082539184976715\n",
      "iteration - 9279 -> loss: 0.00024381019761653025, self.slope: [1.09192204 1.0927065 ], self.intercept: 1.0082546312237057\n",
      "iteration - 9280 -> loss: 0.00024379888573005252, self.slope: [1.0919295  1.09271406], self.intercept: 1.0082553439221198\n",
      "iteration - 9281 -> loss: 0.00024378757492567632, self.slope: [1.09193695 1.09272161], self.intercept: 1.008256056592917\n",
      "iteration - 9282 -> loss: 0.00024377626520324586, self.slope: [1.0919444  1.09272917], self.intercept: 1.0082567692360984\n",
      "iteration - 9283 -> loss: 0.00024376495656259397, self.slope: [1.09195185 1.09273672], self.intercept: 1.0082574818516676\n",
      "iteration - 9284 -> loss: 0.000243753649003578, self.slope: [1.0919593  1.09274427], self.intercept: 1.0082581944396252\n",
      "iteration - 9285 -> loss: 0.00024374234252602021, self.slope: [1.09196675 1.09275182], self.intercept: 1.0082589069999746\n",
      "iteration - 9286 -> loss: 0.0002437310371297855, self.slope: [1.0919742  1.09275937], self.intercept: 1.0082596195327185\n",
      "iteration - 9287 -> loss: 0.00024371973281469954, self.slope: [1.09198165 1.09276693], self.intercept: 1.0082603320378576\n",
      "iteration - 9288 -> loss: 0.00024370842958063637, self.slope: [1.0919891  1.09277448], self.intercept: 1.0082610445153966\n",
      "iteration - 9289 -> loss: 0.00024369712742738111, self.slope: [1.09199655 1.09278203], self.intercept: 1.0082617569653356\n",
      "iteration - 9290 -> loss: 0.00024368582635482492, self.slope: [1.092004   1.09278958], self.intercept: 1.0082624693876792\n",
      "iteration - 9291 -> loss: 0.00024367452636281362, self.slope: [1.09201145 1.09279713], self.intercept: 1.0082631817824268\n",
      "iteration - 9292 -> loss: 0.00024366322745116055, self.slope: [1.0920189  1.09280468], self.intercept: 1.0082638941495827\n",
      "iteration - 9293 -> loss: 0.00024365192961973091, self.slope: [1.09202635 1.09281223], self.intercept: 1.0082646064891492\n",
      "iteration - 9294 -> loss: 0.0002436406328683447, self.slope: [1.0920338  1.09281978], self.intercept: 1.0082653188011286\n",
      "iteration - 9295 -> loss: 0.00024362933719687248, self.slope: [1.09204124 1.09282733], self.intercept: 1.0082660310855223\n",
      "iteration - 9296 -> loss: 0.00024361804260512624, self.slope: [1.09204869 1.09283487], self.intercept: 1.0082667433423318\n",
      "iteration - 9297 -> loss: 0.00024360674909298347, self.slope: [1.09205614 1.09284242], self.intercept: 1.0082674555715625\n",
      "iteration - 9298 -> loss: 0.00024359545666028252, self.slope: [1.09206358 1.09284997], self.intercept: 1.0082681677732157\n",
      "iteration - 9299 -> loss: 0.00024358416530684133, self.slope: [1.09207103 1.09285752], self.intercept: 1.0082688799472916\n",
      "iteration - 9300 -> loss: 0.00024357287503250382, self.slope: [1.09207847 1.09286506], self.intercept: 1.0082695920937945\n",
      "iteration - 9301 -> loss: 0.00024356158583715745, self.slope: [1.09208592 1.09287261], self.intercept: 1.0082703042127261\n",
      "iteration - 9302 -> loss: 0.00024355029772059548, self.slope: [1.09209336 1.09288016], self.intercept: 1.008271016304088\n",
      "iteration - 9303 -> loss: 0.00024353901068269727, self.slope: [1.09210081 1.0928877 ], self.intercept: 1.0082717283678841\n",
      "iteration - 9304 -> loss: 0.00024352772472327046, self.slope: [1.09210825 1.09289525], self.intercept: 1.0082724404041161\n",
      "iteration - 9305 -> loss: 0.00024351643984219838, self.slope: [1.0921157  1.09290279], self.intercept: 1.0082731524127866\n",
      "iteration - 9306 -> loss: 0.00024350515603929784, self.slope: [1.09212314 1.09291034], self.intercept: 1.0082738643938975\n",
      "iteration - 9307 -> loss: 0.00024349387331442602, self.slope: [1.09213058 1.09291788], self.intercept: 1.008274576347452\n",
      "iteration - 9308 -> loss: 0.00024348259166741019, self.slope: [1.09213802 1.09292543], self.intercept: 1.0082752882734498\n",
      "iteration - 9309 -> loss: 0.0002434713110981018, self.slope: [1.09214547 1.09293297], self.intercept: 1.0082760001718958\n",
      "iteration - 9310 -> loss: 0.00024346003160635661, self.slope: [1.09215291 1.09294051], self.intercept: 1.0082767120427905\n",
      "iteration - 9311 -> loss: 0.00024344875319200977, self.slope: [1.09216035 1.09294806], self.intercept: 1.008277423886137\n",
      "iteration - 9312 -> loss: 0.00024343747585489742, self.slope: [1.09216779 1.0929556 ], self.intercept: 1.0082781357019375\n",
      "iteration - 9313 -> loss: 0.00024342619959486173, self.slope: [1.09217523 1.09296314], self.intercept: 1.0082788474901956\n",
      "iteration - 9314 -> loss: 0.0002434149244117636, self.slope: [1.09218267 1.09297068], self.intercept: 1.008279559250912\n",
      "iteration - 9315 -> loss: 0.00024340365030544038, self.slope: [1.09219011 1.09297822], self.intercept: 1.0082802709840897\n",
      "iteration - 9316 -> loss: 0.00024339237727572506, self.slope: [1.09219755 1.09298576], self.intercept: 1.0082809826897323\n",
      "iteration - 9317 -> loss: 0.0002433811053224676, self.slope: [1.09220499 1.0929933 ], self.intercept: 1.0082816943678388\n",
      "iteration - 9318 -> loss: 0.0002433698344455274, self.slope: [1.09221243 1.09300085], self.intercept: 1.0082824060184146\n",
      "iteration - 9319 -> loss: 0.00024335856464473467, self.slope: [1.09221987 1.09300839], self.intercept: 1.0082831176414613\n",
      "iteration - 9320 -> loss: 0.00024334729591992608, self.slope: [1.09222731 1.09301593], self.intercept: 1.0082838292369816\n",
      "iteration - 9321 -> loss: 0.00024333602827094635, self.slope: [1.09223475 1.09302346], self.intercept: 1.0082845408049752\n",
      "iteration - 9322 -> loss: 0.0002433247616976563, self.slope: [1.09224218 1.093031  ], self.intercept: 1.0082852523454464\n",
      "iteration - 9323 -> loss: 0.00024331349619989128, self.slope: [1.09224962 1.09303854], self.intercept: 1.008285963858398\n",
      "iteration - 9324 -> loss: 0.00024330223177748364, self.slope: [1.09225706 1.09304608], self.intercept: 1.0082866753438313\n",
      "iteration - 9325 -> loss: 0.00024329096843029864, self.slope: [1.09226449 1.09305362], self.intercept: 1.00828738680175\n",
      "iteration - 9326 -> loss: 0.00024327970615816306, self.slope: [1.09227193 1.09306116], self.intercept: 1.0082880982321532\n",
      "iteration - 9327 -> loss: 0.00024326844496094097, self.slope: [1.09227937 1.09306869], self.intercept: 1.0082888096350457\n",
      "iteration - 9328 -> loss: 0.00024325718483844596, self.slope: [1.0922868  1.09307623], self.intercept: 1.0082895210104312\n",
      "iteration - 9329 -> loss: 0.00024324592579055506, self.slope: [1.09229424 1.09308377], self.intercept: 1.0082902323583096\n",
      "iteration - 9330 -> loss: 0.00024323466781709359, self.slope: [1.09230167 1.0930913 ], self.intercept: 1.0082909436786855\n",
      "iteration - 9331 -> loss: 0.0002432234109179069, self.slope: [1.09230911 1.09309884], self.intercept: 1.0082916549715581\n",
      "iteration - 9332 -> loss: 0.000243212155092837, self.slope: [1.09231654 1.09310637], self.intercept: 1.0082923662369316\n",
      "iteration - 9333 -> loss: 0.00024320090034173154, self.slope: [1.09232397 1.09311391], self.intercept: 1.008293077474808\n",
      "iteration - 9334 -> loss: 0.00024318964666444751, self.slope: [1.09233141 1.09312144], self.intercept: 1.0082937886851895\n",
      "iteration - 9335 -> loss: 0.00024317839406081052, self.slope: [1.09233884 1.09312898], self.intercept: 1.008294499868078\n",
      "iteration - 9336 -> loss: 0.00024316714253068165, self.slope: [1.09234627 1.09313651], self.intercept: 1.0082952110234766\n",
      "iteration - 9337 -> loss: 0.00024315589207388416, self.slope: [1.0923537  1.09314405], self.intercept: 1.0082959221513874\n",
      "iteration - 9338 -> loss: 0.00024314464269029106, self.slope: [1.09236114 1.09315158], self.intercept: 1.0082966332518135\n",
      "iteration - 9339 -> loss: 0.0002431333943797235, self.slope: [1.09236857 1.09315911], self.intercept: 1.0082973443247545\n",
      "iteration - 9340 -> loss: 0.00024312214714202938, self.slope: [1.092376   1.09316664], self.intercept: 1.0082980553702157\n",
      "iteration - 9341 -> loss: 0.00024311090097706392, self.slope: [1.09238343 1.09317418], self.intercept: 1.0082987663881988\n",
      "iteration - 9342 -> loss: 0.00024309965588466658, self.slope: [1.09239086 1.09318171], self.intercept: 1.0082994773787044\n",
      "iteration - 9343 -> loss: 0.00024308841186467298, self.slope: [1.09239829 1.09318924], self.intercept: 1.0083001883417375\n",
      "iteration - 9344 -> loss: 0.00024307716891694257, self.slope: [1.09240572 1.09319677], self.intercept: 1.0083008992772988\n",
      "iteration - 9345 -> loss: 0.00024306592704130648, self.slope: [1.09241315 1.0932043 ], self.intercept: 1.0083016101853906\n",
      "iteration - 9346 -> loss: 0.0002430546862376284, self.slope: [1.09242058 1.09321183], self.intercept: 1.008302321066015\n",
      "iteration - 9347 -> loss: 0.0002430434465057342, self.slope: [1.09242801 1.09321936], self.intercept: 1.008303031919175\n",
      "iteration - 9348 -> loss: 0.00024303220784547522, self.slope: [1.09243544 1.09322689], self.intercept: 1.0083037427448724\n",
      "iteration - 9349 -> loss: 0.00024302097025668935, self.slope: [1.09244286 1.09323442], self.intercept: 1.0083044535431096\n",
      "iteration - 9350 -> loss: 0.00024300973373923948, self.slope: [1.09245029 1.09324195], self.intercept: 1.0083051643138898\n",
      "iteration - 9351 -> loss: 0.00024299849829295848, self.slope: [1.09245772 1.09324948], self.intercept: 1.008305875057213\n",
      "iteration - 9352 -> loss: 0.0002429872639176943, self.slope: [1.09246515 1.09325701], self.intercept: 1.0083065857730833\n",
      "iteration - 9353 -> loss: 0.00024297603061327523, self.slope: [1.09247257 1.09326453], self.intercept: 1.0083072964615014\n",
      "iteration - 9354 -> loss: 0.0002429647983795756, self.slope: [1.09248    1.09327206], self.intercept: 1.008308007122472\n",
      "iteration - 9355 -> loss: 0.000242953567216426, self.slope: [1.09248742 1.09327959], self.intercept: 1.0083087177559955\n",
      "iteration - 9356 -> loss: 0.00024294233712365766, self.slope: [1.09249485 1.09328712], self.intercept: 1.0083094283620757\n",
      "iteration - 9357 -> loss: 0.00024293110810114302, self.slope: [1.09250227 1.09329464], self.intercept: 1.0083101389407145\n",
      "iteration - 9358 -> loss: 0.00024291988014870793, self.slope: [1.0925097  1.09330217], self.intercept: 1.0083108494919146\n",
      "iteration - 9359 -> loss: 0.00024290865326620837, self.slope: [1.09251712 1.09330969], self.intercept: 1.0083115600156771\n",
      "iteration - 9360 -> loss: 0.00024289742745347526, self.slope: [1.09252455 1.09331722], self.intercept: 1.008312270512005\n",
      "iteration - 9361 -> loss: 0.00024288620271037625, self.slope: [1.09253197 1.09332475], self.intercept: 1.0083129809809004\n",
      "iteration - 9362 -> loss: 0.000242874979036742, self.slope: [1.09253939 1.09333227], self.intercept: 1.008313691422365\n",
      "iteration - 9363 -> loss: 0.00024286375643241243, self.slope: [1.09254682 1.09333979], self.intercept: 1.0083144018364019\n",
      "iteration - 9364 -> loss: 0.00024285253489723715, self.slope: [1.09255424 1.09334732], self.intercept: 1.0083151122230132\n",
      "iteration - 9365 -> loss: 0.00024284131443106697, self.slope: [1.09256166 1.09335484], self.intercept: 1.008315822582201\n",
      "iteration - 9366 -> loss: 0.00024283009503374832, self.slope: [1.09256908 1.09336237], self.intercept: 1.008316532913968\n",
      "iteration - 9367 -> loss: 0.00024281887670512062, self.slope: [1.09257651 1.09336989], self.intercept: 1.008317243218316\n",
      "iteration - 9368 -> loss: 0.00024280765944503628, self.slope: [1.09258393 1.09337741], self.intercept: 1.0083179534952487\n",
      "iteration - 9369 -> loss: 0.00024279644325331582, self.slope: [1.09259135 1.09338493], self.intercept: 1.0083186637447672\n",
      "iteration - 9370 -> loss: 0.0002427852281298423, self.slope: [1.09259877 1.09339245], self.intercept: 1.008319373966873\n",
      "iteration - 9371 -> loss: 0.00024277401407444117, self.slope: [1.09260619 1.09339998], self.intercept: 1.0083200841615687\n",
      "iteration - 9372 -> loss: 0.0002427628010869587, self.slope: [1.09261361 1.0934075 ], self.intercept: 1.0083207943288588\n",
      "iteration - 9373 -> loss: 0.0002427515891672424, self.slope: [1.09262103 1.09341502], self.intercept: 1.0083215044687426\n",
      "iteration - 9374 -> loss: 0.00024274037831515077, self.slope: [1.09262845 1.09342254], self.intercept: 1.0083222145812245\n",
      "iteration - 9375 -> loss: 0.00024272916853049253, self.slope: [1.09263586 1.09343006], self.intercept: 1.0083229246663048\n",
      "iteration - 9376 -> loss: 0.00024271795981315524, self.slope: [1.09264328 1.09343758], self.intercept: 1.0083236347239881\n",
      "iteration - 9377 -> loss: 0.0002427067521629641, self.slope: [1.0926507 1.0934451], self.intercept: 1.0083243447542747\n",
      "iteration - 9378 -> loss: 0.0002426955455797632, self.slope: [1.09265812 1.09345262], self.intercept: 1.008325054757169\n",
      "iteration - 9379 -> loss: 0.00024268434006339572, self.slope: [1.09266554 1.09346014], self.intercept: 1.0083257647326713\n",
      "iteration - 9380 -> loss: 0.00024267313561372319, self.slope: [1.09267295 1.09346765], self.intercept: 1.0083264746807872\n",
      "iteration - 9381 -> loss: 0.00024266193223057713, self.slope: [1.09268037 1.09347517], self.intercept: 1.0083271846015154\n",
      "iteration - 9382 -> loss: 0.0002426507299138137, self.slope: [1.09268778 1.09348269], self.intercept: 1.0083278944948593\n",
      "iteration - 9383 -> loss: 0.0002426395286632755, self.slope: [1.0926952  1.09349021], self.intercept: 1.008328604360821\n",
      "iteration - 9384 -> loss: 0.000242628328478804, self.slope: [1.09270262 1.09349772], self.intercept: 1.0083293141994027\n",
      "iteration - 9385 -> loss: 0.00024261712936024624, self.slope: [1.09271003 1.09350524], self.intercept: 1.0083300240106068\n",
      "iteration - 9386 -> loss: 0.00024260593130745402, self.slope: [1.09271745 1.09351276], self.intercept: 1.0083307337944356\n",
      "iteration - 9387 -> loss: 0.0002425947343202566, self.slope: [1.09272486 1.09352027], self.intercept: 1.0083314435508932\n",
      "iteration - 9388 -> loss: 0.00024258353839851424, self.slope: [1.09273227 1.09352779], self.intercept: 1.0083321532799792\n",
      "iteration - 9389 -> loss: 0.00024257234354208238, self.slope: [1.09273969 1.0935353 ], self.intercept: 1.008332862981697\n",
      "iteration - 9390 -> loss: 0.00024256114975079076, self.slope: [1.0927471  1.09354282], self.intercept: 1.0083335726560494\n",
      "iteration - 9391 -> loss: 0.0002425499570244994, self.slope: [1.09275451 1.09355033], self.intercept: 1.0083342823030381\n",
      "iteration - 9392 -> loss: 0.00024253876536302178, self.slope: [1.09276193 1.09355785], self.intercept: 1.0083349919226665\n",
      "iteration - 9393 -> loss: 0.00024252757476624906, self.slope: [1.09276934 1.09356536], self.intercept: 1.0083357015149355\n",
      "iteration - 9394 -> loss: 0.00024251638523400013, self.slope: [1.09277675 1.09357287], self.intercept: 1.0083364110798485\n",
      "iteration - 9395 -> loss: 0.00024250519676612234, self.slope: [1.09278416 1.09358039], self.intercept: 1.008337120617406\n",
      "iteration - 9396 -> loss: 0.00024249400936247756, self.slope: [1.09279157 1.0935879 ], self.intercept: 1.0083378301276105\n",
      "iteration - 9397 -> loss: 0.00024248282302289314, self.slope: [1.09279898 1.09359541], self.intercept: 1.0083385396104663\n",
      "iteration - 9398 -> loss: 0.00024247163774722893, self.slope: [1.09280639 1.09360292], self.intercept: 1.0083392490659742\n",
      "iteration - 9399 -> loss: 0.0002424604535353212, self.slope: [1.0928138  1.09361043], self.intercept: 1.0083399584941382\n",
      "iteration - 9400 -> loss: 0.00024244927038704215, self.slope: [1.09282121 1.09361795], self.intercept: 1.008340667894957\n",
      "iteration - 9401 -> loss: 0.00024243808830218692, self.slope: [1.09282862 1.09362546], self.intercept: 1.0083413772684358\n",
      "iteration - 9402 -> loss: 0.00024242690728064743, self.slope: [1.09283603 1.09363297], self.intercept: 1.0083420866145762\n",
      "iteration - 9403 -> loss: 0.00024241572732225562, self.slope: [1.09284344 1.09364048], self.intercept: 1.0083427959333815\n",
      "iteration - 9404 -> loss: 0.00024240454842685015, self.slope: [1.09285085 1.09364799], self.intercept: 1.0083435052248524\n",
      "iteration - 9405 -> loss: 0.00024239337059429395, self.slope: [1.09285826 1.0936555 ], self.intercept: 1.008344214488991\n",
      "iteration - 9406 -> loss: 0.00024238219382442024, self.slope: [1.09286567 1.09366301], self.intercept: 1.0083449237258002\n",
      "iteration - 9407 -> loss: 0.00024237101811707543, self.slope: [1.09287307 1.09367051], self.intercept: 1.008345632935284\n",
      "iteration - 9408 -> loss: 0.0002423598434721177, self.slope: [1.09288048 1.09367802], self.intercept: 1.0083463421174432\n",
      "iteration - 9409 -> loss: 0.00024234866988938838, self.slope: [1.09288789 1.09368553], self.intercept: 1.0083470512722794\n",
      "iteration - 9410 -> loss: 0.00024233749736872487, self.slope: [1.09289529 1.09369304], self.intercept: 1.008347760399796\n",
      "iteration - 9411 -> loss: 0.00024232632590998098, self.slope: [1.0929027  1.09370055], self.intercept: 1.0083484694999936\n",
      "iteration - 9412 -> loss: 0.00024231515551301916, self.slope: [1.0929101  1.09370805], self.intercept: 1.0083491785728769\n",
      "iteration - 9413 -> loss: 0.0002423039861776532, self.slope: [1.09291751 1.09371556], self.intercept: 1.008349887618446\n",
      "iteration - 9414 -> loss: 0.0002422928179037453, self.slope: [1.09292491 1.09372307], self.intercept: 1.0083505966367063\n",
      "iteration - 9415 -> loss: 0.00024228165069117386, self.slope: [1.09293232 1.09373057], self.intercept: 1.0083513056276565\n",
      "iteration - 9416 -> loss: 0.00024227048453973746, self.slope: [1.09293972 1.09373808], self.intercept: 1.0083520145913016\n",
      "iteration - 9417 -> loss: 0.00024225931944927838, self.slope: [1.09294713 1.09374558], self.intercept: 1.0083527235276413\n",
      "iteration - 9418 -> loss: 0.00024224815541971277, self.slope: [1.09295453 1.09375309], self.intercept: 1.0083534324366803\n",
      "iteration - 9419 -> loss: 0.00024223699245081354, self.slope: [1.09296193 1.09376059], self.intercept: 1.0083541413184196\n",
      "iteration - 9420 -> loss: 0.00024222583054246064, self.slope: [1.09296933 1.0937681 ], self.intercept: 1.0083548501728612\n",
      "iteration - 9421 -> loss: 0.0002422146696945137, self.slope: [1.09297674 1.0937756 ], self.intercept: 1.0083555590000082\n",
      "iteration - 9422 -> loss: 0.00024220350990677032, self.slope: [1.09298414 1.0937831 ], self.intercept: 1.0083562677998628\n",
      "iteration - 9423 -> loss: 0.00024219235117913331, self.slope: [1.09299154 1.09379061], self.intercept: 1.008356976572427\n",
      "iteration - 9424 -> loss: 0.00024218119351142824, self.slope: [1.09299894 1.09379811], self.intercept: 1.008357685317703\n",
      "iteration - 9425 -> loss: 0.00024217003690348008, self.slope: [1.09300634 1.09380561], self.intercept: 1.0083583940356937\n",
      "iteration - 9426 -> loss: 0.00024215888135515208, self.slope: [1.09301374 1.09381311], self.intercept: 1.0083591027263998\n",
      "iteration - 9427 -> loss: 0.0002421477268663229, self.slope: [1.09302114 1.09382061], self.intercept: 1.0083598113898264\n",
      "iteration - 9428 -> loss: 0.00024213657343680322, self.slope: [1.09302854 1.09382812], self.intercept: 1.0083605200259727\n",
      "iteration - 9429 -> loss: 0.00024212542106645193, self.slope: [1.09303594 1.09383562], self.intercept: 1.008361228634842\n",
      "iteration - 9430 -> loss: 0.00024211426975510834, self.slope: [1.09304334 1.09384312], self.intercept: 1.0083619372164379\n",
      "iteration - 9431 -> loss: 0.00024210311950263708, self.slope: [1.09305074 1.09385062], self.intercept: 1.0083626457707615\n",
      "iteration - 9432 -> loss: 0.00024209197030885396, self.slope: [1.09305814 1.09385812], self.intercept: 1.0083633542978143\n",
      "iteration - 9433 -> loss: 0.0002420808221736302, self.slope: [1.09306554 1.09386562], self.intercept: 1.0083640627976012\n",
      "iteration - 9434 -> loss: 0.00024206967509682098, self.slope: [1.09307293 1.09387312], self.intercept: 1.0083647712701218\n",
      "iteration - 9435 -> loss: 0.0002420585290782605, self.slope: [1.09308033 1.09388062], self.intercept: 1.00836547971538\n",
      "iteration - 9436 -> loss: 0.00024204738411777958, self.slope: [1.09308773 1.09388811], self.intercept: 1.008366188133378\n",
      "iteration - 9437 -> loss: 0.00024203624021526242, self.slope: [1.09309513 1.09389561], self.intercept: 1.0083668965241173\n",
      "iteration - 9438 -> loss: 0.00024202509737053545, self.slope: [1.09310252 1.09390311], self.intercept: 1.0083676048876011\n",
      "iteration - 9439 -> loss: 0.00024201395558344166, self.slope: [1.09310992 1.09391061], self.intercept: 1.0083683132238297\n",
      "iteration - 9440 -> loss: 0.0002420028148538262, self.slope: [1.09311731 1.0939181 ], self.intercept: 1.0083690215328067\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 9441 -> loss: 0.0002419916751815833, self.slope: [1.09312471 1.0939256 ], self.intercept: 1.0083697298145335\n",
      "iteration - 9442 -> loss: 0.00024198053656649497, self.slope: [1.0931321 1.0939331], self.intercept: 1.0083704380690155\n",
      "iteration - 9443 -> loss: 0.00024196939900843315, self.slope: [1.0931395  1.09394059], self.intercept: 1.0083711462962528\n",
      "iteration - 9444 -> loss: 0.00024195826250725334, self.slope: [1.09314689 1.09394809], self.intercept: 1.0083718544962466\n",
      "iteration - 9445 -> loss: 0.00024194712706280467, self.slope: [1.09315429 1.09395558], self.intercept: 1.008372562669\n",
      "iteration - 9446 -> loss: 0.00024193599267492756, self.slope: [1.09316168 1.09396308], self.intercept: 1.0083732708145174\n",
      "iteration - 9447 -> loss: 0.00024192485934347775, self.slope: [1.09316907 1.09397057], self.intercept: 1.0083739789327975\n",
      "iteration - 9448 -> loss: 0.00024191372706828862, self.slope: [1.09317646 1.09397807], self.intercept: 1.0083746870238446\n",
      "iteration - 9449 -> loss: 0.00024190259584922256, self.slope: [1.09318386 1.09398556], self.intercept: 1.008375395087661\n",
      "iteration - 9450 -> loss: 0.00024189146568611051, self.slope: [1.09319125 1.09399306], self.intercept: 1.0083761031242484\n",
      "iteration - 9451 -> loss: 0.000241880336578835, self.slope: [1.09319864 1.09400055], self.intercept: 1.00837681113361\n",
      "iteration - 9452 -> loss: 0.00024186920852719695, self.slope: [1.09320603 1.09400804], self.intercept: 1.008377519115747\n",
      "iteration - 9453 -> loss: 0.00024185808153107054, self.slope: [1.09321342 1.09401553], self.intercept: 1.0083782270706618\n",
      "iteration - 9454 -> loss: 0.00024184695559031848, self.slope: [1.09322081 1.09402303], self.intercept: 1.0083789349983565\n",
      "iteration - 9455 -> loss: 0.00024183583070476065, self.slope: [1.0932282  1.09403052], self.intercept: 1.008379642898834\n",
      "iteration - 9456 -> loss: 0.0002418247068742527, self.slope: [1.09323559 1.09403801], self.intercept: 1.0083803507720972\n",
      "iteration - 9457 -> loss: 0.00024181358409864378, self.slope: [1.09324298 1.0940455 ], self.intercept: 1.0083810586181472\n",
      "iteration - 9458 -> loss: 0.0002418024623777938, self.slope: [1.09325037 1.09405299], self.intercept: 1.0083817664369865\n",
      "iteration - 9459 -> loss: 0.0002417913417115202, self.slope: [1.09325776 1.09406048], self.intercept: 1.008382474228617\n",
      "iteration - 9460 -> loss: 0.00024178022209972645, self.slope: [1.09326515 1.09406797], self.intercept: 1.0083831819930418\n",
      "iteration - 9461 -> loss: 0.0002417691035421986, self.slope: [1.09327254 1.09407546], self.intercept: 1.0083838897302628\n",
      "iteration - 9462 -> loss: 0.00024175798603881516, self.slope: [1.09327993 1.09408295], self.intercept: 1.0083845974402825\n",
      "iteration - 9463 -> loss: 0.0002417468695894328, self.slope: [1.09328731 1.09409044], self.intercept: 1.0083853051231026\n",
      "iteration - 9464 -> loss: 0.0002417357541938766, self.slope: [1.0932947  1.09409793], self.intercept: 1.008386012778727\n",
      "iteration - 9465 -> loss: 0.0002417246398520173, self.slope: [1.09330209 1.09410542], self.intercept: 1.0083867204071555\n",
      "iteration - 9466 -> loss: 0.0002417135265636815, self.slope: [1.09330947 1.0941129 ], self.intercept: 1.008387428008393\n",
      "iteration - 9467 -> loss: 0.0002417024143287446, self.slope: [1.09331686 1.09412039], self.intercept: 1.0083881355824393\n",
      "iteration - 9468 -> loss: 0.00024169130314701938, self.slope: [1.09332425 1.09412788], self.intercept: 1.0083888431292976\n",
      "iteration - 9469 -> loss: 0.0002416801930184035, self.slope: [1.09333163 1.09413537], self.intercept: 1.0083895506489706\n",
      "iteration - 9470 -> loss: 0.00024166908394268312, self.slope: [1.09333902 1.09414285], self.intercept: 1.008390258141461\n",
      "iteration - 9471 -> loss: 0.00024165797591976497, self.slope: [1.0933464  1.09415034], self.intercept: 1.008390965606769\n",
      "iteration - 9472 -> loss: 0.00024164686894945732, self.slope: [1.09335378 1.09415782], self.intercept: 1.0083916730449012\n",
      "iteration - 9473 -> loss: 0.0002416357630316148, self.slope: [1.09336117 1.09416531], self.intercept: 1.008392380455854\n",
      "iteration - 9474 -> loss: 0.00024162465816612424, self.slope: [1.09336855 1.09417279], self.intercept: 1.0083930878396334\n",
      "iteration - 9475 -> loss: 0.00024161355435279382, self.slope: [1.09337593 1.09418028], self.intercept: 1.00839379519624\n",
      "iteration - 9476 -> loss: 0.00024160245159147618, self.slope: [1.09338332 1.09418776], self.intercept: 1.008394502525677\n",
      "iteration - 9477 -> loss: 0.0002415913498820146, self.slope: [1.0933907  1.09419525], self.intercept: 1.0083952098279465\n",
      "iteration - 9478 -> loss: 0.0002415802492242985, self.slope: [1.09339808 1.09420273], self.intercept: 1.0083959171030519\n",
      "iteration - 9479 -> loss: 0.00024156914961813016, self.slope: [1.09340546 1.09421021], self.intercept: 1.0083966243509945\n",
      "iteration - 9480 -> loss: 0.00024155805106338245, self.slope: [1.09341285 1.0942177 ], self.intercept: 1.0083973315717765\n",
      "iteration - 9481 -> loss: 0.00024154695355989422, self.slope: [1.09342023 1.09422518], self.intercept: 1.0083980387653995\n",
      "iteration - 9482 -> loss: 0.00024153585710752474, self.slope: [1.09342761 1.09423266], self.intercept: 1.0083987459318666\n",
      "iteration - 9483 -> loss: 0.0002415247617061075, self.slope: [1.09343499 1.09424014], self.intercept: 1.0083994530711797\n",
      "iteration - 9484 -> loss: 0.00024151366735550644, self.slope: [1.09344237 1.09424763], self.intercept: 1.0084001601833406\n",
      "iteration - 9485 -> loss: 0.00024150257405556024, self.slope: [1.09344975 1.09425511], self.intercept: 1.0084008672683533\n",
      "iteration - 9486 -> loss: 0.0002414914818061265, self.slope: [1.09345713 1.09426259], self.intercept: 1.0084015743262174\n",
      "iteration - 9487 -> loss: 0.00024148039060704573, self.slope: [1.09346451 1.09427007], self.intercept: 1.008402281356938\n",
      "iteration - 9488 -> loss: 0.00024146930045816924, self.slope: [1.09347188 1.09427755], self.intercept: 1.0084029883605155\n",
      "iteration - 9489 -> loss: 0.0002414582113593654, self.slope: [1.09347926 1.09428503], self.intercept: 1.0084036953369537\n",
      "iteration - 9490 -> loss: 0.0002414471233104349, self.slope: [1.09348664 1.09429251], self.intercept: 1.008404402286254\n",
      "iteration - 9491 -> loss: 0.0002414360363112822, self.slope: [1.09349402 1.09429999], self.intercept: 1.0084051092084179\n",
      "iteration - 9492 -> loss: 0.00024142495036171116, self.slope: [1.09350139 1.09430747], self.intercept: 1.0084058161034495\n",
      "iteration - 9493 -> loss: 0.00024141386546160055, self.slope: [1.09350877 1.09431494], self.intercept: 1.0084065229713493\n",
      "iteration - 9494 -> loss: 0.00024140278161078593, self.slope: [1.09351615 1.09432242], self.intercept: 1.00840722981212\n",
      "iteration - 9495 -> loss: 0.00024139169880913754, self.slope: [1.09352352 1.0943299 ], self.intercept: 1.008407936625764\n",
      "iteration - 9496 -> loss: 0.00024138061705646338, self.slope: [1.0935309  1.09433738], self.intercept: 1.0084086434122832\n",
      "iteration - 9497 -> loss: 0.0002413695363526584, self.slope: [1.09353828 1.09434485], self.intercept: 1.00840935017168\n",
      "iteration - 9498 -> loss: 0.00024135845669754282, self.slope: [1.09354565 1.09435233], self.intercept: 1.0084100569039585\n",
      "iteration - 9499 -> loss: 0.0002413473780909725, self.slope: [1.09355303 1.09435981], self.intercept: 1.0084107636091184\n",
      "iteration - 9500 -> loss: 0.00024133630053279953, self.slope: [1.0935604  1.09436728], self.intercept: 1.0084114702871636\n",
      "iteration - 9501 -> loss: 0.00024132522402286815, self.slope: [1.09356777 1.09437476], self.intercept: 1.0084121769380958\n",
      "iteration - 9502 -> loss: 0.0002413141485610279, self.slope: [1.09357515 1.09438223], self.intercept: 1.008412883561917\n",
      "iteration - 9503 -> loss: 0.00024130307414713107, self.slope: [1.09358252 1.09438971], self.intercept: 1.0084135901586286\n",
      "iteration - 9504 -> loss: 0.000241292000781045, self.slope: [1.09358989 1.09439718], self.intercept: 1.0084142967282348\n",
      "iteration - 9505 -> loss: 0.0002412809284625817, self.slope: [1.09359727 1.09440466], self.intercept: 1.0084150032707369\n",
      "iteration - 9506 -> loss: 0.00024126985719162276, self.slope: [1.09360464 1.09441213], self.intercept: 1.0084157097861368\n",
      "iteration - 9507 -> loss: 0.00024125878696800614, self.slope: [1.09361201 1.0944196 ], self.intercept: 1.0084164162744373\n",
      "iteration - 9508 -> loss: 0.00024124771779157148, self.slope: [1.09361938 1.09442708], self.intercept: 1.008417122735641\n",
      "iteration - 9509 -> loss: 0.0002412366496621761, self.slope: [1.09362675 1.09443455], self.intercept: 1.0084178291697508\n",
      "iteration - 9510 -> loss: 0.00024122558257967978, self.slope: [1.09363412 1.09444202], self.intercept: 1.0084185355767665\n",
      "iteration - 9511 -> loss: 0.00024121451654391583, self.slope: [1.09364149 1.09444949], self.intercept: 1.008419241956692\n",
      "iteration - 9512 -> loss: 0.00024120345155475138, self.slope: [1.09364886 1.09445697], self.intercept: 1.0084199483095295\n",
      "iteration - 9513 -> loss: 0.00024119238761202192, self.slope: [1.09365623 1.09446444], self.intercept: 1.0084206546352799\n",
      "iteration - 9514 -> loss: 0.00024118132471559047, self.slope: [1.0936636  1.09447191], self.intercept: 1.0084213609339467\n",
      "iteration - 9515 -> loss: 0.00024117026286528674, self.slope: [1.09367097 1.09447938], self.intercept: 1.008422067205532\n",
      "iteration - 9516 -> loss: 0.00024115920206096804, self.slope: [1.09367834 1.09448685], self.intercept: 1.0084227734500388\n",
      "iteration - 9517 -> loss: 0.00024114814230248905, self.slope: [1.09368571 1.09449432], self.intercept: 1.0084234796674703\n",
      "iteration - 9518 -> loss: 0.00024113708358970465, self.slope: [1.09369308 1.09450179], self.intercept: 1.008424185857826\n",
      "iteration - 9519 -> loss: 0.00024112602592248238, self.slope: [1.09370045 1.09450926], self.intercept: 1.008424892021108\n",
      "iteration - 9520 -> loss: 0.00024111496930060767, self.slope: [1.09370781 1.09451673], self.intercept: 1.0084255981573196\n",
      "iteration - 9521 -> loss: 0.0002411039137239879, self.slope: [1.09371518 1.0945242 ], self.intercept: 1.0084263042664634\n",
      "iteration - 9522 -> loss: 0.00024109285919245185, self.slope: [1.09372255 1.09453166], self.intercept: 1.0084270103485422\n",
      "iteration - 9523 -> loss: 0.00024108180570586678, self.slope: [1.09372991 1.09453913], self.intercept: 1.008427716403559\n",
      "iteration - 9524 -> loss: 0.00024107075326405586, self.slope: [1.09373728 1.0945466 ], self.intercept: 1.0084284224315139\n",
      "iteration - 9525 -> loss: 0.00024105970186688553, self.slope: [1.09374464 1.09455407], self.intercept: 1.0084291284324105\n",
      "iteration - 9526 -> loss: 0.0002410486515142155, self.slope: [1.09375201 1.09456153], self.intercept: 1.0084298344062488\n",
      "iteration - 9527 -> loss: 0.00024103760220587, self.slope: [1.09375937 1.094569  ], self.intercept: 1.0084305403530327\n",
      "iteration - 9528 -> loss: 0.0002410265539417197, self.slope: [1.09376674 1.09457647], self.intercept: 1.0084312462727654\n",
      "iteration - 9529 -> loss: 0.0002410155067216077, self.slope: [1.0937741  1.09458393], self.intercept: 1.0084319521654486\n",
      "iteration - 9530 -> loss: 0.00024100446054537724, self.slope: [1.09378147 1.0945914 ], self.intercept: 1.0084326580310847\n",
      "iteration - 9531 -> loss: 0.00024099341541290243, self.slope: [1.09378883 1.09459886], self.intercept: 1.0084333638696752\n",
      "iteration - 9532 -> loss: 0.00024098237132401065, self.slope: [1.09379619 1.09460633], self.intercept: 1.008434069681222\n",
      "iteration - 9533 -> loss: 0.00024097132827855154, self.slope: [1.09380356 1.09461379], self.intercept: 1.0084347754657268\n",
      "iteration - 9534 -> loss: 0.00024096028627639275, self.slope: [1.09381092 1.09462126], self.intercept: 1.0084354812231942\n",
      "iteration - 9535 -> loss: 0.00024094924531736404, self.slope: [1.09381828 1.09462872], self.intercept: 1.0084361869536251\n",
      "iteration - 9536 -> loss: 0.00024093820540131862, self.slope: [1.09382564 1.09463618], self.intercept: 1.008436892657023\n",
      "iteration - 9537 -> loss: 0.00024092716652812928, self.slope: [1.093833   1.09464365], self.intercept: 1.0084375983333878\n",
      "iteration - 9538 -> loss: 0.00024091612869762489, self.slope: [1.09384036 1.09465111], self.intercept: 1.008438303982723\n",
      "iteration - 9539 -> loss: 0.00024090509190966805, self.slope: [1.09384773 1.09465857], self.intercept: 1.0084390096050313\n",
      "iteration - 9540 -> loss: 0.0002408940561641, self.slope: [1.09385509 1.09466603], self.intercept: 1.0084397152003153\n",
      "iteration - 9541 -> loss: 0.00024088302146076934, self.slope: [1.09386245 1.09467349], self.intercept: 1.0084404207685764\n",
      "iteration - 9542 -> loss: 0.00024087198779954678, self.slope: [1.0938698  1.09468096], self.intercept: 1.0084411263098172\n",
      "iteration - 9543 -> loss: 0.00024086095518025986, self.slope: [1.09387716 1.09468842], self.intercept: 1.0084418318240391\n",
      "iteration - 9544 -> loss: 0.00024084992360276503, self.slope: [1.09388452 1.09469588], self.intercept: 1.0084425373112444\n",
      "iteration - 9545 -> loss: 0.00024083889306691868, self.slope: [1.09389188 1.09470334], self.intercept: 1.0084432427714363\n",
      "iteration - 9546 -> loss: 0.00024082786357257816, self.slope: [1.09389924 1.0947108 ], self.intercept: 1.0084439482046157\n",
      "iteration - 9547 -> loss: 0.00024081683511958225, self.slope: [1.0939066  1.09471826], self.intercept: 1.008444653610786\n",
      "iteration - 9548 -> loss: 0.00024080580770776961, self.slope: [1.09391396 1.09472572], self.intercept: 1.0084453589899494\n",
      "iteration - 9549 -> loss: 0.00024079478133702322, self.slope: [1.09392131 1.09473317], self.intercept: 1.008446064342108\n",
      "iteration - 9550 -> loss: 0.00024078375600715063, self.slope: [1.09392867 1.09474063], self.intercept: 1.0084467696672639\n",
      "iteration - 9551 -> loss: 0.00024077273171804793, self.slope: [1.09393603 1.09474809], self.intercept: 1.0084474749654189\n",
      "iteration - 9552 -> loss: 0.00024076170846952874, self.slope: [1.09394338 1.09475555], self.intercept: 1.0084481802365755\n",
      "iteration - 9553 -> loss: 0.00024075068626148446, self.slope: [1.09395074 1.09476301], self.intercept: 1.008448885480738\n",
      "iteration - 9554 -> loss: 0.0002407396650937218, self.slope: [1.09395809 1.09477046], self.intercept: 1.0084495906979054\n",
      "iteration - 9555 -> loss: 0.00024072864496611955, self.slope: [1.09396545 1.09477792], self.intercept: 1.0084502958880817\n",
      "iteration - 9556 -> loss: 0.00024071762587853256, self.slope: [1.0939728  1.09478538], self.intercept: 1.0084510010512686\n",
      "iteration - 9557 -> loss: 0.00024070660783078073, self.slope: [1.09398016 1.09479283], self.intercept: 1.0084517061874692\n",
      "iteration - 9558 -> loss: 0.00024069559082275937, self.slope: [1.09398751 1.09480029], self.intercept: 1.008452411296685\n",
      "iteration - 9559 -> loss: 0.00024068457485427737, self.slope: [1.09399486 1.09480774], self.intercept: 1.0084531163789174\n",
      "iteration - 9560 -> loss: 0.0002406735599252162, self.slope: [1.09400222 1.0948152 ], self.intercept: 1.0084538214341698\n",
      "iteration - 9561 -> loss: 0.00024066254603539344, self.slope: [1.09400957 1.09482265], self.intercept: 1.0084545264624447\n",
      "iteration - 9562 -> loss: 0.00024065153318470056, self.slope: [1.09401692 1.09483011], self.intercept: 1.0084552314637438\n",
      "iteration - 9563 -> loss: 0.00024064052137295403, self.slope: [1.09402428 1.09483756], self.intercept: 1.0084559364380703\n",
      "iteration - 9564 -> loss: 0.00024062951060002555, self.slope: [1.09403163 1.09484501], self.intercept: 1.0084566413854257\n",
      "iteration - 9565 -> loss: 0.0002406185008657689, self.slope: [1.09403898 1.09485247], self.intercept: 1.0084573463058106\n",
      "iteration - 9566 -> loss: 0.00024060749217002828, self.slope: [1.09404633 1.09485992], self.intercept: 1.008458051199229\n",
      "iteration - 9567 -> loss: 0.00024059648451263676, self.slope: [1.09405368 1.09486737], self.intercept: 1.008458756065683\n",
      "iteration - 9568 -> loss: 0.00024058547789347986, self.slope: [1.09406103 1.09487482], self.intercept: 1.008459460905176\n",
      "iteration - 9569 -> loss: 0.00024057447231238478, self.slope: [1.09406838 1.09488228], self.intercept: 1.0084601657177088\n",
      "iteration - 9570 -> loss: 0.000240563467769216, self.slope: [1.09407573 1.09488973], self.intercept: 1.0084608705032831\n",
      "iteration - 9571 -> loss: 0.0002405524642638195, self.slope: [1.09408308 1.09489718], self.intercept: 1.008461575261902\n",
      "iteration - 9572 -> loss: 0.00024054146179604445, self.slope: [1.09409043 1.09490463], self.intercept: 1.0084622799935674\n",
      "iteration - 9573 -> loss: 0.00024053046036573683, self.slope: [1.09409778 1.09491208], self.intercept: 1.0084629846982827\n",
      "iteration - 9574 -> loss: 0.0002405194599727507, self.slope: [1.09410513 1.09491953], self.intercept: 1.0084636893760495\n",
      "iteration - 9575 -> loss: 0.00024050846061695398, self.slope: [1.09411248 1.09492698], self.intercept: 1.008464394026868\n",
      "iteration - 9576 -> loss: 0.0002404974622981883, self.slope: [1.09411982 1.09493443], self.intercept: 1.0084650986507435\n",
      "iteration - 9577 -> loss: 0.0002404864650162924, self.slope: [1.09412717 1.09494188], self.intercept: 1.0084658032476763\n",
      "iteration - 9578 -> loss: 0.00024047546877113964, self.slope: [1.09413452 1.09494933], self.intercept: 1.008466507817669\n",
      "iteration - 9579 -> loss: 0.00024046447356256592, self.slope: [1.09414186 1.09495677], self.intercept: 1.0084672123607248\n",
      "iteration - 9580 -> loss: 0.00024045347939043, self.slope: [1.09414921 1.09496422], self.intercept: 1.0084679168768467\n",
      "iteration - 9581 -> loss: 0.00024044248625458518, self.slope: [1.09415656 1.09497167], self.intercept: 1.008468621366035\n",
      "iteration - 9582 -> loss: 0.00024043149415487185, self.slope: [1.0941639  1.09497912], self.intercept: 1.008469325828292\n",
      "iteration - 9583 -> loss: 0.00024042050309115595, self.slope: [1.09417125 1.09498656], self.intercept: 1.0084700302636191\n",
      "iteration - 9584 -> loss: 0.00024040951306327117, self.slope: [1.09417859 1.09499401], self.intercept: 1.008470734672021\n",
      "iteration - 9585 -> loss: 0.00024039852407108382, self.slope: [1.09418594 1.09500146], self.intercept: 1.0084714390534986\n",
      "iteration - 9586 -> loss: 0.00024038753611445632, self.slope: [1.09419328 1.0950089 ], self.intercept: 1.0084721434080546\n",
      "iteration - 9587 -> loss: 0.00024037654919319585, self.slope: [1.09420062 1.09501635], self.intercept: 1.0084728477356908\n",
      "iteration - 9588 -> loss: 0.00024036556330720888, self.slope: [1.09420797 1.09502379], self.intercept: 1.0084735520364085\n",
      "iteration - 9589 -> loss: 0.00024035457845632044, self.slope: [1.09421531 1.09503124], self.intercept: 1.0084742563102116\n",
      "iteration - 9590 -> loss: 0.00024034359464038753, self.slope: [1.09422265 1.09503868], self.intercept: 1.008474960557101\n",
      "iteration - 9591 -> loss: 0.00024033261185926622, self.slope: [1.09423    1.09504613], self.intercept: 1.0084756647770798\n",
      "iteration - 9592 -> loss: 0.00024032163011278489, self.slope: [1.09423734 1.09505357], self.intercept: 1.0084763689701495\n",
      "iteration - 9593 -> loss: 0.00024031064940082137, self.slope: [1.09424468 1.09506101], self.intercept: 1.0084770731363146\n",
      "iteration - 9594 -> loss: 0.0002402996697232219, self.slope: [1.09425202 1.09506846], self.intercept: 1.0084777772755746\n",
      "iteration - 9595 -> loss: 0.0002402886910798185, self.slope: [1.09425936 1.0950759 ], self.intercept: 1.0084784813879344\n",
      "iteration - 9596 -> loss: 0.00024027771347051536, self.slope: [1.0942667  1.09508334], self.intercept: 1.0084791854733948\n",
      "iteration - 9597 -> loss: 0.00024026673689509428, self.slope: [1.09427404 1.09509078], self.intercept: 1.0084798895319567\n",
      "iteration - 9598 -> loss: 0.0002402557613534609, self.slope: [1.09428138 1.09509823], self.intercept: 1.0084805935636245\n",
      "iteration - 9599 -> loss: 0.00024024478684544804, self.slope: [1.09428872 1.09510567], self.intercept: 1.0084812975683985\n",
      "iteration - 9600 -> loss: 0.0002402338133709075, self.slope: [1.09429606 1.09511311], self.intercept: 1.008482001546282\n",
      "iteration - 9601 -> loss: 0.00024022284092968944, self.slope: [1.0943034  1.09512055], self.intercept: 1.0084827054972771\n",
      "iteration - 9602 -> loss: 0.00024021186952164427, self.slope: [1.09431074 1.09512799], self.intercept: 1.0084834094213864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 9603 -> loss: 0.00024020089914665748, self.slope: [1.09431808 1.09513543], self.intercept: 1.008484113318611\n",
      "iteration - 9604 -> loss: 0.0002401899298045311, self.slope: [1.09432542 1.09514287], self.intercept: 1.008484817188954\n",
      "iteration - 9605 -> loss: 0.00024017896149513464, self.slope: [1.09433275 1.09515031], self.intercept: 1.0084855210324177\n",
      "iteration - 9606 -> loss: 0.00024016799421834462, self.slope: [1.09434009 1.09515775], self.intercept: 1.0084862248490034\n",
      "iteration - 9607 -> loss: 0.00024015702797398078, self.slope: [1.09434743 1.09516519], self.intercept: 1.0084869286387153\n",
      "iteration - 9608 -> loss: 0.00024014606276191177, self.slope: [1.09435476 1.09517262], self.intercept: 1.0084876324015537\n",
      "iteration - 9609 -> loss: 0.0002401350985819941, self.slope: [1.0943621  1.09518006], self.intercept: 1.0084883361375214\n",
      "iteration - 9610 -> loss: 0.0002401241354340649, self.slope: [1.09436944 1.0951875 ], self.intercept: 1.0084890398466209\n",
      "iteration - 9611 -> loss: 0.0002401131733179845, self.slope: [1.09437677 1.09519494], self.intercept: 1.0084897435288545\n",
      "iteration - 9612 -> loss: 0.00024010221223361318, self.slope: [1.09438411 1.09520237], self.intercept: 1.0084904471842242\n",
      "iteration - 9613 -> loss: 0.00024009125218080098, self.slope: [1.09439144 1.09520981], self.intercept: 1.008491150812732\n",
      "iteration - 9614 -> loss: 0.0002400802931594029, self.slope: [1.09439878 1.09521725], self.intercept: 1.0084918544143804\n",
      "iteration - 9615 -> loss: 0.00024006933516924556, self.slope: [1.09440611 1.09522468], self.intercept: 1.0084925579891715\n",
      "iteration - 9616 -> loss: 0.0002400583782102098, self.slope: [1.09441344 1.09523212], self.intercept: 1.0084932615371085\n",
      "iteration - 9617 -> loss: 0.00024004742228214863, self.slope: [1.09442078 1.09523955], self.intercept: 1.0084939650581939\n",
      "iteration - 9618 -> loss: 0.00024003646738489641, self.slope: [1.09442811 1.09524699], self.intercept: 1.0084946685524274\n",
      "iteration - 9619 -> loss: 0.00024002551351832258, self.slope: [1.09443544 1.09525442], self.intercept: 1.0084953720198129\n",
      "iteration - 9620 -> loss: 0.00024001456068225703, self.slope: [1.09444278 1.09526186], self.intercept: 1.008496075460351\n",
      "iteration - 9621 -> loss: 0.00024000360887659522, self.slope: [1.09445011 1.09526929], self.intercept: 1.0084967788740453\n",
      "iteration - 9622 -> loss: 0.00023999265810114543, self.slope: [1.09445744 1.09527672], self.intercept: 1.0084974822609003\n",
      "iteration - 9623 -> loss: 0.00023998170835577083, self.slope: [1.09446477 1.09528416], self.intercept: 1.0084981856209145\n",
      "iteration - 9624 -> loss: 0.00023997075964034354, self.slope: [1.0944721  1.09529159], self.intercept: 1.008498888954092\n",
      "iteration - 9625 -> loss: 0.00023995981195470658, self.slope: [1.09447943 1.09529902], self.intercept: 1.0084995922604338\n",
      "iteration - 9626 -> loss: 0.00023994886529870273, self.slope: [1.09448676 1.09530645], self.intercept: 1.0085002955399431\n",
      "iteration - 9627 -> loss: 0.00023993791967219757, self.slope: [1.09449409 1.09531388], self.intercept: 1.0085009987926223\n",
      "iteration - 9628 -> loss: 0.00023992697507502512, self.slope: [1.09450142 1.09532131], self.intercept: 1.0085017020184732\n",
      "iteration - 9629 -> loss: 0.0002399160315070822, self.slope: [1.09450875 1.09532875], self.intercept: 1.008502405217498\n",
      "iteration - 9630 -> loss: 0.00023990508896817452, self.slope: [1.09451608 1.09533618], self.intercept: 1.008503108389699\n",
      "iteration - 9631 -> loss: 0.00023989414745816692, self.slope: [1.09452341 1.09534361], self.intercept: 1.008503811535079\n",
      "iteration - 9632 -> loss: 0.00023988320697693983, self.slope: [1.09453074 1.09535104], self.intercept: 1.0085045146536373\n",
      "iteration - 9633 -> loss: 0.0002398722675243042, self.slope: [1.09453806 1.09535847], self.intercept: 1.0085052177453806\n",
      "iteration - 9634 -> loss: 0.00023986132910013743, self.slope: [1.09454539 1.0953659 ], self.intercept: 1.0085059208103087\n",
      "iteration - 9635 -> loss: 0.00023985039170431165, self.slope: [1.09455272 1.09537332], self.intercept: 1.0085066238484237\n",
      "iteration - 9636 -> loss: 0.00023983945533662232, self.slope: [1.09456005 1.09538075], self.intercept: 1.008507326859729\n",
      "iteration - 9637 -> loss: 0.0002398285199969842, self.slope: [1.09456737 1.09538818], self.intercept: 1.0085080298442257\n",
      "iteration - 9638 -> loss: 0.00023981758568521877, self.slope: [1.0945747  1.09539561], self.intercept: 1.0085087328019167\n",
      "iteration - 9639 -> loss: 0.00023980665240118292, self.slope: [1.09458202 1.09540304], self.intercept: 1.0085094357328042\n",
      "iteration - 9640 -> loss: 0.0002397957201447268, self.slope: [1.09458935 1.09541046], self.intercept: 1.0085101386368902\n",
      "iteration - 9641 -> loss: 0.00023978478891572452, self.slope: [1.09459667 1.09541789], self.intercept: 1.008510841514177\n",
      "iteration - 9642 -> loss: 0.0002397738587140123, self.slope: [1.094604   1.09542532], self.intercept: 1.0085115443646662\n",
      "iteration - 9643 -> loss: 0.00023976292953943574, self.slope: [1.09461132 1.09543274], self.intercept: 1.0085122471883596\n",
      "iteration - 9644 -> loss: 0.000239752001391851, self.slope: [1.09461865 1.09544017], self.intercept: 1.0085129499852603\n",
      "iteration - 9645 -> loss: 0.0002397410742711323, self.slope: [1.09462597 1.09544759], self.intercept: 1.0085136527553709\n",
      "iteration - 9646 -> loss: 0.00023973014817711816, self.slope: [1.09463329 1.09545502], self.intercept: 1.0085143554986935\n",
      "iteration - 9647 -> loss: 0.00023971922310966093, self.slope: [1.09464062 1.09546244], self.intercept: 1.00851505821523\n",
      "iteration - 9648 -> loss: 0.00023970829906861765, self.slope: [1.09464794 1.09546987], self.intercept: 1.008515760904984\n",
      "iteration - 9649 -> loss: 0.00023969737605383605, self.slope: [1.09465526 1.09547729], self.intercept: 1.008516463567955\n",
      "iteration - 9650 -> loss: 0.00023968645406518375, self.slope: [1.09466258 1.09548471], self.intercept: 1.0085171662041479\n",
      "iteration - 9651 -> loss: 0.0002396755331024891, self.slope: [1.09466991 1.09549214], self.intercept: 1.008517868813563\n",
      "iteration - 9652 -> loss: 0.0002396646131656355, self.slope: [1.09467723 1.09549956], self.intercept: 1.0085185713962033\n",
      "iteration - 9653 -> loss: 0.00023965369425446814, self.slope: [1.09468455 1.09550698], self.intercept: 1.0085192739520703\n",
      "iteration - 9654 -> loss: 0.00023964277636882305, self.slope: [1.09469187 1.09551441], self.intercept: 1.0085199764811663\n",
      "iteration - 9655 -> loss: 0.00023963185950856845, self.slope: [1.09469919 1.09552183], self.intercept: 1.0085206789834957\n",
      "iteration - 9656 -> loss: 0.00023962094367355438, self.slope: [1.09470651 1.09552925], self.intercept: 1.0085213814590588\n",
      "iteration - 9657 -> loss: 0.00023961002886363681, self.slope: [1.09471383 1.09553667], self.intercept: 1.0085220839078575\n",
      "iteration - 9658 -> loss: 0.00023959911507868395, self.slope: [1.09472115 1.09554409], self.intercept: 1.0085227863298942\n",
      "iteration - 9659 -> loss: 0.00023958820231851006, self.slope: [1.09472847 1.09555151], self.intercept: 1.0085234887251713\n",
      "iteration - 9660 -> loss: 0.00023957729058301274, self.slope: [1.09473578 1.09555893], self.intercept: 1.008524191093692\n",
      "iteration - 9661 -> loss: 0.00023956637987202178, self.slope: [1.0947431  1.09556635], self.intercept: 1.0085248934354576\n",
      "iteration - 9662 -> loss: 0.0002395554701853923, self.slope: [1.09475042 1.09557377], self.intercept: 1.00852559575047\n",
      "iteration - 9663 -> loss: 0.00023954456152299649, self.slope: [1.09475774 1.09558119], self.intercept: 1.0085262980387328\n",
      "iteration - 9664 -> loss: 0.00023953365388467497, self.slope: [1.09476505 1.09558861], self.intercept: 1.0085270003002451\n",
      "iteration - 9665 -> loss: 0.00023952274727026538, self.slope: [1.09477237 1.09559603], self.intercept: 1.0085277025350123\n",
      "iteration - 9666 -> loss: 0.0002395118416796396, self.slope: [1.09477969 1.09560345], self.intercept: 1.0085284047430358\n",
      "iteration - 9667 -> loss: 0.000239500937112654, self.slope: [1.094787   1.09561086], self.intercept: 1.0085291069243165\n",
      "iteration - 9668 -> loss: 0.00023949003356915285, self.slope: [1.09479432 1.09561828], self.intercept: 1.0085298090788584\n",
      "iteration - 9669 -> loss: 0.00023947913104900145, self.slope: [1.09480163 1.0956257 ], self.intercept: 1.0085305112066627\n",
      "iteration - 9670 -> loss: 0.0002394682295520439, self.slope: [1.09480895 1.09563312], self.intercept: 1.0085312133077329\n",
      "iteration - 9671 -> loss: 0.0002394573290781412, self.slope: [1.09481626 1.09564053], self.intercept: 1.0085319153820707\n",
      "iteration - 9672 -> loss: 0.00023944642962714743, self.slope: [1.09482358 1.09564795], self.intercept: 1.008532617429676\n",
      "iteration - 9673 -> loss: 0.0002394355311989202, self.slope: [1.09483089 1.09565536], self.intercept: 1.0085333194505546\n",
      "iteration - 9674 -> loss: 0.00023942463379329, self.slope: [1.09483821 1.09566278], self.intercept: 1.008534021444707\n",
      "iteration - 9675 -> loss: 0.00023941373741013925, self.slope: [1.09484552 1.09567019], self.intercept: 1.008534723412135\n",
      "iteration - 9676 -> loss: 0.00023940284204931861, self.slope: [1.09485283 1.09567761], self.intercept: 1.0085354253528416\n",
      "iteration - 9677 -> loss: 0.00023939194771067557, self.slope: [1.09486015 1.09568502], self.intercept: 1.0085361272668285\n",
      "iteration - 9678 -> loss: 0.00023938105439404986, self.slope: [1.09486746 1.09569244], self.intercept: 1.008536829154098\n",
      "iteration - 9679 -> loss: 0.00023937016209933123, self.slope: [1.09487477 1.09569985], self.intercept: 1.0085375310146518\n",
      "iteration - 9680 -> loss: 0.00023935927082633607, self.slope: [1.09488208 1.09570726], self.intercept: 1.0085382328484938\n",
      "iteration - 9681 -> loss: 0.00023934838057493735, self.slope: [1.09488939 1.09571468], self.intercept: 1.008538934655624\n",
      "iteration - 9682 -> loss: 0.0002393374913449987, self.slope: [1.0948967  1.09572209], self.intercept: 1.008539636436046\n",
      "iteration - 9683 -> loss: 0.0002393266031363802, self.slope: [1.09490401 1.0957295 ], self.intercept: 1.0085403381897609\n",
      "iteration - 9684 -> loss: 0.00023931571594888311, self.slope: [1.09491132 1.09573691], self.intercept: 1.0085410399167725\n",
      "iteration - 9685 -> loss: 0.0002393048297824225, self.slope: [1.09491863 1.09574432], self.intercept: 1.0085417416170812\n",
      "iteration - 9686 -> loss: 0.00023929394463683069, self.slope: [1.09492594 1.09575174], self.intercept: 1.0085424432906904\n",
      "iteration - 9687 -> loss: 0.0002392830605119615, self.slope: [1.09493325 1.09575915], self.intercept: 1.008543144937602\n",
      "iteration - 9688 -> loss: 0.0002392721774076672, self.slope: [1.09494056 1.09576656], self.intercept: 1.0085438465578196\n",
      "iteration - 9689 -> loss: 0.0002392612953238061, self.slope: [1.09494787 1.09577397], self.intercept: 1.0085445481513435\n",
      "iteration - 9690 -> loss: 0.00023925041426024594, self.slope: [1.09495518 1.09578138], self.intercept: 1.0085452497181762\n",
      "iteration - 9691 -> loss: 0.0002392395342168052, self.slope: [1.09496248 1.09578879], self.intercept: 1.0085459512583193\n",
      "iteration - 9692 -> loss: 0.00023922865519338286, self.slope: [1.09496979 1.0957962 ], self.intercept: 1.0085466527717768\n",
      "iteration - 9693 -> loss: 0.00023921777718979146, self.slope: [1.0949771 1.0958036], self.intercept: 1.0085473542585506\n",
      "iteration - 9694 -> loss: 0.00023920690020591873, self.slope: [1.09498441 1.09581101], self.intercept: 1.0085480557186426\n",
      "iteration - 9695 -> loss: 0.00023919602424160452, self.slope: [1.09499171 1.09581842], self.intercept: 1.008548757152054\n",
      "iteration - 9696 -> loss: 0.00023918514929671084, self.slope: [1.09499902 1.09582583], self.intercept: 1.0085494585587875\n",
      "iteration - 9697 -> loss: 0.00023917427537107505, self.slope: [1.09500632 1.09583324], self.intercept: 1.0085501599388458\n",
      "iteration - 9698 -> loss: 0.0002391634024645724, self.slope: [1.09501363 1.09584064], self.intercept: 1.0085508612922298\n",
      "iteration - 9699 -> loss: 0.00023915253057704605, self.slope: [1.09502093 1.09584805], self.intercept: 1.0085515626189439\n",
      "iteration - 9700 -> loss: 0.00023914165970837585, self.slope: [1.09502824 1.09585546], self.intercept: 1.0085522639189888\n",
      "iteration - 9701 -> loss: 0.00023913078985838456, self.slope: [1.09503554 1.09586286], self.intercept: 1.0085529651923684\n",
      "iteration - 9702 -> loss: 0.00023911992102694236, self.slope: [1.09504285 1.09587027], self.intercept: 1.008553666439083\n",
      "iteration - 9703 -> loss: 0.0002391090532139029, self.slope: [1.09505015 1.09587767], self.intercept: 1.0085543676591353\n",
      "iteration - 9704 -> loss: 0.00023909818641911214, self.slope: [1.09505745 1.09588508], self.intercept: 1.008555068852529\n",
      "iteration - 9705 -> loss: 0.00023908732064243686, self.slope: [1.09506476 1.09589248], self.intercept: 1.008555770019264\n",
      "iteration - 9706 -> loss: 0.0002390764558837284, self.slope: [1.09507206 1.09589989], self.intercept: 1.0085564711593438\n",
      "iteration - 9707 -> loss: 0.00023906559214284303, self.slope: [1.09507936 1.09590729], self.intercept: 1.0085571722727684\n",
      "iteration - 9708 -> loss: 0.00023905472941964048, self.slope: [1.09508666 1.09591469], self.intercept: 1.0085578733595424\n",
      "iteration - 9709 -> loss: 0.00023904386771395728, self.slope: [1.09509396 1.0959221 ], self.intercept: 1.008558574419668\n",
      "iteration - 9710 -> loss: 0.00023903300702566638, self.slope: [1.09510127 1.0959295 ], self.intercept: 1.0085592754531458\n",
      "iteration - 9711 -> loss: 0.00023902214735462734, self.slope: [1.09510857 1.0959369 ], self.intercept: 1.0085599764599802\n",
      "iteration - 9712 -> loss: 0.0002390112887006679, self.slope: [1.09511587 1.09594431], self.intercept: 1.0085606774401712\n",
      "iteration - 9713 -> loss: 0.00023900043106368448, self.slope: [1.09512317 1.09595171], self.intercept: 1.0085613783937228\n",
      "iteration - 9714 -> loss: 0.00023898957444349234, self.slope: [1.09513047 1.09595911], self.intercept: 1.0085620793206365\n",
      "iteration - 9715 -> loss: 0.000238978718839978, self.slope: [1.09513777 1.09596651], self.intercept: 1.0085627802209143\n",
      "iteration - 9716 -> loss: 0.00023896786425297412, self.slope: [1.09514507 1.09597391], self.intercept: 1.0085634810945592\n",
      "iteration - 9717 -> loss: 0.00023895701068234423, self.slope: [1.09515236 1.09598131], self.intercept: 1.0085641819415707\n",
      "iteration - 9718 -> loss: 0.00023894615812795233, self.slope: [1.09515966 1.09598871], self.intercept: 1.0085648827619544\n",
      "iteration - 9719 -> loss: 0.00023893530658963613, self.slope: [1.09516696 1.09599611], self.intercept: 1.0085655835557117\n",
      "iteration - 9720 -> loss: 0.00023892445606728155, self.slope: [1.09517426 1.09600351], self.intercept: 1.0085662843228438\n",
      "iteration - 9721 -> loss: 0.0002389136065607087, self.slope: [1.09518156 1.09601091], self.intercept: 1.0085669850633534\n",
      "iteration - 9722 -> loss: 0.00023890275806979624, self.slope: [1.09518885 1.09601831], self.intercept: 1.008567685777242\n",
      "iteration - 9723 -> loss: 0.0002388919105943816, self.slope: [1.09519615 1.09602571], self.intercept: 1.0085683864645134\n",
      "iteration - 9724 -> loss: 0.00023888106413434774, self.slope: [1.09520345 1.09603311], self.intercept: 1.0085690871251678\n",
      "iteration - 9725 -> loss: 0.00023887021868952373, self.slope: [1.09521074 1.0960405 ], self.intercept: 1.0085697877592097\n",
      "iteration - 9726 -> loss: 0.00023885937425978412, self.slope: [1.09521804 1.0960479 ], self.intercept: 1.0085704883666387\n",
      "iteration - 9727 -> loss: 0.00023884853084496705, self.slope: [1.09522533 1.0960553 ], self.intercept: 1.0085711889474573\n",
      "iteration - 9728 -> loss: 0.00023883768844495533, self.slope: [1.09523263 1.09606269], self.intercept: 1.0085718895016695\n",
      "iteration - 9729 -> loss: 0.00023882684705956884, self.slope: [1.09523992 1.09607009], self.intercept: 1.0085725900292772\n",
      "iteration - 9730 -> loss: 0.00023881600668869044, self.slope: [1.09524722 1.09607749], self.intercept: 1.008573290530282\n",
      "iteration - 9731 -> loss: 0.0002388051673321468, self.slope: [1.09525451 1.09608488], self.intercept: 1.008573991004686\n",
      "iteration - 9732 -> loss: 0.00023879432898983734, self.slope: [1.0952618  1.09609228], self.intercept: 1.0085746914524913\n",
      "iteration - 9733 -> loss: 0.00023878349166159214, self.slope: [1.0952691  1.09609967], self.intercept: 1.0085753918737004\n",
      "iteration - 9734 -> loss: 0.00023877265534725945, self.slope: [1.09527639 1.09610707], self.intercept: 1.008576092268316\n",
      "iteration - 9735 -> loss: 0.00023876182004670728, self.slope: [1.09528368 1.09611446], self.intercept: 1.0085767926363394\n",
      "iteration - 9736 -> loss: 0.00023875098575979386, self.slope: [1.09529097 1.09612186], self.intercept: 1.0085774929777733\n",
      "iteration - 9737 -> loss: 0.00023874015248637821, self.slope: [1.09529827 1.09612925], self.intercept: 1.0085781932926188\n",
      "iteration - 9738 -> loss: 0.0002387293202263061, self.slope: [1.09530556 1.09613664], self.intercept: 1.0085788935808804\n",
      "iteration - 9739 -> loss: 0.000238718488979429, self.slope: [1.09531285 1.09614404], self.intercept: 1.0085795938425584\n",
      "iteration - 9740 -> loss: 0.00023870765874560847, self.slope: [1.09532014 1.09615143], self.intercept: 1.0085802940776558\n",
      "iteration - 9741 -> loss: 0.00023869682952472354, self.slope: [1.09532743 1.09615882], self.intercept: 1.008580994286174\n",
      "iteration - 9742 -> loss: 0.0002386860013165902, self.slope: [1.09533472 1.09616621], self.intercept: 1.0085816944681156\n",
      "iteration - 9743 -> loss: 0.00023867517412108402, self.slope: [1.09534201 1.0961736 ], self.intercept: 1.0085823946234824\n",
      "iteration - 9744 -> loss: 0.00023866434793806348, self.slope: [1.0953493 1.096181 ], self.intercept: 1.0085830947522767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 9745 -> loss: 0.00023865352276739152, self.slope: [1.09535659 1.09618839], self.intercept: 1.008583794854502\n",
      "iteration - 9746 -> loss: 0.00023864269860890392, self.slope: [1.09536388 1.09619578], self.intercept: 1.0085844949301594\n",
      "iteration - 9747 -> loss: 0.0002386318754624735, self.slope: [1.09537117 1.09620317], self.intercept: 1.008585194979252\n",
      "iteration - 9748 -> loss: 0.00023862105332794986, self.slope: [1.09537845 1.09621056], self.intercept: 1.0085858950017812\n",
      "iteration - 9749 -> loss: 0.00023861023220518742, self.slope: [1.09538574 1.09621795], self.intercept: 1.0085865949977495\n",
      "iteration - 9750 -> loss: 0.00023859941209405884, self.slope: [1.09539303 1.09622534], self.intercept: 1.008587294967158\n",
      "iteration - 9751 -> loss: 0.00023858859299440233, self.slope: [1.09540032 1.09623273], self.intercept: 1.0085879949100096\n",
      "iteration - 9752 -> loss: 0.00023857777490608696, self.slope: [1.0954076  1.09624011], self.intercept: 1.0085886948263059\n",
      "iteration - 9753 -> loss: 0.0002385669578289572, self.slope: [1.09541489 1.0962475 ], self.intercept: 1.0085893947160507\n",
      "iteration - 9754 -> loss: 0.00023855614176288296, self.slope: [1.09542217 1.09625489], self.intercept: 1.008590094579245\n",
      "iteration - 9755 -> loss: 0.00023854532670770126, self.slope: [1.09542946 1.09626228], self.intercept: 1.0085907944158923\n",
      "iteration - 9756 -> loss: 0.000238534512663279, self.slope: [1.09543675 1.09626966], self.intercept: 1.008591494225994\n",
      "iteration - 9757 -> loss: 0.00023852369962948025, self.slope: [1.09544403 1.09627705], self.intercept: 1.0085921940095517\n",
      "iteration - 9758 -> loss: 0.0002385128876061524, self.slope: [1.09545132 1.09628444], self.intercept: 1.0085928937665667\n",
      "iteration - 9759 -> loss: 0.00023850207659315313, self.slope: [1.0954586  1.09629182], self.intercept: 1.008593593497043\n",
      "iteration - 9760 -> loss: 0.00023849126659034547, self.slope: [1.09546588 1.09629921], self.intercept: 1.008594293200982\n",
      "iteration - 9761 -> loss: 0.00023848045759759004, self.slope: [1.09547317 1.09630659], self.intercept: 1.0085949928783877\n",
      "iteration - 9762 -> loss: 0.00023846964961471464, self.slope: [1.09548045 1.09631398], self.intercept: 1.0085956925292596\n",
      "iteration - 9763 -> loss: 0.00023845884264159331, self.slope: [1.09548773 1.09632136], self.intercept: 1.0085963921536005\n",
      "iteration - 9764 -> loss: 0.000238448036678105, self.slope: [1.09549502 1.09632875], self.intercept: 1.0085970917514147\n",
      "iteration - 9765 -> loss: 0.00023843723172407914, self.slope: [1.0955023  1.09633613], self.intercept: 1.0085977913227018\n",
      "iteration - 9766 -> loss: 0.00023842642777937315, self.slope: [1.09550958 1.09634352], self.intercept: 1.0085984908674643\n",
      "iteration - 9767 -> loss: 0.00023841562484386365, self.slope: [1.09551686 1.0963509 ], self.intercept: 1.0085991903857057\n",
      "iteration - 9768 -> loss: 0.0002384048229173847, self.slope: [1.09552414 1.09635828], self.intercept: 1.0085998898774282\n",
      "iteration - 9769 -> loss: 0.00023839402199981623, self.slope: [1.09553142 1.09636567], self.intercept: 1.0086005893426329\n",
      "iteration - 9770 -> loss: 0.00023838322209099568, self.slope: [1.0955387  1.09637305], self.intercept: 1.008601288781321\n",
      "iteration - 9771 -> loss: 0.00023837242319078153, self.slope: [1.09554598 1.09638043], self.intercept: 1.008601988193498\n",
      "iteration - 9772 -> loss: 0.00023836162529904256, self.slope: [1.09555326 1.09638781], self.intercept: 1.0086026875791627\n",
      "iteration - 9773 -> loss: 0.00023835082841562954, self.slope: [1.09556054 1.09639519], self.intercept: 1.008603386938319\n",
      "iteration - 9774 -> loss: 0.0002383400325404024, self.slope: [1.09556782 1.09640257], self.intercept: 1.00860408627097\n",
      "iteration - 9775 -> loss: 0.00023832923767321175, self.slope: [1.0955751  1.09640995], self.intercept: 1.0086047855771145\n",
      "iteration - 9776 -> loss: 0.0002383184438139176, self.slope: [1.09558238 1.09641734], self.intercept: 1.008605484856758\n",
      "iteration - 9777 -> loss: 0.0002383076509623671, self.slope: [1.09558966 1.09642471], self.intercept: 1.0086061841099019\n",
      "iteration - 9778 -> loss: 0.00023829685911844585, self.slope: [1.09559694 1.09643209], self.intercept: 1.008606883336548\n",
      "iteration - 9779 -> loss: 0.0002382860682819835, self.slope: [1.09560421 1.09643947], self.intercept: 1.0086075825366998\n",
      "iteration - 9780 -> loss: 0.0002382752784528389, self.slope: [1.09561149 1.09644685], self.intercept: 1.0086082817103568\n",
      "iteration - 9781 -> loss: 0.00023826448963088813, self.slope: [1.09561877 1.09645423], self.intercept: 1.008608980857522\n",
      "iteration - 9782 -> loss: 0.00023825370181597655, self.slope: [1.09562604 1.09646161], self.intercept: 1.0086096799781987\n",
      "iteration - 9783 -> loss: 0.0002382429150079683, self.slope: [1.09563332 1.09646899], self.intercept: 1.008610379072388\n",
      "iteration - 9784 -> loss: 0.000238232129206708, self.slope: [1.0956406  1.09647636], self.intercept: 1.0086110781400928\n",
      "iteration - 9785 -> loss: 0.00023822134441205372, self.slope: [1.09564787 1.09648374], self.intercept: 1.0086117771813157\n",
      "iteration - 9786 -> loss: 0.00023821056062387765, self.slope: [1.09565515 1.09649112], self.intercept: 1.0086124761960593\n",
      "iteration - 9787 -> loss: 0.00023819977784202639, self.slope: [1.09566242 1.0964985 ], self.intercept: 1.008613175184324\n",
      "iteration - 9788 -> loss: 0.0002381889960663627, self.slope: [1.09566969 1.09650587], self.intercept: 1.0086138741461128\n",
      "iteration - 9789 -> loss: 0.0002381782152967353, self.slope: [1.09567697 1.09651325], self.intercept: 1.008614573081427\n",
      "iteration - 9790 -> loss: 0.00023816743553300876, self.slope: [1.09568424 1.09652062], self.intercept: 1.008615271990271\n",
      "iteration - 9791 -> loss: 0.00023815665677504104, self.slope: [1.09569152 1.096528  ], self.intercept: 1.0086159708726448\n",
      "iteration - 9792 -> loss: 0.00023814587902267352, self.slope: [1.09569879 1.09653537], self.intercept: 1.0086166697285515\n",
      "iteration - 9793 -> loss: 0.00023813510227579582, self.slope: [1.09570606 1.09654275], self.intercept: 1.008617368557992\n",
      "iteration - 9794 -> loss: 0.0002381243265342364, self.slope: [1.09571333 1.09655012], self.intercept: 1.0086180673609693\n",
      "iteration - 9795 -> loss: 0.00023811355179786863, self.slope: [1.09572061 1.0965575 ], self.intercept: 1.008618766137487\n",
      "iteration - 9796 -> loss: 0.0002381027780665386, self.slope: [1.09572788 1.09656487], self.intercept: 1.008619464887547\n",
      "iteration - 9797 -> loss: 0.00023809200534012949, self.slope: [1.09573515 1.09657224], self.intercept: 1.00862016361115\n",
      "iteration - 9798 -> loss: 0.0002380812336184667, self.slope: [1.09574242 1.09657961], self.intercept: 1.0086208623082993\n",
      "iteration - 9799 -> loss: 0.00023807046290142425, self.slope: [1.09574969 1.09658699], self.intercept: 1.0086215609789957\n",
      "iteration - 9800 -> loss: 0.0002380596931888501, self.slope: [1.09575696 1.09659436], self.intercept: 1.0086222596232428\n",
      "iteration - 9801 -> loss: 0.00023804892448061802, self.slope: [1.09576423 1.09660173], self.intercept: 1.0086229582410429\n",
      "iteration - 9802 -> loss: 0.00023803815677657988, self.slope: [1.0957715 1.0966091], self.intercept: 1.0086236568323965\n",
      "iteration - 9803 -> loss: 0.00023802739007657242, self.slope: [1.09577877 1.09661647], self.intercept: 1.008624355397306\n",
      "iteration - 9804 -> loss: 0.00023801662438047974, self.slope: [1.09578604 1.09662384], self.intercept: 1.0086250539357748\n",
      "iteration - 9805 -> loss: 0.00023800585968815818, self.slope: [1.09579331 1.09663121], self.intercept: 1.0086257524478062\n",
      "iteration - 9806 -> loss: 0.0002379950959994541, self.slope: [1.09580057 1.09663858], self.intercept: 1.0086264509333993\n",
      "iteration - 9807 -> loss: 0.00023798433331423649, self.slope: [1.09580784 1.09664595], self.intercept: 1.0086271493925578\n",
      "iteration - 9808 -> loss: 0.0002379735716323467, self.slope: [1.09581511 1.09665332], self.intercept: 1.0086278478252835\n",
      "iteration - 9809 -> loss: 0.0002379628109536495, self.slope: [1.09582238 1.09666069], self.intercept: 1.008628546231579\n",
      "iteration - 9810 -> loss: 0.00023795205127802988, self.slope: [1.09582964 1.09666806], self.intercept: 1.0086292446114473\n",
      "iteration - 9811 -> loss: 0.00023794129260530547, self.slope: [1.09583691 1.09667543], self.intercept: 1.008629942964889\n",
      "iteration - 9812 -> loss: 0.00023793053493535488, self.slope: [1.09584418 1.0966828 ], self.intercept: 1.0086306412919082\n",
      "iteration - 9813 -> loss: 0.00023791977826803117, self.slope: [1.09585144 1.09669017], self.intercept: 1.0086313395925048\n",
      "iteration - 9814 -> loss: 0.0002379090226031928, self.slope: [1.09585871 1.09669753], self.intercept: 1.0086320378666827\n",
      "iteration - 9815 -> loss: 0.00023789826794069337, self.slope: [1.09586597 1.0967049 ], self.intercept: 1.0086327361144427\n",
      "iteration - 9816 -> loss: 0.0002378875142804144, self.slope: [1.09587324 1.09671227], self.intercept: 1.008633434335789\n",
      "iteration - 9817 -> loss: 0.00023787676162218466, self.slope: [1.0958805  1.09671963], self.intercept: 1.0086341325307224\n",
      "iteration - 9818 -> loss: 0.00023786600996587374, self.slope: [1.09588777 1.096727  ], self.intercept: 1.008634830699243\n",
      "iteration - 9819 -> loss: 0.0002378552593113405, self.slope: [1.09589503 1.09673436], self.intercept: 1.0086355288413564\n",
      "iteration - 9820 -> loss: 0.00023784450965844684, self.slope: [1.09590229 1.09674173], self.intercept: 1.0086362269570632\n",
      "iteration - 9821 -> loss: 0.00023783376100703908, self.slope: [1.09590956 1.09674909], self.intercept: 1.008636925046368\n",
      "iteration - 9822 -> loss: 0.00023782301335699253, self.slope: [1.09591682 1.09675646], self.intercept: 1.0086376231092682\n",
      "iteration - 9823 -> loss: 0.00023781226670815164, self.slope: [1.09592408 1.09676382], self.intercept: 1.0086383211457697\n",
      "iteration - 9824 -> loss: 0.0002378015210603825, self.slope: [1.09593134 1.09677119], self.intercept: 1.008639019155873\n",
      "iteration - 9825 -> loss: 0.00023779077641354057, self.slope: [1.0959386  1.09677855], self.intercept: 1.0086397171395807\n",
      "iteration - 9826 -> loss: 0.00023778003276747554, self.slope: [1.09594587 1.09678591], self.intercept: 1.0086404150968946\n",
      "iteration - 9827 -> loss: 0.00023776929012207053, self.slope: [1.09595313 1.09679328], self.intercept: 1.0086411130278181\n",
      "iteration - 9828 -> loss: 0.00023775854847715656, self.slope: [1.09596039 1.09680064], self.intercept: 1.0086418109323523\n",
      "iteration - 9829 -> loss: 0.0002377478078326198, self.slope: [1.09596765 1.096808  ], self.intercept: 1.0086425088105\n",
      "iteration - 9830 -> loss: 0.00023773706818829094, self.slope: [1.09597491 1.09681536], self.intercept: 1.0086432066622637\n",
      "iteration - 9831 -> loss: 0.00023772632954403231, self.slope: [1.09598217 1.09682272], self.intercept: 1.0086439044876445\n",
      "iteration - 9832 -> loss: 0.00023771559189972557, self.slope: [1.09598943 1.09683009], self.intercept: 1.0086446022866458\n",
      "iteration - 9833 -> loss: 0.00023770485525521096, self.slope: [1.09599669 1.09683745], self.intercept: 1.0086453000592688\n",
      "iteration - 9834 -> loss: 0.00023769411961033354, self.slope: [1.09600394 1.09684481], self.intercept: 1.0086459978055147\n",
      "iteration - 9835 -> loss: 0.000237683384965006, self.slope: [1.0960112  1.09685217], self.intercept: 1.0086466955253863\n",
      "iteration - 9836 -> loss: 0.00023767265131901746, self.slope: [1.09601846 1.09685953], self.intercept: 1.0086473932188862\n",
      "iteration - 9837 -> loss: 0.00023766191867228978, self.slope: [1.09602572 1.09686689], self.intercept: 1.0086480908860171\n",
      "iteration - 9838 -> loss: 0.00023765118702462367, self.slope: [1.09603298 1.09687425], self.intercept: 1.0086487885267812\n",
      "iteration - 9839 -> loss: 0.00023764045637592236, self.slope: [1.09604023 1.0968816 ], self.intercept: 1.0086494861411794\n",
      "iteration - 9840 -> loss: 0.00023762972672601554, self.slope: [1.09604749 1.09688896], self.intercept: 1.008650183729215\n",
      "iteration - 9841 -> loss: 0.00023761899807478296, self.slope: [1.09605474 1.09689632], self.intercept: 1.0086508812908894\n",
      "iteration - 9842 -> loss: 0.00023760827042208877, self.slope: [1.096062   1.09690368], self.intercept: 1.008651578826205\n",
      "iteration - 9843 -> loss: 0.00023759754376774845, self.slope: [1.09606926 1.09691104], self.intercept: 1.0086522763351644\n",
      "iteration - 9844 -> loss: 0.00023758681811166007, self.slope: [1.09607651 1.09691839], self.intercept: 1.0086529738177685\n",
      "iteration - 9845 -> loss: 0.0002375760934536788, self.slope: [1.09608377 1.09692575], self.intercept: 1.0086536712740222\n",
      "iteration - 9846 -> loss: 0.00023756536979366565, self.slope: [1.09609102 1.09693311], self.intercept: 1.008654368703925\n",
      "iteration - 9847 -> loss: 0.00023755464713145233, self.slope: [1.09609828 1.09694046], self.intercept: 1.0086550661074805\n",
      "iteration - 9848 -> loss: 0.00023754392546693342, self.slope: [1.09610553 1.09694782], self.intercept: 1.0086557634846902\n",
      "iteration - 9849 -> loss: 0.00023753320479995112, self.slope: [1.09611278 1.09695517], self.intercept: 1.0086564608355564\n",
      "iteration - 9850 -> loss: 0.00023752248513035884, self.slope: [1.09612004 1.09696253], self.intercept: 1.0086571581600805\n",
      "iteration - 9851 -> loss: 0.00023751176645802583, self.slope: [1.09612729 1.09696988], self.intercept: 1.0086578554582657\n",
      "iteration - 9852 -> loss: 0.00023750104878281095, self.slope: [1.09613454 1.09697724], self.intercept: 1.008658552730114\n",
      "iteration - 9853 -> loss: 0.00023749033210455412, self.slope: [1.09614179 1.09698459], self.intercept: 1.0086592499756273\n",
      "iteration - 9854 -> loss: 0.00023747961642315261, self.slope: [1.09614904 1.09699195], self.intercept: 1.0086599471948074\n",
      "iteration - 9855 -> loss: 0.00023746890173843068, self.slope: [1.0961563 1.0969993], self.intercept: 1.008660644387658\n",
      "iteration - 9856 -> loss: 0.00023745818805026014, self.slope: [1.09616355 1.09700665], self.intercept: 1.0086613415541796\n",
      "iteration - 9857 -> loss: 0.00023744747535848793, self.slope: [1.0961708  1.09701401], self.intercept: 1.0086620386943757\n",
      "iteration - 9858 -> loss: 0.00023743676366302216, self.slope: [1.09617805 1.09702136], self.intercept: 1.0086627358082474\n",
      "iteration - 9859 -> loss: 0.00023742605296367492, self.slope: [1.0961853  1.09702871], self.intercept: 1.0086634328957969\n",
      "iteration - 9860 -> loss: 0.0002374153432602849, self.slope: [1.09619255 1.09703606], self.intercept: 1.0086641299570267\n",
      "iteration - 9861 -> loss: 0.00023740463455277107, self.slope: [1.0961998  1.09704341], self.intercept: 1.0086648269919387\n",
      "iteration - 9862 -> loss: 0.00023739392684096153, self.slope: [1.09620705 1.09705076], self.intercept: 1.0086655240005353\n",
      "iteration - 9863 -> loss: 0.00023738322012471498, self.slope: [1.0962143  1.09705811], self.intercept: 1.0086662209828188\n",
      "iteration - 9864 -> loss: 0.0002373725144039082, self.slope: [1.09622154 1.09706546], self.intercept: 1.0086669179387913\n",
      "iteration - 9865 -> loss: 0.00023736180967836955, self.slope: [1.09622879 1.09707281], self.intercept: 1.0086676148684552\n",
      "iteration - 9866 -> loss: 0.0002373511059479844, self.slope: [1.09623604 1.09708016], self.intercept: 1.0086683117718114\n",
      "iteration - 9867 -> loss: 0.00023734040321260033, self.slope: [1.09624329 1.09708751], self.intercept: 1.008669008648863\n",
      "iteration - 9868 -> loss: 0.0002373297014720847, self.slope: [1.09625053 1.09709486], self.intercept: 1.0086697054996125\n",
      "iteration - 9869 -> loss: 0.0002373190007262929, self.slope: [1.09625778 1.09710221], self.intercept: 1.0086704023240616\n",
      "iteration - 9870 -> loss: 0.00023730830097508704, self.slope: [1.09626503 1.09710956], self.intercept: 1.0086710991222123\n",
      "iteration - 9871 -> loss: 0.00023729760221833138, self.slope: [1.09627227 1.09711691], self.intercept: 1.0086717958940659\n",
      "iteration - 9872 -> loss: 0.000237286904455862, self.slope: [1.09627952 1.09712425], self.intercept: 1.008672492639628\n",
      "iteration - 9873 -> loss: 0.00023727620768755544, self.slope: [1.09628676 1.0971316 ], self.intercept: 1.0086731893588974\n",
      "iteration - 9874 -> loss: 0.00023726551191328592, self.slope: [1.09629401 1.09713895], self.intercept: 1.0086738860518767\n",
      "iteration - 9875 -> loss: 0.00023725481713290084, self.slope: [1.09630125 1.0971463 ], self.intercept: 1.0086745827185697\n",
      "iteration - 9876 -> loss: 0.00023724412334625374, self.slope: [1.0963085  1.09715364], self.intercept: 1.0086752793589768\n",
      "iteration - 9877 -> loss: 0.0002372334305531937, self.slope: [1.09631574 1.09716099], self.intercept: 1.0086759759731005\n",
      "iteration - 9878 -> loss: 0.00023722273875359664, self.slope: [1.09632299 1.09716833], self.intercept: 1.0086766725609448\n",
      "iteration - 9879 -> loss: 0.00023721204794734202, self.slope: [1.09633023 1.09717568], self.intercept: 1.0086773691225097\n",
      "iteration - 9880 -> loss: 0.00023720135813425623, self.slope: [1.09633747 1.09718302], self.intercept: 1.0086780656577972\n",
      "iteration - 9881 -> loss: 0.00023719066931421142, self.slope: [1.09634471 1.09719037], self.intercept: 1.00867876216681\n",
      "iteration - 9882 -> loss: 0.00023717998148708688, self.slope: [1.09635196 1.09719771], self.intercept: 1.0086794586495524\n",
      "iteration - 9883 -> loss: 0.00023716929465269742, self.slope: [1.0963592  1.09720506], self.intercept: 1.0086801551060232\n",
      "iteration - 9884 -> loss: 0.0002371586088109368, self.slope: [1.09636644 1.0972124 ], self.intercept: 1.008680851536226\n",
      "iteration - 9885 -> loss: 0.00023714792396166716, self.slope: [1.09637368 1.09721974], self.intercept: 1.0086815479401634\n",
      "iteration - 9886 -> loss: 0.00023713724010472495, self.slope: [1.09638092 1.09722709], self.intercept: 1.0086822443178363\n",
      "iteration - 9887 -> loss: 0.00023712655723999332, self.slope: [1.09638816 1.09723443], self.intercept: 1.0086829406692475\n",
      "iteration - 9888 -> loss: 0.00023711587536732172, self.slope: [1.0963954  1.09724177], self.intercept: 1.0086836369943992\n",
      "iteration - 9889 -> loss: 0.00023710519448657017, self.slope: [1.09640264 1.09724911], self.intercept: 1.0086843332932938\n",
      "iteration - 9890 -> loss: 0.0002370945145975984, self.slope: [1.09640988 1.09725645], self.intercept: 1.0086850295659335\n",
      "iteration - 9891 -> loss: 0.00023708383570028037, self.slope: [1.09641712 1.09726379], self.intercept: 1.0086857258123212\n",
      "iteration - 9892 -> loss: 0.00023707315779444504, self.slope: [1.09642436 1.09727114], self.intercept: 1.0086864220324576\n",
      "iteration - 9893 -> loss: 0.00023706248087998854, self.slope: [1.0964316  1.09727848], self.intercept: 1.008687118226345\n",
      "iteration - 9894 -> loss: 0.00023705180495675422, self.slope: [1.09643884 1.09728582], self.intercept: 1.008687814393986\n",
      "iteration - 9895 -> loss: 0.00023704113002460044, self.slope: [1.09644608 1.09729316], self.intercept: 1.0086885105353829\n",
      "iteration - 9896 -> loss: 0.00023703045608337847, self.slope: [1.09645331 1.0973005 ], self.intercept: 1.008689206650537\n",
      "iteration - 9897 -> loss: 0.00023701978313296973, self.slope: [1.09646055 1.09730783], self.intercept: 1.0086899027394514\n",
      "iteration - 9898 -> loss: 0.00023700911117323676, self.slope: [1.09646779 1.09731517], self.intercept: 1.008690598802128\n",
      "iteration - 9899 -> loss: 0.00023699844020399767, self.slope: [1.09647502 1.09732251], self.intercept: 1.008691294838568\n",
      "iteration - 9900 -> loss: 0.000236987770225166, self.slope: [1.09648226 1.09732985], self.intercept: 1.0086919908487757\n",
      "iteration - 9901 -> loss: 0.00023697710123657685, self.slope: [1.0964895  1.09733719], self.intercept: 1.0086926868327515\n",
      "iteration - 9902 -> loss: 0.0002369664332380976, self.slope: [1.09649673 1.09734453], self.intercept: 1.008693382790499\n",
      "iteration - 9903 -> loss: 0.0002369557662295805, self.slope: [1.09650397 1.09735186], self.intercept: 1.0086940787220184\n",
      "iteration - 9904 -> loss: 0.0002369451002108919, self.slope: [1.0965112 1.0973592], self.intercept: 1.0086947746273132\n",
      "iteration - 9905 -> loss: 0.00023693443518187692, self.slope: [1.09651844 1.09736654], self.intercept: 1.0086954705063842\n",
      "iteration - 9906 -> loss: 0.00023692377114242554, self.slope: [1.09652567 1.09737387], self.intercept: 1.0086961663592346\n",
      "iteration - 9907 -> loss: 0.00023691310809236733, self.slope: [1.0965329  1.09738121], self.intercept: 1.0086968621858683\n",
      "iteration - 9908 -> loss: 0.00023690244603160219, self.slope: [1.09654014 1.09738854], self.intercept: 1.0086975579862842\n",
      "iteration - 9909 -> loss: 0.00023689178495994422, self.slope: [1.09654737 1.09739588], self.intercept: 1.0086982537604874\n",
      "iteration - 9910 -> loss: 0.00023688112487728441, self.slope: [1.0965546  1.09740321], self.intercept: 1.0086989495084773\n",
      "iteration - 9911 -> loss: 0.00023687046578346895, self.slope: [1.09656184 1.09741055], self.intercept: 1.0086996452302566\n",
      "iteration - 9912 -> loss: 0.00023685980767838, self.slope: [1.09656907 1.09741788], self.intercept: 1.0087003409258293\n",
      "iteration - 9913 -> loss: 0.00023684915056184288, self.slope: [1.0965763  1.09742521], self.intercept: 1.0087010365951956\n",
      "iteration - 9914 -> loss: 0.00023683849443377047, self.slope: [1.09658353 1.09743255], self.intercept: 1.0087017322383578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration - 9915 -> loss: 0.00023682783929395842, self.slope: [1.09659076 1.09743988], self.intercept: 1.0087024278553194\n",
      "iteration - 9916 -> loss: 0.00023681718514233178, self.slope: [1.09659799 1.09744721], self.intercept: 1.008703123446083\n",
      "iteration - 9917 -> loss: 0.0002368065319786947, self.slope: [1.09660522 1.09745455], self.intercept: 1.0087038190106477\n",
      "iteration - 9918 -> loss: 0.00023679587980295167, self.slope: [1.09661245 1.09746188], self.intercept: 1.0087045145490166\n",
      "iteration - 9919 -> loss: 0.0002367852286149399, self.slope: [1.09661968 1.09746921], self.intercept: 1.008705210061194\n",
      "iteration - 9920 -> loss: 0.00023677457841451155, self.slope: [1.09662691 1.09747654], self.intercept: 1.0087059055471792\n",
      "iteration - 9921 -> loss: 0.00023676392920156847, self.slope: [1.09663414 1.09748387], self.intercept: 1.0087066010069772\n",
      "iteration - 9922 -> loss: 0.00023675328097593265, self.slope: [1.09664137 1.0974912 ], self.intercept: 1.0087072964405892\n",
      "iteration - 9923 -> loss: 0.00023674263373748623, self.slope: [1.0966486  1.09749853], self.intercept: 1.0087079918480175\n",
      "iteration - 9924 -> loss: 0.00023673198748606892, self.slope: [1.09665583 1.09750586], self.intercept: 1.0087086872292632\n",
      "iteration - 9925 -> loss: 0.00023672134222157582, self.slope: [1.09666305 1.09751319], self.intercept: 1.0087093825843279\n",
      "iteration - 9926 -> loss: 0.00023671069794382673, self.slope: [1.09667028 1.09752052], self.intercept: 1.0087100779132157\n",
      "iteration - 9927 -> loss: 0.00023670005465272381, self.slope: [1.09667751 1.09752785], self.intercept: 1.0087107732159264\n",
      "iteration - 9928 -> loss: 0.00023668941234809135, self.slope: [1.09668474 1.09753518], self.intercept: 1.0087114684924647\n",
      "iteration - 9929 -> loss: 0.00023667877102981547, self.slope: [1.09669196 1.09754251], self.intercept: 1.0087121637428316\n",
      "iteration - 9930 -> loss: 0.00023666813069773705, self.slope: [1.09669919 1.09754984], self.intercept: 1.008712858967029\n",
      "iteration - 9931 -> loss: 0.00023665749135174478, self.slope: [1.09670641 1.09755716], self.intercept: 1.0087135541650598\n",
      "iteration - 9932 -> loss: 0.00023664685299168087, self.slope: [1.09671364 1.09756449], self.intercept: 1.008714249336924\n",
      "iteration - 9933 -> loss: 0.00023663621561740815, self.slope: [1.09672086 1.09757182], self.intercept: 1.008714944482627\n",
      "iteration - 9934 -> loss: 0.00023662557922878407, self.slope: [1.09672809 1.09757915], self.intercept: 1.0087156396021693\n",
      "iteration - 9935 -> loss: 0.0002366149438256832, self.slope: [1.09673531 1.09758647], self.intercept: 1.008716334695554\n",
      "iteration - 9936 -> loss: 0.0002366043094079561, self.slope: [1.09674254 1.0975938 ], self.intercept: 1.008717029762782\n",
      "iteration - 9937 -> loss: 0.00023659367597548276, self.slope: [1.09674976 1.09760112], self.intercept: 1.0087177248038552\n",
      "iteration - 9938 -> loss: 0.0002365830435280759, self.slope: [1.09675698 1.09760845], self.intercept: 1.008718419818776\n",
      "iteration - 9939 -> loss: 0.00023657241206564883, self.slope: [1.09676421 1.09761577], self.intercept: 1.0087191148075467\n",
      "iteration - 9940 -> loss: 0.00023656178158804923, self.slope: [1.09677143 1.0976231 ], self.intercept: 1.0087198097701684\n",
      "iteration - 9941 -> loss: 0.00023655115209512983, self.slope: [1.09677865 1.09763042], self.intercept: 1.008720504706645\n",
      "iteration - 9942 -> loss: 0.0002365405235867662, self.slope: [1.09678587 1.09763775], self.intercept: 1.0087211996169765\n",
      "iteration - 9943 -> loss: 0.00023652989606279682, self.slope: [1.0967931  1.09764507], self.intercept: 1.0087218945011684\n",
      "iteration - 9944 -> loss: 0.000236519269523093, self.slope: [1.09680032 1.09765239], self.intercept: 1.008722589359222\n",
      "iteration - 9945 -> loss: 0.00023650864396753486, self.slope: [1.09680754 1.09765972], self.intercept: 1.0087232841911373\n",
      "iteration - 9946 -> loss: 0.00023649801939596045, self.slope: [1.09681476 1.09766704], self.intercept: 1.008723978996918\n",
      "iteration - 9947 -> loss: 0.00023648739580823952, self.slope: [1.09682198 1.09767436], self.intercept: 1.008724673776565\n",
      "iteration - 9948 -> loss: 0.00023647677320424066, self.slope: [1.0968292  1.09768168], self.intercept: 1.0087253685300808\n",
      "iteration - 9949 -> loss: 0.00023646615158380433, self.slope: [1.09683642 1.097689  ], self.intercept: 1.0087260632574684\n",
      "iteration - 9950 -> loss: 0.00023645553094682635, self.slope: [1.09684364 1.09769633], self.intercept: 1.0087267579587293\n",
      "iteration - 9951 -> loss: 0.0002364449112931287, self.slope: [1.09685086 1.09770365], self.intercept: 1.0087274526338663\n",
      "iteration - 9952 -> loss: 0.00023643429262260412, self.slope: [1.09685807 1.09771097], self.intercept: 1.0087281472828813\n",
      "iteration - 9953 -> loss: 0.00023642367493509917, self.slope: [1.09686529 1.09771829], self.intercept: 1.008728841905777\n",
      "iteration - 9954 -> loss: 0.0002364130582304905, self.slope: [1.09687251 1.09772561], self.intercept: 1.0087295365025535\n",
      "iteration - 9955 -> loss: 0.00023640244250862645, self.slope: [1.09687973 1.09773293], self.intercept: 1.0087302310732136\n",
      "iteration - 9956 -> loss: 0.00023639182776937902, self.slope: [1.09688695 1.09774025], self.intercept: 1.0087309256177617\n",
      "iteration - 9957 -> loss: 0.00023638121401258372, self.slope: [1.09689416 1.09774757], self.intercept: 1.0087316201361969\n",
      "iteration - 9958 -> loss: 0.00023637060123813235, self.slope: [1.09690138 1.09775488], self.intercept: 1.0087323146285232\n",
      "iteration - 9959 -> loss: 0.00023635998944589138, self.slope: [1.0969086 1.0977622], self.intercept: 1.0087330090947426\n",
      "iteration - 9960 -> loss: 0.00023634937863569732, self.slope: [1.09691581 1.09776952], self.intercept: 1.0087337035348571\n",
      "iteration - 9961 -> loss: 0.00023633876880740869, self.slope: [1.09692303 1.09777684], self.intercept: 1.008734397948868\n",
      "iteration - 9962 -> loss: 0.00023632815996090862, self.slope: [1.09693024 1.09778415], self.intercept: 1.0087350923367777\n",
      "iteration - 9963 -> loss: 0.00023631755209606572, self.slope: [1.09693746 1.09779147], self.intercept: 1.0087357866985884\n",
      "iteration - 9964 -> loss: 0.0002363069452127244, self.slope: [1.09694467 1.09779879], self.intercept: 1.0087364810343031\n",
      "iteration - 9965 -> loss: 0.00023629633931075177, self.slope: [1.09695189 1.0978061 ], self.intercept: 1.0087371753439234\n",
      "iteration - 9966 -> loss: 0.00023628573438998804, self.slope: [1.0969591  1.09781342], self.intercept: 1.008737869627451\n",
      "iteration - 9967 -> loss: 0.00023627513045033146, self.slope: [1.09696631 1.09782074], self.intercept: 1.0087385638848891\n",
      "iteration - 9968 -> loss: 0.00023626452749164108, self.slope: [1.09697353 1.09782805], self.intercept: 1.0087392581162382\n",
      "iteration - 9969 -> loss: 0.00023625392551374845, self.slope: [1.09698074 1.09783537], self.intercept: 1.0087399523215006\n",
      "iteration - 9970 -> loss: 0.00023624332451653584, self.slope: [1.09698795 1.09784268], self.intercept: 1.0087406465006803\n",
      "iteration - 9971 -> loss: 0.00023623272449988525, self.slope: [1.09699516 1.09784999], self.intercept: 1.0087413406537782\n",
      "iteration - 9972 -> loss: 0.000236222125463604, self.slope: [1.09700238 1.09785731], self.intercept: 1.0087420347807972\n",
      "iteration - 9973 -> loss: 0.00023621152740761636, self.slope: [1.09700959 1.09786462], self.intercept: 1.0087427288817383\n",
      "iteration - 9974 -> loss: 0.00023620093033175775, self.slope: [1.0970168  1.09787194], self.intercept: 1.0087434229566026\n",
      "iteration - 9975 -> loss: 0.000236190334235878, self.slope: [1.09702401 1.09787925], self.intercept: 1.0087441170053943\n",
      "iteration - 9976 -> loss: 0.00023617973911984762, self.slope: [1.09703122 1.09788656], self.intercept: 1.0087448110281143\n",
      "iteration - 9977 -> loss: 0.00023616914498354876, self.slope: [1.09703843 1.09789387], self.intercept: 1.0087455050247671\n",
      "iteration - 9978 -> loss: 0.0002361585518268114, self.slope: [1.09704564 1.09790118], self.intercept: 1.0087461989953521\n",
      "iteration - 9979 -> loss: 0.00023614795964952827, self.slope: [1.09705285 1.0979085 ], self.intercept: 1.0087468929398735\n",
      "iteration - 9980 -> loss: 0.0002361373684515338, self.slope: [1.09706006 1.09791581], self.intercept: 1.008747586858332\n",
      "iteration - 9981 -> loss: 0.00023612677823271557, self.slope: [1.09706727 1.09792312], self.intercept: 1.0087482807507293\n",
      "iteration - 9982 -> loss: 0.0002361161889929221, self.slope: [1.09707448 1.09793043], self.intercept: 1.0087489746170688\n",
      "iteration - 9983 -> loss: 0.000236105600732012, self.slope: [1.09708168 1.09793774], self.intercept: 1.008749668457351\n",
      "iteration - 9984 -> loss: 0.0002360950134498628, self.slope: [1.09708889 1.09794505], self.intercept: 1.0087503622715799\n",
      "iteration - 9985 -> loss: 0.00023608442714633454, self.slope: [1.0970961  1.09795236], self.intercept: 1.0087510560597555\n",
      "iteration - 9986 -> loss: 0.0002360738418212767, self.slope: [1.09710331 1.09795967], self.intercept: 1.0087517498218834\n",
      "iteration - 9987 -> loss: 0.00023606325747456324, self.slope: [1.09711051 1.09796698], self.intercept: 1.008752443557963\n",
      "iteration - 9988 -> loss: 0.00023605267410603772, self.slope: [1.09711772 1.09797428], self.intercept: 1.0087531372679972\n",
      "iteration - 9989 -> loss: 0.00023604209171560424, self.slope: [1.09712493 1.09798159], self.intercept: 1.008753830951988\n",
      "iteration - 9990 -> loss: 0.00023603151030310128, self.slope: [1.09713213 1.0979889 ], self.intercept: 1.0087545246099372\n",
      "iteration - 9991 -> loss: 0.0002360209298683676, self.slope: [1.09713934 1.09799621], self.intercept: 1.0087552182418476\n",
      "iteration - 9992 -> loss: 0.00023601035041130296, self.slope: [1.09714654 1.09800352], self.intercept: 1.0087559118477207\n",
      "iteration - 9993 -> loss: 0.00023599977193175262, self.slope: [1.09715375 1.09801082], self.intercept: 1.0087566054275574\n",
      "iteration - 9994 -> loss: 0.00023598919442958634, self.slope: [1.09716095 1.09801813], self.intercept: 1.0087572989813627\n",
      "iteration - 9995 -> loss: 0.00023597861790465596, self.slope: [1.09716816 1.09802543], self.intercept: 1.0087579925091368\n",
      "iteration - 9996 -> loss: 0.00023596804235682841, self.slope: [1.09717536 1.09803274], self.intercept: 1.008758686010882\n",
      "iteration - 9997 -> loss: 0.00023595746778598512, self.slope: [1.09718256 1.09804005], self.intercept: 1.0087593794866008\n",
      "iteration - 9998 -> loss: 0.00023594689419196508, self.slope: [1.09718977 1.09804735], self.intercept: 1.008760072936296\n",
      "iteration - 9999 -> loss: 0.00023593632157463876, self.slope: [1.09719697 1.09805466], self.intercept: 1.0087607663599676\n"
     ]
    }
   ],
   "source": [
    "slope, intercept, loss_history, slope_history, intercept_history = mlr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9f1d6b",
   "metadata": {},
   "source": [
    "# new slope and intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "76795feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.09719697, 1.09805466]), 1.0087607663599676)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slope, intercept"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c41bc6",
   "metadata": {},
   "source": [
    "# plot loss history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d10a87f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20bb2dfbf70>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0485bb06",
   "metadata": {},
   "source": [
    "# plot slope history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "631d95d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.00001359, 1.00001364]),\n",
       " array([1.00002718, 1.00002727]),\n",
       " array([1.00004077, 1.0000409 ]),\n",
       " array([1.00005435, 1.00005454]),\n",
       " array([1.00006794, 1.00006817]),\n",
       " array([1.00008152, 1.0000818 ]),\n",
       " array([1.0000951 , 1.00009543]),\n",
       " array([1.00010869, 1.00010905]),\n",
       " array([1.00012227, 1.00012268]),\n",
       " array([1.00013585, 1.0001363 ]),\n",
       " array([1.00014942, 1.00014993]),\n",
       " array([1.000163  , 1.00016355]),\n",
       " array([1.00017657, 1.00017717]),\n",
       " array([1.00019015, 1.00019079]),\n",
       " array([1.00020372, 1.00020441]),\n",
       " array([1.00021729, 1.00021803]),\n",
       " array([1.00023086, 1.00023165]),\n",
       " array([1.00024443, 1.00024526]),\n",
       " array([1.000258  , 1.00025888]),\n",
       " array([1.00027157, 1.00027249]),\n",
       " array([1.00028513, 1.0002861 ]),\n",
       " array([1.0002987 , 1.00029971]),\n",
       " array([1.00031226, 1.00031332]),\n",
       " array([1.00032582, 1.00032693]),\n",
       " array([1.00033938, 1.00034054]),\n",
       " array([1.00035294, 1.00035414]),\n",
       " array([1.0003665 , 1.00036775]),\n",
       " array([1.00038006, 1.00038135]),\n",
       " array([1.00039362, 1.00039495]),\n",
       " array([1.00040717, 1.00040855]),\n",
       " array([1.00042072, 1.00042215]),\n",
       " array([1.00043428, 1.00043575]),\n",
       " array([1.00044783, 1.00044935]),\n",
       " array([1.00046138, 1.00046295]),\n",
       " array([1.00047493, 1.00047654]),\n",
       " array([1.00048847, 1.00049014]),\n",
       " array([1.00050202, 1.00050373]),\n",
       " array([1.00051557, 1.00051732]),\n",
       " array([1.00052911, 1.00053091]),\n",
       " array([1.00054265, 1.0005445 ]),\n",
       " array([1.00055619, 1.00055809]),\n",
       " array([1.00056973, 1.00057168]),\n",
       " array([1.00058327, 1.00058526]),\n",
       " array([1.00059681, 1.00059885]),\n",
       " array([1.00061035, 1.00061243]),\n",
       " array([1.00062388, 1.00062601]),\n",
       " array([1.00063742, 1.00063959]),\n",
       " array([1.00065095, 1.00065317]),\n",
       " array([1.00066448, 1.00066675]),\n",
       " array([1.00067801, 1.00068033]),\n",
       " array([1.00069154, 1.0006939 ]),\n",
       " array([1.00070507, 1.00070748]),\n",
       " array([1.0007186 , 1.00072105]),\n",
       " array([1.00073212, 1.00073462]),\n",
       " array([1.00074565, 1.00074819]),\n",
       " array([1.00075917, 1.00076177]),\n",
       " array([1.00077269, 1.00077533]),\n",
       " array([1.00078621, 1.0007889 ]),\n",
       " array([1.00079973, 1.00080247]),\n",
       " array([1.00081325, 1.00081603]),\n",
       " array([1.00082677, 1.0008296 ]),\n",
       " array([1.00084028, 1.00084316]),\n",
       " array([1.0008538 , 1.00085672]),\n",
       " array([1.00086731, 1.00087028]),\n",
       " array([1.00088082, 1.00088384]),\n",
       " array([1.00089434, 1.0008974 ]),\n",
       " array([1.00090785, 1.00091096]),\n",
       " array([1.00092135, 1.00092451]),\n",
       " array([1.00093486, 1.00093807]),\n",
       " array([1.00094837, 1.00095162]),\n",
       " array([1.00096187, 1.00096517]),\n",
       " array([1.00097538, 1.00097873]),\n",
       " array([1.00098888, 1.00099228]),\n",
       " array([1.00100238, 1.00100582]),\n",
       " array([1.00101588, 1.00101937]),\n",
       " array([1.00102938, 1.00103292]),\n",
       " array([1.00104288, 1.00104646]),\n",
       " array([1.00105638, 1.00106001]),\n",
       " array([1.00106987, 1.00107355]),\n",
       " array([1.00108337, 1.00108709]),\n",
       " array([1.00109686, 1.00110063]),\n",
       " array([1.00111035, 1.00111417]),\n",
       " array([1.00112384, 1.00112771]),\n",
       " array([1.00113733, 1.00114125]),\n",
       " array([1.00115082, 1.00115478]),\n",
       " array([1.00116431, 1.00116832]),\n",
       " array([1.00117779, 1.00118185]),\n",
       " array([1.00119128, 1.00119538]),\n",
       " array([1.00120476, 1.00120891]),\n",
       " array([1.00121825, 1.00122244]),\n",
       " array([1.00123173, 1.00123597]),\n",
       " array([1.00124521, 1.0012495 ]),\n",
       " array([1.00125869, 1.00126302]),\n",
       " array([1.00127216, 1.00127655]),\n",
       " array([1.00128564, 1.00129007]),\n",
       " array([1.00129911, 1.0013036 ]),\n",
       " array([1.00131259, 1.00131712]),\n",
       " array([1.00132606, 1.00133064]),\n",
       " array([1.00133953, 1.00134416]),\n",
       " array([1.001353  , 1.00135768]),\n",
       " array([1.00136647, 1.00137119]),\n",
       " array([1.00137994, 1.00138471]),\n",
       " array([1.00139341, 1.00139822]),\n",
       " array([1.00140687, 1.00141174]),\n",
       " array([1.00142034, 1.00142525]),\n",
       " array([1.0014338 , 1.00143876]),\n",
       " array([1.00144726, 1.00145227]),\n",
       " array([1.00146072, 1.00146578]),\n",
       " array([1.00147418, 1.00147928]),\n",
       " array([1.00148764, 1.00149279]),\n",
       " array([1.0015011, 1.0015063]),\n",
       " array([1.00151456, 1.0015198 ]),\n",
       " array([1.00152801, 1.0015333 ]),\n",
       " array([1.00154146, 1.0015468 ]),\n",
       " array([1.00155492, 1.0015603 ]),\n",
       " array([1.00156837, 1.0015738 ]),\n",
       " array([1.00158182, 1.0015873 ]),\n",
       " array([1.00159527, 1.0016008 ]),\n",
       " array([1.00160871, 1.00161429]),\n",
       " array([1.00162216, 1.00162779]),\n",
       " array([1.00163561, 1.00164128]),\n",
       " array([1.00164905, 1.00165477]),\n",
       " array([1.00166249, 1.00166826]),\n",
       " array([1.00167594, 1.00168175]),\n",
       " array([1.00168938, 1.00169524]),\n",
       " array([1.00170282, 1.00170873]),\n",
       " array([1.00171625, 1.00172222]),\n",
       " array([1.00172969, 1.0017357 ]),\n",
       " array([1.00174313, 1.00174918]),\n",
       " array([1.00175656, 1.00176267]),\n",
       " array([1.00176999, 1.00177615]),\n",
       " array([1.00178343, 1.00178963]),\n",
       " array([1.00179686, 1.00180311]),\n",
       " array([1.00181029, 1.00181659]),\n",
       " array([1.00182372, 1.00183006]),\n",
       " array([1.00183714, 1.00184354]),\n",
       " array([1.00185057, 1.00185701]),\n",
       " array([1.001864  , 1.00187049]),\n",
       " array([1.00187742, 1.00188396]),\n",
       " array([1.00189084, 1.00189743]),\n",
       " array([1.00190426, 1.0019109 ]),\n",
       " array([1.00191768, 1.00192437]),\n",
       " array([1.0019311 , 1.00193783]),\n",
       " array([1.00194452, 1.0019513 ]),\n",
       " array([1.00195794, 1.00196477]),\n",
       " array([1.00197135, 1.00197823]),\n",
       " array([1.00198477, 1.00199169]),\n",
       " array([1.00199818, 1.00200515]),\n",
       " array([1.00201159, 1.00201861]),\n",
       " array([1.002025  , 1.00203207]),\n",
       " array([1.00203841, 1.00204553]),\n",
       " array([1.00205182, 1.00205899]),\n",
       " array([1.00206523, 1.00207244]),\n",
       " array([1.00207864, 1.0020859 ]),\n",
       " array([1.00209204, 1.00209935]),\n",
       " array([1.00210544, 1.0021128 ]),\n",
       " array([1.00211885, 1.00212626]),\n",
       " array([1.00213225, 1.00213971]),\n",
       " array([1.00214565, 1.00215315]),\n",
       " array([1.00215905, 1.0021666 ]),\n",
       " array([1.00217245, 1.00218005]),\n",
       " array([1.00218584, 1.00219349]),\n",
       " array([1.00219924, 1.00220694]),\n",
       " array([1.00221263, 1.00222038]),\n",
       " array([1.00222602, 1.00223382]),\n",
       " array([1.00223942, 1.00224726]),\n",
       " array([1.00225281, 1.0022607 ]),\n",
       " array([1.0022662 , 1.00227414]),\n",
       " array([1.00227959, 1.00228758]),\n",
       " array([1.00229297, 1.00230101]),\n",
       " array([1.00230636, 1.00231445]),\n",
       " array([1.00231974, 1.00232788]),\n",
       " array([1.00233313, 1.00234131]),\n",
       " array([1.00234651, 1.00235474]),\n",
       " array([1.00235989, 1.00236817]),\n",
       " array([1.00237327, 1.0023816 ]),\n",
       " array([1.00238665, 1.00239503]),\n",
       " array([1.00240003, 1.00240846]),\n",
       " array([1.0024134 , 1.00242188]),\n",
       " array([1.00242678, 1.00243531]),\n",
       " array([1.00244015, 1.00244873]),\n",
       " array([1.00245353, 1.00246215]),\n",
       " array([1.0024669 , 1.00247557]),\n",
       " array([1.00248027, 1.00248899]),\n",
       " array([1.00249364, 1.00250241]),\n",
       " array([1.00250701, 1.00251583]),\n",
       " array([1.00252037, 1.00252924]),\n",
       " array([1.00253374, 1.00254266]),\n",
       " array([1.0025471 , 1.00255607]),\n",
       " array([1.00256047, 1.00256949]),\n",
       " array([1.00257383, 1.0025829 ]),\n",
       " array([1.00258719, 1.00259631]),\n",
       " array([1.00260055, 1.00260972]),\n",
       " array([1.00261391, 1.00262312]),\n",
       " array([1.00262727, 1.00263653]),\n",
       " array([1.00264062, 1.00264994]),\n",
       " array([1.00265398, 1.00266334]),\n",
       " array([1.00266733, 1.00267674]),\n",
       " array([1.00268069, 1.00269015]),\n",
       " array([1.00269404, 1.00270355]),\n",
       " array([1.00270739, 1.00271695]),\n",
       " array([1.00272074, 1.00273035]),\n",
       " array([1.00273409, 1.00274374]),\n",
       " array([1.00274743, 1.00275714]),\n",
       " array([1.00276078, 1.00277054]),\n",
       " array([1.00277413, 1.00278393]),\n",
       " array([1.00278747, 1.00279732]),\n",
       " array([1.00280081, 1.00281071]),\n",
       " array([1.00281415, 1.0028241 ]),\n",
       " array([1.00282749, 1.00283749]),\n",
       " array([1.00284083, 1.00285088]),\n",
       " array([1.00285417, 1.00286427]),\n",
       " array([1.00286751, 1.00287766]),\n",
       " array([1.00288084, 1.00289104]),\n",
       " array([1.00289418, 1.00290442]),\n",
       " array([1.00290751, 1.00291781]),\n",
       " array([1.00292084, 1.00293119]),\n",
       " array([1.00293417, 1.00294457]),\n",
       " array([1.0029475 , 1.00295795]),\n",
       " array([1.00296083, 1.00297132]),\n",
       " array([1.00297416, 1.0029847 ]),\n",
       " array([1.00298748, 1.00299808]),\n",
       " array([1.00300081, 1.00301145]),\n",
       " array([1.00301413, 1.00302482]),\n",
       " array([1.00302745, 1.0030382 ]),\n",
       " array([1.00304077, 1.00305157]),\n",
       " array([1.00305409, 1.00306494]),\n",
       " array([1.00306741, 1.00307831]),\n",
       " array([1.00308073, 1.00309167]),\n",
       " array([1.00309405, 1.00310504]),\n",
       " array([1.00310736, 1.0031184 ]),\n",
       " array([1.00312068, 1.00313177]),\n",
       " array([1.00313399, 1.00314513]),\n",
       " array([1.0031473 , 1.00315849]),\n",
       " array([1.00316061, 1.00317185]),\n",
       " array([1.00317392, 1.00318521]),\n",
       " array([1.00318723, 1.00319857]),\n",
       " array([1.00320054, 1.00321193]),\n",
       " array([1.00321385, 1.00322528]),\n",
       " array([1.00322715, 1.00323864]),\n",
       " array([1.00324045, 1.00325199]),\n",
       " array([1.00325376, 1.00326534]),\n",
       " array([1.00326706, 1.0032787 ]),\n",
       " array([1.00328036, 1.00329205]),\n",
       " array([1.00329366, 1.0033054 ]),\n",
       " array([1.00330696, 1.00331874]),\n",
       " array([1.00332025, 1.00333209]),\n",
       " array([1.00333355, 1.00334544]),\n",
       " array([1.00334684, 1.00335878]),\n",
       " array([1.00336014, 1.00337212]),\n",
       " array([1.00337343, 1.00338547]),\n",
       " array([1.00338672, 1.00339881]),\n",
       " array([1.00340001, 1.00341215]),\n",
       " array([1.0034133 , 1.00342548]),\n",
       " array([1.00342658, 1.00343882]),\n",
       " array([1.00343987, 1.00345216]),\n",
       " array([1.00345316, 1.00346549]),\n",
       " array([1.00346644, 1.00347883]),\n",
       " array([1.00347972, 1.00349216]),\n",
       " array([1.003493  , 1.00350549]),\n",
       " array([1.00350629, 1.00351882]),\n",
       " array([1.00351956, 1.00353215]),\n",
       " array([1.00353284, 1.00354548]),\n",
       " array([1.00354612, 1.00355881]),\n",
       " array([1.0035594 , 1.00357213]),\n",
       " array([1.00357267, 1.00358546]),\n",
       " array([1.00358594, 1.00359878]),\n",
       " array([1.00359922, 1.00361211]),\n",
       " array([1.00361249, 1.00362543]),\n",
       " array([1.00362576, 1.00363875]),\n",
       " array([1.00363903, 1.00365207]),\n",
       " array([1.00365229, 1.00366538]),\n",
       " array([1.00366556, 1.0036787 ]),\n",
       " array([1.00367883, 1.00369202]),\n",
       " array([1.00369209, 1.00370533]),\n",
       " array([1.00370535, 1.00371865]),\n",
       " array([1.00371861, 1.00373196]),\n",
       " array([1.00373188, 1.00374527]),\n",
       " array([1.00374514, 1.00375858]),\n",
       " array([1.00375839, 1.00377189]),\n",
       " array([1.00377165, 1.0037852 ]),\n",
       " array([1.00378491, 1.0037985 ]),\n",
       " array([1.00379816, 1.00381181]),\n",
       " array([1.00381142, 1.00382511]),\n",
       " array([1.00382467, 1.00383841]),\n",
       " array([1.00383792, 1.00385172]),\n",
       " array([1.00385117, 1.00386502]),\n",
       " array([1.00386442, 1.00387832]),\n",
       " array([1.00387767, 1.00389162]),\n",
       " array([1.00389091, 1.00390491]),\n",
       " array([1.00390416, 1.00391821]),\n",
       " array([1.0039174, 1.0039315]),\n",
       " array([1.00393065, 1.0039448 ]),\n",
       " array([1.00394389, 1.00395809]),\n",
       " array([1.00395713, 1.00397138]),\n",
       " array([1.00397037, 1.00398467]),\n",
       " array([1.00398361, 1.00399796]),\n",
       " array([1.00399685, 1.00401125]),\n",
       " array([1.00401008, 1.00402454]),\n",
       " array([1.00402332, 1.00403783]),\n",
       " array([1.00403655, 1.00405111]),\n",
       " array([1.00404979, 1.00406439]),\n",
       " array([1.00406302, 1.00407768]),\n",
       " array([1.00407625, 1.00409096]),\n",
       " array([1.00408948, 1.00410424]),\n",
       " array([1.00410271, 1.00411752]),\n",
       " array([1.00411593, 1.0041308 ]),\n",
       " array([1.00412916, 1.00414407]),\n",
       " array([1.00414239, 1.00415735]),\n",
       " array([1.00415561, 1.00417062]),\n",
       " array([1.00416883, 1.0041839 ]),\n",
       " array([1.00418205, 1.00419717]),\n",
       " array([1.00419527, 1.00421044]),\n",
       " array([1.00420849, 1.00422371]),\n",
       " array([1.00422171, 1.00423698]),\n",
       " array([1.00423493, 1.00425025]),\n",
       " array([1.00424814, 1.00426351]),\n",
       " array([1.00426136, 1.00427678]),\n",
       " array([1.00427457, 1.00429004]),\n",
       " array([1.00428778, 1.00430331]),\n",
       " array([1.00430099, 1.00431657]),\n",
       " array([1.0043142 , 1.00432983]),\n",
       " array([1.00432741, 1.00434309]),\n",
       " array([1.00434062, 1.00435635]),\n",
       " array([1.00435383, 1.00436961]),\n",
       " array([1.00436703, 1.00438286]),\n",
       " array([1.00438024, 1.00439612]),\n",
       " array([1.00439344, 1.00440937]),\n",
       " array([1.00440664, 1.00442263]),\n",
       " array([1.00441984, 1.00443588]),\n",
       " array([1.00443304, 1.00444913]),\n",
       " array([1.00444624, 1.00446238]),\n",
       " array([1.00445944, 1.00447563]),\n",
       " array([1.00447263, 1.00448887]),\n",
       " array([1.00448583, 1.00450212]),\n",
       " array([1.00449902, 1.00451537]),\n",
       " array([1.00451222, 1.00452861]),\n",
       " array([1.00452541, 1.00454185]),\n",
       " array([1.0045386 , 1.00455509]),\n",
       " array([1.00455179, 1.00456834]),\n",
       " array([1.00456498, 1.00458157]),\n",
       " array([1.00457816, 1.00459481]),\n",
       " array([1.00459135, 1.00460805]),\n",
       " array([1.00460453, 1.00462129]),\n",
       " array([1.00461772, 1.00463452]),\n",
       " array([1.0046309 , 1.00464776]),\n",
       " array([1.00464408, 1.00466099]),\n",
       " array([1.00465726, 1.00467422]),\n",
       " array([1.00467044, 1.00468745]),\n",
       " array([1.00468362, 1.00470068]),\n",
       " array([1.00469679, 1.00471391]),\n",
       " array([1.00470997, 1.00472713]),\n",
       " array([1.00472314, 1.00474036]),\n",
       " array([1.00473632, 1.00475359]),\n",
       " array([1.00474949, 1.00476681]),\n",
       " array([1.00476266, 1.00478003]),\n",
       " array([1.00477583, 1.00479325]),\n",
       " array([1.004789  , 1.00480647]),\n",
       " array([1.00480217, 1.00481969]),\n",
       " array([1.00481533, 1.00483291]),\n",
       " array([1.0048285 , 1.00484613]),\n",
       " array([1.00484166, 1.00485934]),\n",
       " array([1.00485482, 1.00487256]),\n",
       " array([1.00486799, 1.00488577]),\n",
       " array([1.00488115, 1.00489898]),\n",
       " array([1.00489431, 1.0049122 ]),\n",
       " array([1.00490746, 1.00492541]),\n",
       " array([1.00492062, 1.00493861]),\n",
       " array([1.00493378, 1.00495182]),\n",
       " array([1.00494693, 1.00496503]),\n",
       " array([1.00496009, 1.00497823]),\n",
       " array([1.00497324, 1.00499144]),\n",
       " array([1.00498639, 1.00500464]),\n",
       " array([1.00499954, 1.00501785]),\n",
       " array([1.00501269, 1.00503105]),\n",
       " array([1.00502584, 1.00504425]),\n",
       " array([1.00503899, 1.00505745]),\n",
       " array([1.00505213, 1.00507064]),\n",
       " array([1.00506528, 1.00508384]),\n",
       " array([1.00507842, 1.00509704]),\n",
       " array([1.00509156, 1.00511023]),\n",
       " array([1.0051047 , 1.00512342]),\n",
       " array([1.00511784, 1.00513662]),\n",
       " array([1.00513098, 1.00514981]),\n",
       " array([1.00514412, 1.005163  ]),\n",
       " array([1.00515726, 1.00517618]),\n",
       " array([1.00517039, 1.00518937]),\n",
       " array([1.00518353, 1.00520256]),\n",
       " array([1.00519666, 1.00521574]),\n",
       " array([1.00520979, 1.00522893]),\n",
       " array([1.00522292, 1.00524211]),\n",
       " array([1.00523605, 1.00525529]),\n",
       " array([1.00524918, 1.00526848]),\n",
       " array([1.00526231, 1.00528166]),\n",
       " array([1.00527544, 1.00529483]),\n",
       " array([1.00528856, 1.00530801]),\n",
       " array([1.00530169, 1.00532119]),\n",
       " array([1.00531481, 1.00533436]),\n",
       " array([1.00532793, 1.00534754]),\n",
       " array([1.00534105, 1.00536071]),\n",
       " array([1.00535417, 1.00537388]),\n",
       " array([1.00536729, 1.00538705]),\n",
       " array([1.00538041, 1.00540022]),\n",
       " array([1.00539352, 1.00541339]),\n",
       " array([1.00540664, 1.00542656]),\n",
       " array([1.00541975, 1.00543973]),\n",
       " array([1.00543287, 1.00545289]),\n",
       " array([1.00544598, 1.00546606]),\n",
       " array([1.00545909, 1.00547922]),\n",
       " array([1.0054722 , 1.00549238]),\n",
       " array([1.00548531, 1.00550554]),\n",
       " array([1.00549841, 1.0055187 ]),\n",
       " array([1.00551152, 1.00553186]),\n",
       " array([1.00552463, 1.00554502]),\n",
       " array([1.00553773, 1.00555817]),\n",
       " array([1.00555083, 1.00557133]),\n",
       " array([1.00556393, 1.00558448]),\n",
       " array([1.00557703, 1.00559764]),\n",
       " array([1.00559013, 1.00561079]),\n",
       " array([1.00560323, 1.00562394]),\n",
       " array([1.00561633, 1.00563709]),\n",
       " array([1.00562942, 1.00565024]),\n",
       " array([1.00564252, 1.00566338]),\n",
       " array([1.00565561, 1.00567653]),\n",
       " array([1.00566871, 1.00568968]),\n",
       " array([1.0056818 , 1.00570282]),\n",
       " array([1.00569489, 1.00571596]),\n",
       " array([1.00570798, 1.0057291 ]),\n",
       " array([1.00572106, 1.00574224]),\n",
       " array([1.00573415, 1.00575538]),\n",
       " array([1.00574724, 1.00576852]),\n",
       " array([1.00576032, 1.00578166]),\n",
       " array([1.00577341, 1.0057948 ]),\n",
       " array([1.00578649, 1.00580793]),\n",
       " array([1.00579957, 1.00582107]),\n",
       " array([1.00581265, 1.0058342 ]),\n",
       " array([1.00582573, 1.00584733]),\n",
       " array([1.00583881, 1.00586046]),\n",
       " array([1.00585188, 1.00587359]),\n",
       " array([1.00586496, 1.00588672]),\n",
       " array([1.00587803, 1.00589985]),\n",
       " array([1.00589111, 1.00591297]),\n",
       " array([1.00590418, 1.0059261 ]),\n",
       " array([1.00591725, 1.00593922]),\n",
       " array([1.00593032, 1.00595235]),\n",
       " array([1.00594339, 1.00596547]),\n",
       " array([1.00595646, 1.00597859]),\n",
       " array([1.00596952, 1.00599171]),\n",
       " array([1.00598259, 1.00600483]),\n",
       " array([1.00599565, 1.00601794]),\n",
       " array([1.00600872, 1.00603106]),\n",
       " array([1.00602178, 1.00604417]),\n",
       " array([1.00603484, 1.00605729]),\n",
       " array([1.0060479, 1.0060704]),\n",
       " array([1.00606096, 1.00608351]),\n",
       " array([1.00607402, 1.00609662]),\n",
       " array([1.00608707, 1.00610973]),\n",
       " array([1.00610013, 1.00612284]),\n",
       " array([1.00611318, 1.00613595]),\n",
       " array([1.00612623, 1.00614906]),\n",
       " array([1.00613929, 1.00616216]),\n",
       " array([1.00615234, 1.00617527]),\n",
       " array([1.00616539, 1.00618837]),\n",
       " array([1.00617844, 1.00620147]),\n",
       " array([1.00619148, 1.00621457]),\n",
       " array([1.00620453, 1.00622767]),\n",
       " array([1.00621757, 1.00624077]),\n",
       " array([1.00623062, 1.00625387]),\n",
       " array([1.00624366, 1.00626696]),\n",
       " array([1.0062567 , 1.00628006]),\n",
       " array([1.00626974, 1.00629315]),\n",
       " array([1.00628278, 1.00630625]),\n",
       " array([1.00629582, 1.00631934]),\n",
       " array([1.00630886, 1.00633243]),\n",
       " array([1.0063219 , 1.00634552]),\n",
       " array([1.00633493, 1.00635861]),\n",
       " array([1.00634797, 1.00637169]),\n",
       " array([1.006361  , 1.00638478]),\n",
       " array([1.00637403, 1.00639787]),\n",
       " array([1.00638706, 1.00641095]),\n",
       " array([1.00640009, 1.00642403]),\n",
       " array([1.00641312, 1.00643711]),\n",
       " array([1.00642615, 1.0064502 ]),\n",
       " array([1.00643917, 1.00646328]),\n",
       " array([1.0064522 , 1.00647635]),\n",
       " array([1.00646522, 1.00648943]),\n",
       " array([1.00647824, 1.00650251]),\n",
       " array([1.00649127, 1.00651558]),\n",
       " array([1.00650429, 1.00652866]),\n",
       " array([1.00651731, 1.00654173]),\n",
       " array([1.00653033, 1.0065548 ]),\n",
       " array([1.00654334, 1.00656787]),\n",
       " array([1.00655636, 1.00658094]),\n",
       " array([1.00656937, 1.00659401]),\n",
       " array([1.00658239, 1.00660708]),\n",
       " array([1.0065954 , 1.00662015]),\n",
       " array([1.00660841, 1.00663321]),\n",
       " array([1.00662142, 1.00664628]),\n",
       " array([1.00663443, 1.00665934]),\n",
       " array([1.00664744, 1.0066724 ]),\n",
       " array([1.00666045, 1.00668546]),\n",
       " array([1.00667345, 1.00669852]),\n",
       " array([1.00668646, 1.00671158]),\n",
       " array([1.00669946, 1.00672464]),\n",
       " array([1.00671247, 1.0067377 ]),\n",
       " array([1.00672547, 1.00675075]),\n",
       " array([1.00673847, 1.00676381]),\n",
       " array([1.00675147, 1.00677686]),\n",
       " array([1.00676447, 1.00678991]),\n",
       " array([1.00677746, 1.00680296]),\n",
       " array([1.00679046, 1.00681601]),\n",
       " array([1.00680345, 1.00682906]),\n",
       " array([1.00681645, 1.00684211]),\n",
       " array([1.00682944, 1.00685516]),\n",
       " array([1.00684243, 1.0068682 ]),\n",
       " array([1.00685542, 1.00688125]),\n",
       " array([1.00686841, 1.00689429]),\n",
       " array([1.0068814 , 1.00690733]),\n",
       " array([1.00689439, 1.00692037]),\n",
       " array([1.00690737, 1.00693341]),\n",
       " array([1.00692036, 1.00694645]),\n",
       " array([1.00693334, 1.00695949]),\n",
       " array([1.00694633, 1.00697253]),\n",
       " array([1.00695931, 1.00698556]),\n",
       " array([1.00697229, 1.0069986 ]),\n",
       " array([1.00698527, 1.00701163]),\n",
       " array([1.00699825, 1.00702466]),\n",
       " array([1.00701122, 1.0070377 ]),\n",
       " array([1.0070242 , 1.00705073]),\n",
       " array([1.00703717, 1.00706375]),\n",
       " array([1.00705015, 1.00707678]),\n",
       " array([1.00706312, 1.00708981]),\n",
       " array([1.00707609, 1.00710284]),\n",
       " array([1.00708906, 1.00711586]),\n",
       " array([1.00710203, 1.00712888]),\n",
       " array([1.007115  , 1.00714191]),\n",
       " array([1.00712797, 1.00715493]),\n",
       " array([1.00714093, 1.00716795]),\n",
       " array([1.0071539 , 1.00718097]),\n",
       " array([1.00716686, 1.00719399]),\n",
       " array([1.00717983, 1.007207  ]),\n",
       " array([1.00719279, 1.00722002]),\n",
       " array([1.00720575, 1.00723304]),\n",
       " array([1.00721871, 1.00724605]),\n",
       " array([1.00723167, 1.00725906]),\n",
       " array([1.00724462, 1.00727207]),\n",
       " array([1.00725758, 1.00728508]),\n",
       " array([1.00727054, 1.00729809]),\n",
       " array([1.00728349, 1.0073111 ]),\n",
       " array([1.00729644, 1.00732411]),\n",
       " array([1.00730939, 1.00733712]),\n",
       " array([1.00732234, 1.00735012]),\n",
       " array([1.00733529, 1.00736313]),\n",
       " array([1.00734824, 1.00737613]),\n",
       " array([1.00736119, 1.00738913]),\n",
       " array([1.00737414, 1.00740213]),\n",
       " array([1.00738708, 1.00741513]),\n",
       " array([1.00740003, 1.00742813]),\n",
       " array([1.00741297, 1.00744113]),\n",
       " array([1.00742591, 1.00745412]),\n",
       " array([1.00743885, 1.00746712]),\n",
       " array([1.00745179, 1.00748011]),\n",
       " array([1.00746473, 1.00749311]),\n",
       " array([1.00747767, 1.0075061 ]),\n",
       " array([1.0074906 , 1.00751909]),\n",
       " array([1.00750354, 1.00753208]),\n",
       " array([1.00751647, 1.00754507]),\n",
       " array([1.0075294 , 1.00755806]),\n",
       " array([1.00754234, 1.00757104]),\n",
       " array([1.00755527, 1.00758403]),\n",
       " array([1.0075682 , 1.00759701]),\n",
       " array([1.00758113, 1.00761   ]),\n",
       " array([1.00759405, 1.00762298]),\n",
       " array([1.00760698, 1.00763596]),\n",
       " array([1.00761991, 1.00764894]),\n",
       " array([1.00763283, 1.00766192]),\n",
       " array([1.00764575, 1.0076749 ]),\n",
       " array([1.00765867, 1.00768787]),\n",
       " array([1.0076716 , 1.00770085]),\n",
       " array([1.00768452, 1.00771382]),\n",
       " array([1.00769743, 1.0077268 ]),\n",
       " array([1.00771035, 1.00773977]),\n",
       " array([1.00772327, 1.00775274]),\n",
       " array([1.00773618, 1.00776571]),\n",
       " array([1.0077491 , 1.00777868]),\n",
       " array([1.00776201, 1.00779165]),\n",
       " array([1.00777492, 1.00780462]),\n",
       " array([1.00778783, 1.00781758]),\n",
       " array([1.00780074, 1.00783055]),\n",
       " array([1.00781365, 1.00784351]),\n",
       " array([1.00782656, 1.00785647]),\n",
       " array([1.00783947, 1.00786944]),\n",
       " array([1.00785237, 1.0078824 ]),\n",
       " array([1.00786528, 1.00789536]),\n",
       " array([1.00787818, 1.00790831]),\n",
       " array([1.00789108, 1.00792127]),\n",
       " array([1.00790398, 1.00793423]),\n",
       " array([1.00791688, 1.00794718]),\n",
       " array([1.00792978, 1.00796014]),\n",
       " array([1.00794268, 1.00797309]),\n",
       " array([1.00795558, 1.00798604]),\n",
       " array([1.00796847, 1.00799899]),\n",
       " array([1.00798137, 1.00801194]),\n",
       " array([1.00799426, 1.00802489]),\n",
       " array([1.00800715, 1.00803784]),\n",
       " array([1.00802004, 1.00805079]),\n",
       " array([1.00803293, 1.00806373]),\n",
       " array([1.00804582, 1.00807668]),\n",
       " array([1.00805871, 1.00808962]),\n",
       " array([1.0080716 , 1.00810256]),\n",
       " array([1.00808448, 1.0081155 ]),\n",
       " array([1.00809737, 1.00812844]),\n",
       " array([1.00811025, 1.00814138]),\n",
       " array([1.00812314, 1.00815432]),\n",
       " array([1.00813602, 1.00816726]),\n",
       " array([1.0081489 , 1.00818019]),\n",
       " array([1.00816178, 1.00819313]),\n",
       " array([1.00817465, 1.00820606]),\n",
       " array([1.00818753, 1.00821899]),\n",
       " array([1.00820041, 1.00823192]),\n",
       " array([1.00821328, 1.00824486]),\n",
       " array([1.00822616, 1.00825778]),\n",
       " array([1.00823903, 1.00827071]),\n",
       " array([1.0082519 , 1.00828364]),\n",
       " array([1.00826477, 1.00829657]),\n",
       " array([1.00827764, 1.00830949]),\n",
       " array([1.00829051, 1.00832241]),\n",
       " array([1.00830338, 1.00833534]),\n",
       " array([1.00831624, 1.00834826]),\n",
       " array([1.00832911, 1.00836118]),\n",
       " array([1.00834197, 1.0083741 ]),\n",
       " array([1.00835483, 1.00838702]),\n",
       " array([1.0083677 , 1.00839994]),\n",
       " array([1.00838056, 1.00841285]),\n",
       " array([1.00839342, 1.00842577]),\n",
       " array([1.00840627, 1.00843868]),\n",
       " array([1.00841913, 1.00845159]),\n",
       " array([1.00843199, 1.00846451]),\n",
       " array([1.00844484, 1.00847742]),\n",
       " array([1.0084577 , 1.00849033]),\n",
       " array([1.00847055, 1.00850324]),\n",
       " array([1.0084834 , 1.00851614]),\n",
       " array([1.00849625, 1.00852905]),\n",
       " array([1.0085091 , 1.00854196]),\n",
       " array([1.00852195, 1.00855486]),\n",
       " array([1.0085348 , 1.00856777]),\n",
       " array([1.00854765, 1.00858067]),\n",
       " array([1.00856049, 1.00859357]),\n",
       " array([1.00857334, 1.00860647]),\n",
       " array([1.00858618, 1.00861937]),\n",
       " array([1.00859902, 1.00863227]),\n",
       " array([1.00861186, 1.00864516]),\n",
       " array([1.0086247 , 1.00865806]),\n",
       " array([1.00863754, 1.00867095]),\n",
       " array([1.00865038, 1.00868385]),\n",
       " array([1.00866322, 1.00869674]),\n",
       " array([1.00867605, 1.00870963]),\n",
       " array([1.00868889, 1.00872252]),\n",
       " array([1.00870172, 1.00873541]),\n",
       " array([1.00871455, 1.0087483 ]),\n",
       " array([1.00872738, 1.00876119]),\n",
       " array([1.00874021, 1.00877408]),\n",
       " array([1.00875304, 1.00878696]),\n",
       " array([1.00876587, 1.00879984]),\n",
       " array([1.0087787 , 1.00881273]),\n",
       " array([1.00879152, 1.00882561]),\n",
       " array([1.00880435, 1.00883849]),\n",
       " array([1.00881717, 1.00885137]),\n",
       " array([1.00883   , 1.00886425]),\n",
       " array([1.00884282, 1.00887713]),\n",
       " array([1.00885564, 1.00889   ]),\n",
       " array([1.00886846, 1.00890288]),\n",
       " array([1.00888128, 1.00891575]),\n",
       " array([1.00889409, 1.00892863]),\n",
       " array([1.00890691, 1.0089415 ]),\n",
       " array([1.00891972, 1.00895437]),\n",
       " array([1.00893254, 1.00896724]),\n",
       " array([1.00894535, 1.00898011]),\n",
       " array([1.00895816, 1.00899298]),\n",
       " array([1.00897097, 1.00900585]),\n",
       " array([1.00898378, 1.00901871]),\n",
       " array([1.00899659, 1.00903158]),\n",
       " array([1.0090094 , 1.00904444]),\n",
       " array([1.00902221, 1.0090573 ]),\n",
       " array([1.00903501, 1.00907017]),\n",
       " array([1.00904782, 1.00908303]),\n",
       " array([1.00906062, 1.00909589]),\n",
       " array([1.00907342, 1.00910875]),\n",
       " array([1.00908622, 1.0091216 ]),\n",
       " array([1.00909902, 1.00913446]),\n",
       " array([1.00911182, 1.00914731]),\n",
       " array([1.00912462, 1.00916017]),\n",
       " array([1.00913742, 1.00917302]),\n",
       " array([1.00915021, 1.00918587]),\n",
       " array([1.00916301, 1.00919873]),\n",
       " array([1.0091758 , 1.00921158]),\n",
       " array([1.00918859, 1.00922442]),\n",
       " array([1.00920138, 1.00923727]),\n",
       " array([1.00921417, 1.00925012]),\n",
       " array([1.00922696, 1.00926297]),\n",
       " array([1.00923975, 1.00927581]),\n",
       " array([1.00925254, 1.00928865]),\n",
       " array([1.00926532, 1.0093015 ]),\n",
       " array([1.00927811, 1.00931434]),\n",
       " array([1.00929089, 1.00932718]),\n",
       " array([1.00930368, 1.00934002]),\n",
       " array([1.00931646, 1.00935286]),\n",
       " array([1.00932924, 1.00936569]),\n",
       " array([1.00934202, 1.00937853]),\n",
       " array([1.0093548 , 1.00939137]),\n",
       " array([1.00936757, 1.0094042 ]),\n",
       " array([1.00938035, 1.00941703]),\n",
       " array([1.00939313, 1.00942986]),\n",
       " array([1.0094059, 1.0094427]),\n",
       " array([1.00941867, 1.00945553]),\n",
       " array([1.00943144, 1.00946835]),\n",
       " array([1.00944422, 1.00948118]),\n",
       " array([1.00945699, 1.00949401]),\n",
       " array([1.00946975, 1.00950683]),\n",
       " array([1.00948252, 1.00951966]),\n",
       " array([1.00949529, 1.00953248]),\n",
       " array([1.00950805, 1.0095453 ]),\n",
       " array([1.00952082, 1.00955813]),\n",
       " array([1.00953358, 1.00957095]),\n",
       " array([1.00954634, 1.00958377]),\n",
       " array([1.00955911, 1.00959658]),\n",
       " array([1.00957187, 1.0096094 ]),\n",
       " array([1.00958462, 1.00962222]),\n",
       " array([1.00959738, 1.00963503]),\n",
       " array([1.00961014, 1.00964785]),\n",
       " array([1.0096229 , 1.00966066]),\n",
       " array([1.00963565, 1.00967347]),\n",
       " array([1.0096484 , 1.00968628]),\n",
       " array([1.00966116, 1.00969909]),\n",
       " array([1.00967391, 1.0097119 ]),\n",
       " array([1.00968666, 1.00972471]),\n",
       " array([1.00969941, 1.00973752]),\n",
       " array([1.00971216, 1.00975032]),\n",
       " array([1.0097249 , 1.00976313]),\n",
       " array([1.00973765, 1.00977593]),\n",
       " array([1.0097504 , 1.00978873]),\n",
       " array([1.00976314, 1.00980153]),\n",
       " array([1.00977588, 1.00981433]),\n",
       " array([1.00978863, 1.00982713]),\n",
       " array([1.00980137, 1.00983993]),\n",
       " array([1.00981411, 1.00985273]),\n",
       " array([1.00982684, 1.00986552]),\n",
       " array([1.00983958, 1.00987832]),\n",
       " array([1.00985232, 1.00989111]),\n",
       " array([1.00986505, 1.0099039 ]),\n",
       " array([1.00987779, 1.0099167 ]),\n",
       " array([1.00989052, 1.00992949]),\n",
       " array([1.00990326, 1.00994228]),\n",
       " array([1.00991599, 1.00995507]),\n",
       " array([1.00992872, 1.00996785]),\n",
       " array([1.00994145, 1.00998064]),\n",
       " array([1.00995417, 1.00999343]),\n",
       " array([1.0099669 , 1.01000621]),\n",
       " array([1.00997963, 1.01001899]),\n",
       " array([1.00999235, 1.01003178]),\n",
       " array([1.01000508, 1.01004456]),\n",
       " array([1.0100178 , 1.01005734]),\n",
       " array([1.01003052, 1.01007012]),\n",
       " array([1.01004324, 1.01008289]),\n",
       " array([1.01005596, 1.01009567]),\n",
       " array([1.01006868, 1.01010845]),\n",
       " array([1.0100814 , 1.01012122]),\n",
       " array([1.01009411, 1.010134  ]),\n",
       " array([1.01010683, 1.01014677]),\n",
       " array([1.01011954, 1.01015954]),\n",
       " array([1.01013226, 1.01017231]),\n",
       " array([1.01014497, 1.01018508]),\n",
       " array([1.01015768, 1.01019785]),\n",
       " array([1.01017039, 1.01021062]),\n",
       " array([1.0101831 , 1.01022338]),\n",
       " array([1.01019581, 1.01023615]),\n",
       " array([1.01020851, 1.01024891]),\n",
       " array([1.01022122, 1.01026168]),\n",
       " array([1.01023392, 1.01027444]),\n",
       " array([1.01024663, 1.0102872 ]),\n",
       " array([1.01025933, 1.01029996]),\n",
       " array([1.01027203, 1.01031272]),\n",
       " array([1.01028473, 1.01032548]),\n",
       " array([1.01029743, 1.01033824]),\n",
       " array([1.01031013, 1.01035099]),\n",
       " array([1.01032283, 1.01036375]),\n",
       " array([1.01033552, 1.0103765 ]),\n",
       " array([1.01034822, 1.01038925]),\n",
       " array([1.01036091, 1.01040201]),\n",
       " array([1.0103736 , 1.01041476]),\n",
       " array([1.0103863 , 1.01042751]),\n",
       " array([1.01039899, 1.01044026]),\n",
       " array([1.01041168, 1.010453  ]),\n",
       " array([1.01042437, 1.01046575]),\n",
       " array([1.01043705, 1.0104785 ]),\n",
       " array([1.01044974, 1.01049124]),\n",
       " array([1.01046243, 1.01050398]),\n",
       " array([1.01047511, 1.01051673]),\n",
       " array([1.01048779, 1.01052947]),\n",
       " array([1.01050048, 1.01054221]),\n",
       " array([1.01051316, 1.01055495]),\n",
       " array([1.01052584, 1.01056769]),\n",
       " array([1.01053852, 1.01058042]),\n",
       " array([1.0105512 , 1.01059316]),\n",
       " array([1.01056387, 1.01060589]),\n",
       " array([1.01057655, 1.01061863]),\n",
       " array([1.01058922, 1.01063136]),\n",
       " array([1.0106019 , 1.01064409]),\n",
       " array([1.01061457, 1.01065683]),\n",
       " array([1.01062724, 1.01066956]),\n",
       " array([1.01063991, 1.01068228]),\n",
       " array([1.01065258, 1.01069501]),\n",
       " array([1.01066525, 1.01070774]),\n",
       " array([1.01067792, 1.01072046]),\n",
       " array([1.01069059, 1.01073319]),\n",
       " array([1.01070325, 1.01074591]),\n",
       " array([1.01071592, 1.01075864]),\n",
       " array([1.01072858, 1.01077136]),\n",
       " array([1.01074124, 1.01078408]),\n",
       " array([1.0107539, 1.0107968]),\n",
       " array([1.01076656, 1.01080952]),\n",
       " array([1.01077922, 1.01082223]),\n",
       " array([1.01079188, 1.01083495]),\n",
       " array([1.01080454, 1.01084766]),\n",
       " array([1.01081719, 1.01086038]),\n",
       " array([1.01082985, 1.01087309]),\n",
       " array([1.0108425, 1.0108858]),\n",
       " array([1.01085516, 1.01089852]),\n",
       " array([1.01086781, 1.01091123]),\n",
       " array([1.01088046, 1.01092394]),\n",
       " array([1.01089311, 1.01093664]),\n",
       " array([1.01090576, 1.01094935]),\n",
       " array([1.0109184 , 1.01096206]),\n",
       " array([1.01093105, 1.01097476]),\n",
       " array([1.0109437 , 1.01098747]),\n",
       " array([1.01095634, 1.01100017]),\n",
       " array([1.01096898, 1.01101287]),\n",
       " array([1.01098163, 1.01102557]),\n",
       " array([1.01099427, 1.01103827]),\n",
       " array([1.01100691, 1.01105097]),\n",
       " array([1.01101955, 1.01106367]),\n",
       " array([1.01103218, 1.01107636]),\n",
       " array([1.01104482, 1.01108906]),\n",
       " array([1.01105746, 1.01110175]),\n",
       " array([1.01107009, 1.01111445]),\n",
       " array([1.01108273, 1.01112714]),\n",
       " array([1.01109536, 1.01113983]),\n",
       " array([1.01110799, 1.01115252]),\n",
       " array([1.01112062, 1.01116521]),\n",
       " array([1.01113325, 1.0111779 ]),\n",
       " array([1.01114588, 1.01119059]),\n",
       " array([1.01115851, 1.01120327]),\n",
       " array([1.01117113, 1.01121596]),\n",
       " array([1.01118376, 1.01122864]),\n",
       " array([1.01119638, 1.01124133]),\n",
       " array([1.01120901, 1.01125401]),\n",
       " array([1.01122163, 1.01126669]),\n",
       " array([1.01123425, 1.01127937]),\n",
       " array([1.01124687, 1.01129205]),\n",
       " array([1.01125949, 1.01130473]),\n",
       " array([1.01127211, 1.0113174 ]),\n",
       " array([1.01128473, 1.01133008]),\n",
       " array([1.01129734, 1.01134275]),\n",
       " array([1.01130996, 1.01135543]),\n",
       " array([1.01132257, 1.0113681 ]),\n",
       " array([1.01133518, 1.01138077]),\n",
       " array([1.0113478 , 1.01139344]),\n",
       " array([1.01136041, 1.01140611]),\n",
       " array([1.01137302, 1.01141878]),\n",
       " array([1.01138563, 1.01143145]),\n",
       " array([1.01139823, 1.01144412]),\n",
       " array([1.01141084, 1.01145678]),\n",
       " array([1.01142345, 1.01146945]),\n",
       " array([1.01143605, 1.01148211]),\n",
       " array([1.01144865, 1.01149477]),\n",
       " array([1.01146126, 1.01150743]),\n",
       " array([1.01147386, 1.01152009]),\n",
       " array([1.01148646, 1.01153275]),\n",
       " array([1.01149906, 1.01154541]),\n",
       " array([1.01151166, 1.01155807]),\n",
       " array([1.01152425, 1.01157072]),\n",
       " array([1.01153685, 1.01158338]),\n",
       " array([1.01154944, 1.01159603]),\n",
       " array([1.01156204, 1.01160869]),\n",
       " array([1.01157463, 1.01162134]),\n",
       " array([1.01158722, 1.01163399]),\n",
       " array([1.01159981, 1.01164664]),\n",
       " array([1.0116124 , 1.01165929]),\n",
       " array([1.01162499, 1.01167194]),\n",
       " array([1.01163758, 1.01168458]),\n",
       " array([1.01165017, 1.01169723]),\n",
       " array([1.01166275, 1.01170988]),\n",
       " array([1.01167534, 1.01172252]),\n",
       " array([1.01168792, 1.01173516]),\n",
       " array([1.0117005, 1.0117478]),\n",
       " array([1.01171309, 1.01176045]),\n",
       " array([1.01172567, 1.01177308]),\n",
       " array([1.01173825, 1.01178572]),\n",
       " array([1.01175082, 1.01179836]),\n",
       " array([1.0117634, 1.011811 ]),\n",
       " array([1.01177598, 1.01182363]),\n",
       " array([1.01178855, 1.01183627]),\n",
       " array([1.01180113, 1.0118489 ]),\n",
       " array([1.0118137 , 1.01186153]),\n",
       " array([1.01182627, 1.01187417]),\n",
       " array([1.01183884, 1.0118868 ]),\n",
       " array([1.01185142, 1.01189943]),\n",
       " array([1.01186398, 1.01191205]),\n",
       " array([1.01187655, 1.01192468]),\n",
       " array([1.01188912, 1.01193731]),\n",
       " array([1.01190169, 1.01194993]),\n",
       " array([1.01191425, 1.01196256]),\n",
       " array([1.01192681, 1.01197518]),\n",
       " array([1.01193938, 1.0119878 ]),\n",
       " array([1.01195194, 1.01200043]),\n",
       " array([1.0119645 , 1.01201305]),\n",
       " array([1.01197706, 1.01202567]),\n",
       " array([1.01198962, 1.01203828]),\n",
       " array([1.01200218, 1.0120509 ]),\n",
       " array([1.01201473, 1.01206352]),\n",
       " array([1.01202729, 1.01207613]),\n",
       " array([1.01203984, 1.01208875]),\n",
       " array([1.0120524 , 1.01210136]),\n",
       " array([1.01206495, 1.01211397]),\n",
       " array([1.0120775 , 1.01212658]),\n",
       " array([1.01209005, 1.01213919]),\n",
       " array([1.0121026, 1.0121518]),\n",
       " array([1.01211515, 1.01216441]),\n",
       " array([1.0121277 , 1.01217702]),\n",
       " array([1.01214024, 1.01218962]),\n",
       " array([1.01215279, 1.01220223]),\n",
       " array([1.01216533, 1.01221483]),\n",
       " array([1.01217787, 1.01222743]),\n",
       " array([1.01219042, 1.01224004]),\n",
       " array([1.01220296, 1.01225264]),\n",
       " array([1.0122155 , 1.01226524]),\n",
       " array([1.01222804, 1.01227784]),\n",
       " array([1.01224057, 1.01229043]),\n",
       " array([1.01225311, 1.01230303]),\n",
       " array([1.01226565, 1.01231563]),\n",
       " array([1.01227818, 1.01232822]),\n",
       " array([1.01229072, 1.01234081]),\n",
       " array([1.01230325, 1.01235341]),\n",
       " array([1.01231578, 1.012366  ]),\n",
       " array([1.01232831, 1.01237859]),\n",
       " array([1.01234084, 1.01239118]),\n",
       " array([1.01235337, 1.01240377]),\n",
       " array([1.0123659 , 1.01241636]),\n",
       " array([1.01237842, 1.01242894]),\n",
       " array([1.01239095, 1.01244153]),\n",
       " array([1.01240347, 1.01245411]),\n",
       " array([1.012416 , 1.0124667]),\n",
       " array([1.01242852, 1.01247928]),\n",
       " array([1.01244104, 1.01249186]),\n",
       " array([1.01245356, 1.01250444]),\n",
       " array([1.01246608, 1.01251702]),\n",
       " array([1.0124786, 1.0125296]),\n",
       " array([1.01249112, 1.01254217]),\n",
       " array([1.01250363, 1.01255475]),\n",
       " array([1.01251615, 1.01256733]),\n",
       " array([1.01252866, 1.0125799 ]),\n",
       " array([1.01254118, 1.01259247]),\n",
       " array([1.01255369, 1.01260505]),\n",
       " array([1.0125662 , 1.01261762]),\n",
       " array([1.01257871, 1.01263019]),\n",
       " array([1.01259122, 1.01264276]),\n",
       " array([1.01260373, 1.01265533]),\n",
       " array([1.01261623, 1.01266789]),\n",
       " array([1.01262874, 1.01268046]),\n",
       " array([1.01264125, 1.01269302]),\n",
       " array([1.01265375, 1.01270559]),\n",
       " array([1.01266625, 1.01271815]),\n",
       " array([1.01267875, 1.01273071]),\n",
       " array([1.01269126, 1.01274327]),\n",
       " array([1.01270375, 1.01275583]),\n",
       " array([1.01271625, 1.01276839]),\n",
       " array([1.01272875, 1.01278095]),\n",
       " array([1.01274125, 1.01279351]),\n",
       " array([1.01275374, 1.01280606]),\n",
       " array([1.01276624, 1.01281862]),\n",
       " array([1.01277873, 1.01283117]),\n",
       " array([1.01279122, 1.01284373]),\n",
       " array([1.01280372, 1.01285628]),\n",
       " array([1.01281621, 1.01286883]),\n",
       " array([1.0128287 , 1.01288138]),\n",
       " array([1.01284119, 1.01289393]),\n",
       " array([1.01285367, 1.01290648]),\n",
       " array([1.01286616, 1.01291902]),\n",
       " array([1.01287864, 1.01293157]),\n",
       " array([1.01289113, 1.01294411]),\n",
       " array([1.01290361, 1.01295666]),\n",
       " array([1.01291609, 1.0129692 ]),\n",
       " array([1.01292858, 1.01298174]),\n",
       " array([1.01294106, 1.01299428]),\n",
       " array([1.01295354, 1.01300682]),\n",
       " array([1.01296601, 1.01301936]),\n",
       " array([1.01297849, 1.0130319 ]),\n",
       " array([1.01299097, 1.01304444]),\n",
       " array([1.01300344, 1.01305697]),\n",
       " array([1.01301592, 1.01306951]),\n",
       " ...]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slope_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e67f81bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_history1 = [i[0][0] for i in zip(slope_history)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "07103306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20bb41f0400>]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(slope_history1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6ecc0370",
   "metadata": {},
   "outputs": [],
   "source": [
    "slope_history2 = [i[0][1] for i in zip(slope_history)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "59a2f9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20bb412d5d0>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(slope_history2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f344028",
   "metadata": {},
   "source": [
    "# plot intercept history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "62038922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20bb4428a30>]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(intercept_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c22756",
   "metadata": {},
   "source": [
    "# for 3d plotting - split x_trains 2d array as px1(1d), px2(1d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c220bf26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.158947974537746,\n",
       " 3.0406195931436515,\n",
       " 2.207347460108596,\n",
       " 4.926214200070466,\n",
       " 3.2142491336268706,\n",
       " 4.240244198921534,\n",
       " 2.1475282948598347,\n",
       " 3.835492926939737,\n",
       " 3.100062287663721,\n",
       " 2.405326835083403,\n",
       " 4.4756001184833245,\n",
       " 4.040573443614365,\n",
       " 2.9148348623122273,\n",
       " 3.9288500515935625,\n",
       " 2.710125253756995,\n",
       " 4.607599317608043,\n",
       " 2.0885716735150086,\n",
       " 4.628294059303631,\n",
       " 3.6327601200386486,\n",
       " 4.592820604433478,\n",
       " 4.10429750902722,\n",
       " 4.596102668852486,\n",
       " 2.067276508857999,\n",
       " 2.5634711327051845,\n",
       " 2.399342445659127,\n",
       " 2.5107095219704743,\n",
       " 4.794821553692439,\n",
       " 2.5738033888656293,\n",
       " 4.091296001754115,\n",
       " 4.364026929510049,\n",
       " 3.658847155211838,\n",
       " 2.028805033817128,\n",
       " 3.5907117974472396,\n",
       " 3.3013464732638593,\n",
       " 4.4555536458430645,\n",
       " 4.278815171713985,\n",
       " 4.3442164979103,\n",
       " 3.2400462191834123,\n",
       " 4.030625718941026,\n",
       " 4.426255354838685,\n",
       " 3.2209015645554895,\n",
       " 4.8680026825515395,\n",
       " 3.9185611749671816,\n",
       " 2.7531173818606542,\n",
       " 4.190899043785579,\n",
       " 4.77545965565569,\n",
       " 2.219202033138865,\n",
       " 4.904087341756902,\n",
       " 2.6318986358468495,\n",
       " 4.497478073060264,\n",
       " -6.807188408946653,\n",
       " -6.67077091011482,\n",
       " -2.8643190621594075,\n",
       " -4.827482148833295,\n",
       " -9.933266829810815,\n",
       " -8.553778934349129,\n",
       " -4.767551360879062,\n",
       " -5.565779746568262,\n",
       " -6.217862535371755,\n",
       " -3.8189151104324877,\n",
       " -2.934411886506095,\n",
       " -6.532084773425326,\n",
       " -5.4910884373775755,\n",
       " -8.179563267761779,\n",
       " -5.800924542238857,\n",
       " -6.652004035554699,\n",
       " -4.696602263236798,\n",
       " -2.7940509962835796,\n",
       " -5.452299977715919,\n",
       " -5.5569062653399515,\n",
       " -5.531138258651364,\n",
       " -9.59116576921514,\n",
       " -5.301385285268674,\n",
       " -3.906081538163118,\n",
       " -4.026257337942285,\n",
       " -5.0723406007439165,\n",
       " -5.244885223081761,\n",
       " -9.64552126754407,\n",
       " -7.874698611660507,\n",
       " -6.96135323880024,\n",
       " -5.945881990285536,\n",
       " -7.882511128197814,\n",
       " -2.719674653159771,\n",
       " -4.173627089569289,\n",
       " -9.394803882607327,\n",
       " -8.124866558540269,\n",
       " -6.5810286112247365,\n",
       " -7.20744624565689,\n",
       " -3.816560599966472,\n",
       " -4.959812867237298,\n",
       " -8.3686166011649,\n",
       " -7.481023269543301,\n",
       " -5.889017242349186,\n",
       " -6.678727125197093,\n",
       " -3.199242291529953,\n",
       " -7.989579691354308,\n",
       " -3.1546959074873246,\n",
       " -9.384701108860387,\n",
       " -6.703283268454129,\n",
       " -6.787952214000362]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px1 = [i[0][0] for i in zip(x_train)]\n",
    "px1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "896b4d2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.961282150751345,\n",
       " 3.7541093874294456,\n",
       " 2.92927729031674,\n",
       " 3.2444337179190526,\n",
       " 4.340634305974299,\n",
       " 4.409425672158925,\n",
       " 3.0680644188911,\n",
       " 2.360241551613631,\n",
       " 2.4855644682354767,\n",
       " 3.3571013767386675,\n",
       " 3.6402605312488148,\n",
       " 4.788429227466757,\n",
       " 3.39069096116149,\n",
       " 3.005006058071149,\n",
       " 4.372193852732163,\n",
       " 3.6871566195597,\n",
       " 3.5083103723672213,\n",
       " 3.802767262568047,\n",
       " 2.47944379598926,\n",
       " 4.342763825638654,\n",
       " 2.5145892248806607,\n",
       " 4.506719356494912,\n",
       " 4.521249331903855,\n",
       " 3.361735475537381,\n",
       " 4.363049387155872,\n",
       " 4.091387364312688,\n",
       " 3.312892343291823,\n",
       " 4.3711247302500364,\n",
       " 2.0613105187189547,\n",
       " 3.7920151038593546,\n",
       " 2.634603516635135,\n",
       " 2.817933290127411,\n",
       " 3.2172274565100336,\n",
       " 4.073292748434113,\n",
       " 2.5149206938330573,\n",
       " 3.2996396433391215,\n",
       " 4.664816016859663,\n",
       " 3.1134012302402274,\n",
       " 3.1124457957532234,\n",
       " 4.518797669053069,\n",
       " 2.5713487636119488,\n",
       " 4.019018654092625,\n",
       " 4.751916501631554,\n",
       " 4.820099451251551,\n",
       " 4.0411832842847275,\n",
       " 3.536962808919237,\n",
       " 2.666910763243443,\n",
       " 3.4556269358541503,\n",
       " 4.589102110401365,\n",
       " 3.2755552148571834,\n",
       " -5.171307974129423,\n",
       " -7.62058381259444,\n",
       " -7.175056913297349,\n",
       " -6.060540902093311,\n",
       " -9.900794686274196,\n",
       " -7.982006696570801,\n",
       " -6.5192650616435746,\n",
       " -4.482050351254907,\n",
       " -2.813052610834675,\n",
       " -6.462451531041208,\n",
       " -8.271253943119566,\n",
       " -8.913940443641758,\n",
       " -5.8263282394189355,\n",
       " -6.326440681348352,\n",
       " -8.569069272975007,\n",
       " -8.274283169967251,\n",
       " -7.388235265750378,\n",
       " -9.984645935463334,\n",
       " -6.886541887889755,\n",
       " -7.160017586601461,\n",
       " -8.061586224038802,\n",
       " -2.364332643895458,\n",
       " -9.068355094743648,\n",
       " -6.699652651542941,\n",
       " -6.2030413820666555,\n",
       " -6.086294563345178,\n",
       " -3.199258926331141,\n",
       " -3.208792343611199,\n",
       " -8.773727309442354,\n",
       " -3.9655739420861353,\n",
       " -6.821510869920358,\n",
       " -2.4777361669494793,\n",
       " -4.1135870007204876,\n",
       " -3.2759405094711482,\n",
       " -8.656209908597049,\n",
       " -4.347497478686336,\n",
       " -9.638927374277744,\n",
       " -8.365635207157565,\n",
       " -9.226146232583918,\n",
       " -2.6466878099684275,\n",
       " -8.304371729972933,\n",
       " -2.006937728751513,\n",
       " -5.963683244014999,\n",
       " -4.766182247025237,\n",
       " -2.635345550112593,\n",
       " -3.3950542356300053,\n",
       " -7.412969355580492,\n",
       " -2.3806933527074783,\n",
       " -9.524906427823424,\n",
       " -8.452161183440776]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "px2 = [i[0][1] for i in zip(x_train) ]\n",
    "px2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cd36fb",
   "metadata": {},
   "source": [
    "# 3d ploting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9d7b199f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'y')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.axes(projection = '3d')\n",
    "ax.scatter(px1[:50], px2[:50], y_train[:50], color='red')\n",
    "ax.scatter(px1[50:], px2[50:], y_train[50:], color='green')\n",
    "#ax.plot3D(px1, px2, y_train[:50], 'green')\n",
    "ax.set_xlabel('x1')\n",
    "ax.set_ylabel('x2')\n",
    "ax.set_zlabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b80ef45",
   "metadata": {},
   "source": [
    "# apply pred_prob method for x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9c6664b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.99958690e-01, 9.99876575e-01, 9.98707175e-01, 9.99781269e-01,\n",
       "       9.98472727e-01, 9.99605304e-01, 9.99873933e-01, 9.99902052e-01,\n",
       "       9.99925593e-01, 9.99710582e-01, 9.99762693e-01, 9.99849020e-01,\n",
       "       9.99970110e-01, 9.99830044e-01, 9.99516910e-01, 9.99983607e-01,\n",
       "       9.99788570e-01, 9.99762842e-01, 9.99934035e-01, 9.99298521e-01,\n",
       "       8.18280039e-08, 1.14178028e-06, 9.68542671e-04, 1.01779893e-07,\n",
       "       1.82637512e-07, 5.70415198e-07, 1.36383228e-05, 3.75716228e-07,\n",
       "       2.12019711e-05, 3.42202823e-07, 3.53358198e-07, 5.62257084e-06,\n",
       "       2.18434339e-06, 9.92744702e-06, 1.99035552e-06, 3.32481424e-04,\n",
       "       7.94692807e-08, 1.43925525e-05, 2.40260944e-05, 5.13526611e-05])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred_prob = mlr.pred_porb(x_test)\n",
    "y_test_pred_prob= np.array(y_test_pred_prob)\n",
    "y_test_pred_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92c759f5",
   "metadata": {},
   "source": [
    "# plot y_test_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2ba65a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20bb306bc70>]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34865328",
   "metadata": {},
   "source": [
    "# apply pred method for x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2105468e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred = mlr.pred(x_test)\n",
    "y_test_pred= np.array(y_test_pred)\n",
    "y_test_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596bfe41",
   "metadata": {},
   "source": [
    "# plot y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4e6329f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x20bb41098a0>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(y_test_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e46c5c",
   "metadata": {},
   "source": [
    "# 3d plot - plane plotting using x_test1 and x_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8972887d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [7.00, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "x_grid, y_grid = np.meshgrid(x_test1, x_test2)\n",
    "plane = (slope[0]*x_grid) + (slope[1]*y_grid) + intercept\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter(px1[:50], px2[:50], y_train[:50], color='red')\n",
    "ax.scatter(px1[50:], px2[50:], y_train[50:], color='green')\n",
    "ax.plot_surface(x_grid, y_grid, plane)\n",
    "ax.set_xlabel('$X1$', fontsize=20)\n",
    "\n",
    "# disable auto rotation\n",
    "ax.zaxis.set_rotate_label(False) \n",
    "ax.set_ylabel('$X2$', fontsize=20)\n",
    "ax.set_zlabel('$y$', fontsize=60, rotation = 0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc25ee2b",
   "metadata": {},
   "source": [
    "# Another test - using np.arange method way of x1_test and x2_test data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "27580087",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1200"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1_test = np.arange(-10, 2, 0.01)\n",
    "len(x1_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "97edf200",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1197,)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_test = np.arange(-2, 5, 0.00585)\n",
    "x2_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6c29e054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200,)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2_test = np.array(x2_test.tolist()+[4.9966]*3)\n",
    "x2_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523f7276",
   "metadata": {},
   "source": [
    "# calculate plane using new slope1, slope2 and intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "eff86f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200,)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plane = (slope[0]*x1_test) + (slope[1]*x2_test) + intercept\n",
    "plane.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964d038a",
   "metadata": {},
   "source": [
    "# 3d plot - plane plotting using x1_test and x2_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1a177cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [7.00, 3.50]\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "\n",
    "x_grid, y_grid = np.meshgrid(x1_test, x2_test)\n",
    "plane = (slope[0]*x_grid) + (slope[1]*y_grid) + intercept\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "ax.scatter(px1[:50], px2[:50], y_train[:50], color='red')\n",
    "ax.scatter(px1[50:], px2[50:], y_train[50:], color='green')\n",
    "ax.plot_surface(x_grid, y_grid, plane)\n",
    "ax.set_xlabel('$X1$', fontsize=20)\n",
    "\n",
    "# disable auto rotation\n",
    "ax.zaxis.set_rotate_label(False) \n",
    "ax.set_ylabel('$X2$', fontsize=20)\n",
    "ax.set_zlabel('$y$', fontsize=60, rotation = 0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3db5aa",
   "metadata": {},
   "source": [
    "# thank you!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca536704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
